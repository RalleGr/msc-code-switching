<doc id="22018" url="https://en.wikipedia.org/wiki?curid=22018" title="Nashville, Tennessee">
Nashville, Tennessee

Nashville is the capital and most populous city of the U.S. state of Tennessee. The city is the county seat of Davidson County and is located on the Cumberland River. It is the 23rd most-populous city in the United States.

Named for Francis Nash, a general of the Continental Army during the American Revolutionary War, the city was founded in 1779. The city grew quickly due to its strategic location as a port on the Cumberland River and, in the 19th century, a railroad center. Nashville seceded with Tennessee during the American Civil War; in 1862 it was the first state capital in the Confederacy to fall to Union troops. After the war, the city reclaimed its position and developed a manufacturing base.

Since 1963, Nashville has had a consolidated city-county government, which includes six smaller municipalities in a two-tier system. The city is governed by a mayor, a vice-mayor, and a 40-member metropolitan council; 35 of the members are elected from single-member districts, while the other five are elected at-large. Reflecting the city's position in state government, Nashville is home to the Tennessee Supreme Court's courthouse for Middle Tennessee, one of the state's three divisions.

A major center for the music industry, especially country music, Nashville is commonly known as "Music City". It is also home to numerous colleges and universities, including Tennessee State University, Vanderbilt University, Belmont University, Fisk University, Trevecca Nazarene University, and Lipscomb University, and is sometimes referred to as "Athens of the South" due to the large number of educational institutions. Nashville is also a major center for the healthcare, publishing, private prison, banking, automotive, and transportation industries. Entities with headquarters in the city include Asurion, Bridgestone Americas, Captain D's, CoreCivic, Dollar General, Hospital Corporation of America, LifeWay Christian Resources, Logan's Roadhouse, and Ryman Hospitality Properties.

The town of Nashville was founded by James Robertson, John Donelson, and a party of Overmountain Men in 1779, near the original Cumberland settlement of Fort Nashborough. It was named for Francis Nash, the American Revolutionary War hero. Nashville quickly grew because of its strategic location as a port on the Cumberland River, a tributary of the Ohio River; and its later status as a major railroad center. By 1800, the city had 345 residents, including 136 enslaved African Americans and 14 free African Americans. In 1806, Nashville was incorporated as a city and became the county seat of Davidson County, Tennessee. In 1843, the city was named as the permanent capital of the state of Tennessee.

The city government of Nashville owned 24 slaves by 1831, and 60 prior to the Civil War. They were "put to work to build the first successful water system and maintain the streets." Auction blocks and brokers' offices were part of the slave market at the heart of the city. It was the center of plantations cultivating tobacco and hemp as commodity crops, in addition to the breeding and training of thoroughbred horses, and other livestock. For years Nashville was considered one of the wealthiest southern capitals and a large portion of its prominence was from the iron business. Nashville led the south for iron production.

The cholera epidemic that struck Nashville in 1849–1850 took the life of former U.S. President James K. Polk and resulted in high fatalities. There were 311 deaths from cholera in 1849 and an estimated 316 to about 500 in 1850.

Before the Civil War, about 700 free Blacks lived in small enclaves in northern Nashville while there were over 3,200 Black slaves in the city. By 1860, when the first rumblings of secession began to be heard across the South, antebellum Nashville was a prosperous city. The city's significance as a shipping port and rail center made it a desirable prize for competing military forces that wanted to control the region's important river and railroad transportation routes. In February 1862, Nashville became the first Confederate state capital to fall to Union troops, and the state was occupied by Union troops for the duration of the war. Then African-Americans from Middle Tennessee fled to contraband camps around military installations in Nashville's eastern, western, and southern borders. The Battle of Nashville (December 15–16, 1864) was a significant Union victory and perhaps the most decisive tactical victory gained by either side in the war; it was also the war's final major military action in which Tennessee regiments played a large part on both sides of the battle. Afterward, the Confederates conducted a war of attrition, making guerrilla raids and engaging in small skirmishes, with the Confederate forces in the Deep South almost constantly in retreat.

In 1868, three years after the end of the Civil War, the Nashville chapter of the Ku Klux Klan was founded by Confederate veteran John W. Morton. He was reported to have initiated General Nathan Bedford Forrest into the vigilante organization. Chapters of this secret insurgent group formed throughout the state and the South; they opposed voting and political organizing by freedmen, tried to control their behavior, and sometimes also attacked their White allies, including schoolteachers from the North.

Whites directed violence against freedmen and their descendants both during and after the Reconstruction era. Two freedmen, David Jones and Jo Reed, were lynched in Nashville by White mobs in 1872 and 1875, respectively. Reed was hanged from a bridge over the river, but survived after the rope broke and he subsequently fell into the water, and fled the city soon thereafter.

In 1873 Nashville suffered another cholera epidemic, along with towns throughout Sumner County along railroad routes and the Cumberland River. This was part of a larger epidemic that struck much of the United States. The epidemic is estimated to have killed around 1,000 people in Nashville.
Meanwhile, the city had reclaimed its important shipping and trading position and developed a solid manufacturing base. The post–Civil War years of the late 19th century brought new prosperity to Nashville and Davidson County. Wealthy planters and businessmen built grand, classical-style buildings. A replica of the Parthenon was constructed in Centennial Park, near downtown.

On April 30, 1892, Ephraim Grizzard, an African-American man, was lynched in a spectacle murder in front of a White mob of 10,000 in Nashville. His lynching was described by journalist Ida B. Wells as: "A naked, bloody example of the blood-thirstiness of the nineteenth century civilization of the Athens of the South." His brother, Henry Grizzard, had been lynched and hanged on April 24, 1892, in nearby Goodlettsville as a suspect in the same assault incident. From 1877 to 1950, a total of six lynchings of Blacks were conducted in Davidson County, four before the turn of the century.

By the turn of the century, Nashville had become the cradle of the Lost Cause of the Confederacy. The first chapter of the United Daughters of the Confederacy was founded here, and the "Confederate Veteran" magazine was published here. Most "guardians of the Lost Cause" lived Downtown or in the West End, near Centennial Park.

At the same time, Jefferson Street became the historic center of the African-American community, with similar districts developing in the Black neighborhoods in East and North Nashville. In 1912, the Tennessee Agricultural and Industrial and Normal School as moved to Jefferson Street. The first Prince's Hot Chicken Shack originated at the corner of Jefferson Street and 28th Avenue in 1945. Jefferson Street became a destination for jazz and blues musicians, and remained so until the federal government split the area by construction of Interstate 40 in the late 1960s.

In 1950 the state legislature approved a new city charter that provided for the election of city council members from single-member districts, rather than at-large voting. This change was supported because at-large voting required candidates to gain a majority of votes from across the city. The previous system prevented the minority population, which then tended to support Republican candidates, from being represented by candidates of their choice; apportionment under single-member districts meant that some districts in Nashville had Black majorities. In 1951, after passage of the new charter, African-American attorneys Z. Alexander Looby and Robert E. Lillard were elected to the city council.

With the United States Supreme Court ruling in 1954 that public schools had to desegregate with "all deliberate speed", the family of student Robert Kelley filed a lawsuit in 1956, arguing that Nashville administrators should open all-White East High School to him. A similar case was filed by Reverend Henry Maxwell due to his children having to take a 45-minute bus ride from South Nashville to the north end of the city. These suits caused the courts to announce what became known as the "Nashville Plan", where the city's public schools would desegregate one grade per year beginning in the fall of 1957.

Urban redevelopment accelerated over the next several decades, and the city grew increasingly segregated. An interstate was placed on the edge of East Nashville while another highway was built through Edgehill, a lower-income, predominantly minority community.

Rapid suburbanization occurred during the years immediately after World War II, as new housing was being built outside city limits. This resulted in a demand for many new schools and other support facilities, which the county found difficult to provide. At the same time, suburbanization led to a declining tax base in the city, although many suburban residents used unique city amenities and services that were supported financially only by city taxpayers. After years of discussion, a referendum was held in 1958 on the issue of consolidating city and county government. It failed to gain approval although it was supported by the then-elected leaders of both jurisdictions, County Judge Beverly Briley and Mayor Ben West.

Following the referendum's failure, Nashville annexed some 42 square miles of suburban jurisdictions to expand its tax base. This increased uncertainty among residents, and created resentment among many suburban communities. Under the second charter for metropolitan government, which was approved in 1962, two levels of service provision were proposed: the General Services District and the Urban Services District, to provide for a differential in tax levels. Residents of the Urban Services District had a full range of city services. The areas that made up the General Services District, however, had a lower tax rate until full services were provided. This helped reconcile aspects of services and taxation among the differing jurisdictions within the large metro region.

In the early 1960s, Tennessee still had racial segregation of public facilities, including lunch counters and department store fitting rooms. Hotels and restaurants were also segregated. Between February 13 and May 10, 1960, a series of sit-ins were organized at lunch counters in downtown Nashville by the Nashville Student Movement and Nashville Christian Leadership Council, and were part of a broader sit-in movement in the southeastern United States as part of an effort to end racial segregation of public facilities. On April 19, 1960, the house of Z. Alexander Looby, an African-American attorney and council member, was bombed by segregationists. Protesters marched to the city hall the next day. Mayor Ben West said he supported the desegregation of lunch counters, which civil rights activists had called for.

In 1963, Nashville consolidated its government with Davidson County, forming a metropolitan government. The membership on the Metro Council, the legislative body, was increased from 21 to 40 seats. Of these, five members are elected at-large and 35 are elected from single-member districts, each to serve a term of four years. In 1957 Nashville desegregated its school system using an innovative grade a year plan, in response to a class action suit Kelly vs. Board of Education of Nashville. By 1966 the Metro Council abandoned the grade a year plan and completely desegregated the entire school system at one time.

Congress passed civil rights legislation in 1964 and 1965, but tensions continued as society was slow to change. On April 8, 1967, a riot broke out on the college campuses of Fisk University and Tennessee State University, historically Black colleges, after Stokely Carmichael spoke about Black Power at Vanderbilt University. Although it was viewed as a "race riot", it had classist characteristics.

In 1979, the Ku Klux Klan burnt crosses outside two African-American sites in Nashville, including the city headquarters of the NAACP.

Since the 1970s the city and county have undergone tremendous growth, particularly during the economic boom of the 1990s under the leadership of then-Mayor and later-Tennessee Governor, Phil Bredesen. Making urban renewal a priority, Bredesen fostered the construction or renovation of several city landmarks, including the Country Music Hall of Fame and Museum, the downtown Nashville Public Library, the Bridgestone Arena, and Nissan Stadium.

Nissan Stadium (formerly Adelphia Coliseum and LP Field) was built after the National Football League's (NFL) Houston Oilers agreed to move to the city in 1995. The NFL team debuted in Nashville in 1998 at Vanderbilt Stadium, and Nissan Stadium opened in the summer of 1999. The Oilers changed their name to the Tennessee Titans and finished the season with the Music City Miracle and a close Super Bowl game. The St. Louis Rams won in the last play of the game.

In 1997, Nashville was awarded a National Hockey League expansion team; this was named the Nashville Predators. Since the 2003–04 season, the Predators have made the playoffs in all but three seasons. In 2017, they made the Stanley Cup Finals for the first time in franchise history, but ultimately fell to the Pittsburgh Penguins, 4games to 2, in the best-of-seven series.

On January 22, 2009, residents rejected Nashville Charter Amendment 1, which sought to make English the official language of the city.

Between May 1 and 7, 2010, much of Nashville was extensively flooded as part of a series of 1,000 year floods throughout Middle and West Tennessee. Much of the flooding took place in areas along the Cumberland and Harpeth Rivers and Mill Creek, and caused extensive damage to the many buildings and structures in the city, including the Grand Ole Opry House, Gaylord Opryland Resort & Convention Center, Opry Mills Mall, Schermerhorn Symphony Center, Bridgestone Arena, and Nissan Stadium. Sections of Interstate 24 and Briley Parkway were also flooded. Eleven people died in the Nashville area as a result of the flooding, and damages were estimated to be over $2 billion.

The city bounced back after the Great Recession. In March 2012, a Gallup poll ranked Nashville in the top five regions for job growth. In 2013, Nashville was described as "Nowville" and "It City" by "GQ", "Forbes", and "The New York Times".

Nashville elected its first female mayor, Megan Barry, on September 25, 2015. As a council member, Barry had officiated at the city's first same-sex wedding on June 26, 2015.

In 2017, Nashville's economy was deemed the third fastest-growing in the nation, and the city was named the "hottest housing market in the US" by Freddie Mac realtors. In May 2017, census estimates showed Nashville had passed Memphis to become most populated city in Tennessee. Nashville has also made national headlines for its "homelessness crisis". Rising housing prices and the opioid crisis have resulted in more people being out on the streets: , between 2,300 and 20,000 Nashvillians are homeless.

On March 6, 2018, due to felony charges filed against Mayor Barry relating to the misuse of public funds, she resigned before the end of her term. A special election was called. Following a ruling by the Tennessee Supreme Court, the Davidson County Election Commission set the special election for May 24, 2018, to meet the requirement of 75 to 80 days from the date of resignation. David Briley, who was Vice Mayor during the Barry administration and Acting Mayor after her resignation, won the special election with just over 54% of the vote, becoming the 70th mayor of Nashville.

On May 1, 2018, voters rejected Let's Move Nashville, a referendum which would have funded construction of an $8.9 billion mass transit system under the Nashville Metropolitan Transit Authority, by a 2 to 1 margin.

On March 3, 2020, a tornado tracked west to east, just north of the downtown Nashville area, killing at least 25 people and leaving tens of thousands without electricity. Neighborhoods impacted included North Nashville, Germantown, East Nashville, Donelson, and Hermitage.

Nashville lies on the Cumberland River in the northwestern portion of the Nashville Basin. Nashville's elevation ranges from its lowest point, above sea level at the Cumberland River, to its highest point, above sea level in the Radnor Lake State Natural Area. Nashville also sits at the start of the Highland Rim, a Geophysical region of very hilly area. Because of this Nashville is very hilly. Nashville also has some stand alone hills around the city such as the hill on which the Tennessee State Capitol building sits. According to the United States Census Bureau, the city has a total area of , of which of it is land and of it (4.53%) is water.

Nashville's downtown area features a diverse assortment of entertainment, dining, cultural and architectural attractions. The Broadway and 2nd Avenue areas feature entertainment venues, night clubs and an assortment of restaurants. North of Broadway lie Nashville's central business district, Legislative Plaza, Capitol Hill and the Tennessee Bicentennial Mall. Cultural and architectural attractions can be found throughout the city.

Three major interstate highways (I-40, I-65 and I-24) converge near the core area of downtown, and many regional cities are within a day's driving distance.

Nashville's first skyscraper, the Life & Casualty Tower, was completed in 1957 and launched the construction of other high rises in downtown Nashville. After the construction of the AT&T Building (commonly referred to by locals as the "Batman Building") in 1994, the downtown area saw little construction until the mid-2000s. The Pinnacle, a high rise office building, opened in 2010, the first Nashville skyscraper completed in more than 15 years. Ten more skyscrapers have since been constructed or are under construction.

Many civic and infrastructure projects are being planned, in progress, or recently completed. A new MTA bus hub was recently completed in downtown Nashville, as was the Music City Star pilot project. Several public parks have been constructed, such as the Public Square. Riverfront Park is scheduled to be extensively updated. The Music City Center opened in May 2013. It is a 1,200,000 square foot (110,000 m2) convention center with 370,000 square feet (34,000 m2) of exhibit space.
The nearby city of Lebanon is notable and even named for its so-called "cedar glades", which occur on soils too poor to support most trees and are instead dominated by Virginian juniper. Blackberry bushes, Virginia pine, loblolly pine, sassafras, red maple, river birch, American beech, river cane, mountain laurel and sycamore are all common native trees, along with many others.

In addition to the native forests, the combination of hot summers, abundant rainfall and mild winters permit a wide variety of both temperate and subtropical plants to be cultivated easily. Southern magnolia and cherry blossom trees are commonly cultivated here, with the city having an annual cherry blossom festival. Crepe myrtles and yew bushes are also commonly grown throughout Metro Nashville, and the winters are mild enough that sweetbay magnolia is evergreen whenever it is cultivated. The pansy flower is popular to plant during the autumn, and some varieties will flower overwinter in Nashville's subtropical climate. However, many hot-weather plants like petunia and even papyrus thrive as annuals, and Japanese banana will die aboveground during winter but re-sprout after the danger of frost is over. Unbeknownst to most Tennesseans, even cold-hardy palms, particularly needle palm and dwarf palmetto, are grown uncommonly but often successfully. High desert plants like Colorado spruce and prickly pear cactus are also grown somewhat commonly, as are "Yucca filamentosa".

Nashville has a humid subtropical climate (Köppen "Cfa", Trewartha "Cf"), with hot, humid summers and generally cool winters typical of the Upper South. Monthly averages range from in January to in July, with a diurnal temperature variation of .

Snowfall occurs during the winter months, but it is usually not heavy. Average annual snowfall is about , falling mostly in January and February and occasionally in March and December. The largest snow event since 2003 was on January 22, 2016, when Nashville received of snow in a single storm; the largest overall was , received on March 17, 1892, during the St. Patrick's Day Snowstorm.

Rainfall is typically greater in November and December, and spring, while August to October are the driest months on average. Spring and fall are prone to severe thunderstorms, which may bring tornadoes, large hail, and damaging wind, with recent major events on April 16, 1998; April 7, 2006; February 5, 2008; April 10, 2009; May 1–2, 2010; and March 3, 2020. Relative humidity in Nashville averages 83% in the mornings and 60% in the afternoons, which is considered moderate for the Southeastern United States. In recent decades, due to urban development, Nashville has developed an urban heat island; especially on cool, clear nights, temperatures are up to warmer in the heart of the city than in rural outlying areas. The Nashville region lies within USDA Plant Hardiness Zone 7a.

Nashville's long springs and autumns combined with a diverse array of trees and grasses can often make it uncomfortable for allergy sufferers. In 2008, Nashville was ranked as the 18th-worst spring allergy city in the U.S. by the Asthma and Allergy Foundation of America.

The coldest temperature ever recorded in Nashville was on January 21, 1985, and the highest was on June 29, 2012.

According to the 2016 American Community Survey, there were 667,885 people living in the city; in 2019 it rose to an estimated 670,820. The population density was . There were 294,794 housing units at an average density of .

At the 2010 census, the racial makeup of the city was 65.5% White (58.6% non-Hispanic White), 28.6% African American, 0.8% American Indian and Alaska Native, 3.5% Asian, 0.1% Native Hawaiian and Other Pacific Islander, and 1.4% from two or more races. 9.0% of the total population was of Hispanic or Latino origin (they may be of any race). The non-Hispanic White population was 79.5% in 1970.

There were 254,651 households and 141,469 families (55.6% of households). Of households with families, 37.2% had married couples living together, 14.1% had a female householder with no husband present, and 4.2% had a male householder with no wife present. 27.9% of all households had children under the age of 18, and 18.8% had at least one member 65 years of age or older. Of the 44.4% of households that are non-families, 36.2% were individuals, and 8.2% had someone living alone who was 65 years of age or older. The average household size was 2.38 and the average family size was 3.16.

The age distribution was 22.2% under 18, 10.3% from 18 to 24, 32.8% from 25 to 44, 23.9% from 45 to 64, and 10.7% who were 65 or older. The median age was 34.2 years. For every 100 females, there were 94.1 males. For every 100 females age 18 and over, there were 91.7 males.

The median income for a household in the city was $46,141, and the median income for a family was $56,377. Males with a year-round, full-time job had a median income of $41,017 versus $36,292 for females. The per capita income for the city was $27,372. About 13.9% of families and 18.2% of the population were below the poverty line, including 29.5% of those under age 18 and 9.9% of those age 65 or over. Of residents 25 or older, 33.4% have a bachelor's degree or higher.

Because of its relatively low cost of living and large job market, Nashville has become a popular city for immigrants. Nashville's foreign-born population more than tripled in size between 1990 and 2000, increasing from 12,662 to 39,596. The city's largest immigrant groups include Mexicans, Kurds, Vietnamese, Laotians, Arabs, and Somalis. There are also smaller communities of Pashtuns from Afghanistan and Pakistan concentrated primarily in Antioch. Nashville has the largest Kurdish community in the United States, numbering approximately 15,000. In 2009, about 60,000 Bhutanese refugees were being admitted to the U.S., and some were expected to resettle in Nashville. During the Iraqi election of 2005, Nashville was one of the few international locations where Iraqi expatriates could vote. The American Jewish community in Nashville dates back over 150 years, and numbered about 8,000 in 2015, plus 2,000 Jewish college students.

, Nashville has the largest metropolitan area in the state of Tennessee, with an estimated population of 1,959,495. The Nashville metropolitan area encompasses 14 of 41 Middle Tennessee counties: Cannon, Cheatham, Davidson, Dickson, Hickman, Macon, Maury, Robertson, Rutherford, Smith, Sumner, Trousdale, Williamson, and Wilson. The 2019 population of the Nashville-Davidson–Murfreesboro–Columbia combined statistical area was estimated at 2,087,725.

59.6% of people in Nashville claim religious affiliation according to information compiled by Sperling's BestPlaces. The dominant religion in Nashville is Christianity, comprising 57.7% of the population. The Christian population is broken down into 20.6% Baptists, 6.2% Catholics, 5.6% Methodists, 3.4% Pentecostals, 3.4% Presbyterians, 0.8% Mormons, and 0.5% Lutherans. 15.7% identify with other forms of Christianity, including the Orthodox Church and Disciples of Christ. Islam is the second largest religion, comprising 0.8% of the population. 0.6% of the population adhere to eastern religions such as Buddhism, Sikhism, Jainism and Hinduism, and 0.3% follow Judaism.

As the "home of country music", Nashville has become a major music recording and production center. The Big Three record labels, as well as numerous independent labels, have offices in Nashville, mostly in the Music Row area. Nashville has been the headquarters of guitar company Gibson since 1984. Since the 1960s, Nashville has been the second-largest music production center (after New York City) in the United States. Nashville's music industry is estimated to have a total economic impact of about $10billion per year and to contribute approximately 56,000 jobs to the Nashville area.

In recent times Nashville has been described as a "southern boomtown" by numerous publications, with it having the third fastest growing economy in the United States as of 2017. It has been stated by the US Census bureau that Nashville "adds an average of 100 people a day to its net population increase". The Nashville region was also stated to be the "Number One" Metro Area for Professional and Business Service Jobs in America, as well as having the "hottest Housing market in America" as stated by Zillow.

Although Nashville is renowned as a music recording center and tourist destination, its largest industry is health care. Nashville is home to more than 300 health care companies, including Hospital Corporation of America (HCA), the world's largest private operator of hospitals. , it is estimated the health care industry contributes per year and 200,000 jobs to the Nashville-area economy.

CoreCivic, formerly known as Corrections Corporation of America and one of the largest private corrections company in the United States, was founded in Nashville in 1983. Vanderbilt University was one of its investors prior to the company's initial public offering. The City of Nashville's pension fund includes "a $921,000 stake" in the company as of 2017. The "Nashville Scene" notes that, "A drop in CoreCivic stock value, however minor, would have a direct impact on the pension fund that represents nearly 25,000 current and former Metro employees."

The automotive industry is also becoming important for the Middle Tennessee region. Nissan North America moved its corporate headquarters in 2006 from Gardena, California (Los Angeles County) to Franklin, a suburb south of Nashville. Nissan also has its largest North American manufacturing plant in Smyrna, another suburb of Nashville. Largely as a result of the increased development of Nissan and other Japanese economic interests in the region, Japan moved its former New Orleans consulate-general to Nashville's Palmer Plaza. General Motors also operates an assembly plant in Spring Hill, about south of Nashville.

Bridgestone has a strong presence with their North American headquarters located in Nashville, with manufacturing plants and a distribution center in nearby counties.

Other major industries in Nashville include insurance, finance, and publishing (especially religious publishing). The city hosts headquarters operations for several Protestant denominations, including the United Methodist Church, Southern Baptist Convention, National Baptist Convention USA, and the National Association of Free Will Baptists.

Nashville is also known for some of their famously popular Southern confections, including Goo Goo Clusters (which have been made in Nashville since 1912).

Fortune 500 companies with offices within Nashville include BNY Mellon, Bridgestone Americas, Ernst & Young, Community Health Systems, Dell, Deloitte, Dollar General, Hospital Corporation of America, Nissan North America, Philips, Tractor Supply Company, and UBS. Of these, Community Health Systems, Dollar General, Hospital Corporation of America, and Tractor Supply Company are headquartered in the city.

In 2013, the city ranked No. 5 on "Forbes" list of the Best Places for Business and Careers. In 2015, Forbes put Nashville as the 4th Best City for White Collar Jobs.

In 2015, Business Facilities' 11th Annual Rankings report named Nashville the number one city for Economic Growth Potential.

In May 2018, AllianceBernstein pledged to build a private client office in the city by mid-2019 and to move its headquarters from New York City to Nashville by 2024. Additionally, in November 2018, Amazon announced its plans to build an operations center in the Nashville Yards development to serve as the hub for their Retail Operations division.

In December 2019, iHeartMedia selected Nashville as the site of its second digital headquarters.

Real estate is becoming a driver for the city's economy. Based on a survey of nearly 1,500 real estate industry professionals conducted by PricewaterhouseCoopers and the Urban Land Institute, Nashville ranked 7th nationally in terms of attractiveness to real estate investors for 2016. , according to city figures, there is more than $2 billion in real estate projects underway or projected to start in 2016. Due to high yields available to investors, Nashville has been attracting a lot of capital from out-of-state. A key factor that has been attributed to the increase in investment is the adjustment to the city's zoning code. Developers can easily include a combination of residential, office, retail and entertainment space into their projects. Additionally, the city has invested heavily into public parks. Centennial Park is undergoing extensive renovations. The change in the zoning code and the investment in public space is consistent with the millennial generation's preference for walkable urban neighborhoods.

According to the city's 2016 Comprehensive Annual Financial Report, the top employers in the city are:

Much of the city's cultural life has revolved around its large university community. Particularly significant in this respect were two groups of critics and writers who were associated with Vanderbilt University in the early 20th century: the Fugitives and the Agrarians.

Popular destinations include Fort Nashborough and Fort Negley, the former being a reconstruction of the original settlement, the latter being a semi-restored Civil War battle fort; the Tennessee State Museum; and The Parthenon, a full-scale replica of the original Parthenon in Athens. The Tennessee State Capitol is one of the oldest working state capitol buildings in the nation. The Hermitage, the former home of President Andrew Jackson, is one of the largest presidential homes open to the public, and is also one of the most visited.

Some of the more popular types of local cuisine include hot chicken, hot fish, barbecue, and meat and three.

Nashville has a vibrant music and entertainment scene spanning a variety of genres. With a long history in the music scene it is no surprise that city was nicknamed 'Music City.' The Tennessee Performing Arts Center is the major performing arts center of the city. It is the home of the Nashville Repertory Theatre, the Nashville Opera, the Music City Drum and Bugle Corps, and the Nashville Ballet. In September 2006, the Schermerhorn Symphony Center opened as the home of the Nashville Symphony.

As the city's name itself is a metonym for the country music industry, many popular attractions involve country music, including the Country Music Hall of Fame and Museum, Belcourt Theatre, and Ryman Auditorium. Hence, the city became known as America's 'Country Music Capital.' The Ryman was home to the "Grand Ole Opry" until 1974 when the show moved to the Grand Ole Opry House, east of downtown. The Opry plays there several times a week, except for an annual winter run at the Ryman.
Many music clubs and honky-tonk bars are in downtown Nashville, particularly the area encompassing Lower Broadway, Second Avenue, and Printer's Alley, which is often referred to as "the District".

Each June, the CMA Music Festival (formerly known as Fan Fair) brings thousands of country fans to the city. The Tennessee State Fair is also held annually in September.

Nashville was once home of television shows such as "Hee Haw" and "Pop! Goes the Country", as well as The Nashville Network and later, RFD-TV. Country Music Television and Great American Country currently operate from Nashville. The city was also home to the Opryland USA theme park, which operated from 1972 to 1997 before being closed by its owners (Gaylord Entertainment Company) and soon after demolished to make room for the Opry Mills mega-shopping mall.

The Contemporary Christian music industry is based along Nashville's Music Row, with a great influence in neighboring Williamson County. The Christian record companies include EMI Christian Music Group, Provident Label Group and Word Records.

Music Row houses many gospel music and Contemporary Christian music companies centered around 16th and 17th Avenues South. On River Road, off Charlotte Pike in West Nashville, the "CabaRay" opened its doors on January 18, 2018. The performing venue of Ray Stevens it offers a Vegas-style dinner and a show atmosphere. There is also a piano bar and a gift shop.

Although Nashville was never known as a major jazz town, it did have many great jazz bands, including The Nashville Jazz Machine led by Dave Converse and its current version, the Nashville Jazz Orchestra, led by Jim Williamson, as well as The Establishment, led by Billy Adair. The Francis Craig Orchestra entertained Nashvillians from 1929 to 1945 from the Oak Bar and Grille Room in the Hermitage Hotel. Craig's orchestra was also the first to broadcast over local radio station WSM-AM and enjoyed phenomenal success with a 12-year show on the NBC Radio Network. In the late 1930s, he introduced a newcomer, Dinah Shore, a local graduate of Hume Fogg High School and Vanderbilt University.

Radio station WMOT-FM in nearby Murfreesboro, which formerly programmed jazz almost exclusively and still does so on the weekends, aided significantly in the recent revival of the city's jazz scene, as has the non-profit Nashville Jazz Workshop, which holds concerts and classes in a renovated building in the north Nashville neighborhood of Germantown. Fisk University also maintains a jazz station, WFSK.

Nashville has an active theatre scene and is home to several professional and community theatre companies. Nashville Children's Theatre, Nashville Repertory Theatre, the Nashville Shakespeare Festival, the Dance Theatre of Tennessee and the Tennessee Women's Theater Project are among the most prominent professional companies. One community theatre, Circle Players, has been in operation for over 60 years.

The Barbershop Harmony Society has its headquarters in Nashville.

Perhaps the biggest factor in drawing visitors to Nashville is its association with country music, in which the Nashville sound played a role. Many visitors to Nashville attend live performances of the Grand Ole Opry, the world's longest-running live radio show. The Country Music Hall of Fame and Museum is another major attraction relating to the popularity of country music. The Gaylord Opryland Resort & Convention Center, the Opry Mills regional shopping mall and the "General Jackson" showboat, are all located in what is known as Music Valley.

Civil War history is important to the city's tourism industry. Sites pertaining to the Battle of Nashville and the nearby Battle of Franklin and Battle of Stones River can be seen, along with several well-preserved antebellum plantation houses such as Belle Meade Plantation, Carnton plantation in Franklin, and Belmont Mansion.

Nashville has many arts centers and museums, including the Frist Center for the Visual Arts, Cheekwood Botanical Garden and Museum of Art, the Tennessee State Museum, the Johnny Cash Museum, Fisk University's Van Vechten and Aaron Douglas Galleries, Vanderbilt University's Fine Art Gallery and Sarratt Gallery, the National Museum of African American Music, and the full-scale replica of the Parthenon.

Nashville has become an increasingly popular destination for bachelor and bachelorette parties. In 2017 "Nashville Scene" counted 33 bachelorette parties on Lower Broadway ("from Fifth Avenue down to the Cumberland River, it's their town") in less than two hours on a Friday night, and stated that the actual number was likely higher. Downtown, the newspaper wrote, "offers five blocks of bars with live music and no cover". In 2018, "The New York Times" called Nashville "the hottest destination for bachelorette parties in the country" because of the honky-tonk bars' live music. City boosters welcome the bachelorette parties because temporary visitors may become permanent; "BuzzFeed" wrote, "These women are at precisely the point in their lives when a move to Nashville is possible". The CMT reality television series "Bachelorette Weekend" follows the employees at Bach Weekend, a Nashville company that designs and throws bachelor and bachelorette parties.

Nashville is a colorful, well-known city in several different arenas. As such, it has earned various sobriquets, including:

Nashville has additionally earned the moniker "The Hot Chicken Capital", becoming known for the local specialty cuisine hot chicken. The Music City Hot Chicken Festival is hosted annually in Nashville and several restaurants make this spicy version of southern fried chicken.

Nashville is home to four professional sports franchises. Three play at the highest professional level of their respective sports: the Tennessee Titans of the National Football League, the Nashville Predators of the National Hockey League, and Nashville SC of Major League Soccer. The city is also home to one minor league team: the Nashville Sounds of Minor League Baseball's Pacific Coast League. An investment group, Music City Baseball LLC, seeks to secure a Major League Baseball expansion franchise or lure an existing team to the city.

The Tennessee Titans moved to Nashville in 1998. Previously known as the Houston Oilers, which began play in 1960 in Houston, Texas, the team relocated to Tennessee in 1997. They played at the Liberty Bowl Memorial Stadium in Memphis for one season, then moved to Nashville in 1998 and played in Vanderbilt Stadium for one season. During those two years, the team was known as the Tennessee Oilers, but changed its name to Titans in 1999. The team now plays at Nissan Stadium in Nashville, which opened in 1999. Since moving to Nashville, the Titans have won three division championships (2000, 2002, and 2008) and one conference championship (1999). They competed in 1999's Super Bowl XXXIV, losing to the St. Louis Rams, 23–16. The city previously hosted the 1939 Nashville Rebels of the American Football League and two Arena Football League teams named the Nashville Kats (1997–2001 and 2005–2007).

From April 25–27, 2019, Nashville hosted the 2019 NFL Draft, which saw an estimated 200,000 fans attend each day.

The Nashville Predators joined the National Hockey League as an expansion team in the 1998–99 season. The team plays its home games at Bridgestone Arena. The Predators have won two division championships (2017–18 and 2018–19) and one conference championship (2016–17).

Nashville SC, a Major League Soccer franchise, began play in 2020 at Nissan Stadium. It is expected to relocate to the Nashville Fairgrounds Stadium upon its planned completion in 2022.

The Nashville Sounds baseball team was established in 1978 as expansion franchise of the Double-A Southern League. The Sounds won the league championship in 1979 and 1982. In 1985, the Double-A Sounds were replaced by a Triple-A team of the American Association. After the American Association dissolved in 1997, the Sounds joined the Triple-A Pacific Coast League in 1998 and won the league championship in 2005. The Sounds left their original ballpark, Herschel Greer Stadium, in 2015 for First Horizon Park, a new ballpark built on the former site of Sulphur Dell ballpark. In total, the Sounds have won ten division titles, two conference titles, and three league championships.

Nashville is the home of the second-oldest continually operating race track in the United States, the Fairgrounds Speedway. It hosted NASCAR Winston Cup races from 1958 to 1984, NASCAR Busch Series and NASCAR Truck Series in the 1980s and 1990s, and later the NASCAR Whelen All-American Series and ARCA Racing Series.

Nashville Superspeedway is located southeast of Nashville in Gladeville, part of the Nashville Metropolitan Statistical Area. The track held NASCAR sanctioned events from 2001 to 2011 as well as IndyCar races from 2001 to 2008. Nashville Superspeedway will reopen in 2021 and host the premier NASCAR Cup Series for the first time.

The Nashville Invitational was a golf tournament on the PGA Tour from 1944 to 1946. The Sara Lee Classic was part of the LPGA Tour from 1988 to 2002. The BellSouth Senior Classic of the Champions Tour was held from 1994 to 2003. The Nashville Golf Open is part of the Web.com Tour since 2016. The 1961 Women's Western Open and 1980 U.S. Women's Open Golf Championship were also held in Nashville.

Nashville is also home to four Division I athletic programs. Nashville is also home to the NCAA college football Music City Bowl.

The Nashville Rollergirls are Nashville's only women's flat track roller derby team. Established in 2006, Nashville Rollergirls compete on a regional and national level. They play their home games at the Nashville Fairgrounds Sports Arena. In 2014, they hosted the WFTDA Championships at Municipal Auditorium.

The Nashville Kangaroos are an Australian Rules Football team that compete in the United States Australian Football League. The Kangaroos play their home games at Elmington Park. The team is the reigning USAFL Central Region Champions.

Three Little League Baseball teams from Nashville (one in 1970; one in 2013; and, one in 2014) have qualified for the Little League World Series. Teams from neighboring Goodlettsville qualified for the 2012 and 2016 series, giving the metropolitan area teams in three consecutive years to so qualify; and four teams in five years.

Metro Board of Parks and Recreation owns and manages of land and 99 parks and greenways (comprising more than 3% of the total area of the county).

Warner Parks, situated on of land, consists of a learning center, of scenic roads, of hiking trails, and of horse trails. It is also the home of the annual Iroquois Steeplechase.

The United States Army Corps of Engineers maintains parks on Old Hickory Lake and Percy Priest Lake. These parks are used for activities such as fishing, water skiing, sailing and boating. The Harbor Island Yacht Club makes its headquarters on Old Hickory Lake, and Percy Priest Lake is home to the Vanderbilt Sailing Club and Nashville Shores.

Other parks in Nashville include Centennial Park, Shelby Park, Cumberland Park, and Radnor Lake State Natural Area.

On August 27, 2013, Nashville mayor Karl Dean revealed plans for two new riverfront parks on the east and west banks of the Cumberland River downtown. Construction on the east bank park began in the fall of 2013, and the projected completion date for the west bank park is 2015. Among many exciting benefits of this Cumberland River re-development project is the construction of a highly anticipated outdoor amphitheater. Located on the west bank, this music venue will be surrounded by a new park and will replace the previous thermal plant site. It will include room for 6,500 spectators with 2,500 removable seats and additional seating on an overlooking grassy knoll. In addition, the east bank park will include a river landing, providing people access to the river. In regard to the parks' benefits for Nashvillian civilians, Mayor Dean remarked that "if done right, the thermal site can be an iconic park that generations of Nashvillians will be proud of and which they can enjoy".

The city of Nashville and Davidson County merged in 1963 as a way for Nashville to combat the problems of urban sprawl. The combined entity is officially known as "the Metropolitan Government of Nashville and Davidson County", and is popularly known as "Metro Nashville" or simply "Metro". It offers services such as police, fire, electricity, water and sewage treatment. When the Metro government was formed in 1963, the government was split into two service districts—the "urban services district" and the "general services district." The urban services district encompasses the 1963 boundaries of the former City of Nashville, approximately , and the general services district includes the remainder of Davidson County. There are six smaller municipalities within the consolidated city-county: Belle Meade, Berry Hill, Forest Hills, Oak Hill, Goodlettsville (partially), and Ridgetop (partially). These municipalities use a two-tier system of government, with the smaller municipality typically providing police services and the Metro Nashville government providing most other services. Previously, the city of Lakewood also had a separate charter. However, Lakewood residents voted in 2010 and 2011 to dissolve its city charter and join the metropolitan government, with both votes passing.

Nashville is governed by a mayor, vice-mayor, and 40-member Metropolitan Council. It uses the strong-mayor form of the mayor–council system. The current mayor of Nashville is John Cooper. The Metropolitan Council is the legislative body of government for Nashville and Davidson County. There are five council members who are elected at large and 35 council members that represent individual districts. The Metro Council has regular meetings that are presided over by the vice-mayor, who is currently Jim Shulman. The Metro Council meets on the first and third Tuesday of each month at 6:00pm, according to the Metropolitan Charter.

Nashville is home to the Tennessee Supreme Court's courthouse for Middle Tennessee and the Estes Kefauver Federal Building and United States Courthouse, home of the United States District Court for the Middle District of Tennessee.

Nashville has been a Democratic stronghold since at least the end of Reconstruction, and has remained staunchly Democratic even as the state as a whole has trended strongly Republican. Pockets of Republican influence exist in the wealthier portions of the city, but they are usually no match for the overwhelming Democratic trend in the rest of the city. The issue of school busing roiled politics for years but subsided after the 1990s. While local elections are officially nonpartisan, nearly all the city's elected officials are publicly known as Democrats. The city is split among 10 state house districts, all of which are held by Democrats. Three state senate districts and part of a fourth are within the county; two are held by Democrats and two by Republicans.

In the state legislature, Nashville politicians serve as leaders of both the Senate and House Democratic Caucuses. Representative Mike Stewart serves as Chairman of the House Caucus. Senator Jeff Yarbro serves as Chairman of the Senate Caucus.

Democrats are no less dominant at the federal level. Democratic presidential candidates have failed to carry Davidson County only five times since reconstruction; in 1928, 1968, 1972, 1984 and 1988. In most years, Democrats have carried Nashville at the presidential level with relatively little difficulty, even in years when they lose Tennessee as a whole. This has been especially true in recent elections. In the 2000 presidential election, Tennessean Democrat Al Gore carried Nashville with over 59% of the vote even as he narrowly lost his home state. In the 2004 election, Democrat John Kerry carried Nashville with 55% of the vote even as George W. Bush won the state by 14 points. In 2008, Barack Obama carried Nashville with 60% of the vote even as Republican John McCain won Tennessee by 15 points.

Despite its large size, Nashville has been in a single congressional district for most of the time since Reconstruction; it is currently the 5th District, represented by Democrat Jim Cooper, who is also the brother of Nashville's current mayor John Cooper. A Republican has not represented a significant portion of Nashville since 1874. Republicans made a few spirited challenges in the mid-1960s and early 1970s. The Republicans almost won it in 1968; only a strong showing by a candidate from Wallace's American Independent Party kept the seat in Democratic hands. However, they have not made a serious bid for the district since 1972, when the Republican candidate gained only 38% of the vote even as Nixon carried the district in the presidential election by a large margin. The district's best-known congressman was probably Jo Byrns, who represented the district from 1909 to 1936 and was Speaker of the House for much of Franklin Roosevelt's first term as President. Another nationally prominent congressman from Nashville was Percy Priest, who represented the district from 1941 to 1956 and was House Majority Whip from 1949 to 1953. Former mayors Richard Fulton and Bill Boner also sat in the U.S. House before assuming the Metro mayoral office.

From 2003 to 2013, a sliver of southwestern Nashville was located in the 7th District, represented by Republican Marsha Blackburn. This area was roughly coextensive with the portion of Nashville she had represented in the state senate from 1998 to 2002. However, the 5th regained all of Nashville after the 2010 census.

According to the FBI's Uniform Crime Reporting database, Metropolitan Nashville has a violent crime rate approximately three times the national average, and a property crime rate approximately 1.6 times the average. The following table shows Nashville's crime rate per 100,000 inhabitants for seven UCR categories.

The city is served by Metropolitan Nashville Public Schools, also referred to as Metro Schools. This district is the second largest school district in Tennessee, and enrolls approximately 85,000 students at 169 schools. In addition, Nashville is home to numerous private schools, including Montgomery Bell Academy, Harpeth Hall School, University School of Nashville, Lipscomb Academy, The Ensworth School, Christ Presbyterian Academy, Father Ryan High School, Pope John Paul II High School, Franklin Road Academy, Davidson Academy, Nashville Christian School, Donelson Christian Academy, and St. Cecilia Academy. Combined, all of the private schools in Nashville enroll more than 15,000 students.

Nashville is often labeled the "Athens of the South" due to the many colleges and universities in the city and the metropolitan area. Vanderbilt University is the largest university in Nashville, with approximately 13,000 students. Vanderbilt is considered one of the most prestigious research universities in the United States, and is particularly known for its medical, legal, and education programs.

Nashville is home to four historically Black institutions of higher education, the second highest in the nation, behind Atlanta, Georgia. These are Fisk University, Tennessee State University, Meharry Medical College, and American Baptist College.

Other schools based in Nashville include Belmont University, Lipscomb University, Trevecca Nazarene University, John A. Gupton College, Watkins College of Art, Design & Film. The Tennessee Board of Regents operates Nashville State Community College and the Nashville branch of the Tennessee Colleges of Applied Technology. In total, enrollment in post-secondary education in Nashville is around 43,000.

In addition, there are several other institutes of higher education in the Nashville metropolitan area. Middle Tennessee State University (MTSU), a full-sized public university with Tennessee's second largest undergraduate population, is located in Murfreesboro. Other schools include Daymar College and O'More College of Design, both in Franklin, and Cumberland University in Lebanon.

The daily newspaper in Nashville is "The Tennessean", which until 1998 competed with the "Nashville Banner", another daily paper that was housed in the same building under a joint-operating agreement. "The Tennessean" is the city's most widely circulated newspaper. Online news service "NashvillePost.com" competes with the printed dailies to break local and state news. Several weekly papers are also published in Nashville, including "The Nashville Pride", "Nashville Business Journal", "Nashville Scene" and "The Tennessee Tribune". Historically, "The Tennessean" was associated with a broadly liberal editorial policy, while "The Banner" carried staunchly conservative views in its editorial pages; "The Banner"s heritage had been carried on, to an extent, by "The City Paper" which folded in August 2013 after having been founded in October 2000. The "Nashville Scene" is the area's alternative weekly broadsheet. "The Nashville Pride" is aimed towards community development and serves Nashville's entrepreneurial population. "Nashville Post" is an online news source covering business, politics and sports.

Nashville is home to eleven broadcast television stations, although most households are served by direct cable network connections. Comcast Cable has a monopoly on terrestrial cable service in Davidson County (but not throughout the entire media market). Nashville is ranked as the 29th largest television market in the United States. Major stations include WKRN-TV 2 (ABC), WSMV-TV 4 (NBC), WTVF 5 (CBS), WNPT 8 (PBS), WZTV 17 (Fox), WNPX-TV 28 (ion), WPGD-TV 50 (TBN), WLLC-LP 42 (Univision), WUXP-TV 30 (MyNetworkTV), and WNAB 58 (CW).

Nashville is also home to cable networks Country Music Television (CMT), among others. CMT's master control facilities are located in New York City with the other Viacom properties. The Top 20 Countdown and CMT Insider are taped in their Nashville studios. Shop at Home Network was once based in Nashville, but the channel signed off in 2008.

Several FM and AM radio stations broadcast in the Nashville area, including five college stations and one LPFM community radio station. Nashville is ranked as the 44th largest radio market in the United States. WSM-FM is owned by Cumulus Media and is 95.5 FM. WSM-AM, owned by Gaylord Entertainment Company, can be heard nationally on 650 AM or online at WSM Online from its studios located inside the Gaylord Opryland Resort & Convention Center. WSM is famous for carrying live broadcasts of the Grand Ole Opry, through which it helped spread the popularity of country music in America, and continues to broadcast country music throughout its broadcast day. WLAC, whose over-the-air signal is heard at 1510 AM, is an iHeartMedia-owned talk station which was originally sponsored by the Life and Casualty Insurance Company of Tennessee, and its competitor WWTN is owned by Cumulus.

Several major motion pictures have been filmed in Nashville, including "The Green Mile", "The Last Castle", "Gummo", "The Thing Called Love", "Two Weeks", "Coal Miner's Daughter", "Nashville", and "Country Strong", as well as the ABC television series "Nashville".

According to the 2016 American Community Survey, 78.1% of working Nashville residents commuted by driving alone, 9.8% carpooled, 2% used public transportation, and 2.2% walked. About 1.1% used all other forms of transportation, including taxicab, motorcycle, and bicycle. About 6.7% of working Nashville residents worked at home. In 2015, 7.9% of city of Nashville households were without a car; this figure decreased to 5.9% in 2016. The national average was 8.7 percent in 2016. Nashville averaged 1.72 cars per household in 2016, compared to a national average of 1.8 per household.

Nashville is centrally located at the crossroads of three Interstate Highways, I-40 (east-west), I-24 (northwest-southeast) and I-65 (north-south). I-40 connects the city between Memphis to the west and Knoxville to the east, I-24 connects between Clarksville to the northwest and Chattanooga to the southeast, and I-65 connects between Louisville, Kentucky to the north and Huntsville, Alabama to the south. All three of these interstate highways, which also serve the suburbs, form brief concurrencies with each other in the city, and completely encircle downtown. Interstate 440 is a bypass route connecting I-40, I-65, and I-24 south of downtown Nashville. Briley Parkway, the majority of which is a freeway, forms a bypass around the north side of the city and its interstates. Ellington Parkway, a freeway made up of a section of U.S. Route 31E, runs between east of downtown and Briley Parkway, serving as an alternative route to I-65. Interstate 840 provides an outer southern bypass for the city and its suburbs. U.S. Routes 31, 31E, 31W, 31 Alternate, 41, 41 Alternate, 70, 70S, and 431 also serve Nashville, intersecting in the city's center as arterial surface roads and radiating outward. Most of these routes are called "pikes" and many carry the names of nearby towns to which they lead. Among these are Clarksville Pike, Gallatin Pike, Lebanon Pike, Murfreesboro Pike, Nolensville Pike, and Franklin Pike.

The Metropolitan Transit Authority provides bus transit within the city. Routes utilize a hub and spoke method, centered around the Music City Central transit station in downtown. A rejected expansion plan included use of bus rapid transit and light rail service at some point in the future.

Nashville is considered a gateway city for rail and air traffic for the Piedmont Atlantic Megaregion.

The city is served by Nashville International Airport (BNA), which is operated by the Metropolitan Nashville Airport Authority (MNAA). 18.27 million passengers visited the airport in 2019, making it the 31st busiest airport in the US. BNA is ranked fastest growing airport among the top 50 airports in the United States. Nashville International Airport serves 600 daily flights to more than 85 nonstop markets.

In late 2014, BNA became the first major U.S. airport to establish dedicated pick-up and drop-off areas for vehicle for hire companies.

The airport authority also operates the John C. Tune Airport, a Class E airspace general aviation airport.

Although a major freight hub for CSX Transportation, Nashville is not currently served by Amtrak, the third-largest metropolitan area in the U.S. to have this distinction. Nashville's Union Station had once been a major intercity passenger rail center for the Louisville and Nashville Railroad; Nashville, Chattanooga and St. Louis Railway; and the Tennessee Central Railway, reaching Midwestern cities and cities on the Gulf of Mexico and the Atlantic Ocean. However, by the time of Amtrak's founding, service had been cut back to a single train, the "Floridian", which ran from Chicago to Miami and St. Petersburg, Florida. It served Union Station until its cancellation on October 9, 1979, due to poor track conditions resulting in late trains and low ridership, ending over 120 years of intercity rail service in Nashville.

While there have been few proposals to restore Amtrak service to Nashville, there have been repeated calls from residents. In addition to scarce federal funding, Tennessee state officials do not believe that Nashville is large enough to support intercity rail. "It would be wonderful to say I can be in Memphis and jump on a train to Nashville, but the volume of people who would do that isn't anywhere close to what the cost would be to provide the service," said Ed Cole, chief of environment and planning with the Tennessee Department of Transportation. Ross Capon, executive director of the National Association of Railroad Passengers, said rail trips would catch on if routes were expanded, but conceded that it would be nearly impossible to resume Amtrak service to Nashville without a substantial investment from the state. However, in 2020, Amtrak indicated it was considering a service that would run from Atlanta to Nashville by way of Chattanooga.

Nashville launched a passenger commuter rail system called the Music City Star on September 18, 2006. The only currently operational leg of the system connects the city of Lebanon to downtown Nashville at the Nashville Riverfront station. Legs to Clarksville, Murfreesboro and Gallatin are currently in the feasibility study stage. The system plan includes seven legs connecting Nashville to surrounding suburbs.

Bridges within the city include:
The city of Nashville owns the Nashville Electric Service (NES), Metro Water Services (MWS) and Nashville District Energy System (NDES). The Nashville Electric Service provides electricity to the entirety of Davidson County and small portions of the six adjacent counties, and purchases its power from the Tennessee Valley Authority. Metro Water Services provides water, wastewater, and stormwater to Nashville and the majority of Davidson County, as well as water services to small portions of Rutherford and Williamson counties, and wastewater services to small portions of all of the surrounding counties except for Cheatham County. MWS sources its water from the Cumberland River and operates two water treatment plants and three wastewater treatment plants. Ten additional utility companies provide water and sewer service to Nashville and Davidson County. The Nashville District Energy System provides heating and cooling services to certain buildings in downtown, including multiple government buildings. Natural gas is provided by Piedmont Natural Gas, a subsidiary of Duke Energy.

As a major center for the healthcare industry, Nashville is home to several hospitals and other primary care facilities. Most hospitals in Nashville are operated by Vanderbilt University Medical Center, the TriStar Division of Hospital Corporation of America, and Saint Thomas Health. The Metropolitan Nashville Hospital Authority operates Nashville General Hospital, which is affiliated with Meharry Medical College.

Nashville is an active participant in the sister cities program and has relationships with the following towns and cities:









</doc>
<doc id="22024" url="https://en.wikipedia.org/wiki?curid=22024" title="Novial">
Novial

Novial is a constructed international auxiliary language (IAL) for universal communication between speakers of different native languages. It was devised by Otto Jespersen, a Danish linguist who had been involved in the Ido movement, and later in the development of Interlingua.

Its vocabulary is based largely on the Germanic and Romance languages and its grammar is influenced by English.

Novial was introduced in Jespersen's book "An International Language" in 1928. It was updated in his dictionary "Novial Lexike" in 1930, and further modifications were proposed in the 1930s, but the language became dormant with Jespersen's death in 1943. In the 1990s, with the revival of interest in constructed languages brought on by the Internet, some people rediscovered Novial.

The basic rule is: stress the vowel before the last consonant. However, consonantal flexional endings (ie. -d, -m, -n, -s) do not count for this (eg. "bóni" but "bónim", not "boním"; "apérta" but "apértad", not "apertád") so perhaps it is better to say that the vowel before the final consonant of the stem takes the stress.

The digraphs "ch" and "sh" represent or , depending on the speaker. For example, "chokolate" would be pronounced either or .

In Novial, nominative and oblique pronouns are identical.

The standard word order is subject-verb-object, as in English. Therefore, the object need not be marked to distinguish it from the subject:
E.g.:

The accusative (direct object) is therefore most often identical to the nominative (subject). However, in case of an ambiguity problem, an optional accusative ending, -m (-em after a consonant), is available but is rarely used. The preposition em is equivalent to this ending.

The personal possessive adjectives are formed from the pronouns by adding -n or after a consonant -en. This is in fact the genitive (possessive) of the pronoun so "men" means both "my" and "mine" ("of me"):
E.g.:

Possession may also be expressed with the preposition de: "de me", "de vu", and so on.

Verb forms never change with person or number. Most verb tenses, moods and voices are expressed with auxiliary verbs preceding the root form of the main verb. The auxiliaries follow the same word order as the English equivalent. The pronouns are indicated with parentheses and are given for example purposes.


Novial clearly distinguishes the passive of becoming and the passive of being. In English the forms are often the same, using the auxiliary verb "to be" followed by the past participle. However, the passive of becoming is also often expressed with the verb "to get" which is used in the examples below.

The passive voice of becoming is formed with the auxiliary bli followed by the root verb form.

The passive voice of being is formed with the auxiliary es followed by the past passive participle (stem + -t).

The definite article is "li" which is invariant. It is used as in English.

There is no indefinite article, although "un" (one) can be used.

The plural noun is formed by adding –s to the singular (-es after a consonant).

The accusative case is generally identical to the nominative but can optionally be marked with the ending -m (-em after a consonant) with the plural being -sem (-esem after a consonant) or with the preposition em.

The genitive is formed with the ending -n (-en after a consonant) with the plural being -sen (-esen after a consonant) or with the preposition de.

Other cases are formed with prepositions.

All adjectives end in -i, but this may be dropped if it is easy enough to pronounce and no confusion will be caused. Adjectives precede the noun qualified. Adjectives do not agree with the noun but may be given noun endings if there is no noun present to receive them.

Comparative adjectives are formed by placing various particles ("plu, tam," and "min") in front of the adjective receiving the comparison. Likewise, the superlative particles ("maxim" and "minim") precede the adjective. The adjective does not receive an inflection to its ending.

An adjective is converted to a corresponding adverb by adding -m after the -i ending of the adjective.

Comparative and superlative adverbs are formed in the same manner as comparative and superlative adjectives: by placing a specific particle before the adverb receiving the comparison.

See the and at the Novial Wikibook.

Jespersen was a professional linguist, unlike Esperanto's creator. He disliked the arbitrary and artificial character that he found in Esperanto and Ido. Additionally, he objected to those languages' inflectional systems, which he found needlessly complex. He sought to make Novial at once euphonious and regular while also preserving useful structures from natural languages.

In Novial:

A major difference between Novial and Esperanto/Ido concerns noun endings. Jespersen rejected a single vowel to terminate all nouns (-o in Esperanto/Ido), finding it unnatural and potentially confusing. Instead, Novial nouns may end in "-o", "-a", "-e", or "-u" or "-um". These endings may be taken to indicate natural sex according to the custom in Romance languages. Also there is no grammatical gender or requirement for adjectives to agree with nouns.

Here is the Lord's Prayer in Novial and several related languages:
As Jespersen relates in his autobiography, in 1934 he proposed an orthographic reform to Novial, which displeased a part of the users. Jespersen abandoned the essential principle of "one sound, one letter" :

Some of Jespersen's colleagues among philologists jokingly referred to Novial as "Jesperanto", combining his surname with Esperanto, the prototypical auxiliary language.




</doc>
<doc id="22026" url="https://en.wikipedia.org/wiki?curid=22026" title="Musical note">
Musical note

In music, a note is a symbol denoting a musical sound. In English usage a note is also the sound itself.

Notes can represent the pitch and duration of a sound in musical notation. A note can also represent a pitch class.

Notes are the building blocks of much written music: discretizations of musical phenomena that facilitate performance, comprehension, and analysis.

The term "note" can be used in both generic and specific senses: one might say either "the piece 'Happy Birthday to You' begins with two notes having the same pitch", or "the piece begins with two repetitions of the same note". In the former case, one uses "note" to refer to a specific musical event; in the latter, one uses the term to refer to a class of events sharing the same pitch. (See also: Key signature names and translations.)

Two notes with fundamental frequencies in a ratio equal to any integer power of two (e.g., half, twice, or four times) are perceived as very similar. Because of that, all notes with these kinds of relations can be grouped under the same pitch class.

In traditional music theory, most countries in the world use the solfège naming convention do–re–mi–fa–sol–la–si, including for instance Italy, Portugal, Spain, France, Romania, most Latin American countries, Greece, Albania, Bulgaria, Turkey, Russia, Arabic-speaking countries and Persian-speaking countries. However, in English- and Dutch-speaking regions, pitch classes are typically represented by the first seven letters of the Latin alphabet (A, B, C, D, E, F and G). A few European countries, including Germany, adopt an almost identical notation, in which H substitutes for B (see below for details). Byzantium used the names Pa–Vu–Ga–Di–Ke–Zo–Ni (Πα—Βου—Γα—Δι—Κε—Ζω—Νη).

The eighth note, or octave, is given the same name as the first, but has double its frequency. The name octave is also used to indicate the span between a note and another with double frequency. To differentiate two notes that have the same pitch class but fall into different octaves, the system of scientific pitch notation combines a letter name with an Arabic numeral designating a specific octave. For example, the now-standard tuning pitch for most Western music, 440 Hz, is named a′ or A4.

There are two formal systems to define each note and octave, the Helmholtz pitch notation and the scientific pitch notation.

Letter names are modified by the accidentals. The sharp sign raises a note by a semitone or half-step, and a flat lowers it by the same amount. In modern tuning a half step has a frequency ratio of , approximately 1.0595. The accidentals are written after the note name: so, for example, F represents F-sharp, B is B-flat, and C is C natural (or C).
Additional accidentals are the double-sharp , raising the frequency by two semitones, and double-flat , lowering it by that amount.

In musical notation, accidentals are placed before the note symbols. Systematic alterations to the seven lettered pitches in the scale can be indicated by placing the symbols in the key signature, which then apply implicitly to all occurrences of corresponding notes. Explicitly noted accidentals can be used to override this effect for the remainder of a bar. A special accidental, the natural symbol , is used to indicate a pitch unmodified by the alterations in the key signature. Effects of key signature and local accidentals do not accumulate. If the key signature indicates G, a local flat before a G makes it G (not G), though often this type of rare accidental is expressed as a natural, followed by a flat () to make this clear. Likewise (and more commonly), a double sharp sign on a key signature with a single sharp indicates only a double sharp, not a triple sharp.

Assuming enharmonicity, many accidentals will create equivalences between pitches that are written differently. For instance, raising the note B to B is equal to the note C. Assuming all such equivalences, the complete chromatic scale adds five additional pitch classes to the original seven lettered notes for a total of 12 (the 13th note completing the octave), each separated by a half-step.

Notes that belong to the diatonic scale relevant in the context are sometimes called "diatonic notes"; notes that do not meet that criterion are then sometimes called "chromatic notes".

Another style of notation, rarely used in English, uses the suffix "is" to indicate a sharp and "es" (only "s" after A and E) for a flat, e.g., Fis for F, Ges for G, Es for E. This system first arose in Germany and is used in almost all European countries whose main language is not English, Greek, or a Romance language (French, Portuguese, Spanish, Italian, Romanian)

In most countries using these suffixes, the letter H is used to represent what is B natural in English, the letter B is used instead of B, and Heses (i.e., H) is used instead of B (although Bes and Heses both denote the English B). Dutch-speakers in Belgium and the Netherlands use the same suffixes, but applied throughout to the notes A to G, so that B, B and B have the same meaning as in English, although they are called B, Bes, and Beses instead of B, B flat and B double flat. Denmark also uses H, but uses Bes instead of Heses for B.

The following chart lists the names used in different countries for the 12 notes of a chromatic scale built on C. The corresponding symbols are shown within parenthesis. Differences between German and English notation are highlighted in bold typeface. Although the English and Dutch names are different, the corresponding symbols are identical.

The table below shows each octave and the frequencies for every note of pitch class A. The traditional (Helmholtz) system centers on the great octave (with capital letters) and small octave (with lower case letters). Lower octaves are named "contra" (with primes before), higher ones "lined" (with primes after). Another system (scientific) suffixes a number (starting with 0, or sometimes −1). In this system A is nowadays standardised at 440 Hz, lying in the octave containing notes from C (middle C) to B. The lowest note on most pianos is A, the highest C. The MIDI system for electronic musical instruments and computers uses a straight count starting with note 0 for C at 8.1758 Hz up to note 127 for G at 12,544 Hz.

A written note can also have a note value, a code that determines the note's relative duration. In order of halving duration, they are: double note (breve); whole note (semibreve); half note (minim); quarter note (crotchet); eighth note (quaver); sixteenth note (semiquaver).; thirty-second note (demisemiquaver), sixty-fourth note (hemidemisemiquaver), and hundred twenty-eighth note.
In a score, each note is assigned a specific vertical position on a staff position (a line or space) on the staff, as determined by the clef. Each line or space is assigned a note name. These names are memorized by musicians and allow them to know at a glance the proper pitch to play on their instruments.
<score vorbis="true">
\relative c' {
c1 d1 e1 f1 g1 a1 b1 c1 b1 a1 g1 f1 e1 d1 c1
\layout {
\midi {
</score>
The staff above shows the notes C, D, E, F, G, A, B, C and then in reverse order, with no key signature or accidentals.

In all technicality, "music" can be composed of notes at any arbitrary physical frequency. Since the physical causes of music are vibrations of mechanical systems, they are often measured in hertz (Hz), with 1 Hz meaning one vibration per second. For historical and other reasons, especially in Western music, only twelve notes of fixed frequencies are used. These fixed frequencies are mathematically related to each other, and are defined around the central note, A. The current "standard pitch" or modern "concert pitch" for this note is 440 Hz, although this varies in actual practice (see History of pitch standards).

The note-naming convention specifies a letter, any accidentals, and an octave number. Each note is an integer number of half-steps away from concert A (A). Let this distance be denoted "n". If the note is above A, then "n" is positive; if it is below A, then "n" is negative. The frequency of the note ("f") (assuming equal temperament) is then:

For example, one can find the frequency of C, the first C above A. There are 3 half-steps between A and C (A → A → B → C), and the note is above A, so "n" = 3. The note's frequency is:

To find the frequency of a note below A4, the value of "n" is negative. For example, the F below A is F. There are 4 half-steps (A → A → G → G → F), and the note is below A, so "n" = −4. The note's frequency is:

Finally, it can be seen from this formula that octaves automatically yield powers of two times the original frequency, since "n" is a multiple of 12 (12"k", where "k" is the number of octaves up or down), and so the formula reduces to:

yielding a factor of 2. In fact, this is the means by which this formula is derived, combined with the notion of equally-spaced intervals.

The distance of an equally tempered semitone is divided into 100 cents. So 1200 cents are equal to one octave – a frequency ratio of 2:1. This means that a cent is precisely equal to , which is approximately .

For use with the MIDI (Musical Instrument Digital Interface) standard, a frequency mapping is defined by:

where "p" is the MIDI note number (and 69 is the number of semitones between C (note 0) and A). And in the opposite direction, to obtain the frequency from a MIDI note "p", the formula is defined as:

For notes in an A440 equal temperament, this formula delivers the standard MIDI note number ("p"). Any other frequencies fill the space between the whole numbers evenly. This lets MIDI instruments be tuned accurately in any microtuning scale, including non-western traditional tunings.

Music notation systems have used letters of the alphabet for centuries. The 6th-century philosopher Boethius is known to have used the first fourteen letters of the classical Latin alphabet (the letter J did not exist until the 16th century),
to signify the notes of the two-octave range that was in use at the time and in modern scientific pitch notation are represented as

Though it is not known whether this was his devising or common usage at the time, this is nonetheless called "Boethian notation". Although Boethius is the first author known to use this nomenclature in the literature, Ptolemy wrote of the two-octave range five centuries before, calling it the "perfect system" or "complete system" – as opposed to other, smaller-range note systems that did not contain all possible species of octave (i.e., the seven octaves starting from A, B, C, D, E, F, and G).

Following this, the range (or compass) of used notes was extended to three octaves, and the system of repeating letters A–G in each octave was introduced, these being written as lower-case for the second octave (a–g) and double lower-case letters for the third (aa–gg). When the range was extended down by one note, to a G, that note was denoted using the Greek letter gamma (Γ). (It is from this that the French word for scale, "gamme" derives, and the English word gamut, from "Gamma-Ut", the lowest note in Medieval music notation.)

The remaining five notes of the chromatic scale (the black keys on a piano keyboard) were added gradually; the first being B, since B was flattened in certain modes to avoid the dissonant tritone interval. This change was not always shown in notation, but when written, B (B-flat) was written as a Latin, round "b", and B (B-natural) a Gothic script (known as Blackletter) or "hard-edged" b. These evolved into the modern flat () and natural () symbols respectively. The sharp symbol arose from a barred b, called the "cancelled b".

In parts of Europe, including Germany, the Czech Republic, Slovakia, Poland, Hungary, Norway, Denmark, Serbia, Croatia, Slovenia, Finland and Iceland (and Sweden before about 1990s), the Gothic b transformed into the letter H (possibly for "hart", German for "hard", or just because the Gothic b resembled an H). Therefore, in German music notation, H is used instead of B (B-natural), and B instead of B (B-flat). Occasionally, music written in German for international use will use H for B-natural and B for B-flat (with a modern-script lower-case b instead of a flat sign). Since a Bes or B in Northern Europe (i.e., a B elsewhere) is both rare and unorthodox (more likely to be expressed as Heses), it is generally clear what this notation means.

In Italian, Portuguese, Spanish, French, Romanian, Greek, Albanian, Russian, Mongolian, Flemish, Persian, Arabic, Hebrew, Ukrainian, Bulgarian, Turkish and Vietnam the note names are "do–re–mi–fa–sol–la–si" rather than C–D–E–F–G–A–B. These names follow the original names reputedly given by Guido d'Arezzo, who had taken them from the first syllables of the first six musical phrases of a Gregorian chant melody "Ut queant laxis", which began on the appropriate scale degrees. These became the basis of the solfège system. For ease of singing, the name "ut" was largely replaced by "do" (most likely from the beginning of "Dominus", Lord), though "ut" is still used in some places. For the seventh degree, the name "si" (from "Sancte Iohannes", St. John, to whom the hymn is dedicated), though in some regions the seventh is named "ti".

The two notation systems most commonly used today are the Helmholtz pitch notation system and the scientific pitch notation system. As shown in the table above, they both include several octaves, each starting from C rather than A. The reason is that the most commonly used scale in Western music is the major scale, and the sequence C–D–E–F–G–A–B–C (the C major scale) is the simplest example of a major scale. Indeed, it is the only major scale that can be obtained using natural notes (the white keys on the piano keyboard) and is typically the first musical scale taught in music schools.

In a newly developed system, primarily in use in the United States, notes of scales become independent of music notation. In this system the natural symbols C–D–E–F–G–A–B refer to the absolute notes, while the names "do–re–mi–fa–so–la–ti" are relativized and show only the relationship between pitches, where "do" is the name of the base pitch of the scale (the tonic), "re" is the name of the second degree, etc. The idea of this so-called "movable do," first suggested by John Curwen in the 19th century, was fully developed and involved into a whole educational system by Zoltán Kodály in the middle of the 20th century, which system is known as the Kodály method or Kodály concept.




</doc>
<doc id="22028" url="https://en.wikipedia.org/wiki?curid=22028" title="Nephrology">
Nephrology

Nephrology (from Greek" nephros" "kidney", combined with the suffix "-logy", "the study of") is a specialty of medicine focused on the kidneys, specifically normal kidney function and kidney disease, the preservation of kidney health, and the treatment of kidney disease, from diet and medication to renal replacement therapy (dialysis and kidney transplantation).

Nephrology also studies systemic conditions that affect the kidneys, such as diabetes and autoimmune disease; and systemic diseases that occur as a result of kidney disease, such as renal osteodystrophy and hypertension. A physician who has undertaken additional training and become certified in nephrology is called a "nephrologist".

The term "nephrology" was first used in about 1960, according to the french "néphrologie" proposed by Pr. Jean Hamburger in 1953, from the greek νεφρός / nephrós (kidney). Before then, the specialty was usually referred to as "kidney medicine."

Nephrology concerns the diagnosis and treatment of kidney diseases, including electrolyte disturbances and hypertension, and the care of those requiring renal replacement therapy, including dialysis and renal transplant patients. The word 'dialysis' is from the mid 19th century: via Latin from the Greek word 'dialusis'; from 'dialuein' (split, separate), from 'dia' (apart) and 'luein' (set free). In other words, dialysis replaces the primary (excretory) function of the kidney, which separates (and removes) excess toxins and water from the blood, placing them in the urine.

Many diseases affecting the kidney are systemic disorders not limited to the organ itself, and may require special treatment. Examples include acquired conditions such as systemic vasculitides (e.g. ANCA vasculitis) and autoimmune diseases (e.g., lupus), as well as congenital or genetic conditions such as polycystic kidney disease.

Patients are referred to nephrology specialists after a urinalysis, for various reasons, such as acute kidney failure, chronic kidney disease, hematuria, proteinuria, kidney stones, hypertension, and disorders of acid/base or electrolytes.

A nephrologist is a physician who specializes in the care and treatment of kidney disease. Nephrology requires additional training to become an expert with advanced skills. Nephrologists may provide care to people without kidney problems and may work in general/internal medicine, transplant medicine, immunosuppression management, intensive care medicine, clinical pharmacology, perioperative medicine, or pediatric nephrology.

Nephrologists may further sub-specialise in dialysis, kidney transplantation, chronic kidney disease, cancer-related kidney diseases (Onconephrology), procedural nephrology or other non-nephrology areas as described above.

Procedures a nephrologist may perform include native kidney and transplant kidney biopsy, dialysis access insertion (temporary vascular access lines, tunnelled vascular access lines, peritoneal dialysis access lines), fistula management (angiographic or surgical fistulogram and plasty), and bone biopsy. Bone biopsies are now unusual.

India

To become a nephrologist in India, one has to complete an MBBS (5 and 1/2 years) degree, followed by an MD/DNB (3 years) either in medicine or paediatrics, followed by a DM/DNB (3 years) course in either nephrology or paediatric nephrology.

Nephrology training in Australia and New Zealand typically includes completion of a medical degree (Bachelor of Medicine, Bachelor of Surgery: 4–6 years), internship (1 year), Basic Physician Training (3 years minimum), successful completion of the Royal Australasian College of Physicians written and clinical examinations, and Advanced Physician Training in Nephrology (2–3 years). The training pathway is overseen and accredited by the Royal Australasian College of Physicians. Increasingly, nephrologists may additionally complete of a post-graduate degree (usually a PhD) in a nephrology research interest (3–4 years). Finally, all Australian and New Zealand nephrologists participate in career-long professional and personal development through the Royal Australasian College of Physicians and other bodies such as the Australian and New Zealand Society of Nephrology and the Transplant Society of Australia and New Zealand.

In the United Kingdom, nephrology (often called renal medicine) is a subspecialty of general medicine. A nephrologist has completed medical school, foundation year posts (FY1 and FY2) and core medical training (CMT), specialist training (ST) and passed the Membership of the Royal College of Physicians (MRCP) exam before competing for a National Training Number (NTN) in renal medicine. The typical Specialty Training (when they are called a registrar, or a ST) is five years and leads to a Certificate of Completion of Training (CCT) in both renal medicine and general (internal) medicine. In that five years, they usually rotate yearly between hospitals on a region (known as a deanery). They are then accepted on to the Specialist Register of the General Medical Council (GMC). Specialty trainees often interrupt their clinical training to obtain research degrees (MD/PhD). After achieving CCT, the registrar (ST) may apply for a permanent post as Consultant in Renal Medicine. Subsequently, some Consultants practice nephrology alone. Others work in this area, and in Intensive Care (ICU) , or General (Internal) or Acute Medicine.

Nephrology training can be accomplished through one of two routes. The first pathway is through an internal medicine pathway leading to an Internal Medicine/Nephrology specialty, and sometimes known as "adult nephrology". The second pathway is through Pediatrics leading to a speciality in Pediatric Nephrology. In the United States, after medical school adult nephrologists complete a three-year residency in internal medicine followed by a two-year (or longer) fellowship in nephrology. Complementary to an adult nephrologist, a pediatric nephrologist will complete a three-year pediatric residency after medical school or a four-year Combined Internal Medicine and Pediatrics residency. This is followed by a three-year fellowship in Pediatic Nephrology. Once training is satisfactorily completed, the physician is eligible to take the American Board of Internal Medicine (ABIM) or American Osteopathic Board of Internal Medicine (AOBIM) nephrology examination. Nephrologists must be approved by one of these boards. To be approved, the physician must fulfill the requirements for education and training in nephrology in order to qualify to take the board's examination. If a physician passes the examination, then he or she can become a nephrology specialist. Typically, nephrologists also need two to three years of training in an ACGME or AOA accredited fellowship in nephrology. Nearly all programs train nephrologists in continuous renal replacement therapy; fewer than half in the United States train in the provision of plasmapheresis. Only pediatric trained physicians are able to train in pediatric nephrology, and internal medicine (adult) trained physicians may enter general (adult) nephrology fellowships.

History and physical examination are central to the diagnostic workup in nephrology. The history typically includes the present illness, family history, general medical history, diet, medication use, drug use and occupation. The physical examination typically includes an assessment of volume state, blood pressure, heart, lungs, peripheral arteries, joints, abdomen and flank. A rash may be relevant too, especially as an indicator of autoimmune disease.

Examination of the urine (urinalysis) allows a direct assessment for possible kidney problems, which may be suggested by appearance of blood in the urine (haematuria), protein in the urine (proteinuria), pus cells in the urine (pyuria) or cancer cells in the urine. A 24-hour urine collection used to be used to quantify daily protein loss (see proteinuria), urine output, creatinine clearance or electrolyte handling by the renal tubules. It is now more common to measure protein loss from a small random sample of urine.

Basic blood tests can be used to check the concentration of hemoglobin, white count, platelets, sodium, potassium, chloride, bicarbonate, urea, creatinine, albumin, calcium, magnesium, phosphate, alkaline phosphatase and parathyroid hormone (PTH) in the blood. All of these may be affected by kidney problems. The serum creatinine concentration is the most important blood test as it is used to estimate the function of the kidney, called the creatinine clearance or estimated glomerular filtration rate (GFR).

It is good idea for patients with longterm kidney disease to know an up-to-date list of medications, and their latest blood tests, especially the blood creatinine level. In the United Kingdom, blood tests can monitored online by the patient, through a website called RenalPatientView.

More specialized tests can be ordered to discover or link certain systemic diseases to kidney failure such as infections (hepatitis B, hepatitis C), autoimmune conditions (systemic lupus erythematosus, ANCA vasculitis), paraproteinemias (amyloidosis, multiple myeloma) and metabolic diseases (diabetes, cystinosis).

Structural abnormalities of the kidneys are identified with imaging tests. These may include Medical ultrasonography/ultrasound, computed axial tomography (CT), scintigraphy (nuclear medicine), angiography or magnetic resonance imaging (MRI).

In certain circumstances, less invasive testing may not provide a certain diagnosis. Where definitive diagnosis is required, a biopsy of the kidney (renal biopsy) may be performed. This typically involves the insertion, under local anaesthetic and ultrasound or CT guidance, of a core biopsy needle into the kidney to obtain a small sample of kidney tissue. The kidney tissue is then examined under a microscope, allowing direct visualization of the changes occurring within the kidney. Additionally, the pathology may also stage a problem affecting the kidney, allowing some degree of prognostication. In some circumstances, kidney biopsy will also be used to monitor response to treatment and identify early relapse. A transplant kidney biopsy may also be performed to look for rejection of the kidney.

Treatments in nephrology can include medications, blood products, surgical interventions (urology, vascular or surgical procedures), renal replacement therapy (dialysis or kidney transplantation) and plasma exchange. Kidney problems can have significant impact on quality and length of life, and so psychological support, health education and advanced care planning play key roles in nephrology.

Chronic kidney disease is typically managed with treatment of causative conditions (such as diabetes), avoidance of substances toxic to the kidneys (nephrotoxins like radiologic contrast and non-steroidal anti-inflammatory drugs), antihypertensives, diet and weight modification and planning for end-stage kidney failure. Impaired kidney function has systemic effects on the body. An erythropoetin stimulating agent (ESA) may be required to ensure adequate production of red blood cells, activated vitamin D supplements and phosphate binders may be required to counteract the effects of kidney failure on bone metabolism, and blood volume and electrolyte disturbance may need correction. Diuretics (such as furosemide) may be used to correct fluid overload, and alkalis (such as sodium bicarbonate) can be used to treat metabolic acidosis.

Auto-immune and inflammatory kidney disease, such as vasculitis or transplant rejection, may be treated with immunosuppression. Commonly used agents are prednisone, mycophenolate, cyclophosphamide, ciclosporin, tacrolimus, everolimus, thymoglobulin and sirolimus. Newer, so-called "biologic drugs" or monoclonal antibodies, are also used in these conditions and include rituximab, basiliximab and eculizumab. Blood products including intravenous immunoglobulin and a process known as plasma exchange can also be employed.

When the kidneys are no longer able to sustain the demands of the body, end-stage kidney failure is said to have occurred. Without renal replacement therapy, death from kidney failure will eventually result. Dialysis is an artificial method of replacing some kidney function to prolong life. Renal transplantation replaces kidney function by inserting into the body a healthier kidney from an organ donor and inducing immunologic tolerance of that organ with immunosuppression. At present, renal transplantation is the most effective treatment for end-stage kidney failure although its worldwide availability is limited by lack of availability of donor organs. Generally speaking, kidneys from living donors are 'better' than those from deceased donors, as they last longer.

Most kidney conditions are chronic conditions and so long term followup with a nephrologist is usually necessary. In the United Kingdom, care may be shared with the patient's primary care physician, called a General Practitioner (GP).

The world's first society of nephrology was the French 'Societe de Pathologie Renale'. Its first president was Jean Hamburger, and its first meeting was in Paris in February 1949. In 1959, Hamburger also founded the 'Société de Néphrologie', as a continuation of the older society. The UK's Renal Association was founded in 1950; the second society of nephrologists. Its first president was Arthur Osman. Its first meeting was on 30 March 1950 in London. The Società di Nefrologia Italiana was founded in 1957 and was the first national society to incorporate the phrase nephrologia (or nephrology) into its name.

The word 'nephrology' appeared for the first time in a conference, on 1–4 September 1960 at the "Premier Congrès International de Néphrologie" in Evian and Geneva, the first meeting of the International Society of Nephrology (ISN, International Society of Nephrology). The first day (1.9.60) was in Geneva and the next three (2–4.9.60) were in Evian, France. The early history of the ISN is described by Robinson and Richet in 2005 and the later history by Barsoum in 2011. The ISN is the largest global society representing medical professionals engaged in advancing kidney care worldwide.

In the USA, founded in 1964, the National Kidney Foundation is a national organization representing patients and professionals who treat kidney diseases. Founded in 1966, the American Society of Nephrology (ASN) is the world’s largest professional society devoted to the study of kidney disease. The American Nephrology Nurses' Association (ANNA), founded in 1969, promotes excellence in and appreciation of nephrology nursing to make a positive difference for patients with kidney disease. The American Association of Kidney Patients (AAKP) is a non-profit, patient-centric group focused on improving the health and well-being of CKD and dialysis patients. The National Renal Administrators Association (NRAA), founded in 1977, is a national organization that represents and supports the independent and community-based dialysis providers. The American Kidney Fund directly provides financial support to patients in need, as well as participating in health education and prevention efforts. ASDIN (American Society of Diagnostic and Interventional Nephrology) is the main organization of interventional nephrologists. Other organizations include CIDA, VASA etc. which deal with dialysis vascular access. The Renal Support Network (RSN) is a nonprofit, patient-focused, patient-run organization that provides non-medical services to those affected by chronic kidney disease (CKD).

In the United Kingdom, UK National Kidney Federation and Kidney Care UK (previously known as British Kidney Patient Association, BKPA) represent patients, and the Renal Association represents renal physicians and works closely with the National Service Framework for kidney disease.

There is as well an International Office in Brussels, Belgium.



</doc>
<doc id="22031" url="https://en.wikipedia.org/wiki?curid=22031" title="Native Esperanto speakers">
Native Esperanto speakers

Native Esperanto speakers (Esperanto: "denaskuloj" or "denaskaj esperantistoj") are people who have acquired Esperanto as one of their native languages. As of 1996, there were 350 or so attested cases of families with native Esperanto speakers. Estimates from associations indicate that there were around 1,000 Esperanto-speaking families, involving perhaps 2,000 children in 2004. According to a 2019 synthesis of all the estimates made, they would be between several hundred and 2000, and would compose between <1% and 4.5% of the Esperanto community. In all known cases, speakers are natively bilingual, or multilingual, raised in both Esperanto and either the local national language or the native language of their parents. In all but a handful of cases, it was the father who used Esperanto with the child. In the majority of such families, the parents had the same native language, though in many the parents had different native languages, and only Esperanto in common.

Raising children in Esperanto occurred early in the history of the language, notably with the five children of Montagu Butler (1884–1970). Because of this, some families have passed Esperanto on to their children for several generations. Also notable are young Holocaust victim Petr Ginz, whose drawing of the planet Earth as viewed from the moon was carried aboard the Space Shuttle Columbia, and Daniel Bovet, the recipient of the 1957 Nobel Prize in Physiology or Medicine.

Esperanto is not the primary language of any geographic region, outside of temporary gatherings (such as conventions like the World Congress of Esperanto) and isolated offices (such as the World Esperanto Association's central office in Rotterdam). Consequently, native speakers have limited opportunity to meet one another except where meetings are specially arranged. For this reason, many parents consider it important to bring their children regularly to Esperanto conventions such as the annual "Renkontiĝo de Esperanto-familioj" (or "Esperantistaj familioj"; REF, since 1979). Similarly, the annual happens alongside the largest Esperanto convention, the World Congress of Esperanto ("Universala Kongreso").

Below is a list of noted native Esperanto speakers.

The Esperanto of native-speaking children differs from the standard Esperanto spoken by their parents. In some cases this is due to interference from their other native language (the adstrate), but in others it appears to be an effect of acquisition.

Bergen (2001) found the following patterns in a study of eight native-speaking children, aged 6 to 14, who were bilingual in Hebrew (two siblings), Slovak (two siblings), French, Swiss German, Russian, and Croatian.


Among children that do use the accusative, its usage may be regularized from adult usage, at least at young ages. For example, when a screw dropped out of a lock, a young (≤ 5-year-old) child said it "malvenis la pordon." Besides the novel use of "mal-" with "veni" 'to come' to mean 'come away from', the accusative is not used in adult speech for motion away, but only motion towards. However, in this case the child generalized the usage of the accusative for direct objects.

Lindstedt, on the other hand, referencing Bergen's study, contends that "it is difficult to find convincing examples of changes introduced by the process of nativisation. All examples proposed seem rather to be due to (1) transfers from the children’s other native languages, (2) differences between the spoken and written register of Esperanto and, in some cases, (3) incomplete acquisition." Some of the features, such as phonological reduction, can be found in the speech of some fluent non-native speakers, while some other, such as the attrition of the accusative, are completely absent from the speech of some native-speaking children.

Native-speaking children, especially at a young age, may coin words that do not exist in the speech of their parents, often for concepts for which Esperanto has a word they do not yet know, by exploiting the morphology of the language. This is analogous to what adult speakers do for concepts where Esperanto lacks a word, and indicates that some of the grammatical alterations that adult learners may find difficult come easily to native-speaking children. For example,


















</doc>
<doc id="22033" url="https://en.wikipedia.org/wiki?curid=22033" title="Nicaragua v. United States">
Nicaragua v. United States

The Republic of Nicaragua v. The United States of America (1986) was a case where the International Court of Justice (ICJ) held that the U.S. had violated international law by supporting the Contras in their rebellion against the Sandinistas and by mining Nicaragua's harbors. 

The Court had 15 final decisions upon which it voted. In Statement 9, the Court stated that while the U.S. encouraged human rights violations by the Contras by the manual entitled "Psychological Operations in Guerrilla Warfare", this did not make such acts attributable to the U.S.

The case was decided by the ICJ, when the ICJ ruled in favor of Nicaragua and against the United States, to award reparations to Nicaragua.

The Court found in its verdict that the United States was "in breach of its obligations under customary international law not to use force against another State", "not to intervene in its affairs", "not to violate its sovereignty", "not to interrupt peaceful maritime commerce", and "in breach of its obligations under Article XIX of the Treaty of Friendship, Commerce and Navigation between the Parties signed at Managua on 21 January 1956."

The United States refused to participate in the proceedings after the Court rejected its argument that the ICJ lacked jurisdiction to hear the case. The U.S. also blocked enforcement of the judgment by the United Nations Security Council and thereby prevented Nicaragua from obtaining any compensation. Nicaragua, under the later, post-FSLN government of Violeta Chamorro, withdrew the complaint from the court in September 1992 following a repeal of the law which had required the country to seek compensation.

The first armed intervention by the United States in Nicaragua occurred under President Taft. In 1909, he ordered the overthrow of Nicaraguan President José Santos Zelaya. During August and September 1912, a contingent of 2,300 U.S. Marines landed at the port of Corinto and occupied León and the railway line to Granada. A pro-U.S. government was formed under the occupation. The 1914 Bryan–Chamorro Treaty granted perpetual canal rights to the U.S. in Nicaragua and was signed ten days before the U.S.-operated Panama Canal opened for use, thus preventing anyone from building a competing canal in Nicaragua without U.S. permission.

In 1927, under Augusto César Sandino, a major peasant uprising was launched against both the U.S. occupation and the Nicaraguan establishment. In 1933, the Marines withdrew and left the Nicaraguan National Guard in charge of internal security and elections. In 1934, Anastasio Somoza García, the head of the National Guard, ordered his forces to capture and murder Sandino. In 1937, Somoza assumed the presidency, while still in control of the National Guard, and established a dictatorship that his family controlled until 1979.

The downfall of the regime is attributed to its embezzlement of millions of dollars in foreign aid that was given to the country in response to the devastating 1972 earthquake. Many moderate supporters of the dictatorship began abandoning it in the face of growing revolutionary sentiment. The Sandinista (FSLN) movement organized relief, began to expand its influence and assumed the leadership of the revolution. A popular uprising brought the FSLN to power in 1979. The United States had long been opposed to the socialist FSLN, and after the revolution the Carter administration moved quickly to support the Somocistas with financial and material aid. When Ronald Reagan took office, he augmented the direct support to an anti-Sandinista group, called the Contras, which included factions loyal to the former dictatorship. When Congress prohibited further funding to the Contras, Oliver North continued the funding through arms sales that were also prohibited by Congress.

Nicaragua charged:

Nicaragua demanded that all such actions cease and that the United States had an obligation to pay reparations to the government for damage to their people, property, and economy.

It is noteworthy that the United States, the defaulting party, was the only member that put forward arguments against the validity of the judgment of the court, arguing that it passed a decision that it "had neither the jurisdiction nor the competence to render." Members that sided with the United States in opposing Nicaragua's claims did not challenge the court's jurisdiction, its findings, nor the substantive merits of the case.

The very long judgment first listed 291 points, among them that the United States had been involved in the "unlawful use of force". The alleged violations included attacks on Nicaraguan facilities and naval vessels, the mining of Nicaraguan ports, the invasion of Nicaraguan air space, and the training, arming, equipping, financing and supplying of forces (the "Contras") and seeking to overthrow Nicaragua's Sandinista government. This was followed by the statements that the judges voted on.

The court found evidence of an arms flow between Nicaragua and insurgents in El Salvador between 1979–81. However, there was not enough evidence to show that the Nicaraguan government was imputable for this or that the US response was proportional. The court also found that certain transborder incursions into the territory of Guatemala and Costa Rica, in 1982, 1983 and 1984, were imputable to the Government of Nicaragua. However, neither Guatemala nor Costa Rica had made any request for US intervention; El Salvador did in 1984, well after the US had intervened unilaterally.

"As regards El Salvador, the Court considers that in customary international law the provision of arms to the opposition in another State does not constitute an armed attack on that State. As regards Honduras and Costa Rica, the Court states that, in the absence of sufficient information as to the transborder incursions into the territory of those two States from Nicaragua, it is difficult to decide whether they amount, singly or collectively, to an armed attack by Nicaragua. The Court finds that neither these incursions nor the alleged supply of arms may be relied on as justifying the exercise of the right of collective self-defence." 

Regarding human rights violations by the Contras, "The Court has to determine whether the relationship of the contras to the United States Government was such that it would be right to equate the Contras, for legal purposes, with an organ of the United States Government, or as acting on behalf of that Government. The Court considers that the evidence available to it is insufficient to demonstrate the total dependence of the Contras on United States aid. A partial dependency, the exact extent of which the Court cannot establish, may be inferred from the fact that the leaders were selected by the United States, and from other factors such as the organisation, training and equipping of the force, planning of operations, the choosing of targets and the operational support provided. There is no clear evidence that the United States actually exercised such a degree of control as to justify treating the contras as acting on its behalf... Having reached the above conclusion, the Court takes the view that the Contras remain responsible for their acts, in particular the alleged violations by them of humanitarian law. For the United States to be legally responsible, it would have to be proved that that State had effective control of the operations in the course of which the alleged violations were committed."

The Court concluded that the United States, despite its objections, was subject to the Court's jurisdiction. The Court had ruled on November 26 by 11 votes to one that it had jurisdiction in the case on the basis of either Article 36 of the Statute of the International Court of Justice (i.e. compulsory jurisdiction) or the 1956 Treaty of Friendship, Commerce and Navigation between the United States and Nicaragua. The Charter provides that, in case of doubt, it is for the Court itself to decide whether it has jurisdiction, and that each member of the United Nations undertakes to comply with the decision of the Court. The Court also ruled by unanimity that the present case was admissible. The United States then announced that it had "decided not to participate in further proceedings in this case." About a year after the Court's jurisdictional decision, the United States took the further, radical step of withdrawing its consent to the Court's compulsory jurisdiction, ending its previous 40 year legal commitment to binding international adjudication. The Declaration of acceptance of the general compulsory jurisdiction of the International Court of Justice terminated after a 6-month notice of termination delivered by the Secretary of State to the United Nations on October 7, 1985.
Although the Court called on the United States to "cease and to refrain" from the unlawful use of force against Nicaragua and stated that the US was "in breach of its obligation under customary international law not to use force against another state" and ordered it to pay reparations, the United States refused to comply. As a permanent member of the Security Council, the U.S. has been able to block any enforcement mechanism attempted by Nicaragua. On November 3, 1986 the United Nations General Assembly passed, by a vote of 94-3 (El Salvador, Israel and the US voted against), a non-binding resolution urging the US to comply.

On June 27, 1986, the Court made the following ruling:

The Court

The ruling did in many ways clarify issues surrounding prohibition of the use of force and the right of self-defence. Arming and training the Contra was found to be in breach with principles of non-intervention and prohibition of use of force, as was laying mines in Nicaraguan territorial waters.

Nicaragua's dealings with the armed opposition in El Salvador, although it might be considered a breach with the principle of non-intervention and the prohibition of use of force, did not constitute "an armed attack", which is the wording in article 51 justifying the right of self-defence.

The Court considered also the United States claim to be acting in collective self-defence of El Salvador and found the conditions for this not reached as El Salvador never requested the assistance of the United States on the grounds of self-defence.

In regards to laying mines, "...the laying of mines in the waters of another State without any warning or notification is not only an unlawful act but also a breach of the principles of humanitarian law underlying the Hague Convention No. VIII of 1907."

Votes of Judges – Nicaragua v. United States
Judge Schwebel's dissent was twice as long as the actual judgment. Judge Schwebel argued that the Sandinista government came to power with support of foreign intervention similar to what it was now complaining about. He argued that the Sandinista government achieved international recognition and received large amounts of foreign aid in exchange for commitments they subsequently violated. He cited evidence that the Sandinista government had indeed supported the rebels in El Salvador and noted that Nicaragua's own CIA witness contradicted their assertions that they had never at any point supported the rebels in El Salvador. The CIA witness said that there was no evidence of weapon shipments since early 1981, but Schwebel argued that he could not credibly explain why opponents of Contra aid such as Congressman Boland, who also saw the evidence, believed that weapon shipments were ongoing. He further argued that Daniel Ortega publicly admitted such shipments in statements in 1985 and 1986. Furthermore, there was no dispute that the leadership of the rebels operated in Nicaragua from time to time.

He stated that in August 1981 the U.S. offered to resume aid to Nicaragua and to not support regime change in exchange for Nicaraguan commitments to not support the rebels in El Salvador. These proposals were rejected by the Sandinistas, and judge Schwebel argued that the U.S. was entitled to take action in collective self-defense with El Salvador by authorizing Contra aid in December 1981. He stated that further U.S. proposals to resolve the issue made in early 1982 were also ignored by the Sandinistas. The Sandinista government in 1983 began advancing proposals in which it would undertake not to support the rebels, but Schwebel noted that these were coupled with demands that the U.S. cease supporting the lawful government of El Salvador. The judge noted that since early 1985 the U.S. had increasingly made regime change a primary objective but argued this was not inconsistent with self-defense because it was reasonable to believe that Nicaragua would not maintain any commitments unless Sandinista power was diluted.

The judge said that both sides of the wars in Nicaragua and El Salvador had committed atrocities. He said the U.S. mining of Nicaraguan harbors was unlawful in regard to third parties, but not Nicaragua.

The first witness called by Nicaragua was Nicaragua's first Vice Minister of the Interior, Commander Luis Carrion. Commander Carrion had overall responsibility for state security and was in charge of all government operations in the "principal war zone". He was responsible for monitoring United States involvement in military and paramilitary activities against Nicaragua, directing Nicaragua's military and intelligence efforts against the contra guerrillas.

Commander Carrion began by explaining the condition of the contras prior to United States' aid in December 1981. Commander Carrion stated that the contras consisted of insignificant bands of poorly armed and poorly organized members of Somoza's National Guard, who carried out uncoordinated border raids and rustled cattle (presumably for food).

In December 1981, the U.S. Congress authorized an initial appropriation of 19 million dollars to finance paramilitary operations in Nicaragua and elsewhere in Central America. Because of this aid, Commander Carrion stated that the contras began to become centralized and received both training and weapons from the CIA. During 1982 the contra guerrillas engaged the Sandinista armed forces in a series of hit and run border raids and carried out a number of sabotage operations including:

The United States Central Intelligence Agency, and Argentine military officers financed by the CIA, were engaged in the training of the contra forces. The guerrillas received both basic infantry training as well as training in specialized sabotage and demolition for "special operation groups".

The U.S. Congress apportioned new funds for the contras to the amount of $30 million at the end of 1982. This made it possible for the contra forces to launch a military offensive against Nicaragua. According to Commander Carrion, the offensive known as "C Plan" had the objective of capturing the Nicaraguan border town of Jalapa in order to install a provisional government, which could receive international recognition. This plan failed.

After the failure of the Jalapa offensive the contras changed their tactics from frontal assaults to economic warfare against State farms, coffee plantations, grain storage centers, road junctions, etc.

The CIA began to support the contras by setting up and coordinating a communications and logistical system. The CIA supplied aircraft and the construction of airfields in the Honduran border area next to Nicaragua. This allowed the contras to carry out deep penetration raids into the more developed and populated areas of the Nicaraguan interior. U.S. Army engineers created this airfield. The purpose of these deep penetration attacks upon economic targets was to weaken the Nicaraguan economy, causing a shortages of goods.

As a part of its training program for the contras, the CIA prepared and distributed a manual entitled Psychological Operations in Guerrilla Warfare. This manual included instructions in the "use of implicit and explicit terror", and in the "selective use of violence for propaganda effects". Commander Carrion explained that the manual was given to the Contras, "All of these terrorist instructions have the main purpose of alienating the population from the Government through creating a climate of terror and fear, so that nobody would dare support the Government". The manual calls for the "neutralization" (i.e. assassination) of Sandinista local government officials, judges, etc. for purposes of intimidation. It was openly admitted by the President Reagan in a press conference that the manual had been prepared by a CIA contract employee.

After the United States Congress approved an additional $24 million aid to the contras in December 1983, a new offensive was launched, named Plan Sierra. This offensive involved approximately 7000 members of the contra forces. As in earlier attacks, the initial objective of this offensive was to capture the border town of Jalapa to install a provisional government, which the CIA informed the contras would be immediately recognized by the United States Government. But this contra offensive was also repulsed by the Nicaraguan government forces.

In the beginning of 1984, the contras made a major effort to prevent the harvesting of the coffee crop, which is one of Nicaragua's most important export products. Coffee plantations and state farms where coffee is grown were attacked, vehicles were destroyed, and coffee farmers were killed.

Commander Carrion testified that the ability of the contras to carry out military operations was completely dependent upon United States funding, training and logistical support. Carrion stated that the U.S. Government supplied the contras with uniforms, weapons, communications equipment, intelligence, training, and coordination in using this material aid.

In September 1983, CIA operatives blew up Nicaragua's only oil pipeline, which was used to transport oil from off-loading facilities to storage tanks on shore. The United States was also directly involved in a large scale sabotage operation directed against Nicaragua's oil storage facilities. This last attack was carried out by CIA contract employees termed by that organization as "Unilaterally Controlled Latin Assets" (UCLAs). The CIA personnel were also directly involved in a helicopter attack on a Nicaraguan army training camp. One of the helicopters was shot down by Nicaraguan ground fire resulting in the death of two U.S. citizens.

Commander Carrion testified that the United States was involved in the mining of Nicaragua's ports between February – April 1984. The mining operation was carried out by CIA ships directing the operation from international waters, while the actual mining was carried out by CIA employees on board speedboats operating inshore. After the mine-laying was completed the speedboats returned to the mother vessel.

Carrion stated that 3,886 people had been killed and 4,731 wounded in the four years since the contras began their attacks. Carrion estimated property damage at $375 million.

Commander Carrion stated if the United States stopped aid, support and training, this would result in the end of the contras military activities within three months. Asked why he was so sure of this, Commander Carrion answered, "Well, because the contras are an artificial force, artificially set up by the United States, that exists only because it counts on United States direction, on United States training, on United States assistance, on United States weapons, on United States everything...Without that kind of support and direction the contras would simply disband, disorganize, and thus lose their military capacity in a very short time".

David MacMichael was an expert on counter-insurgency, guerrilla warfare, and Latin American affairs, he was also a witness because he was closely involved with U.S. intelligence activities as a contract employee from March 1981 – April 1983. MacMichael worked for Stanford Research Institute, which was contracted by the U.S. Department of Defense. After this he worked two years for the CIA as a "senior estimates officer", preparing the National Intelligence Estimate. Dr. MacMichael's responsibility was centered upon Central America. He had top-secret clearance. He was qualified and authorized to have access to all relevant U.S. intelligence concerning Central America, including intelligence relating to alleged Nicaraguan support for, and arms shipments to the anti-Government insurgents in El Salvador. He took part in high level meetings of the Latin American affairs office of the CIA. Including a fall 1981 meeting, which submitted the initial plan to set up a 1500-man covert force on the Nicaraguan border, shipping arms from Nicaragua to the El Salvador insurgents. This plan was approved by President Reagan.

"The overall purpose (for the creation of the contras) was to weaken, even destabilize the Nicaraguan Government and thus reduce the menace it allegedly posed to the United States' interests in Central America..."

Contra paramilitary actions would "hopefully provoke cross-border attacks by Nicaraguan forces and thus serve to demonstrate Nicaragua's aggressive nature and possibly call into play the Organization of American States' provisions (regarding collective self-defense). It was hoped that the Nicaraguan Government would clamp down on civil liberties within Nicaragua itself, arresting its opposition, so demonstrating its allegedly inherent totalitarian nature and thus increase domestic dissent within the country, and further that there would be reaction against United States citizens, particularly against United States diplomatic personnel within Nicaragua and thus to demonstrate the hostility of Nicaragua towards the United States".

Mr. Glennon testified about a fact-finding mission he had conducted in Nicaragua to investigate alleged human rights violations committed by the Contra guerrillas, sponsored by the International Human Rights Law Group, and the Washington Office on Latin America. Glennon conducted the investigation with Mr. Donald T. Fox who is a New York attorney and a member of the International Commission of Jurists.

They traveled to Nicaragua, visiting the northern region where the majority of contra military operations took place. The two lawyers interviewed around 36 northern frontier residents who had direct experience with the contras. They also spoke with the U.S. Ambassador to Nicaragua, and with senior officials of the U.S. Department of State in Washington after returning to the United States.

No hearsay evidence was accepted. Professor Glennon stated that those interviewed were closely questioned and their evidence was carefully cross-checked with available documentary evidence. Doubtful "testimonies" were rejected, and the results were published in April 1985.

The conclusions of the report were summarized by Glennon in Court:

We found that there is substantial credible evidence that the contras were engaged with some frequency in acts of terroristic violence directed at Nicaraguan civilians. These are individuals who have no connection with the war effort-persons with no economic, political or military significance. These are Individuals who are not caught in the cross-fire between Government and contra forces, but rather individuals who are deliberately targeted by the contras for acts of terror. "Terror" was used in the same sense as in recently enacted United States law, i.e. "an activity that involves a violent act or an act dangerous to human life that Is a violation or the criminal law, and appears to be intended to intimidate or coerce a civilian population, to Influence the policy of a government by intimidation or coercion, or to affect the conduct of a government by assassination or kidnapping.

In talks with U.S. State Department officials, at those in Managua U.S. Embassy, and with officials in Washington, Professor Glennon had inquired whether the U.S. Government had ever investigated human rights abuses by the contras. Professor Glennon testified that no such investigation had ever been conducted, because in the words of a ranking State Department official who he could not name, the U.S. Government maintained a policy of "intentional ignorance" on the matter. State Department officials in Washington- had admitted to Glennon that "it was clear that the level of atrocities was enormous". Those words "enormous" and "atrocities" were the ranking State Department official's words.

Father Jean Loison was a French priest who worked as a nurse in a hospital in the northern frontier region close to Honduras.

Asked whether the contras engaged in acts of violence directed against the civilian population, Father Loison answered:

Yes, I could give you several examples. Near Quilali, at about 30 kilometers east of Quilali, there was a little village called El Coco. The contras arrived, they devastated it, they destroyed and burned everything. They arrived in front of a little house and turned their machinegun fire on it, without bothering to check if there were any people inside. Two children, who had taken fright and hidden under a bed, were hit. I could say the same thing of a man and woman who were hit, this was in the little co-operative of Sacadias Olivas. It was just the same. They too had taken fright and got into bed. Unlike El Coco, the contras had just been on the attack, they had encountered resistance and were now in flight. During their flight they went into a house, and seeing that there were people there, they threw grenade. The man and the woman were killed and one of the children was injured.

About contra kidnappings:

I would say that kidnappings are one of the reasons why some of the peasants have formed themselves into groups. Here (indicates a point on the map) is Quilali. Between Quilali and Uilili, in this region to the north, there are hardly any peasants left of any age to bear arms, because they have all been carried off.

Father Loison described many examples of violence, mostly indiscriminate, directed at the civilian population in the region where he resides. The picture that emerges from his testimony is that the contras engage in brutal violation of minimum standards of humanity. He described murders of unarmed civilians, including women and children, rape followed in many instances by torture or murder, and indiscriminate terror designed to coerce the civilian population. His testimony was similar to various reports including the International Human Rights Law Group, Amnesty International, and others.

William Hüper was Nicaragua's Minister of Finance. He testified about Nicaragua economic damage, including the loss of fuel as a result of the attack in the oil storage facilities at Corinto, the damage to Nicaragua's commerce as a result of the mining of its ports, and other economic damage.

After five vetoes in the Security Council between 1982 and 1985 of resolutions concerning the situation in Nicaragua , the United States made one final veto on 28 October 1986 (France, Thailand, and United Kingdom abstaining) of a resolution calling for full and immediate compliance with the judgment.

Nicaragua brought the matter to the U.N. Security Council, where the United States vetoed a resolution (11 to 1, 3 abstentions) calling on all states to observe international law. Nicaragua also turned to the General Assembly, which passed a resolution 94 to 3 calling for compliance with the World Court ruling. Two states, Israel and El Salvador, joined the United States in opposition. At that time, El Salvador was receiving substantial funding and military advisement from the U.S., which was aiming to crush a Sandinista-like revolutionary movement by the FMLN. At the same session, Nicaragua called upon the U.N. to send an independent fact-finding mission to the border to secure international monitoring of the borders after a conflict there; the proposal was rejected by Honduras with U.S. backing. A year later, on November 12, 1987, the General Assembly again called for "full and immediate compliance" with the World Court decision. This time only Israel joined the United States in opposing adherence to the ruling.

The United States refused to participate in the merits phase of the proceedings, but the Court found that the US refusal did not prevent it from deciding the case. The Court also rejected the United States defense that its action constituted collective self-defense.
The United States argued that the Court did not have jurisdiction, with U.S. ambassador to the United Nations Jeane Kirkpatrick dismissing the Court as a "semi-legal, semi-juridical, semi-political body, which nations sometimes accept and sometimes don't." 

The United States had signed the treaty accepting the Court's decision as binding, but with the exception that the court would not have the power to hear cases based on multilateral treaty obligations unless it involved all parties to the treaty affected by that decision or the United States specially agreed to jurisdiction. The court found that it was obliged to apply this exception and refused to take on claims by Nicaragua based on the United Nations Charter and Organization of American States charter, but concluded that it could still decide the case based on customary international law obligations with 11-4 majority.

After five vetoes in the Security Council between 1982 and 1985 of resolutions concerning the situation in Nicaragua , the United States made one final veto on 28 October 1986 (France, Thailand, and United Kingdom abstaining) of a resolution calling for full and immediate compliance with the Judgement.

When a similar but crucially non-binding resolution was brought before the United Nations General Assembly on 3 November it was passed. Only El Salvador and Israel voted with the U.S. against it. El Salvador's ruling junta was at that time receiving substantial funding and military advisement from the U.S., which was aiming to crush a Sandinista-like revolutionary movement by the FMLN. In spite of this resolution, the U.S. still chose not to pay the fine.

Professor of International Law, Anthony D'Amato, writing for the "American Journal of International Law" (Vol. 80, 1986), commented on this case, stating that "...law would collapse if defendants could only be sued when they agreed to be sued, and the proper measurement of that collapse would be not just the drastically diminished number of cases but also the necessary restructuring of a vast system of legal transactions and relations predicated on the availability of courts as a last resort. There would be talk of a return to the law of the jungle." The author also notes that the case resulted in an unusual candor. A month after the announced withdrawal, Secretary of State Shultz suggested, and President Reagan later confirmed in a press conference, that the goal of U.S. policy was to overthrow the Sandinista Government of Nicaragua. Although this was what Nicaragua had alleged to be the U.S. goal, while the case was actively pending, the United States could not concede that goal without serious risk of undermining its litigating position.




</doc>
<doc id="22034" url="https://en.wikipedia.org/wiki?curid=22034" title="Naturalistic planned language">
Naturalistic planned language

A naturalistic planned language is a constructed language specifically devised to reproduce the commonalities in morphology and vocabulary from a group of closely related languages, usually with the idea that such a language will be relatively easier to use passively -- in many cases, without prior study -- by speakers of one or more languages in the group.

The term is most commonly used to apply to planned languages predominantly based on the Romance languages, best known of which are Interlingue (previously known as "Occidental") and Interlingua. Both were designed to serve as international auxiliary languages. However, there are also languages intended for speakers of a particular language family (zonal constructed languages), including Pan-Germanic, Pan-Slavic and even Pan-Celtic naturalistic planned languages.

Since the creation of such a language often includes shared idiosyncrasies from the source languages, active use seems to be generally more difficult to learn than for schematic planned languages, though because of grammatical simplification considerably easier than for ethnic languages of the same type.


</doc>
<doc id="22035" url="https://en.wikipedia.org/wiki?curid=22035" title="No-cloning theorem">
No-cloning theorem

In physics, the no-cloning theorem states that it is impossible to create an independent and identical copy of an arbitrary unknown quantum state, a statement which has profound implications in the field of quantum computing among others. The theorem is an evolution of the 1970 no-go theorem authored by James Park, in which he demonstrates that a non-disturbing measurement scheme which is both simple and perfect cannot exist (the same result would be independently derived in 1982 by Wootters and Zurek as well as Dieks the same year). One should note that the aforementioned theorems do not preclude the state of one system becoming entangled with the state of another as cloning specifically refers to the creation of a separable state with identical factors. For example, one might use the controlled NOT gate and the Walsh–Hadamard gate to entangle two qubits without violating the no-cloning theorem as no well-defined state may be defined in terms of a subsystem of an entangled state. The no-cloning theorem (as generally understood) concerns only pure states whereas the generalized statement regarding mixed states is known as the no-broadcast theorem.

The no-cloning theorem has a time-reversed dual, the no-deleting theorem. Together, these underpin the interpretation of quantum mechanics in terms of category theory, and, in particular, as a dagger compact category. This formulation, known as categorical quantum mechanics, allows, in turn, a connection to be made from quantum mechanics to linear logic as the logic of quantum information theory (in the same sense that intuitionistic logic arises from Cartesian closed categories).

According to Asher Peres and David Kaiser, the publication of the 1982 proof of the no-cloning theorem by
Wootters and Zurek and by Dieks was prompted by a proposal of Nick Herbert for a superluminal communication device using quantum entanglement. However, Ortigoso pointed out in 2018 that a complete proof along with an interpretation in terms of the lack of simple nondisturbing measurements in quantum mechanics was already delivered by Park in 1970.

Suppose we have two quantum systems "A" and "B" with a common Hilbert space formula_1. Suppose we want to have a procedure to copy the state formula_2 of quantum system "A", in quantum system "B" irrespective of the original state formula_2 (see bra–ket notation). That is, beginning with the state formula_2, we want to end up with the state formula_5 To make a "copy" of the state "A", we combine it with system "B" in some unknown initial, or blank, state formula_6 independent of formula_2, of which we have no prior knowledge. The state of the composite system is then described by the following tensor product:

(in the following we will omit the formula_9 symbol and keep it implicit). There are only two permissible quantum operations with which we may manipulate the composite system.

We can perform an observation, which irreversibly collapses the system into some eigenstate of an observable, corrupting the information contained in the qubit(s). This is obviously not what we want.

Alternatively, we could control the Hamiltonian of the "combined" system, and thus the time-evolution operator "U"("t"), e.g. for a time-independent Hamiltonian, formula_10. Evolving up to some fixed time formula_11 yields a unitary operator "U" on formula_12, the Hilbert space of the combined system. However, no such unitary operator "U" can clone all states.

Theorem: There is no unitary operator "U" on formula_12 such that for all normalised states formula_14 and formula_6 in formula_16

for some real number formula_18 depending on formula_19 and formula_20.

The extra phase factor expresses the fact that a quantum-mechanical state defines a normalised vector in Hilbert space only up to a phase factor i.e. as an element of projectivised Hilbert space.

To prove the theorem, we select an arbitrary pair of states formula_2 and formula_22 in the Hilbert space formula_16. Because "U" is unitary,

Since the quantum state formula_25 is assumed to be normalized, we thus get

This implies that either formula_27 or formula_28. Hence by the Cauchy–Schwarz inequality either formula_29 or formula_19 is orthogonal to formula_31. However, this cannot be the case for two "arbitrary" states. Therefore, a single universal "U" cannot clone a "general" quantum state. This proves the no-cloning theorem.

Take a qubit for example. It can be represented by two complex numbers, called probability amplitudes (normalised to 1), that is three real numbers (two polar angles and one radius). Copying three numbers on a classical computer using any copy and paste operation is trivial (up to a finite precision) but the problem manifests if the qubit is unitarily transformed (e.g. by the Hadamard quantum gate) to be polarised (which unitary transformation is a surjective isometry). In such a case the qubit can be represented by just two real numbers (one polar angle and one radius equal to 1), while the value of the third can be arbitrary in such a representation. Yet a realisation of a qubit (polarisation-encoded photon, for example) is capable of storing the whole qubit information support within its "structure". Thus no single universal unitary evolution "U" can clone an arbitrary quantum state according to the no-cloning theorem. It would have to depend on the transformed qubit (initial) state and thus would not have been "universal".

In the statement of the theorem, two assumptions were made: the state to be copied is a pure state and the proposed copier acts via unitary time evolution. These assumptions cause no loss of generality. If the state to be copied is a mixed state, it can be purified. Alternately, a different proof can be given that works directly with mixed states; in this case, the theorem is often known as the no-broadcast theorem. Similarly, an arbitrary quantum operation can be implemented via introducing an ancilla and performing a suitable unitary evolution. Thus the no-cloning theorem holds in full generality.

Non-clonability can be seen as a property of arbitrary sets of quantum states. If we know that a system's state is one of the states in some set S, but we do not know which one, can we prepare another system in the same state? If the elements of S are pairwise orthogonal, the answer is always yes: for any such set there exists a measurement which will ascertain the exact state of the system without disturbing it, and once we know the state we can prepare another system in the same state.

On the other hand, if S contains a pair of elements that are not pairwise orthogonal, then an argument like that given above shows that the answer is no. So even if we can narrow down the state of a quantum system to just "two" possibilities, we still cannot clone it in general (unless the states happen to be orthogonal).

Another way of stating the no-cloning theorem is that amplification of a quantum signal can only happen with respect to some orthogonal basis. This is related to the emergence of the rules of classical probability via quantum decoherence.

There is a classical analogue to the quantum no-cloning theorem, which might be stated as follows: given only the result of one flip of a (possibly biased) coin, we cannot simulate a second, independent toss of the same coin. The proof of this statement uses the linearity of classical probability, and has exactly the same structure as the proof of the quantum no-cloning theorem. Thus, in order to claim that no-cloning is a uniquely quantum result, some care is necessary in stating the theorem. One way of restricting the result to quantum mechanics is to restrict the states to pure states, where a pure state is defined to be one that is not a convex combination of other states. The classical pure states are pairwise orthogonal, but quantum pure states are not.

In logic, the idea of no-cloning and no-deleting correspond to the notion of disallowing two rules of inference: the rule of weakening (monotonicity of entailment) and the rule of contraction (idempotency of entailment). The removal of these two rules of inference from classical logic results in linear logic, which is the form of logic that describes quantum systems (or, more generally, the behavior of tensor products on Hilbert spaces).


Even though it is impossible to make perfect copies of an unknown quantum state, it is possible to produce imperfect copies. This can be done by coupling a larger auxiliary system to the system that is to be cloned, and applying a unitary transformation to the combined system. If the unitary transformation is chosen correctly, several components of the combined system will evolve into approximate copies of the original system. In 1996, V. Buzek and M. Hillery showed that a universal cloning machine can make a clone of an unknown state with the surprisingly high fidelity of 5/6.

Imperfect cloning can be used as an eavesdropping attack on quantum cryptography protocols, among other uses in quantum information science.



</doc>
<doc id="22036" url="https://en.wikipedia.org/wiki?curid=22036" title="Norman Hackerman">
Norman Hackerman

Norman Hackerman (March 2, 1912 – June 16, 2007) was an American chemist, professor, and academic administrator who served as the 18th President of the University of Texas at Austin (1967–1970) and later as the 4th President of Rice University (1970–1985). He was an internationally known expert in metal corrosion.

Born in Baltimore, Maryland, he was the only son of Jacob Hackerman and Anna Raffel, immigrants from the Baltic regions of the Russian Empire that later became Estonia and Latvia, respectively.

Hackerman earned his bachelor's degree in 1932 and his doctor's degree in chemistry in 1935 from Johns Hopkins University. He taught at Johns Hopkins, Loyola College in Baltimore and the Virginia Polytechnic Institute and State University in Blacksburg, Virginia, before working on the Manhattan Project in World War II.

He joined the University of Texas in 1945 as an assistant professor of chemistry, became an associate professor in 1946, a full professor in 1950, a department chair in 1952, dean of research in 1960, vice president and provost in 1961, and vice chancellor for academic affairs for the University of Texas System in 1963. Hackerman left the University of Texas in 1970 for Rice, where he retired 15 years later. He was named professor emeritus of chemistry at the University of Texas in 1985 and taught classes until the end of his life. 

He was a member of the National Academy of Sciences and the American Academy of Arts and Sciences. Among his many honors are the Olin Palladium Award of the Electrochemical Society, the Gold Medal of the American Institute of Chemists (1978), the Charles Lathrop Parsons Award, the Vannevar Bush Award and the National Medal of Science. He was awarded the Acheson Award by the Electrochemical Society in 1984.

Hackerman served on advisory committees and boards of several technical societies and government agencies, including the National Science Board, the Texas Governor's Task Force on Higher Education and the Scientific Advisory Board of the Welch Foundation. He also served as editor of the "Journal of the Electrochemical Society" and as president of the Electrochemical Society.

Hackerman's wife of 61 years, Gene Coulbourn, died in 2002; they had three daughters and one son.

In 1982 The Electrochemical Society created the Norman Hackerman Young Author Award to honor the best paper published in the Journal of the Electrochemical Society for a topic in the field of electrochemical science and technology by a young author or authors. In 2000 the Welch Foundation created the Norman Hackerman Award in Chemical Research to recognize the work of young researchers in Texas. The Rice Board of Trustees established the Norman Hackerman Fellowship in Chemistry in honor of Hackerman's 90th birthday in 2002. In 2008, the original Experimental Science Building at the University of Texas at Austin campus was demolished and rebuilt as the Norman Hackerman Experimental Science Building in his name and honor. The building was completed in late 2010, with the opening and dedication ceremony on March 2, 2011, which was both Hackerman's 99th Birthday and the 175th Anniversary of Texas Independence. The main building at the J. Erik Jonsson Center of the National Academy of Sciences is Hackerman House, named in his honor. Hackerman House overlooks Quissett Harbor in Woods Hole MA, on Cape Cod.



 


</doc>
<doc id="22037" url="https://en.wikipedia.org/wiki?curid=22037" title="N ray">
N ray

N rays (or N-rays) were a hypothesized form of radiation, described by Prosper-René Blondlot in 1903, and initially confirmed by others, but subsequently found to be illusory.

The N ray affair occurred shortly after a series of major breakthroughs in experimental physics. Victor Schumann discovered vacuum ultraviolet radiation in 1893, Wilhelm Röntgen discovered X-rays in 1895, Henri Becquerel discovered radioactivity in 1896, and, in 1897, J. J. Thomson discovered electrons, showing that they were the constituents of cathode rays. This created an expectation within the scientific community that other forms of radiation might be discovered.

At this time, Prosper-René Blondlot was a professor of physics at the University of Nancy studying electromagnetic radiation. Blondlot was a respected member of the scientific community: he was one of eight physicists who were corresponding members of the French Academy of Sciences and was awarded the Academy's Gaston Planté prize in 1893 and the LaCaze prize in 1899. His attempts to measure the speed of electromagnetic waves were commended by Thomson and Henri Poincaré. After the discovery of X-rays, Blondlot began investigating the nature of X-rays, trying to determine whether they behaved as particles or electromagnetic waves. (This was before wave-particle duality became widely accepted among scientists.)

In 1903, Blondlot announced his discovery while working at the University of Nancy and attempting to polarize X-rays. He had perceived changes in the brightness of an electric spark in a spark gap placed in an X-ray beam which he photographed, and he later attributed to the novel form of radiation, naming this the "N rays" for the University of Nancy. Blondlot, Augustin Charpentier, Arsène d'Arsonval and approximately 120 other scientists in 300 published articles claimed to be able to detect N rays emanating from most substances, including the human body with the peculiar exceptions that they were not emitted by green wood and by some treated metals. Most researchers of the subject at the time used the perceived light of a dim phosphorescent surface as "detectors", although work in the period clearly showed the change in brightness to be a physiological phenomenon rather than some actual change in the level of illumination. Physicists Gustave le Bon and P. Audollet and spiritualist Carl Huter even claimed the discovery as their own, leading to a commission of the Académie des sciences to decide priority.

The "discovery" excited international interest and many physicists worked to replicate the effects. However, the notable physicists Lord Kelvin, William Crookes, Otto Lummer, and Heinrich Rubens failed to do so. Following his own failure, self-described as "wasting a whole morning", the American physicist Robert W. Wood, who had a reputation as a popular "debunker" of nonsense during the period, was prevailed upon by the British journal "Nature" to travel to Blondlot's laboratory in France to investigate further. Wood suggested that Rubens should go since he had been the most embarrassed when Kaiser Wilhelm II of Germany asked him to repeat the French experiments, and then after two weeks Rubens had to report his failure to do so. Rubens, however, felt it would look better if Wood went, since Blondlot had been most polite in answering his many questions.

In the darkened room during Blondlot's demonstration, Wood surreptitiously removed an essential prism from the experimental apparatus, yet the experimenters still said that they observed N rays. Wood also stealthily swapped a large file that was supposed to be giving off N rays with an inert piece of wood, yet the N rays were still "observed". His report on these investigations were published in "Nature",
and they suggested that the N rays were a purely subjective phenomenon, with the scientists involved having recorded data that matched their expectations. There is reason to believe that Blondlot in particular was misled by his laboratory assistant, who confirmed all observations. By 1905, no one outside of Nancy believed in N rays, but Blondlot himself is reported to have still been convinced of their existence in 1926. Martin Gardner, referencing Wood's biographer William Seabrook's account of the affair, attributed a subsequent decline in mental health and eventual death of Blondlot to the resulting scandal, but there is evidence that this is at least some exaggeration of the facts.

The term "N ray" was added to dictionaries upon its announcement and was described as a real phenomenon until at least the 1940s. For instance, the 1946 Webster's Dictionary defined it as "An emanation or radiation from certain hot bodies which increases the luminosity without increasing the temperature: as yet, not fully determined."

The incident is used as a cautionary tale among scientists on the dangers of error introduced by experimenter bias. N rays were cited as an example of pathological science by Irving Langmuir. Nearly identical properties of an equally unknown radiation had been recorded about 50 years before in another country by Carl Reichenbach in his treatise "Researches on Magnetism, Electricity, Heat, Light, Crystallization, and Chemical Attraction in their relations to the Vital Force" in 1850, and before that in Vienna by Franz Mesmer in his "Mémoire on the Discovery of Animal-Magnetism" in 1779. It is clear that Reichenbach was aware of Mesmer's work and that researchers in Paris working with Blondlot were aware of Reichenbach's work, although there is no proof that Blondlot was personally aware of it.

A park in central Nancy is named after Blondlot. He left his house and garden to the city, which transformed it into a public park. James Randi reported that many citizens of Nancy and members of the faculty at the university did not remember having heard about N-rays or of Blondlot.




</doc>
<doc id="22039" url="https://en.wikipedia.org/wiki?curid=22039" title="Nikolai Kuznetsov (admiral)">
Nikolai Kuznetsov (admiral)

Nikolay Gerasimovich Kuznetsov (; 24 July 1904 – 6 December 1974) was a Soviet naval officer who achieved the rank of Admiral of the Fleet of the Soviet Union and served as People's Commissar of the Navy during the Second World War. The N. G. Kuznetsov Naval Academy and the Russian aircraft carrier are named in his honor.

Kuznetsov was born into a peasant family in the village of Medvedki, Velikoustyuzhsky Uyezd, Vologda Governorate, Russian Empire (now in Kotlassky District of Arkhangelsk Oblast, Russia). His father, a Serbian immigrant, had settled in Russia before the turn of the century.

In 1919 Kuznetsov joined the Northern Dvina Naval Flotilla, having added two years to his age to make himself eligible to serve. In 1920 he was stationed at Petrograd and in 1924, as a member of a naval unit, he attended the funeral ceremony of Vladimir Lenin.

That same year he joined the Communist Party.

Upon graduation from the Frunze Higher Naval School in 1926 Kuznetsov served on the cruiser , first as watch officer and then as First Lieutenant. In 1932 he graduated from the Naval College after studying operational tactics. Upon graduation, he was offered two options – a desk job with the general staff or a command post on a ship.

Kuznetsov successfully applied for the post of executive officer on the cruiser . Within a year the young officer earned his next promotion. In 1934 he returned to the "Chervona Ukraina", this time as her commander. Under Kuznetsov the ship became an outstanding example of discipline and organization, quickly drawing attention to her young captain.

From 5 September 1936 to 15 August 1937, Kuznetsov served as the Soviet naval attaché and chief naval advisor to Republican Spain. During the early stages of the Spanish Civil War of 1936-1939 he developed a strong dislike of fascism.

On returning home, on January 10, 1938, he was promoted to the rank of flag officer, 2nd rank, and given command of the Pacific Fleet. While in this position, he came face to face with Stalin's purge of the military. Kuznetsov himself was never implicated, but many of the officers under his command were. Kuznetsov resisted the purges at every step, and his intervention saved the lives of many Soviet officers.

On 28 April 1939, Kuznetsov, still only thirty-four, was appointed the People's Commissar (Minister) of the Navy, a post he would hold throughout the Second World War until 1946. In 1939, despite Stalin's negative attitude to the Nikolaevsky Engineering Academy, Nikolay Gerasimovich Kuznetsov ordered the return of the Naval Engineering faculty from Moscow to Leningrad, and set up the Military Engineering-Technical University to educate engineers for the construction of naval bases.

Kuznetsov played a crucial role during the first hours of the war – at this pivotal moment, his resolve and blatant disregard for orders averted the destruction of the Soviet Navy. By June 21, 1941, Kuznetzov was convinced of the inevitability of war with Nazi Germany. On the same day Semyon Timoshenko and Georgy Zhukov issued a directive prohibiting Soviet commanders from responding to "German provocations". The Navy, however, constituted a distinct ministry (narkomat), and thus Kuznetsov held a position which was technically outside the direct chain of command. He utilized this fact in a very bold move.

Shortly after midnight on the morning of June 22, Kuznetsov ordered all Soviet fleets to battle readiness. At 3:15 am that same morning, the Wehrmacht began Operation Barbarossa. The Soviet Navy was the only branch of the military in the highest state of combat readiness at the start of the initial German push.

In the following two years, Kuznetsov's primary concern was the protection of the Caucasus from a German invasion. Throughout the war, the Black Sea remained the primary theater of operations for the Soviet Navy. During the war years Kuznetsov honed Soviet methods of amphibious assault. A notable subordinate in the Black Sea and in command of the Azov Flotilla was S.G. Gorshkov who would later succeed him as Commander-in-Chief of the Navy. In May 1944 he was given the rank of Admiral of the Fleet – a newly created position initially equated to that of a four-star general. In the same year, Kuznetsov was given the title of Hero of the Soviet Union. On May 31, 1945, his rank was equated to the rank of Marshal of the Soviet Union with a similar insignia.

From 1946 to 1947 he was the Deputy Minister of the USSR Armed Forces and Commander-in-Chief of the Naval Forces.

In 1947 he was removed from his post on Stalin's orders and in 1948 he, as well as several other admirals were put on trial by the Naval Tribunal. Kuznetsov was demoted to vice-admiral, while the other admirals received prison sentences of varying length.

In 1951 Stalin ended Kuznetsov's pariah status, once again placing him in command of the Navy (as the Minister of the Navy of the USSR), but without restoring his military rank, which was returned to him upon Stalin's death in 1953. In the same year, he became the First Deputy Minister of Defense of the USSR. In 1955, Kuznetsov was made Commander-in-Chief of the Naval Forces. His rank was raised to Admiral of the Fleet of the Soviet Union and he was awarded the Marshal's Star.

His newfound prominence brought him into direct conflict with now Defense Minister Marshal Zhukov, with whom he had clashed during the war years. On December 8, 1955, using the loss of the battleship as a pretext, Zhukov removed the Admiral from his post. The commission that inspected the ship's loss was headed by Vyacheslav Malyshev and its findings were used by Zhukov to blame Kuznetsov. In February 1956 he was again demoted to the rank of vice-admiral, retired and expressly forbidden "any and all work connected with the navy."

During his retirement he wrote and published many essays and articles, as well as several longer works, including his memoirs and an officially sanctioned book, "With a Course for Victory", which dealt with the Patriotic War. His memoirs, unlike those of many other prominent leaders, were written by him personally and are noted for their style.

Kuznetsov also authored several books on the war, on Stalin's repressions, and on the navy which were published posthumously. In these he was highly critical of the Party's interference in the internal affairs of the military, and insisted that "the state must be ruled by law."

After the retirement of Zhukov in 1957, and of Khrushchev in 1964, a group of naval veterans began a campaign addressed to the Soviet leadership to restore Kuznetsov's rank, with all benefits, and to make him one of the General Inspectors of the Ministry of Defence. Invariably, these requests fell on deaf ears. Not until July 26, 1988 under Andrey Gromyko did the Presidium of the Supreme Soviet of the USSR reinstate Kuznetsov to his former rank of Admiral of the Fleet of the Soviet Union. Kuznetzov is now recognized as one of the most prominent men in the history of the Soviet and, today, of the Russian Navy.

"Personal ranks for the Russian Navy were abolished in 1918, and were only restored in 1935, excepting the various ranks of admiral which were not restored until 1940."




"My whole life has been the Soviet Navy. I made my choice when young and have never regretted it."





</doc>
<doc id="22042" url="https://en.wikipedia.org/wiki?curid=22042" title="Nuon (DVD technology)">
Nuon (DVD technology)

Nuon is a technology developed by VM Labs that adds features to a DVD player. In addition to viewing DVDs, one can play 3D video games and use enhanced DVD navigational tools such as zoom and smooth scanning of DVD playback. One could also play CDs while the Nuon graphics processor generates synchronized graphics on the screen. There were plans to provide Internet access capability in the next generation of Nuon-equipped DVD players.

Nuon originally started off as "Project X," and was featured in "Electronic Gaming Monthly"s 1999 Video Game Buyer's Guide. One of the Nuon's main software developers was Jeff Minter, who created a version of "Tempest" titled "Tempest 3000" for the system and the built-in VLM-2 audio visualizer. However, the Nuon platform was primarily marketed as an expanded DVD format. A large majority of Nuon players that were sold in fact resembled typical consumer DVD players with the only noticeable difference being a Nuon logo. Nuon players offered a number of features that were not available on other DVD players when playing standard DVD-formatted titles. These included very smooth forward and reverse functionality and the ability to smoothly zoom in and out of sections of the video image. In addition, Nuon provided a software platform to DVD authors to provide interactive software like features to their titles.

In North America, Nuon was used in the Samsung DVD-N501 and DVD-N2000 models; they also released several models in other parts of the world: DVD-N504 (Europe), DVD N505 (Europe), and DVD-N591 (Korea). Toshiba released the SD-2300 DVD player, and there are two RCA models, the DRC300N and DRC480N. The Nuon was also used in Motorola's Streamaster 5000 "Digital DNA" set-top box. However, the format has appeared to have died off. Nuon was created by VM Labs, whose assets were sold to Genesis Microchip in April 2002. As of November 2004, there were no Nuon-enabled DVD players shipping and no new Nuon software titles, meaning that it was 
discontinued.


Peripherals for Nuon-enhanced DVD players included the following:

Only four DVD releases utilized Nuon technology. All of them were released by 20th Century Fox Home Entertainment:


Only eight games were officially released for the Nuon:



During late 2001, VM Labs released a homebrew SDK which allowed people to be able to program apps/games for their Nuon system. Only the Samsung DVD-N501/DVDN504/DVDN505 and RCA DRC300N/DRC480N can load homebrew games.

Some homebrew titles have been created for or ported to Nuon. They are not commercially available and require the user to burn the material to a Nuon-compatible CD-R.



</doc>
<doc id="22045" url="https://en.wikipedia.org/wiki?curid=22045" title="Nashville (disambiguation)">
Nashville (disambiguation)

Nashville is the capital of the U.S. state of Tennessee.

Nashville may also refer to:





</doc>
<doc id="22048" url="https://en.wikipedia.org/wiki?curid=22048" title="Cuisine of New England">
Cuisine of New England

New England cuisine is an American cuisine which originated in the New England region of the United States, and traces its roots to English cuisine. It is characterized by extensive use of seafood and dairy products, which results from its historical reliance on its seaports and fishing industry, as well as extensive dairy farming in inland regions. Many of New England's earliest Puritan settlers were from eastern England, where baking foods (for instance pies, beans, and turkey) was more common than frying, as was the tradition elsewhere. 

Two prominent characteristic foodstuffs native to New England are maple syrup and cranberries. The traditional standard starch is potato, though rice has a somewhat increased popularity in modern cooking. New England cuisine is known for limited use of spices aside from ground black pepper, although parsley, garlic, and sage are common, with a few Caribbean additions such as nutmeg, plus several Italian spices. Use of cream is common, due to the reliance on dairy. The favored cooking techniques are stewing, steaming, and baking. Many local ingredients, such as squash, corn and local beans, sunflowers, wild turkey, maple syrup, cranberries and dishes such as cornbread, Johnnycakes and Indian pudding were adopted from Southern New England Algonquian cuisine.

The traditional diet of the Wampanoag people included chestnuts, beechnuts, walnuts, beans, multi-colored corn (called "flint corn"), and varieties of squash and pumpkins.

In 1620, the newly arrived Pilgrims faced the prospect of surviving their first winter in Plymouth Colony. The climate was harsh and the growing season was shorter than they were accustomed to due to the long and frosty winters. The newly arrived colonists brought vital techniques of food preservation like smoking, curing and drying that helped them survive the harsh New England winter. They also received help from the Wampanoag, who taught the newly arrived Pilgrims how to grow the staple crops of squash, beans and corn. It is not known for certain what crops were grown in early colonial gardens, but later sources mention turnips, onions, carrots, garlic and pumpkins.

The Pilgrims used corn to make hasty pudding and Wampanoag recipes like popcorn, sagamite and nasaump. The Wampanoag also taught the Pilgrims to bake in hot ashes, and ash cakes (also called johnny cakes or breakfast bannocks) became a staple breakfast bread. Beans were used to make stews or combined with corn to make succotash.

Many of New England's earliest Puritan settlers were from eastern England and brought with the traditions of English cuisine with them. Roast duck, goose, lamb, and hams were brought to the so-called "New World" as farmyard stock as soon as the colonies began to prosper. Even today, traditional English cuisine remains a strong part of New England's identity. Some of its plates are now enjoyed by the entire United States, including clam chowder, baked beans, apple pies, baked or roast turkey, pease porridge, and steamed puddings.

The first Thanksgiving meal was shared by the Wampanoag and Pilgrims at Plymouth Rock. The menu would have been considerably more humble than the modern Thanksgiving dinner which typically includes turkey with stuffing, cranberry sauce, candied yams, mashed potatoes and pumpkin pie. Though filled pastries were common in English cuisine, the colonists did not have wheat flour or butter, so pie would have been absent from the original Thanksgiving table. White potatoes and sweet potatoes had not yet reached North America, and the first literary mention of cranberry sauce dates some 50 years after the first Thanksgiving meal.

The original menu included "Indian corn", wild fowl, including wild turkey and waterfowl, and venison. These are only foods mentioned by primary sources, however food historians have speculated as to what else may have been served. In addition to wild turkey, duck and goose, swan and passenger pigeons were plentiful. In those times birds were typically stuffed with onion and herbs and one 17th century recipe for goose includes a stuffing of chestnuts. It is likely that the meal included local seafood like clams, mussels, lobsters and eels.

Since the 1800s New England's culinary traditions have been influenced by the arrival of Irish Americans, Portuguese Americans, and Italian Americans. Irish-style braised pickled beef was the origin of New England boiled dinner.

"Country stores" sold homemade jams, fruit preserves and penny candy. Common crackers are still made with the original recipe dating to 1828.

In the post World War II era July 4 celebrations frequently feature steak, hot dogs, hamburgers and grilled chicken. In the more distant past lamb was more traditional inland, and coastal communities in New England typically served salmon with dill mayo, peas, new potatoes and corn on the cob. Dessert often includes a seasonal fruit, for example strawberry shortcake and blueberry pie.

Drinks in the Colonial era were made with local ingredients like honey, molasses, apples, hops and wild berries. These drinks included apple brandy ("applejack"), fruit wines, rum and mead. Some of the finest rum distilleries were located in New England prior to Prohibition.

The hot ale flip is a traditional drink historically made by mixing a pitcher of beer with rum, frothy eggs and a sweetener like dried pumpkin, maple syrup or molasses. The beverage was warmed by plunging a hot poker into the drink to caramelize the sugars creating the drink's characteristic hot froth. Like the flip, the Rattle-Skull was a mix of beer (in this case a dark beer like porter) and hard liquor - usually a mix of rum and brandy. The beverage is flavored with lime and garnished with nutmeg.

The Stone Fence was a mix of hard cider and rum. Reportedly, Ethan Allen and his men drank it before their raid of Fort Ticonderoga in 1775. Egg cider was made by cracking eggs into heated cider and adding a sweetener like molasses. Another cider based beverage syllabub was made with rum, cream and sweetener. Mulled cider could be made with sweetener, spices, rum and egg yolks.

Birch beer, made with sap from the "betula lenta" tree, was made by both the English and early American colonists. The "betula lenta" is known for producing a fragrant sap with a unique minty flavor. John Mortimer wrote that birch beer was usually made by the poor by boiling birch sap with sugar and fermenting it with yeast.

Many local breweries produce lagers and ales. Notable examples include Samuel Adams of the Boston Beer Company in Boston (even though the recipe for the beer does not come from New England); Sea Dog Brewing Company of Bangor; Shipyard Brewing Company of Portland; Smuttynose Brewing Company of Portsmouth, New Hampshire. Vermont-based Woodchuck Draft Cider is a popular alcoholic cider. New England has also played a major role in the craft beer revolution, with Connecticut, Massachusetts, and Vermont having notable breweries such as Treehouse Brewing Company, Trillium Brewing Company, The Alchemist Brewery, Rock Art Brewery, Long Trail Brewing Company, Kent Falls Brewing Company and Two Roads Brewing Company.

The custom of bringing one-dish casseroles (also called hot dishes) to barn raisings and church suppers was not exclusive to New England, but included traditional variations of baked beans and succotash. Modern recipes can be made with any ingredients available at markets. Seafood casseroles are made with cream sauce and bread crumb topping.

American chop suey is a casserole dish made with ground beef, macaroni and a seasoned tomato sauce. Though unrelated to Hungarian goulash, in other regions of the United States it may be called American goulash amongst other names.

Blueberries are made into jams and jellies and feature in breads and regional desserts like pies, cobblers and cakes.

Wild beach plums are foraged and used to make fruit preserves like jams and jellies. Beach plums were cultivated and used for the commercial manufacture of beach plum jelly in the 1930s, but beach plum products are no longer widely available in commercial markets.

The local purple concord grapes are a cross between native and European grapes. The large grapes are prized for their juiciness and used in the production of commercial grape juice, wine and grape jelly. It is a common ingredient in peanut butter and jelly sandwiches.

Until the pilgrims planted apple seeds from Europe, the only regional apples were crab apples. Cross-pollination altered the results of these first attempts, but over the years thousands of new varieties were bred by the pilgrims. William Blaxton planted the first apple orchard in 1625. The earliest apple varieties produced in New England included Lady (1628), Roxbury Russet (1630), Pomme Grise (1650), Baldwin (1740), Porter (1800), Mother (1844) and Wright (1875). In modern times apples are grown commercially throughout Massachusetts.
The first attempts at commercial cranberry growing were pioneered by Captain Henry Hall, who developed the technique of covering the vines with sand to accelerate the plant's growth.

New England hot dog rolls are split on top instead of on the side, and have a more rectangular shape. While smaller than common hot dog rolls, New England hot dog rolls have a larger soft surface area which allows for buttering and toasting, which are also commonly used for convenient serving of seafood like lobster or fried clams. Regional bread makers often differentiate between these and the more traditional-style American hot dog rolls by referring to the New England variation as "Frankfurt Rolls" on packaging, with both commonly available next to each other on store shelves (though when purchasing a cooked hot dog or seafood "roll" from a restaurant or food stand, the Frankfurt style is almost exclusively used).

Maple sap is collected annually during New England's "sugaring season". The new sap is reduced and thickened to form syrup. An issue of "Yankee" dating from 1939 gives some details on seasonal recipes with recipes for maple butternut fudge, maple sauce ice cream and "Sugar on Snow". Sugar on Snow, a regional specialty also called maple syrup taffy, is made by pouring freshly heated maple syrup on fresh snow, forming candy with a taffy consistency as the syrup hardens.

Desserts like cobbler, pie, and custard were made with local sweeteners like maple syrup and molasses instead of sugar. Molasses and rum were common in New England cuisine, due to New England's involvement in the Triangle Trade in the 18th century. Molasses from the Caribbean and honey were staple sweeteners for all but the upper class well into the 19th century.

Sandwiches typical of New England's cuisine include baked bean on Boston brown bread; the Fluffernutter with Fluff marshmallow creme and peanut butter, usually served on Wonder bread; served cold or hot, lobster rolls can optionally include fixings like mayo or warmed butter; clam rolls dressed with tartar or cocktail sauce on a New England style hot dog bun; and chow mein sandwich with noodles, celery, onions, meat and sauce in a hamburger bun; from Fall River, Massachusetts.

The waters of the Gulf of Maine and Long Island Sound provide a rich variety of fish and shellfish that are a signature of the cuisine in New England. Commercial cod fishing along Cape Ann dates back as far as 1623 when salt cod was carried by merchant vessels to Africa, which returned with slaves for plantations in the Caribbean before carrying sugar back to New England. Cod, the fish for which Cape Cod is named, remains a staple of the regional cuisine to this day. Bluefish can be found throughout Cape Cod and Nantucket during the summer months and is consumed smoked, broiled or sauteed. American lobster is usually consumed grilled, steamed, or boiled.

Breaded deep fried clams are popular pub fare in New England. The regional clam varieties can be soft shell or hard shell and include razor clams; the latter of these is more likely to be caught by hand owing to how difficult it is to harvest them without damaging the beach upon which they dwell. Hard shell clams are sometimes called littlenecks, cherrystones or quahogs depending on their size. These are used to make New England style clam chowder, and may also be consumed steamed or even raw. The preferred methods of preparing soft-shell clams (also called "steamers") are frying or steaming. Adapted from the Native Americans, the clambake is a traditional meal in New England where clams, lobsters and corn are cooked over a firepit. Modern versions of the dish may include mussels, fish, crabs and non seafood ingredients like chicken, sausage, potatoes and other root vegetables.

The official state fish are as follows:

Many herbs were uncommon, particularly Mediterranean herbs, which are not hardy in much of New England away from the coast. As a result, most savory New England dishes do not have much strong seasoning, aside from salt and ground black pepper, nor are there many particularly spicy staple items. Other dishes meant as desserts often contain ingredients such as nutmeg, cinnamon, allspice, cloves, and ground ginger which are a legacy of trade with the Caribbean Sea that began in the 17th Century and lasted well into the 19th.

Much of the pizza in New England is Greek pizza, owing to the strong presence of Greek immigrants and Greek Americans in the food service industry in New England. Greek pizza (as understood in New England) is typified by its chewy, bready crust similar to focaccia, which is baked in shallow, round metal pan liberally coated with olive oil. Greek-style pizzerias in New England are often found under the name "House of Pizza".

Italians emigrated to New England beginning a little over a century ago, 
and Southern New England pizza tends to be more Italian influenced. World famous restaurants such as “Pepe’s Pizza” in New Haven, CT serve a thin, wood fired, hand tossed style of pie. “New Haven” style pizza is typified by a slightly burnt, crunchy exterior crust and soft, slightly chewy interior. Southern New England pizza (or apizza) is closely related to Neapolitan style pizza.

Irish American influences are common in the interior portions of the state, including the Hartford area. During the 18th century the Hartford election cake was a spicy, boozy yeast-leavened cake based on a traditional English holiday cake. During the colonial era elections were celebrated with drink and a huge celebration cake large enough to feed the entire community, and the recipe as given by Amelia Simmons in 1796 called for butter, sugar, raisins, eggs, wine and spices in enormous quantities. Hasty pudding is sometimes found in rural communities, particularly around Thanksgiving.

Italian-inspired cuisine is dominant in the New Haven area, which is known for charred thin-crust New Haven style pizza baked in coal-fired ovens. The well-known white clam pie is made with fresh clams, olive oil, fresh garlic, oregano and grated Romano cheese. Some pizza places also offer subs on Italian bread ("grinders") and standard Italian fare like eggplant rollatini, manicotti, baked ziti and chicken parmesan. Well-known pizzerias include Pepe's Pizza, Sally's Apizza and Modern Apizza,

The cuisine of Southeastern Connecticut is heavily based on the local fishing industry. Typical New England seafood dishes are available at local restaurants like Abbot's Lobster in the rough. Lobster rolls, crab cakes, oysters, clam chowder, steamer clams and mussels are served with sides like potato chips, remoulade sauce and coleslaw. Shad is the state fish and is cooked on planks (usually hickory, oak, or cedar) by the fire, called a "shad bake", deboning the fish requires some skill with a boning knife.

Louis' Lunch began as a lunch wagon started by Danish immigrant Louis Lassen in 1895. Their burgers are still cooked in the original antique cast iron broiler. A local specialty of Meriden, Connecticut, steamed cheeseburgers started as simple steamed cheese on a roll sandwiches sold off horse-drawn food carts in the 1900s. Some believe the hamburger originated in New Haven at Louis', and like the butter burger and deep-fried hamburger, the steamed version may be remnant of an earlier time before the broiled hamburger on a bun became the standard form.

Ice cream is made with milk from local creameries at UCONN Dairy Bar using a century old recipe to produce 24 different flavors of ice cream. Ferris Acres Creamery is a 150 year old dairy farm offering 50 flavors of ice cream. The most popular is the "Cow Trax" - a base of vanilla with peanut butter swirls and chocolate chips.

Maine is known for its lobster. Relatively inexpensive lobster rolls—lobster meat mixed with mayonnaise and other ingredients, served in a grilled hot dog roll are often available in the summer, particularly on the coast. Northern Maine produces potato crops, second only to Idaho in the United States.

Fiddlehead ferns were part of the Native American cuisine and are still prized in Maine, where they are gathered in springtime. Wild blueberries are a common ingredient or garnish, and blueberry pie is the official state dessert (when made with wild Maine blueberries). Red snappers are considered the most popular type of hot dog in Maine, natural casing frankfurters colored bright red. The whoopie pie, which is also a staple in the Philadelphia/Pennsylvania Dutch cuisine, is the official state treat. Maine is the place of origin for the needham, a dessert bar made from chocolate, coconut, and potato. Finally, the Italian sandwich is popular in Portland and southern Maine. Portland restaurant Amato's claims to have invented the Italian sandwich in 1902—specifically, a submarine sandwich made with ham, cheese, tomato, raw peppers, and pickles, served with or without oil, salt, and pepper. The city of Portland, Maine is known for its numerous nationally renowned restaurants; it was ranked as Bon Appétit magazine's "America's Foodiest Small Town" in 2009.

Moxie was America's first mass-produced soft drink and is the official state soft drink. It is known for its strong aftertaste and is found throughout New England. Wax-wrapped salt water taffy is a popular item sold in tourist areas, although it is originally from New Jersey.

Coastal Massachusetts is known for its clams, haddock, and cranberries, and previously cod. Massachusetts had similar immigrant influences as the coastal regions, though historically strong Eastern European populations instilled kielbasa and pierogi as common dishes.

Named after the town of Newton, Fig Newtons were first made in 1891 using a machine invented by James Mitchell to fill cookie dough with fig jam. The small round Necco Wafers, made with the first American candy machine, similarly originated in Cambridge. Graham bread was first made in 19th-century Massachusetts by Sylvester Graham. Tollhouse cookies, the official state cookie of Massachusetts were created in 1930 at the Toll House Inn, located in Whitman.
Boston is known for, baked beans (hence the nickname "Beantown"), bulkie rolls, and various pastries. Boston cream pie is not a pie but a cake with custard filling. The origins are mysterious, but it is likely that antecedent cakes were made with either a sponge cake or pound cake.

Parker's Restaurant was the premier dining establishment in Boston in the 19th century. The a la carte menu from 1865 included a range of local seafood offerings like oysters, fried clams, mackerel, shad, salmon in anchovy sauce, cod in oyster sauce, and soft-shell crab. Other meat dishes included chicken fricassee, potted pigeons, corned beef and baked beans with pork. Sides included corn, rice, macaroni, potatoes, asparagus, green peas, radishes and fried bananas. Sweet pastry and puddings were also served such as Indian pudding, custard, apple pie, rhubarb pie, Washington pie, Charlotte Russe, and blancmange.

The North Shore area is locally known for its roast beef shops and "steak tips" (marinated cubes of sirloin), a common menu item at pizza establishments and backyard cookouts. The South Shore area maintains a following for bar pizza, with many popular restaurants serving these crisp, thin, often heavily topped creations.

Common plant foods in Massachusetts are similar to those of interior northern New England, because of the landlocked, hilly terrain, including potatoes, maple syrup, and wild blueberries. Dairy production is also prominent in this central and western area.

Southern New Hampshire cuisine is similar to that of the Boston area, featuring fish, shellfish, and local apples. As with Maine and Vermont, French-Canadian dishes are popular, including tourtière, which is traditionally served on Christmas Eve, and poutine. Corn chowder is also common, which is similar to clam chowder but with corn and bacon replacing the clams. Portsmouth is known for its orange cake.

Rhode Island is known for johnnycakes, doughboys, and clam cakes.

Johnnycakes, variously and contentiously known as jonnycakes, journeycakes and Shawnee cakes, can vary in thickness and preparation, and disagreements over whether they should be make with milk or water persist. East of Narrangasett Bay johnnycakes are made with cold milk and a little butter, but around South County the batter is sweetened and made with scalded cornmeal. One attempt by the Rhode Island Legislature to settle on an "authentic" recipe ended in a fistfight. They were traditionally served as a flatbread alongside chipped beef or baked beans, but in modern times they are usually eaten for breakfast with butter and maple syrup. According to The Society for the Propagation of the Johnnycake Tradition in Rhode Island, authentic johnnycakes must be made with whitecap flint corn historically grown in the region around Narrangasett Bay. Stone-ground flint corn is not commercially available, but can still be found at a few historic gristmills like the Prescott Farm museum in Middletown.

Hot dogs, known "wieners" or sometimes "New York System wieners", are slow cooked over low heat and served in a steamed bun, often topped with some combination of celery salt, mustard, raw onion and ground beef sauce.

Sweetened coffee-flavored dairy products are popular in Rhode Island. Coffee ice cream is popular and a locally produced coffee gelatin dessert mix can be found at supermarkets. Coffee milk has been the official state drink since 1993. While the origins may date to the 1930s, when some shopkeeps sweetened leftover coffee ground with milk and sugar, its now made with coffee extract syrups like those produced by Autocrat.

Also popular in the state are clear clam chowder known as Rhode Island clam chowder, quahogs, milkshakes (called "cabinets" in Rhode Island and "frappes" elsewhere in New England), submarine sandwiches, pizza strips, the chow mein sandwich, and Del's Frozen Lemonade. Italian cooking is long established in the region. In Rhode Island and other parts of New England with a large Portuguese American population, Portuguese foods are common, including linguiça, chouriço, caldo verde, malasadas, and Portuguese sweet bread.

Vermont produces cheddar cheese and other dairy products. Small cheesemakers recognized for producing hand-crafted cheddar cheeses include the Crowley Cheese Factory Grafton Village Cheese Company, and Shelburne Farms.

The Vermonter sandwich is made with cold cuts (often turkey and ham), apple, sharp Vermont cheddar and maple mustard (a mix of maple syrup and grainy mustard). The toasted sandwich is served warm.

It is known in and outside of New England for its maple syrup. Maple syrup is used as an ingredient in some Vermont dishes, including baked beans. Rhubarb pie is a common dessert and has been combined with strawberries in late spring.

The oldest operating restaurant in the United States is the Union Oyster House (1826) located in Boston.

Legal Sea Foods is a chain restaurant that began by selling fresh fish and fish and chips. The original 1950 shop was located at Cambridge's Inman Square.

Woodman's of Essex began selling homemade potato chips in 1914. Their signature dish of fried claims was introduced only a few years later, in 1916. The chowder has won prizes at the annual Essex Clamfest.

Friendly's was founded in 1935 during the Great Depression in Springfield, Massachusetts as an ice cream parlor selling two scoops for a nickel. By 1960, the company offered 63 flavors of ice cream. They were producing 25 million gallons per year and had moved their headquarters to Wilbraham. It only becomes a full-service chain restaurant after being acquired by Donald Smith in 1988.

At local shops along the North Shore of Massachusetts, "three-way" roast beef sandwiches are often served on an onion roll and topped with mayo, barbecue sauce and white American cheese. Kelly's Roast Beef claims to have originated the first roast beef sandwich. Open-faced roast beef sandwiches predate Kelly's version but are typically eaten with a knife and fork. Other well-known North Shore roast beef shops include Londi's and Bill & Bob's.

D'Angelo's is a regional chain with locations in Connecticut, Maine, Rhode Island, New Hampshire, and Massachusetts specializing in subs (called heroes in New York and hoagies in Philadelphia). Their first shop opened in Dedham, Massachusetts in 1967. They serve foot-long lobster rolls and other sandwich varieties like steak and cheese. Italian sandwiches are the specialty Moe's Italian Sandwiches, founded in Portsmouth, New Hampshire in 1959. Based on a family recipe their sandwich is made with salami, provolone, veggies, spices and olive oil. Amato's claims to have originated the Maine Italian sandwich, made with ham, American cheese, onion, sour pickles, tomatoes, black olives, green peppers and olive oil.

Fluff marshmallow creme, used to make Fluffernutter sandwiches, is made in Lynn, Massachusetts. Welch's, headquartered in Concord, Massachusetts, produces grape juices, jellies and jams from purple Concord grapes. The company has been owned by the National Grape Cooperative Association since 1956.

Autocrat is a company based in Lincoln, Rhode Island that produces coffee and tea extracts. Their coffee syrups are used to make coffee milk which became the official state drink of Rhode Island in 1993. The Moxie Beverage Company of Bedford, New Hampshire, acquired by the Coca-Cola Company in 2018, produces the Moxie soft drink. Flavored with gentian root extract, Moxie has been the official soft drink of Maine since May 10, 2005.

Organic dairy company Stonyfield Farm, owned by the French dairy company Lactalis, is located in Londonderry, New Hampshire. Ice cream company Ben & Jerry's, purchased in 2000 by the Anglo-Dutch company Unilever, was founded in 1978 in Burlington, Vermont.





</doc>
<doc id="22049" url="https://en.wikipedia.org/wiki?curid=22049" title="Neil Simon">
Neil Simon

Marvin Neil Simon (July 4, 1927 – August 26, 2018) was an American playwright, screenwriter and author. He wrote more than 30 plays and nearly the same number of movie screenplays, mostly adaptations of his plays. He has received more combined Oscar and Tony Award nominations than any other writer.

Simon grew up in New York City during the Great Depression. His parents' financial difficulties affected their marriage, giving him a mostly unhappy and unstable childhood. He often took refuge in movie theaters, where he enjoyed watching early comedians like Charlie Chaplin. After graduating from high school and serving a few years in the Army Air Force Reserve, he began writing comedy scripts for radio programs and popular early television shows. Among the latter were Sid Caesar's "Your Show of Shows", (where in 1950 he worked alongside other young writers including Carl Reiner, Mel Brooks and Selma Diamond) and "The Phil Silvers Show", which ran from 1955 to 1959.

His first produced play was "Come Blow Your Horn" (1961). It took him three years to complete and ran for 678 performances on Broadway. It was followed by two more successes, "Barefoot in the Park" (1963) and "The Odd Couple" (1965). He won a Tony Award for the latter. It made him a national celebrity and "the hottest new playwright on Broadway." From the 1960s to the 1980s he wrote for stage and screen; some of his screenplays were based on his own works for the stage. His style ranged from farce to romantic comedy to more serious dramatic comedy. Overall, he garnered 17 Tony nominations and won three awards. In 1966, he had four successful productions running on Broadway at the same time, and in 1983 he became the only living playwright to have a New York theatre, the Neil Simon Theatre, named in his honor.

Neil Simon was born on July 4, 1927, in The Bronx, New York, to Jewish parents. His father, Irving Simon, was a garment salesman, and his mother, Mamie (Levy) Simon, was mostly a homemaker. Neil had one brother, eight years his senior, television writer and comedy teacher Danny Simon. He grew up in Washington Heights, Manhattan, and graduated from DeWitt Clinton High School when he was sixteen. He was nicknamed 'Doc', and the school yearbook described him as extremely shy.

Simon's childhood was marked by his parents' "tempestuous marriage" and the financial hardship caused by the Depression. Sometimes at night he blocked out their arguments by putting a pillow over his ears. His father often abandoned the family for months at a time, causing them further financial and emotional suffering. As a result, the family took in boarders, and Simon and his brother Danny were sometimes forced to live with different relatives.

During an interview with writer Lawrence Grobel, Simon said: "To this day I never really knew what the reason for all the fights and battles were about between the two of them ... She'd hate him and be very angry, but he would come back and she would take him back. She really loved him." Simon has said that one of the reasons he became a writer was to fulfill a need to be independent of such emotional family issues, a need he recognized when he was seven or eight: "I'd better start taking care of myself somehow ... It made me strong as an independent person.

He was able to do that at the movies, in the work of stars like Charlie Chaplin, Buster Keaton, and Laurel and Hardy. "I was constantly being dragged out of movies for laughing too loud." Simon acknowledged these childhood films as his inspiration: "I wanted to make a whole audience fall onto the floor, writhing and laughing so hard that some of them pass out." He made writing comedy his long-term goal, and also saw it as a way to connect with people. "I was never going to be an athlete or a doctor." He began writing for pay while still in high school: At the age of fifteen, Simon and his brother created a series of comedy sketches for employees at an annual department store event. To help develop his writing skill, he often spent three days a week at the library reading books by famous humorists such as Mark Twain, Robert Benchley, George S. Kaufman and S. J. Perelman.

Soon after graduating from high school, he signed up with the Army Air Force Reserve at New York University. He attained the rank of corporal and was eventually sent to Colorado. During those years in the Reserve, Simon wrote professionally, starting as a sports editor. He was assigned to Lowry Air Force Base during 1945 and attended the University of Denver from 1945 to 1946.

Simon quit his job as a mailroom clerk in the Warner Brothers offices in Manhattan to write radio and television scripts with his brother Danny Simon, under the tutelage of radio humourist Goodman Ace, who ran a short-lived writing workshop for CBS. Their work for the radio series "The Robert Q. Lewis Show" led to other writing jobs. Max Liebman hired the duo for the writing team of his popular television comedy series "Your Show of Shows." The program received Emmy Award nominations for Best Variety Show in 1951, 1952, 1953, and 1954, and won in 1952 and 1953. Simon later wrote scripts for "The Phil Silvers Show", for episodes broadcast during 1958 and 1959.

Simon later recalled the importance of these two writing jobs to his career: "Between the two of them, I spent five years and learned more about what I was eventually going to do than in any other previous experience." "I knew when I walked into "Your Show of Shows", that this was the most talented group of writers that up until that time had ever been assembled together."

Simon described a typical writing session:

Simon incorporated some of these experiences into his play "Laughter on the 23rd Floor" (1993). A 2001 TV adaptation of the play won him two Emmy Award nominations.

His first Broadway experience was on "Catch a Star!" (1955); he collaborated on sketches with his brother, Danny.

In 1961, Simon's first Broadway play, "Come Blow Your Horn", ran for 678 performances at the Brooks Atkinson Theatre. Simon took three years to create that first play, partly because he was also working on television scripts. He rewrote it at least twenty times from beginning to end: "It was the lack of belief in myself," he recalled. "I said, 'This isn't good enough. It's not right.' ... It was the equivalent of three years of college." Besides being a "monumental effort" for Simon, that play was a turning point in his career: "The theater and I discovered each other."
"Barefoot in the Park" (1963) and "The Odd Couple" (1965), for which he won a Tony Award, brought him national celebrity, and he was considered "the hottest new playwright on Broadway", according to Susan Koprince. Those successes were followed by others. During 1966, Simon had four shows playing simultaneously at Broadway theatres: "Sweet Charity", "The Star-Spangled Girl", "The Odd Couple" and "Barefoot in the Park". His professional association with producer Emanuel Azenberg began with "The Sunshine Boys" and continued with "The Good Doctor", "God's Favorite", "Chapter Two", "They're Playing Our Song", "I Ought to Be in Pictures", "Brighton Beach Memoirs", "Biloxi Blues", "Broadway Bound", "Jake's Women", "The Goodbye Girl" and "Laughter on the 23rd Floor", among others. His work ranged from romantic comedies to serious drama. Overall, he received seventeen Tony nominations and won three awards.

Simon also adapted material originated by others, such as the musical "Little Me" (1962), based on the novel by Patrick Dennis; "Sweet Charity" (1966) from the screenplay for the film "Nights of Cabiria ("1957), written by Federico Fellini and others; and "Promises, Promises" (1968) a musical version of Billy Wilder's film, "The Apartment". Simon also served as an uncredited "script doctor,” helping to hone the books of Broadway-bound plays or musicals under development, as he did for "A Chorus Line" (1975). During the 1970s, he wrote a string of successful plays; sometimes more than one was playing at the same time, to standing room only audiences. Although he was, by then, recognized as one of the country's leading playwrights, his inner drive kept him writing:
Simon drew "extensively on his own life and experience" for his stories. His settings are typically working-class New York City neighborhoods, similar to the ones in which he grew up. In 1983, he began writing the first of three autobiographical plays, "Brighton Beach Memoirs" (1983), which would be followed by "Biloxi Blues" (1985) and "Broadway Bound" (1986). He received his greatest critical acclaim for this trilogy. He received a Pulitzer Prize for his follow-up play, "Lost in Yonkers" (1991).

Simon chose not to write the screenplay for the first film adaptation of his work, "Come Blow Your Horn" (1963), preferring to focus on his playwriting. However, he was disappointed with the picture, and thereafter tried to control the conversion of his works. Simon wrote screenplays for more than twenty films and received four Academy Award nominations—for The Odd Couple (1969), The Sunshine Boys (1976), The Goodbye Girl (1978) and California Suite (1979). Other movies include "The Out-of-Towners (1970) and" "Murder by Death" (1976). Although most of his films were successful, movies were always of secondary importance to his plays:

Many of his earlier adaptations of his own work were very similar to the original plays. Simon observed in hindsight: "I really didn't have an interest in films then. I was mainly interested in continuing writing for the theater ... The plays never became cinematic". "The Odd Couple" (1968), was one highly successful early adaptation, faithful to the stage play but also opened out, with more scenic variety.

Theater critic John Lahr believes that Simon's primary theme is "the silent majority,” many of whom are "frustrated, edgy, and insecure". Simon's characters are "likable" and easy for audiences to identify with. They often have difficult relationships in marriage, friendship or business, as they "struggle to find a sense of belonging". According to biographer Edythe McGovern, there is always "an implied seeking for solutions to human problems through relationships with other people, [and] Simon is able to deal with serious topics of universal and enduring concern,” while still making people laugh.

McGovern adds that one of Simon's hallmarks is his "great compassion for his fellow human beings," an opinion shared by author Alan Cooper, who observes that Simon's plays "are essentially about friendships, even when they are about marriage or siblings or crazy aunts ..."

Many of Simon's plays are set in New York City, with a resulting urban flavor. Within that setting, Simon's themes include marital conflict, infidelity, sibling rivalry, adolescence, bereavement and fear of aging. Despite the serious nature of these ideas, Simon always manages to tell the stories with humor, embracing both realism and comedy. Simon would tell aspiring comedy playwrights "not to try to make it funny ... try and make it real and then the comedy will come."

"When I was writing plays," he said, "I was almost always (with some exceptions) writing a drama that was funny ... I wanted to tell a story about real people." Simon explained how he managed this combination:
His comedies often portray struggles with marital difficulties or fading love, sometimes leading to separation, divorce and child custody issues. After many twists in the plot, the endings typically show renewal of the relationships.

Politics seldom plays in Simon's stories, and his characters avoid confronting society as a whole, despite their personal problems. "Simon is simply interested in showing human beings as they are—with their foibles, eccentricities, and absurdities." Drama critic Richard Eder noted that Simon's popularity relies on his ability to portray a "painful comedy," where characters say and do funny things in extreme contrast to the unhappiness they are feeling.

Simon's plays are generally semi-autobiographical, often portraying aspects of his troubled childhood and first marriages. According to Koprince, Simon's plays also "invariably depict the plight of white middle-class Americans, most of whom are New Yorkers and many of whom are Jewish, like himself." He has said, "I suppose you could practically trace my life through my plays." In "Lost in Yonkers", Simon suggests the necessity of a loving marriage (as opposed to his parents'), and how children who are deprived of it in their home, "end up emotionally damaged and lost".

According to Koprince, Simon's Jewish heritage is a key influence on his work, although he is unaware of it when writing. For example, in the "Brighton Beach" trilogy, she explains, the lead character is a "master of self-deprecating humor, cleverly poking fun at himself and at his Jewish culture as a whole." Simon himself has said that his characters are people who are "often self-deprecating and [who] usually see life from the grimmest point of view," explaining, "I see humor in even the grimmest of situations. And I think it's possible to write a play so moving it can tear you apart and still have humor in it." This theme in writing, notes Koprince, "belongs to a tradition of Jewish humor ... a tradition which values laughter as a defense mechanism and which sees humor as a healing, life-giving force."

Simon's characters are typically "imperfect, unheroic figures who are at heart decent human beings", according to Koprince, and she traces Simon's style of comedy back to that of Menander, a playwright of ancient Greece. Menander, like Simon, also used average people in domestic life settings, and also blended humor and tragedy into his themes. Many of Simon's most memorable plays are built around two-character scenes, as in segments of "California Suite" and "Plaza Suite".

Before writing, Simon tried to create an image of his characters. He said that the play "Star Spangled Girl", which was a box-office failure, was "the only play I ever wrote where I did not have a clear visual image of the characters in my mind as I sat down at the typewriter." Simon considered "character building" an obligation, stating that the "trick is to do it skillfully". While other writers have created vivid characters, they have not created nearly as many as Simon did: "Simon has no peers among contemporary comedy playwrights," stated biographer Robert Johnson.

Simon's characters often amuse the audience with sparkling "zingers," made believable by Simon's skillful writing of dialogue. He reproduces speech so "adroitly" that his characters are usually plausible and easy for audiences to identify with and laugh at. His characters may also express "serious and continuing concerns of mankind ... rather than purely topical material". McGovern notes that his characters are always impatient "with phoniness, with shallowness, with amorality", adding that they sometimes express "implicit and explicit criticism of modern urban life with its stress, its vacuity, and its materialism." However, Simon's characters are never seen thumbing their noses at society."

The key aspect most consistent in Simon's writing style is comedy, situational and verbal, and presents serious subjects in a way that makes audiences "laugh to avoid weeping." He achieved this with rapid-fire jokes and wisecracks, in a wide variety of urban settings and stories. This creates a "sophisticated, urban humor", says editor Kimball King, and results in plays that represent "middle America." Simon created everyday, apparently simple conflicts with his stories, which became comical premises for problems which needed be solved.

Another feature of his writing is his adherence to traditional values regarding marriage and family. McGovern states that this thread of the monogamous family runs through most of Simon's work, and is one he feels is necessary to give stability to society. Some critics have therefore described his stories as somewhat old fashioned, although Johnson points out that most members of his audiences "are delighted to find Simon upholding their own beliefs." And where infidelity is the theme in a Simon play, rarely, if ever, do those characters gain happiness: "In Simon's eyes, adds Johnson, "divorce is never a victory."

Another aspect of Simon's style is his ability to combine both comedy and drama. "Barefoot in the Park", for example, is a light romantic comedy, while portions of "Plaza Suite" were written as "farce", and portions of "California Suite" are "high comedy".

Simon was willing to experiment and take risks, often moving his plays in new and unexpected directions. In "The Gingerbread Lady", he combined comedy with tragedy; "Rumors" (1988) is a full-length farce; in "Jake's Women" and "Brighton Beach Memoirs" he used dramatic narration; in "The Good Doctor", he created a "pastiche of sketches" around various stories by Chekhov; and "Fools" (1981), was written as a fairy-tale romance similar to stories by Sholem Aleichem. Although some of these efforts failed to win approval from many critics, Koprince claims that they nonetheless demonstrate Simon's "seriousness as a playwright and his interest in breaking new ground."

During most of his career Simon's work received mixed reviews, with many critics admiring his comedy skills, much of it a blend of "humor and pathos". Other critics were less complimentary, noting that much of his dramatic structure was weak and sometimes relied too heavily on gags and one-liners. As a result, notes Kopince, "literary scholars had generally ignored Simon's early work, regarding him as a commercially successful playwright rather than a serious dramatist." Clive Barnes, theater critic for "The New York Times", wrote that like his British counterpart Noël Coward, Simon was "destined to spend most of his career underestimated", but nonetheless very "popular".
This attitude changed after 1991, when he won a Pulitzer Prize for drama with "Lost in Yonkers". McGovern writes that "seldom has even the most astute critic recognized what depths really exist in the plays of Neil Simon." Although, when "Lost in Yonkers" was considered by the Pulitzer Advisory Board, board member Douglas Watt noted that it was the only play nominated by all five jury members, and that they judged it "a mature work by an enduring (and often undervalued) American playwright."

McGovern compares Simon with noted earlier playwrights, including Ben Jonson, Molière, and George Bernard Shaw, pointing out that those playwrights had "successfully raised fundamental and sometimes tragic issues of universal and therefore enduring interest without eschewing the comic mode." She concludes, "It is my firm conviction that Neil Simon should be considered a member of this company ... an invitation long overdue." McGovern attempts to explain the response of many critics:
Similarly, literary critic Robert Johnson explains that Simon's plays have given us a "rich variety of entertaining, memorable characters" who portray the human experience, often with serious themes. Although his characters are "more lifelike, more complicated and more interesting" than most of the characters audiences see on stage, Simon has "not received as much critical attention as he deserves." Lawrence Grobel, in fact, calls him "the Shakespeare of his time", and possibly the "most successful playwright in history." He states:

Broadway critic Walter Kerr tries to rationalize why Simon's work has been underrated:

Simon was married five times. He was married to dancer Joan Baim for 20 years (1953–1973) and had two children. Simon became a widower when Baim died of bone cancer. Simon married actress Marsha Mason (1973–1983), actress Diane Lander in two separate marriages (1987–1988 and 1990–1998), and actress Elaine Joyce (1999–2018). He was the father of Nancy and Ellen, from his first marriage, and Bryn, Lander's daughter from a previous relationship, whom he adopted.

Simon's nephew is U.S. District Judge Michael H. Simon and his niece-in-law is U.S. Congresswoman Suzanne Bonamici.

Simon was on the board of selectors of Jefferson Awards for Public Service.

In 2004, Simon received a kidney transplant from his long-time friend and publicist Bill Evans.

Neil Simon died on August 26, 2018, after being on life support while hospitalized for kidney failure. He also had Alzheimer's disease. He was 91. The cause of death was complications of pneumonia, according to his publicist, Bill Evans. Simon died around 1 a.m. Sunday at New York-Presbyterian Hospital in New York City.

Simon held three honorary degrees; a Doctor of Humane Letters from Hofstra University, a Doctor of Letters from Marquette University and a Doctor of Law from Williams College. In 1983 Simon became the only living playwright to have a New York City theatre named after him. The Alvin Theatre on Broadway was renamed the Neil Simon Theatre in his honor, and he was an honorary member of the Walnut Street Theatre's board of trustees. Also in 1983, Simon was inducted into the American Theater Hall of Fame.

In 1965, he won the Tony Award for Best Playwright ("The Odd Couple"), and in 1975, a special Tony Award for his overall contribution to American theater. Simon won the 1978 Golden Globe Award for Best Motion Picture Screenplay for "The Goodbye Girl". For "Brighton Beach Memoirs" (1983), he was awarded the New York Drama Critics' Circle Award, followed by another Tony Award for Best Play of 1985, "Biloxi Blues". In 1991, he won the Pulitzer Prize along with the Tony Award for "Lost in Yonkers" (1991).

The Neil Simon Festival is a professional summer repertory theatre devoted to preserving the works of Simon and his contemporaries. The Neil Simon Festival was founded by Richard Dean Bugg in 2003.

In 2006, Simon received the Mark Twain Prize for American Humor.



Simon is credited as playwright and contributing writer to at least 49 plays on Broadway:

In addition to the plays and musicals above, Simon has twice rewritten or updated his 1965 play "The Odd Couple", both of which versions have run under new titles. These new versions are "The Female Odd Couple" (1985), and "Oscar and Felix: A New Look at the Odd Couple" (2002).


Simon, as a member of a writing staff, penned material for the following shows:

The following made-for-TV movies were all written solely by Simon, and all based on his earlier plays or screenplays




</doc>
<doc id="22050" url="https://en.wikipedia.org/wiki?curid=22050" title="North American Free Trade Agreement">
North American Free Trade Agreement

The North American Free Trade Agreement (NAFTA; , TLCAN; , ALÉNA) was an agreement signed by Canada, Mexico, and the United States that created a trilateral trade bloc in North America. The agreement came into force on January 1, 1994, and superseded the 1988 Canada–United States Free Trade Agreement between the United States and Canada. The NAFTA trade bloc formed one of the largest trade blocs in the world by gross domestic product.

The impetus for a North American free trade zone began with U.S. president Ronald Reagan, who made the idea part of his 1980 presidential campaign. After the signing of the Canada–United States Free Trade Agreement in 1988, the administrations of U.S. president George H. W. Bush, Mexican president Carlos Salinas de Gortari, and Canadian prime minister Brian Mulroney agreed to negotiate what became NAFTA. Each submitted the agreement for ratification in their respective capitals in December 1992, but NAFTA faced significant opposition in both the United States and Canada. All three countries ratified NAFTA in 1993 after the addition of two side agreements, the North American Agreement on Labor Cooperation (NAALC) and the North American Agreement on Environmental Cooperation (NAAEC).

Passage of NAFTA resulted in the elimination or reduction of barriers to trade and investment between the U.S., Canada, and Mexico. The effects of the agreement regarding issues such as employment, the environment, and economic growth have been the subject of political disputes. Most economic analyses indicated that NAFTA was beneficial to the North American economies and the average citizen, but harmed a small minority of workers in industries exposed to trade competition. Economists held that withdrawing from NAFTA or renegotiating NAFTA in a way that reestablished trade barriers would've adversely affected the U.S. economy and cost jobs. However, Mexico would've been much more severely affected by job loss and reduction of economic growth in both the short term and long term.

After U.S. president Donald Trump took office in January 2017, he sought to replace NAFTA with a new agreement, beginning negotiations with Canada and Mexico. In September 2018, the United States, Mexico, and Canada reached an agreement to replace NAFTA with the United States–Mexico–Canada Agreement (USMCA), and all three countries had ratified it by March 2020. NAFTA remained in force until USMCA was implemented. In April 2020, Canada and Mexico notified the U.S. that they were ready to implement the agreement. The USMCA took effect on July 1, 2020, replacing NAFTA.

The impetus for a North American free trade zone began with U.S. president Ronald Reagan, who made the idea part of his campaign when he announced his candidacy for the presidency in November 1979. Canada and the United States signed the Canada–United States Free Trade Agreement (FTA) in 1988, and shortly afterward Mexican President Carlos Salinas de Gortari decided to approach U.S. president George H. W. Bush to propose a similar agreement in an effort to bring in foreign investment following the Latin American debt crisis. As the two leaders began negotiating, the Canadian government under Prime Minister Brian Mulroney feared that the advantages Canada had gained through the Canada–US FTA would be undermined by a US–Mexican bilateral agreement, and asked to become a party to the US–Mexican talks.

Following diplomatic negotiations dating back to 1990, the leaders of the three nations signed the agreement in their respective capitals on December 17, 1992. The signed agreement then needed to be ratified by each nation's legislative or parliamentary branch.

The earlier Canada–United States Free Trade Agreement had been controversial and divisive in Canada, and featured as an issue in the 1988 Canadian election. In that election, more Canadians voted for anti-free trade parties (the Liberals and the New Democrats), but the split of the votes between the two parties meant that the pro-free trade Progressive Conservatives (PCs) came out of the election with the most seats and so took power. Mulroney and the PCs had a parliamentary majority and easily passed the 1987 Canada–US FTA and NAFTA bills. However, Mulroney was replaced as Conservative leader and prime minister by Kim Campbell. Campbell led the PC party into the 1993 election where they were decimated by the Liberal Party under Jean Chrétien, who campaigned on a promise to renegotiate or abrogate NAFTA. Chrétien subsequently negotiated two supplemental agreements with Bush, who had subverted the LAC advisory process and worked to "fast track" the signing prior to the end of his term, ran out of time and had to pass the required ratification and signing of the implementation law to incoming president Bill Clinton.

Before sending it to the United States Senate Clinton added two side agreements, the North American Agreement on Labor Cooperation (NAALC) and the North American Agreement on Environmental Cooperation (NAAEC), to protect workers and the environment, and to also allay the concerns of many House members. The U.S. required its partners to adhere to environmental practices and regulations similar to its own. After much consideration and emotional discussion, the U.S. House of Representatives passed the North American Free Trade Agreement Implementation Act on November 17, 1993, 234–200. The agreement's supporters included 132 Republicans and 102 Democrats. The bill passed the Senate on November 20, 1993, 61–38. Senate supporters were 34 Republicans and 27 Democrats. Republican Representative David Dreier of California, a strong proponent of NAFTA since the Reagan Administration, played a leading role in mobilizing support for the agreement among Republicans in Congress and across the country.

Clinton signed it into law on December 8, 1993; the agreement went into effect on January 1, 1994. At the signing ceremony, Clinton recognized four individuals for their efforts in accomplishing the historic trade deal: Vice President Al Gore, Chairwoman of the Council of Economic Advisers Laura Tyson, Director of the National Economic Council Robert Rubin, and Republican Congressman David Dreier. Clinton also stated that "NAFTA means jobs. American jobs, and good-paying American jobs. If I didn't believe that, I wouldn't support this agreement." NAFTA replaced the previous Canada-US FTA.

NAFTA (TLCAN in Spanish) was approved by the Mexican Senate on November 22, 1993, and was published in the Official Gazette of the Federation on December 8, 1993.

The decree implementing NAFTA and the various changes to accommodate NAFTA in Mexican law was promulgated on December 14, 1993, with entry into force on January 1, 1994.

The goal of NAFTA was to eliminate barriers to trade and investment between the U.S., Canada and Mexico. The implementation of NAFTA on January 1, 1994, brought the immediate elimination of tariffs on more than one-half of Mexico's exports to the U.S. and more than one-third of U.S. exports to Mexico. Within 10 years of the implementation of the agreement, all U.S.–Mexico tariffs were to be eliminated except for some U.S. agricultural exports to Mexico, to be phased out within 15 years. Most U.S.–Canada trade was already duty-free. NAFTA also sought to eliminate non-tariff trade barriers and to protect the intellectual property rights on traded products.

Chapter 20 provided a procedure for the international resolution of disputes over the application and interpretation of NAFTA. It was modeled after Chapter 69 of the Canada–United States Free Trade Agreement.

NAFTA is, in part, implemented by Technical Working Groups composed of government officials from each of the three partner nations.

The North American Free Trade Agreement Implementation Act made some changes to the copyright law of the United States, foreshadowing the Uruguay Round Agreements Act of 1994 by restoring copyright (within the NAFTA nations) on certain motion pictures which had entered the public domain.

U.S. congressional approval for NAFTA would have been impossible without addressing public concerns about NAFTA's environmental impact. The Clinton administration negotiated a side agreement on the environment with Canada and Mexico, the North American Agreement on Environmental Cooperation (NAAEC), which led to the creation of the Commission for Environmental Cooperation (CEC) in 1994. To alleviate concerns that NAFTA, the first regional trade agreement between a developing country and two developed countries, would have negative environmental impacts, the commission was mandated to conduct ongoing "ex post" environmental assessment, It created one of the first "ex post" frameworks for environmental assessment of trade liberalization, designed to produce a body of evidence with respect to the initial hypotheses about NAFTA and the environment, such as the concern that NAFTA would create a "race to the bottom" in environmental regulation among the three countries, or that NAFTA would pressure governments to increase their environmental protections. The CEC has held four symposia to evaluate the environmental impacts of NAFTA and commissioned 47 papers on the subject from leading independent experts.

From the earliest negotiation, agriculture was a controversial topic within NAFTA, as it has been with almost all free trade agreements signed within the WTO framework. Agriculture was the only section that was not negotiated trilaterally; instead, three separate agreements were signed between each pair of parties. The Canada–U.S. agreement contained significant restrictions and tariff quotas on agricultural products (mainly sugar, dairy, and poultry products), whereas the Mexico–U.S. pact allowed for a wider liberalization within a framework of phase-out periods (it was the first North–South FTA on agriculture to be signed).

NAFTA established the CANAMEX Corridor for road transport between Canada and Mexico, also proposed for use by rail, pipeline, and fiber optic telecommunications infrastructure. This became a High Priority Corridor under the U.S. Intermodal Surface Transportation Efficiency Act of 1991.

Another contentious issue was the investor-state dispute settlement obligations contained in Chapter 11 of NAFTA. Chapter 11 allowed corporations or individuals to sue Mexico, Canada or the United States for compensation when actions taken by those governments (or by those for whom they are responsible at international law, such as provincial, state, or municipal governments) violated international law.

This chapter has been criticized by groups in the United States, Mexico, and Canada for a variety of reasons, including not taking into account important social and environmental considerations. In Canada, several groups, including the Council of Canadians, challenged the constitutionality of Chapter 11. They lost at the trial level and the subsequent appeal.

Methanex Corporation, a Canadian corporation, filed a US$970 million suit against the United States. Methanex claimed that a California ban on methyl "tert"-butyl ether (MTBE), a substance that had found its way into many wells in the state, was hurtful to the corporation's sales of methanol. The claim was rejected, and the company was ordered to pay US$3 million to the U.S. government in costs, based on the following reasoning: "But as a matter of general international law, a non-discriminatory regulation for a public purpose, which is enacted in accordance with due process and, which affects, inter alios, a foreign investor or investment is not deemed expropriatory and compensable unless specific commitments had been given by the regulating government to the then putative foreign investor contemplating investment that the government would refrain from such regulation."

In another case, Metalclad, an American corporation, was awarded US$15.6 million from Mexico after a Mexican municipality refused a construction permit for the hazardous waste landfill it intended to construct in Guadalcázar, San Luis Potosí. The construction had already been approved by the federal government with various environmental requirements imposed (see paragraph 48 of the tribunal decision). The NAFTA panel found that the municipality did not have the authority to ban construction on the basis of its environmental concerns.

In Eli Lilly and Company v. Government of Canada the plaintiff presented a US$500 million claim for the way Canada requires usefulness in its drug patent legislation. Apotex is sued the U.S. for US$520 million because of opportunity it says it lost in an FDA generic drug decision.

Lone Pine Resources Inc. v. Government of Canada filed a US$250 million claim against Canada, accusing it of "arbitrary, capricious and illegal" behaviour, because Quebec intends to prevent fracking exploration under the St. Lawrence Seaway.

Lone Pine Resources is incorporated in Delaware but headquartered in Calgary, and had an initial public offering on the NYSE May 25, 2011, of 15 million shares each for $13, which raised US$195 million.

Barutciski acknowledged "that NAFTA and other investor-protection treaties create an anomaly in that Canadian companies that have also seen their permits rescinded by the very same Quebec legislation, which expressly forbids the paying of compensation, do not have the right (to) pursue a NAFTA claim", and that winning "compensation in Canadian courts for domestic companies in this case would be more difficult since the Constitution puts property rights in provincial hands".

A treaty with China would extend similar rights to Chinese investors, including SOEs.

NAFTA's Chapter 19 was a trade dispute mechanism which subjects antidumping and countervailing duty (AD/CVD) determinations to binational panel review instead of, or in addition to, conventional judicial review. For example, in the United States, review of agency decisions imposing antidumping and countervailing duties are normally heard before the U.S. Court of International Trade, an Article III court. NAFTA parties, however, had the option of appealing the decisions to binational panels composed of five citizens from the two relevant NAFTA countries. The panelists were generally lawyers experienced in international trade law. Since NAFTA did not include substantive provisions concerning AD/CVD, the panel was charged with determining whether final agency determinations involving AD/CVD conformed with the country's domestic law. Chapter 19 was an anomaly in international dispute settlement since it did not apply international law, but required a panel composed of individuals from many countries to re-examine the application of one country's domestic law.

A Chapter 19 panel was expected to examine whether the agency's determination was supported by "substantial evidence". This standard assumed significant deference to the domestic agency. Some of the most controversial trade disputes in recent years, such as the U.S.–Canada softwood lumber dispute, have been litigated before Chapter 19 panels.

Decisions by Chapter 19 panels could be challenged before a NAFTA extraordinary challenge committee. However, an extraordinary challenge committee did not function as an ordinary appeal. Under NAFTA, it only vacated or remanded a decision if the decision involveed a significant and material error that threatens the integrity of the NAFTA dispute settlement system. Since January 2006, no NAFTA party had successfully challenged a Chapter 19 panel's decision before an extraordinary challenge committee.

The roster of NAFTA adjudicators included many retired judges, such as Alice Desjardins, John Maxwell Evans, Constance Hunt, John Richard, Arlin M. Adams, Susan Getzendanner, George C. Pratt, Charles B. Renfrew and Sandra Day O'Connor.

In 2008, Canadian exports to the United States and Mexico were at $381.3 billion, with imports at $245.1 billion. According to a 2004 article by University of Toronto economist Daniel Trefler, NAFTA produced a significant net benefit to Canada in 2003, with long-term productivity increasing by up to 15 percent in industries that experienced the deepest tariff cuts. While the contraction of low-productivity plants reduced employment (up to 12 percent of existing positions), these job losses lasted less than a decade; overall, unemployment in Canada has fallen since the passage of the act. Commenting on this trade-off, Trefler said that the critical question in trade policy is to understand "how freer trade can be implemented in an industrialized economy in a way that recognizes both the long-run gains and the short-term adjustment costs borne by workers and others".

A study in 2007 found that NAFTA had "a substantial impact on international trade volumes, but a modest effect on prices and welfare".

According to a 2012 study, with reduced NAFTA trade tariffs, trade with the United States and Mexico only increased by a modest 11% in Canada compared to an increase of 41% for the U.S. and 118% for Mexico. Moreover, the U.S. and Mexico benefited more from the tariff reductions component, with welfare increases of 0.08% and 1.31%, respectively, with Canada experiencing a decrease of 0.06%.

According to a 2017 report by the New York City based public policy think tank report, Council on Foreign Relations (CFR), bilateral trade in agricultural products tripled in size from 1994 to 2017 and is considered to be one of the largest economic effects of NAFTA on U.S.-Canada trade with Canada becoming the U.S. agricultural sectors' leading importer. Canadian fears of losing manufacturing jobs to the United States did not materialize with manufacturing employment holding "steady". However, with Canada's labour productivity levels at 72% of U.S. levels, the hopes of closing the "productivity gap" between the two countries were also not realized.

According to a 2018 Sierra Club report, Canada's commitments under NAFTA and the Paris agreement conflicted. The Paris commitments were voluntary, and NAFTA's were compulsory.

According to a 2018 report by Gordon Laxter published by the Council of Canadians, NAFTA's Article 605, energy proportionality rule ensures that Americans had "virtually unlimited first access to most of Canada's oil and natural gas" and Canada could not reduce oil, natural gas and electricity exports (74% its oil and 52% its natural gas) to the U.S., even if Canada was experiencing shortages. These provisions that seemed logical when NAFTA was signed in 1993 are no longer appropriate. The Council of Canadians promoted environmental protection and was against NAFTA's role in encouraging development of the tar sands and fracking.

US President Donald Trump, angered by Canada's dairy tax of "almost 300%", threatened to leave Canada out of the NAFTA. Since 1972, Canada has been operating on a "supply management" system, which the United States is attempting to pressure it out of, specifically focusing on the dairy industry. However, this has not yet taken place, as Quebec, which holds approximately half the country's dairy farms, still supports supply management.

Maquiladoras (Mexican assembly plants that take in imported components and produce goods for export) became the landmark of trade in Mexico. They moved to Mexico from the United States, hence the debate over the loss of American jobs. Income in the maquiladora sector had increased 15.5% since the implementation of NAFTA in 1994. Other sectors also benefited from the free trade agreement, and the share of exports to the U.S. from non-border states increased in the last five years while the share of exports from border states decreased. This allowed for rapid growth in non-border metropolitan areas such as Toluca, León, and Puebla, which were all larger in population than Tijuana, Ciudad Juárez, and Reynosa.

The overall effect of the Mexico–U.S. agricultural agreement is disputed. Mexico did not invest in the infrastructure necessary for competition, such as efficient railroads and highways. This resulted in more difficult living conditions for the country's poor. Mexico's agricultural exports increased 9.4 percent annually between 1994 and 2001, while imports increased by only 6.9 percent a year during the same period.

One of the most affected agricultural sectors was the meat industry. Mexico went from a small player in the pre-1994 U.S. export market to the second largest importer of U.S. agricultural products in 2004, and NAFTA may have been a major catalyst for this change. Free trade removed the hurdles that impeded business between the two countries, so Mexico provided a growing market for meat for the U.S., and increased sales and profits for the U.S. meat industry. A coinciding noticeable increase in the Mexican per capita GDP greatly changed meat consumption patterns as per capita meat consumption grew.

Production of corn in Mexico increased since NAFTA. However, internal demand for corn had increased beyond Mexico's supply to the point where imports became necessary, far beyond the quotas Mexico originally negotiated. Zahniser & Coyle pointed out that corn prices in Mexico, adjusted for international prices, have drastically decreased, but through a program of subsidies expanded by former president Vicente Fox, production remained stable since 2000. Reducing agricultural subsidies, especially corn subsidies, was suggested as a way to reduce harm to Mexican farmers.

A 2001 "Journal of Economic Perspectives" review of the existing literature found that NAFTA was a net benefit to Mexico. By the year 2003, 80% of the commerce in Mexico was executed only with the U.S. The commercial sales surplus, combined with the deficit with the rest of the world, created a dependency in Mexico's exports. These effects were evident in the 2001 recession, which resulted in either a low rate or a negative rate in Mexico's exports.

A 2015 study found that Mexico's welfare increased by 1.31% as a result of the NAFTA tariff reductions and that Mexico's intra-bloc trade increased by 118%. Inequality and poverty fell in the most globalization-affected regions of Mexico. 2013 and 2015 studies showed that Mexican small farmers benefited more from NAFTA than large-scale farmers.

NAFTA had also been credited with the rise of the Mexican middle class. A Tufts University study found that NAFTA lowered the average cost of basic necessities in Mexico by up to 50%. This price reduction increased cash-on-hand for many Mexican families, allowing Mexico to graduate more engineers than Germany each year.

Growth in new sales orders indicated an increase in demand for manufactured products, which resulted in expansion of production and a higher employment rate to satisfy the increment in the demand. The growth in the maquiladora industry and in the manufacturing industry was of 4.7% in August 2016. Three quarters of the imports and exports are with the U.S.

Tufts University political scientist Daniel W. Drezner argued that NAFTA made it easier for Mexico to transform to a real democracy and become a country that views itself as North American. This has boosted cooperation between the United States and Mexico.

Economists generally agreed that the United States economy benefited overall from NAFTA as it increased trade. In a 2012 survey of the Initiative on Global Markets' Economic Experts Panel, 95% of the participants said that, on average, U.S. citizens benefited from NAFTA while none said that NAFTA hurt US citizens, on average. A 2001 "Journal of Economic Perspectives" review found that NAFTA was a net benefit to the United States. A 2015 study found that US welfare increased by 0.08% as a result of NAFTA tariff reductions, and that US intra-bloc trade increased by 41%.

A 2014 study on the effects of NAFTA on US trade jobs and investment found that between 1993 and 2013, the US trade deficit with Mexico and Canada increased from $17.0 to $177.2 billion, displacing 851,700 US jobs.

In 2015, the Congressional Research Service concluded that the "net overall effect of NAFTA on the US economy appears to have been relatively modest, primarily because trade with Canada and Mexico accounts for a small percentage of US GDP. However, there were worker and firm adjustment costs as the three countries adjusted to more open trade and investment among their economies." The report also estimated that NAFTA added $80 billion to the US economy since its implementation, equivalent to a 0.5% increase in US GDP.

The US Chamber of Commerce credited NAFTA with increasing U.S. trade in goods and services with Canada and Mexico from $337 billion in 1993 to $1.2 trillion in 2011, while the AFL–CIO blamed the agreement for sending 700,000 American manufacturing jobs to Mexico over that time.

University of California, San Diego economics professor Gordon Hanson said that NAFTA helped the US compete against China and therefore saved US jobs. While some jobs were lost to Mexico as a result of NAFTA, considerably more would have been lost to China if not for NAFTA.

The US had a trade surplus with NAFTA countries of $28.3 billion for services in 2009 and a trade deficit of $94.6 billion (36.4% annual increase) for goods in 2010. This trade deficit accounted for 26.8% of all US goods trade deficit. A 2018 study of global trade published by the Center for International Relations identified irregularities in the patterns of trade of NAFTA ecosystem using network theory analytical techniques. The study showed that the US trade balance was influenced by tax avoidance opportunities provided in Ireland.

A study published in the August 2008 issue of the "American Journal of Agricultural Economics", found NAFTA increased US agricultural exports to Mexico and Canada, even though most of the increase occurred a decade after its ratification. The study focused on the effects that gradual "phase-in" periods in regional trade agreements, including NAFTA, have on trade flows. Most of the increases in members' agricultural trade, which was only recently brought under the purview of the World Trade Organization, was due to very high trade barriers before NAFTA or other regional trade agreements.

The U.S. foreign direct investment (FDI) in NAFTA countries (stock) was $327.5 billion in 2009 (latest data available), up 8.8% from 2008. The US direct investment in NAFTA countries was in non-bank holding companies and the manufacturing, finance/insurance, and mining sectors. The foreign direct investment of Canada and Mexico in the United States (stock) was $237.2 billion in 2009 (the latest data available), up 16.5% from 2008.

In their May 24, 2017 report, the Congressional Research Service (CRS) wrote that the economic impacts of NAFTA on the U.S. economy were modest. In a 2015 report, the Congressional Research Service summarized multiple studies as follows: "In reality, NAFTA did not cause the huge job losses feared by the critics or the large economic gains predicted by supporters. The net overall effect of NAFTA on the U.S. economy appears to have been relatively modest, primarily because trade with Canada and Mexico accounts for a small percentage of U.S. GDP. However, there were worker and firm adjustment costs as the three countries adjusted to more open trade and investment among their economies."

Many American small businesses depended on exporting their products to Canada or Mexico under NAFTA. According to the U.S. Trade Representative, this trade supported over 140,000 small- and medium-sized businesses in the US.

According to University of California, Berkeley professor of economics Brad DeLong, NAFTA had an insignificant impact on US manufacturing. The adverse impact on manufacturing was exaggerated in US political discourse according to DeLong and Harvard economist Dani Rodrik.

According to a 2013 article by Jeff Faux published by the Economic Policy Institute, California, Texas, Michigan and other states with high concentrations of manufacturing jobs were most affected by job loss due to NAFTA. According to a 2011 article by EPI economist Robert Scott, about 682,900 U.S. jobs were "lost or displaced" as a result of the trade agreement. More recent studies agreed with reports by the Congressional Research Service that NAFTA only had a modest impact on manufacturing employment and automation explained 87% of the losses in manufacturing jobs.

According to a study in the "Journal of International Economics", NAFTA reduced pollution emitted by the US manufacturing sector: "On average, nearly two-thirds of the reductions in coarse particulate matter (PM and sulfur dioxide (SO emissions from the U.S. manufacturing sector between 1994 and 1998 can be attributed to trade liberalization following NAFTA."

According to the Sierra Club, NAFTA contributed to large-scale, export-oriented farming, which led to the increased use of fossil fuels, pesticides and GMO. NAFTA also contributed to environmentally destructive mining practices in Mexico. It prevented Canada from effectively regulating its tar sands industry, and created new legal avenues for transnational corporations to fight environmental legislation. In some cases, environmental policy was neglected in the wake of trade liberalization; in other cases, NAFTA's measures for investment protection, such as Chapter 11, and measures against non-tariff trade barriers threatened to discourage more vigorous environmental policy. The most serious overall increases in pollution due to NAFTA were found in the base metals sector, the Mexican petroleum sector, and the transportation equipment sector in the United States and Mexico, but not in Canada.

According to the Department of Homeland Security Yearbook of Immigration Statistics, during fiscal year 2006 (October 2005—September 2006), 73,880 foreign professionals (64,633 Canadians and 9,247 Mexicans) were admitted into the United States for temporary employment under NAFTA (i.e., in the TN status). Additionally, 17,321 of their family members (13,136 Canadians, 2,904 Mexicans, as well as a number of third-country nationals married to Canadians and Mexicans) entered the U.S. in the treaty national's dependent (TD) status. Because DHS counts the number of the new I-94 arrival records filled at the border, and the TN-1 admission is valid for three years, the number of non-immigrants in TN status present in the U.S. at the end of the fiscal year is approximately equal to the number of admissions during the year. (A discrepancy may be caused by some TN entrants leaving the country or changing status before their three-year admission period has expired, while other immigrants admitted earlier may change their status "to" TN or TD, or extend TN status granted earlier).

According to the International Organization for Migration, deaths of migrants have been on the rise worldwide with 5,604 deaths in 2016. An increased number of undocumented farmworkers in California may be due to the initial passing of NAFTA.

Canadian authorities estimated that on December 1, 2006, 24,830 U.S. citizens and 15,219 Mexican citizens were in Canada as "foreign workers". These numbers include both entrants under NAFTA and those who entered under other provisions of Canadian immigration law. New entries of foreign workers in 2006 totalled 16,841 U.S. citizens and 13,933 Mexicans.

In the second 1992 presidential debate, Ross Perot argued:

Perot ultimately lost the election, and the winner, Bill Clinton, supported NAFTA, which went into effect on January 1, 1994.

In 1996, the gasoline additive MMT was brought to Canada by Ethyl Corporation, an American company when the Canadian federal government banned imports of the additive. The American company brought a claim under NAFTA Chapter 11 seeking US$201 million, from the Canadian federal government as well as the Canadian provinces under the Agreement on Internal Trade (AIT). They argued that the additive had not been conclusively linked to any health dangers, and that the prohibition was damaging to their company. Following a finding that the ban was a violation of the AIT, the Canadian federal government repealed the ban and settled with the American company for US$13 million. Studies by Health and Welfare Canada (now Health Canada) on the health effects of MMT in fuel found no significant health effects associated with exposure to these exhaust emissions. Other Canadian researchers and the U.S. Environmental Protection Agency disagreed citing studies that suggested possible nerve damage.

The United States and Canada argued for years over the United States' 27% duty on Canadian softwood lumber imports. Canada filed many motions to have the duty eliminated and the collected duties returned to Canada. After the United States lost an appeal before a NAFTA panel, spokesperson for U.S. Trade Representative Rob Portman responded by saying: "we are, of course, disappointed with the [NAFTA panel's] decision, but it will have no impact on the anti-dumping and countervailing duty orders." On July 21, 2006, the United States Court of International Trade found that imposition of the duties was contrary to U.S. law.

On October 30, 2007, American citizens Marvin and Elaine Gottlieb filed a Notice of Intent to Submit a Claim to Arbitration under NAFTA, claiming thousands of U.S. investors lost a total of $5 billion in the fall-out from the Conservative Government's decision the previous year to change the tax rate on income trusts in the energy sector. On April 29, 2009, a determination was made that this change in tax law was not expropriation.

Several studies rejected NAFTA responsibility for depressing the incomes of poor corn farmers. The trend existed more than a decade before NAFTA existed. Also, maize production increased after 1994, and there wasn't a measurable impact on the price of Mexican corn because of subsidized corn from the United States. The studies agreed that the abolition of U.S. agricultural subsidies would benefit Mexican farmers.

Preparations for NAFTA included cancellation of Article 27 of Mexico's constitution, the cornerstone of Emiliano Zapata's revolution in 1910–1919. Under the historic Article 27, indigenous communal landholdings were protected from sale or privatization. However, this barrier to investment was incompatible with NAFTA. Indigenous farmers feared the loss of their remaining land and cheap imports (substitutes) from the US. The Zapatistas labelled NAFTA a "death sentence" to indigenous communities all over Mexico and later declared war on the Mexican state on January 1, 1994, the day NAFTA came into force.

In a "60 Minutes" interview in September 2015, 2016 presidential candidate Donald Trump called NAFTA "the single worst trade deal ever approved in [the United States]", and said that if elected, he would "either renegotiate it, or we will break it". , president of the trade group Consejo Coordinador Empresarial, expressed concern about renegotiation and the willingness to focus on the car industry. A range of trade experts said that pulling out of NAFTA would have a range of unintended consequences for the United States, including reduced access to its biggest export markets, a reduction in economic growth, and higher prices for gasoline, cars, fruits, and vegetables. Members of the private initiative in Mexico noted that to eliminate NAFTA, many laws must be adapted by the U.S. Congress. The move would also eventually result in legal complaints by the World Trade Organization. The "Washington Post" noted that a Congressional Research Service review of academic literature concluded that the "net overall effect of NAFTA on the U.S. economy appears to have been relatively modest, primarily because trade with Canada and Mexico accounts for a small percentage of U.S. GDP".

Democratic candidate Bernie Sanders, opposing the Trans-Pacific Partnership trade agreement, called it "a continuation of other disastrous trade agreements, like NAFTA, CAFTA, and permanent normal trade relations with China". He believes that free trade agreements have caused a loss of American jobs and depressed American wages. Sanders said that America needs to rebuild its manufacturing base using American factories for well-paying jobs for American labor rather than outsourcing to China and elsewhere.

Shortly after his election, U.S. President Donald Trump said he would begin renegotiating the terms of NAFTA, to resolve trade issues he had campaigned on. The leaders of Canada and Mexico have indicated their willingness to work with the Trump administration. Although vague on the exact terms he seeks in a renegotiated NAFTA, Trump threatened to withdraw from it if negotiations fail.

In July 2017, the Trump administration provided a detailed list of changes that it would like to see to NAFTA. The top priority was a reduction in the United States' trade deficit. The administration also called for the elimination of provisions that allowed Canada and Mexico to appeal duties imposed by the United States and limited the ability of the United States to impose import restrictions on Canada and Mexico. The list also alleged subsidized state-owned enterprises and currency manipulation.

According to Chad Bown of the Peterson Institute for International Economics, the Trump administration's list "is very consistent with the president's stance on liking trade barriers, liking protectionism. This makes NAFTA in many respects less of a free-trade agreement." The concerns expressed by the US Trade Representative over subsidized state-owned enterprises and currency manipulation are not thought to apply to Canada and Mexico, but rather to be designed to send a message to countries beyond North America. Jeffrey Schott of the Peterson Institute for International Economics noted that it would not be possible to conclude renegotiations quickly while also addressing all the concerns on the list. He also said that it would be difficult to do anything about trade deficits.

An October 2017 op-ed in Toronto's "The Globe and Mail" questioned whether the United States wanted to re-negotiate the agreement or planned to walk away from it no matter what, noting that newly appointed American ambassador Kelly Knight Craft is married to the owner of Alliance Resource Partners, a big US coal operation. Canada is implementing a carbon plan, and there is also the matter of a sale of Bombardier jets. "The Americans inserted so many poison pills into last week's talks in Washington that they should have been charged with murder", wrote the columnist, John Ibbitson.

"A number of the proposals that the United States has put on the table have little or no support from the U.S. business and agriculture community. It isn't clear who they're intended to benefit", said John Murphy, vice-president of the U.S. Chamber of Commerce. Pat Roberts, the senior US senator from Kansas, called for an outcry against Trump anti-NAFTA moves, saying the "issues affect real jobs, real lives and real people". Kansas is a major agricultural exporter, and farm groups warn that just threatening to leave NAFTA might cause buyers to minimize uncertainty by seeking out non-US sources.

A fourth round of talks included a U.S. demand for a sunset clause that would end the agreement in five years, unless the three countries agreed to keep it in place, a provision U.S. Commerce Secretary Wilbur Ross has said would allow the countries to kill the deal if it was not working. Canadian Prime Minister Justin Trudeau met with the House Ways and Means Committee, since Congress would have to pass legislation rolling back the treaty's provisions if Trump tries to withdraw from the pact.

From June to late August 2018, Canada was sidelined as the United States and Mexico held bilateral talks. On 27 August 2018 Mexico and the United States announced they had reached a bilateral understanding on a revamped NAFTA trade deal that included provisions that would boost automobile production in the U.S., a 10-year data protection period against generic drug production on an expanded list of products that benefits pharmaceutical companies, particularly US makers producers of high-cost biologic drugs, a sunset clause—a 16-year expiration date with regular 6-year reviews to possibly renew the agreement for additional 16-year terms, and an increased "de minimis" threshold in which Mexico raised the "de minimis" value to $100 from $50 regarding online duty- and tax-free purchases. According to an August 30 article in "The Economist", Mexico agreed to increase the rules of origin threshold which would mean that 75% as opposed to the previous 62.5% of a vehicle's components must be made in North America to avoid tariffs. Since car makers currently import less expensive components from Asia, under the revised agreement, consumers would pay more for vehicles. As well, approximately 40 to 45 per cent of vehicle components must be made by workers earning a minimum of US$16 per hour, in contrast to the current US$2.30 an hour that a worker earns on average in a Mexican car manufacturing plant. "The Economist" described this as placing "Mexican carmaking into a straitjacket".

Trudeau and Canadian Foreign Minister Chrystia Freeland announced that they were willing to join the agreement if it was in Canada's interests. Freeland returned from her European diplomatic tour early, cancelling a planned visit to Ukraine, to participate in NAFTA negotiations in Washington, D.C. in late August. According to an August 31 "Canadian Press" published in the "Ottawa Citizen", key issues under debate included supply management, Chapter 19, pharmaceuticals, cultural exemption, the sunset clause, and "de minimis" thresholds.

Although President Donald Trump warned Canada on September 1 that he would exclude them from a new trade agreement unless Canada submitted to his demands, it is not clear that the Trump administration has the authority to do so without the approval of Congress. According to Congressional Research Service (CRS) reports, one published in 2017 and another on July 26, 2018, it is likely that congressional approval to make substantive changes to NAFTA would have to be secured by President Trump before the changes could be implemented.

On September 30, 2018, the day of the deadline for the Canada–U.S. negotiations, a preliminary deal between the two countries was reached, thus preserving the trilateral pact when the Trump administration submits the agreement before Congress. The new name for the agreement was the "United States—Mexico—Canada Agreement" (USMCA) and came into effect on July 1, 2020.

Following Donald Trump's election to the presidency, a range of trade experts said that pulling out of NAFTA as Trump proposed would have a range of unintended consequences for the U.S., including reduced access to the U.S.'s biggest export markets, a reduction in economic growth, and increased prices for gasoline, cars, fruits, and vegetables. The worst affected sectors would be textiles, agriculture and automobiles.

According to Tufts University political scientist Daniel W. Drezner, the Trump administration's desire to return relations with Mexico to the pre-NAFTA era are misguided. Drezner argued that NAFTA made it easier for Mexico to transform to a real democracy and become a country that views itself as North American. If Trump acts on many of the threats that he has made against Mexico, it is not inconceivable that Mexicans would turn to left-wing populist strongmen, as several South American countries have. At the very least, US-Mexico relations would worsen, with adverse implications for cooperation on border security, counterterrorism, drug-war operations, deportations and managing Central American migration.

According to Chad P. Bown (senior fellow at the Peterson Institute for International Economics), "a renegotiated NAFTA that would reestablish trade barriers is unlikely to help workers who lost their jobs—regardless of the cause—take advantage of new employment opportunities".

According to Harvard economist Marc Melitz, "recent research estimates that the repeal of NAFTA would not increase car production in the United States". Melitz noted that this would cost manufacturing jobs.

If the original Trans-Pacific Partnership (TPP) had come into effect, existing agreements such as NAFTA would be reduced to those provisions that do not conflict with the TPP, or that require greater trade liberalization than the TPP. However, only Canada and Mexico would have the prospect of becoming members of the TPP after U.S. President Donald Trump withdrew the United States from the agreement in January 2017. In May 2017, the 11 remaining members of the TPP, including Canada and Mexico, agreed to proceed with a revised version of the trade deal without U.S. participation.

The American public was largely divided on its view of the North American Free Trade Agreement (NAFTA), with a wide partisan gap in beliefs. In a February 2018 Gallup Poll, 48% of Americans said NAFTA was good for the U.S., while 46% said it was bad.

According to a journal from the "Law and Business Review of the Americas (LBRA)", U.S. public opinion of NAFTA centers around three issues: NAFTA's impact on the creation or destruction of American jobs, NAFTA's impact on the environment, and NAFTA's impact on immigrants entering the U.S.

After President Trump's election in 2016, support for NAFTA became very polarized between Republicans and Democrats. Donald Trump expressed negative views of NAFTA, calling it "the single worst trade deal ever approved in this country". Republican support for NAFTA decreased from 43% support in 2008 to 34% in 2017. Meanwhile, Democratic support for NAFTA increased from 41% support in 2008 to 71% in 2017.

The political gap was especially large in concern to views on free trade with Mexico. As opposed to a favorable view of free trade with Canada, whom 79% of American described as a fair trade partner, only 47% of Americans believed Mexico practices fair trade. The gap widened between Democrats and Republicans: 60% of Democrats believed Mexico is practicing fair trade, while only 28% of Republicans did. This was the highest level from Democrats and the lowest level from Republicans ever recorded by the Chicago Council Survey. Republicans had more negative views of Canada as a fair trade partner than Democrats as well.

NAFTA had strong support from young Americans. In a February 2017 Gallup poll, 73% of Americans aged 18–29 said NAFTA was good for the U.S, showing higher support than any other U.S. age group. It also had slightly stronger support from unemployed Americans than from employed Americans. 





</doc>
<doc id="22051" url="https://en.wikipedia.org/wiki?curid=22051" title="National Lampoon (magazine)">
National Lampoon (magazine)

National Lampoon was an American humor magazine which ran from 1970 to 1998. The magazine started out as a spinoff from the "Harvard Lampoon". "National Lampoon" magazine reached its height of popularity and critical acclaim during the 1970s, when it had a far-reaching effect on American humor and comedy. The magazine spawned films, radio, live theatre, various sound recordings, and print products including books. Many members of the creative staff from the magazine subsequently went on to contribute creatively to successful media of all types.

During the magazine's most successful years, parody of every kind was a mainstay; surrealist content was also central to its appeal. Almost all the issues included long text pieces, shorter written pieces, a section of actual news items (dubbed "True Facts"), cartoons and comic strips. Most issues also included "Foto Funnies" or fumetti, which often featured nudity. The result was an unusual mix of intelligent, cutting-edge wit, combined with some crass, bawdy jesting.
In both cases, "National Lampoon" humor often pushed far beyond the boundaries of what was generally considered appropriate and acceptable. It was especially anarchic, satirically attacking what was considered holy and sacred. As co-founder Henry Beard described the experience years later: "There was this big door that said, 'Thou shalt not.' We touched it, and it fell off its hinges."

The magazine declined during the late 1980s, and ceased publication altogether, in 1998. Projects under the "National Lampoon" brand name continue to this day.

"National Lampoon" was started by Harvard graduates and "Harvard Lampoon" alumni Doug Kenney, Henry Beard and Robert Hoffman in 1969, when they first licensed the "Lampoon" name for a monthly national publication. The Harvard Lampoon was established in 1876 as a long-standing tradition of the campus, influencing the later National Lampoon Brand in its evolution from illustration heavy publications to satirical wit, ranging from short fiction to comic strips. The magazine's first issue was dated April 1970. The company that owned the magazine was called Twenty First Century Communications.

After a shaky start for a few issues, the magazine rapidly grew in popularity. Like the "Harvard Lampoon," individual issues had themes, including such topics as "The Future," "Back to School," "Death," "Self-Indulgence," and "Blight." The magazine regularly reprinted material in "best-of" omnibus collections. Its writers joyfully targeted every kind of phoniness, and had no specific political stance, even though individual staff members had strong political views.

Thomas Carney, writing in New Times, traced the history and style of the National Lampoon and the impact it had on comedy's new wave. "The National Lampoon," Carney wrote, "was the first full-blown appearance of non-Jewish humor in years--not anti-Semitic, just non-Jewish. Its roots were W.A.S.P. and Irish Catholic, with a weird strain of Canadian detachment. . . . This was not Jewish street-smart humor as a defense mechanism; this was slash-and-burn stuff that alternated in pitch but moved very much on the offensive. It was always disrespect everything, mostly yourself, a sort of reverse deism."

"National Lampoon" was a monthly magazine for most of its publication history. Numerous "special editions" were also published and sold simultaneously on newsstands. Some of the special editions were anthologies of reprinted material; others were entirely original. Additional projects included a calendar, a songbook, a collection of transfer designs for T-shirts, and a number of books. The magazine sold yellow binders with the Lampoon logo, designed to store a year's worth of issues.

The original art directors were cartoonist Peter Bramley and Bill Skurski, founders of New York's Cloud Studio, an alternative-culture outfit known at the time for its eclectic style. Bramley created the "Lampoon"'s first cover and induced successful cartoonists Arnold Roth and Gahan Wilson to become regular contributors.

Beginning with the eighth issue, the art direction of the magazine was taken over by Michael C. Gross, who directed the look of the magazine until 1974. A number of the "National Lampoon"'s most acerbic and humorous covers were designed or overseen by Gross, including:

Michael Gross and Doug Kenney chose a young designer from "Esquire" named Peter Kleinman to succeed the team of Gross and David Kaestle. During his" Lampoon" tenure, Kleinman was also the art director of "Heavy Metal" magazine, published by the same company. The best known of Kleinman's" Lampoon "covers were "Stevie Wonder with 3-D Glasses" painted by Sol Korby, a photographed "Nose to The Grindstone" cover depicting a man's face being pressed against a spinning grinder wheel for the "Work" issue, the "JFK's First 6000 Days" issue featuring a portrait of an old John F. Kennedy, the "Fat Elvis" cover which appeared a year before Elvis Presley died, and many of the Mara McAfee covers done in a classic Norman Rockwell style. Kleinman designed the logos for "Animal House" and "Heavy Metal." 
Kleinman left in 1979 to open an ad agency.

He was succeeded by Skip Johnson, the designer responsible for the "Sunday Newspaper Parody" and the "Arab Getting Punched in the Face" cover of the "Revenge" issue. Johnson went on to "The New York Times." He was followed by Michael Grossman, who changed the logo and style of the magazine.

In 1984, Kleinman returned as creative director and went back to the 1970s logo and style, bringing back many of the artists and writers from the magazine's heyday. He left four years later to pursue a career in corporate marketing. At that time, the "National Lampoon" magazine entered a period of precipitous decline.

Every regular monthly issue of the magazine had an editorial at the front of the magazine. This often appeared to be straightforward, but was always a parody. It was written by whoever was the editor of that particular issue, since that role rotated among the staff. A few issues were guest-edited.

The magazine was an outlet for some notable writing talents, including Douglas Kenney, Henry Beard, George W. S. Trow, Chris Miller, P. J. O'Rourke, Michael O'Donoghue, Chris Rush, Sean Kelly, Tony Hendra, Brian McConnachie, Gerald Sussman, Ellis Weiner, Ted Mann, Chris Cluess, Al Jean, Mike Reiss, Jeff Greenfield, John Hughes and Ed Subitzky.

The work of many important cartoonists, photographers, and illustrators appeared in the magazine's pages, including Neal Adams, Gahan Wilson, Robert Grossman, Michael Sullivan, Ron Barrett, Peter Bramley, Vaughn Bode, Bruce McCall, Rick Meyerowitz, Warren Sattler, M. K. Brown, Shary Flenniken, Bobby London, Edward Gorey, Jeff Jones, Joe Orlando, Arnold Roth, Rich Grote, Ed Subitzky, Mara McAfee, Sam Gross, Charles Rodrigues, Buddy Hickerson, B. K. Taylor, Birney Lettick, Frank Frazetta, Boris Vallejo, Marvin Mattelson, Stan Mack, Chris Callis, John E. Barrett, Raymond Kursar, Andy Lackow, and David C.K. McClelland.

Comedy stars John Belushi, Chevy Chase, Gilda Radner, Bill Murray, Brian Doyle Murray, Harold Ramis, and Richard Belzer first gained national attention for their performances in the National Lampoon's stage show and radio show. The first three subsequently went on to become part of "Saturday Night Live"'s original wave of Not Ready for Primetime Players, Bill Murray replaced Chase when Chase left "SNL" after the first season, and Brian Doyle Murray later appeared as an "SNL" regular. Harold Ramis went on to be a prolific director and writer working on such films as "Animal House", "Caddyshack", "Ghostbusters", and many more. Brian Doyle Murray has had roles in dozens of films, and Belzer is an Emmy Award-winning TV actor.

Gerald L. "Jerry" Taylor was the publisher, followed by William T. Lippe. The business side of the magazine was controlled by Matty Simmons, who was chairman of the board and CEO of Twenty First Century Communications, a publishing company.

"True Facts" was a section near the front of the magazine which contained true but ridiculous items from real life. Together with the masthead, it was one of the few parts of the magazine that was factual. "True Facts" included photographs of unintentionally funny signage, extracts from ludicrous newspaper reports, strange headlines, and so on. For many years John Bendel was in charge of the "True Facts" section of the magazine. Steven Brykman edited the "True Facts" section of the National Lampoon website. Several "True Facts" compilation books were published in the 1980s and early 90s, and several all-True-Facts issues of the magazine were published during the 1980s.

Most issues of the magazine featured one or more "Foto Funny" or fumetti, comic strips that use photographs instead of drawings as illustrations. The characters who appeared in the Lampoon's Foto Funnies were usually writers, editors, artists, photographers or contributing editors of the magazine, often cast alongside nude or semi-nude models. In 1980, a paperback compilation book, "National Lampoon Foto Funnies" which appeared as a part of National Lampoon Comics, was published.

The "Funny Pages" was a large section at the back of the magazine that was composed entirely of comic strips of various kinds. These included work from a number of artists who also had pieces published in the main part of the magazine, including Gahan Wilson, Ed Subitzky and Vaughn Bode, as well as artists whose work was only published in this section. The regular strips included "Dirty Duck" by Bobby London, "Trots and Bonnie" by Shary Flenniken, "The Appletons" by B. K. Taylor, "Politeness Man" by Ron Barrett, and many other strips. A compilation of Gahan Wilson's "Nuts" strip was published in 2011. The Funny Pages logo header art, which was positioned above Gahan Wilson's "Nuts" in each issue, and showed a comfortable, old-fashioned family reading newspaper-sized funny papers, was drawn by Mike Kaluta.

From time to time, the magazine advertised Lampoon-related merchandise for sale, including T-shirts that had been especially designed.

The magazine existed from 1970 to 1998. Some consider its finest period was from 1971 to 1975, although it continued to be produced on a monthly schedule throughout the 1970s and the early 1980s, and did well during that time.

However, during the late 1980s, a much more serious decline set in. In 1989, the company that controlled the magazine and its related projects (which was part of "Twenty First Century Communications") was the subject of a hostile takeover by Daniel Grodnik, a Hollywood Producer, and Tim Matheson, an actor who starred in the Lampoon's first big hit, Animal House. In 1991 it was sold outright to another company, "J2 Communications".

At that point "National Lampoon" was considered valuable only as a brand name that could be licensed out to other companies. The magazine was issued erratically and rarely from 1991 onwards. 1998 saw the last issue.

The first issue was April 1970; by November of that year, Michael C. Gross had become the art director. He achieved a unified, sophisticated, and integrated look for the magazine, which enhanced its humorous appeal.

National Lampoon's most successful sales period was 1973–75. Its national circulation peaked at 1,000,096 copies sold of the October 1974 "Pubescence" issue. The 1974 monthly average was 830,000, which was also a peak. Former "Lampoon" editor Tony Hendra's book "Going Too Far" includes a series of precise circulation figures.

It was also during this time that Lemmings (National Lampoon) Show and The National Lampoon Radio Hour show was broadcast, bringing interest and acclaim to the National Lampoon brand with magazine talent like writer Michael O'Donoghue that would go on to write for Saturday Night Live with many of the players transitioning from Lemmings (National Lampoon) and The National Lampoon Radio Hour.

The magazine was considered by many to be at its creative zenith during this time. It should however be noted that the publishing industry's newsstand sales were excellent for many other titles during that time: there were sales peaks for "Mad" (more than 2 million), "Playboy" (more than 7 million), and "TV Guide" (more than 19 million).

Some fans consider the glory days of National Lampoon to have ended in 1975, although the magazine remained popular and profitable long after that point. During 1975, the three founders (Kenney, Beard, and Hoffman) took advantage of a buyout clause in their contracts for $7.5 million. About the same time, writers Michael O'Donoghue and Anne Beatts left to join the NBC comedy show "Saturday Night Live" ("SNL"). At the same time, the" National Lampoon Show's "John Belushi and Gilda Radner left the troupe to join the original septet of" SNL's" Not Ready for Primetime Players.

The magazine was a springboard to the cinema of the United States for a generation of comedy writers, directors, and performers. Various alumni went on to create and write for "SNL," "The David Letterman Show," SCTV, "The Simpsons", "Married... with Children", "Night Court", and various films including "National Lampoon's Animal House", "Caddyshack", "National Lampoon's Vacation", and "Ghostbusters".

As some of the original creators departed, the magazine remained popular and profitable as it had the emergence of John Hughes and editor-in-chief P.J. O'Rourke, along with artists and writers such as Gerry Sussman, Ellis Weiner, Tony Hendra, Ted Mann, Peter Kleinman, Chris Cluess, Stu Kreisman, John Weidman, Jeff Greenfield, Bruce McCall, and Rick Meyerowitz.

In 1985, Matty Simmons (who had been working only on the business end of the Lampoon up to that point) took over as editor-in-chief. He fired the entire editorial staff, and appointed his two sons, Michael Simmons and Andy Simmons, as editors, Peter Kleinman as creative director and editor, and Larry "Ratso" Sloman as executive editor. The magazine was on an increasingly shaky financial footing, and beginning in November 1986, the magazine was published six times a year instead of every month.

In 1989, the magazine was acquired in a hostile takeover by a business partnership of producer Daniel Grodnik and actor Tim Matheson (who played "Otter" in the 1978 film "National Lampoon's Animal House"). Grodnik and Matheson became the co-Chairmen/co-CEOs. During their tenure, the stock went up from under $2 to $6, and the magazine was able to double its monthly ad pages. The company moved its headquarters from New York to Los Angeles to focus on film and television. The publishing operation stayed in New York. Grodnik and Matheson sold the company in the 1990s.

In 1991, the magazine (and more importantly, the rights to the brand name "National Lampoon") were bought by a company called J2 Communications (a company previously known for marketing Tim Conway's "Dorf" videos), headed by James P. Jimirro.

J2 Communications' focus was to make money by licensing out the brand name "National Lampoon". The company was contractually obliged to publish at least one new issue of the magazine per year to retain the rights to the Lampoon name. However, the company had very little interest in the magazine itself; throughout the 1990s, the number of issues per year declined precipitously and erratically. In 1991, an attempt at monthly publication was made; nine issues were produced that year. Only two issues were released in 1992. This was followed by one issue in 1993, five in 1994, and three in 1995. For the last three years of its existence, the magazine was published only once a year.

The magazine's final print publication was November 1998, after which the contract was renegotiated, and in a sharp reversal, J2 Communications was then prohibited from publishing issues of the magazine. J2, however, still owned the rights to the brand name, which it continued to franchise out to other users. In 2002, the use of the brand name and the rights to republish old material were sold to a new, and otherwise unrelated, company which chose to call itself National Lampoon, Incorporated.

During its most active period, the magazine spun off numerous productions in a wide variety of media.
"National Lampoon" released books, special issues, anthologies, and other print pieces, including:



"True Facts" special editions and books

Vinyl record albums

Vinyl singles


Many of the older albums that were originally on vinyl have been re-issued as CDs and a number of tracks from certain albums are available as MP3s.




Considerable ambiguity exists about what actually constitutes a "National Lampoon" film.

During the 1970s and early 1980s, a few films were made as spin-offs from the original "National Lampoon" magazine, using its creative staff. The first theatrical release, and by far the most successful "National Lampoon" film was "National Lampoon's Animal House" (1978). Starring John Belushi and written by Doug Kenney, Harold Ramis, and Chris Miller, it became the highest-grossing comedy film of that time. Produced on a low budget, it was so enormously profitable that, from that point on for the next two decades, the name "National Lampoon" applied to the title of a movie was considered to be a valuable selling point in and of itself.

Numerous movies were subsequently made that had "National Lampoon" as part of the title. Many of these were unrelated projects because, by that time, the name "National Lampoon" could simply be licensed on a one-time basis, by any company, for a fee. Critics such as the "Orlando Sentinel"′s Roger Moore and "The New York Times"′ Andrew Adam Newman have written about the cheapening of the "National Lampoon"′s movie imprimatur; in 2006, an Associated Press review said: "The National Lampoon, once a brand name above nearly all others in comedy, has become shorthand for pathetic frat boy humor."

The first of the "National Lampoon" movies was a not-very-successful made-for-TV movie:

In 1978, "National Lampoon's Animal House" was released. Made on a small budget, it did phenomenally well at the box office. In 2001, the United States Library of Congress considered the film "culturally significant", and preserved it in the National Film Registry.

The script had its origins in a series of short stories that had been previously published in the magazine. These included Chris Miller's "Night of the Seven Fires", which dramatized a fraternity initiation and included the characters Pinto and Otter, which contained prose versions of the toga party, the "road trip", and the dead horse incident. Another source was Doug Kenney's "First Lay Comics", which included the angel and devil scene and the grocery-cart affair. According to the authors, most of these elements were based on real incidents.

The film was of great cultural significance to its time, as "The New York Times" describes the magazine's 1970s period as "Hedonism {} in full sway and political correctness in its infancy." Animal House, as the article describes was a crucial film manifestation of that culture.

An article from "The Atlantic Monthly" describes how "Animal House" captures the struggle between "elitist {fraternity} who willingly aligned itself with the establishment, and the kind full of kooks who refused to be tamed." That concept was a crucial figment of the early National Lampoon Magazine, according to a "The New York Times" article concerning the early years of the Magazine and co-founder Douglas Kenney's brand of comedy as a "liberating response to a rigid and hypocritical culture."

This 1982 movie was an attempt by John Hughes to make something similar to "Animal House". "National Lampoon's Class Reunion" was not successful, however.

Released in 1983, the movie "National Lampoon's Vacation" was based upon John Hughes's "National Lampoon" story "Vacation '58". The movie's financial success gave rise to several follow-up films, including "National Lampoon's European Vacation" (1985), "National Lampoon's Christmas Vacation" (1989), based on John Hughes's "Christmas '59", "Vegas Vacation" (1997), and most recently "Vacation" (2015), all featuring Chevy Chase.

The Robert Altman film "O.C. and Stiggs" (1987) was based on two characters who had been featured in several written pieces in "National Lampoon" magazine, including an issue-long story from October 1982 entitled "The Utterly Monstrous, Mind-Roasting Summer of O.C. and Stiggs." Completed in 1984, the film was not released until 1987, when it was shown in a small number of theaters and without the "National Lampoon" name. It was not a success.

Following the success of "Animal House", "MAD" magazine lent its name to a 1980 comedy titled "Up the Academy". Although two of "Animal House"′s co-writers were the "Lampoon"′s Doug Kenney and Chris Miller, "Up The Academy" was strictly a licensing maneuver, with no creative input from "Mad"′s staff or contributors. It was a critical and commercial failure.

In 2015, a documentary film was released called "". The film featured a great deal of content from the magazine, as well as interviews with staff members and fans, and it explains how the magazine changed the course of humor.

The 2018 film "A Futile and Stupid Gesture", a biography of co-founder Douglas Kenney, also depicts the magazine's early years. The film was described by a 2018 The New York Times Article as a "snapshot of a moment where comedy's freshest counter-culture impulse was gleefully crass and willfully offensive." In the same article, Douglas Kenney was said to "spot a comical hollowness and rot in the society he and his peers were trained to join."




</doc>
<doc id="22052" url="https://en.wikipedia.org/wiki?curid=22052" title="Non-disclosure agreement">
Non-disclosure agreement

A non-disclosure agreement (NDA), also known as a confidentiality agreement (CA), confidential disclosure agreement (CDA), proprietary information agreement (PIA) or secrecy agreement (SA), is a legal contract between at least two parties that outlines confidential material, knowledge, or information that the parties wish to share with one another for certain purposes, but wish to restrict access to. Doctor–patient confidentiality (physician–patient privilege), attorney–client privilege, priest–penitent privilege, bank–client confidentiality, and kickback agreements are examples, often not enshrined in a written contract between the parties. 

It is a contract through which the parties agree not to disclose information covered by the agreement. An NDA creates a confidential relationship between the parties, typically to protect any type of confidential and proprietary information or trade secrets. As such, an NDA protects non-public business information. Like all contracts, they cannot be enforced if the contracted activities are felonies. NDAs are commonly signed when two companies, individuals, or other entities (such as partnerships, societies, etc.) are considering doing business and need to understand the processes used in each other's business for the purpose of evaluating the potential business relationship. NDAs can be "mutual", meaning both parties are restricted in their use of the materials provided, or they can restrict the use of material by a single party. An employee can be required to sign an NDA or NDA-like agreement with an employer, protecting trade secrets. In fact, some employment agreements include a clause restricting employees' use and dissemination of company-owned confidential information. In legal disputes resolved by settlement, the parties often sign a confidentiality agreement relating to the terms of the settlement. Examples of this agreement are The Dolby Trademark Agreement with Dolby Laboratories, the Windows Insider Agreement, and the Halo CFP (Community Feedback Program) with Microsoft.

In some cases, employees who are dismissed following their complaints about unacceptable practices (whistleblowers), or discrimination against and harassment of themselves, may be paid compensation subject to an NDA forbidding them from disclosing the events complained about. Such conditions in an NDA may not be enforceable in law, although they may intimidate the former employee into silence.

A non-disclosure agreement (NDA) may be classified as unilateral, bilateral, or multilateral:

A unilateral NDA (sometimes referred to as a one-way NDA) involves two parties where only one party (i.e., the disclosing party) anticipates disclosing certain information to the other party (i.e., the receiving party) and requires that the information be protected from further disclosure for some reason (e.g., maintaining the secrecy necessary to satisfy patent laws or legal protection for trade secrets, limiting disclosure of information prior to issuing a press release for a major announcement, or simply ensuring that a receiving party does not use or disclose information without compensating the disclosing party).

A bilateral NDA (sometimes referred to as a mutual NDA or a two-way NDA) involves two parties where both parties anticipate disclosing information to one another that each intends to protect from further disclosure. This type of NDA is common when businesses are considering some kind of joint venture or merger.

When presented with a unilateral NDA, some parties may insist upon a bilateral NDA, even though they anticipate that only one of the parties will disclose information under the NDA. This approach is intended to incentivize the drafter to make the provisions in the NDA more "fair and balanced" by introducing the possibility that a receiving party could later become a disclosing party or vice versa, which is not an entirely uncommon occurrence.

A multilateral NDA involves three or more parties where at least one of the parties anticipates disclosing information to the other parties and requires that the information be protected from further disclosure. This type of NDA eliminates the need for separate unilateral or bilateral NDAs between only two parties. E.g., a single multiparty NDA entered into by three parties who each intend to disclose information to the other two parties could be used in place of three separate bilateral NDAs between the first and second parties, second and third parties, and third and first parties.

A multilateral NDA can be advantageous because the parties involved review, execute, and implement just one agreement. However, this advantage can be offset by more complex negotiations that may be required for the parties involved to reach a unanimous consensus on a multilateral agreement.

A non-disclosure agreement can protect any type of information that is not generally known. However, non-disclosure agreements may also contain clauses that will protect the person receiving the information so that if they lawfully obtained the information through other sources they would not be obligated to keep the information secret. In other words, the non-disclosure agreement typically only requires the receiving party to maintain information in confidence when that information has been directly supplied by the disclosing party. However, it is sometimes easier to get a receiving party to sign a simple agreement that is shorter, less complex and does not contain safety provisions protecting the receiver.

Some common issues addressed in an NDA include:


Deeds of confidentiality and fidelity (also referred to as deeds of confidentiality or confidentiality deeds) are commonly used in Australia. These documents generally serve the same purpose as and contain provisions similar to non-disclosure agreements (NDAs) used elsewhere. However, these documents are legally treated as deeds and are thus binding, unlike contracts, without consideration.

In California, (and some other U.S. states), there are some special circumstances relating to non-disclosure agreements and non-compete clauses. California's courts and legislature have signaled that they generally value an employee's mobility and entrepreneurship more highly than they do protectionist doctrine.

Use of non-disclosure agreements are on the rise in India and is governed by the Indian Contract Act 1872. Use of an NDA is crucial in many circumstances, such as to tie in employees who are developing patentable technology if the employer intends to apply for a patent. Non-disclosure agreements have become very important in light of India's burgeoning outsourcing industry. In India, an NDA must be stamped to be a valid enforceable document.

In Britain, in addition to use to protect trade secrets, NDAs are often used as a condition of a financial settlement in an attempt to silence whistleblowing employees from making public the misdeeds of their former employers. There is law allowing protected disclosure despite an NDA, although employers sometimes intimidate the former employee into silence despite this.


1. Information about non-disclosure-agreements (NDAs) published by the UK Intellectual Property Office - ("2018-01-15")

2. Confidentiality and Confidential Disclosure Agreements (CDA) booklet edited by the UK Intellectual Property Office ("300 KB pdf file") - ("2005-01")


</doc>
<doc id="22053" url="https://en.wikipedia.org/wiki?curid=22053" title="Network effect">
Network effect

A network effect (also called network externality or demand-side economies of scale) is the effect described in economics and business that an additional user of goods or services has on the value of that product to others. When a network effect is present, the value of a product or service increases according to the number of others using it.

The classic example is the telephone, where a greater number of users increases the value to each. A positive externality is created when a telephone is purchased without its owner intending to create value for other users, but does so regardless. Online social networks work similarly, with platforms like Twitter, Facebook, and WhatsApp increasing in value to each member as more users join.

The network effect can create a bandwagon effect as the network becomes more valuable and more people join, resulting in a positive feedback loop.

The expression "network effect" is applied to positive network externalities as in the case of the telephone. Negative network externalities can also occur, where more users make a product less valuable, but they are more commonly referred to as "congestion" (as in traffic congestion or network congestion).

Network effects were a central theme in the arguments of Theodore Vail, the first post-patent president of Bell Telephone, in gaining a monopoly on US telephone services. In 1908, when he presented the concept in Bell's annual report, there were over 4,000 local and regional telephone exchanges, most of which were eventually merged into the Bell System.

Network effects were popularized by Robert Metcalfe, stated as Metcalfe's law. Metcalfe was one of the co-inventors of Ethernet and a co-founder of the company 3Com. In selling the product, Metcalfe argued that customers needed Ethernet cards to grow above a certain critical mass if they were to reap the benefits of their network. According to Metcalfe, the rationale behind the sale of networking cards was that the cost of the network was directly proportional to the number of cards installed, but the value of the network was proportional to the square of the number of users. This was expressed algebraically as having a cost of N, and a value of N. While the actual numbers behind this proposition were never firm, the concept allowed customers to share access to expensive resources like disk drives and printers, send e-mail, and eventually access the Internet.

The economic theory of the network effect was advanced significantly between 1985 and 1995 by researchers Michael L. Katz, Carl Shapiro, Joseph Farrell and Garth Saloner. Author, high-tech entrepreneur Rod Beckstrom presented a mathematical model for describing networks that are in a state of positive network effect at BlackHat and Defcon in 2009 and also presented the "inverse network effect" with an economic model for defining it as well.

Network effects become significant after a certain subscription percentage has been achieved, called critical mass. At the critical mass point, the value obtained from the good or service is greater than or equal to the price paid for the good or service. As the value of the good is determined by the user base, this implies that after a certain number of people have subscribed to the service or purchased the good, additional people will subscribe to the service or purchase the good due to the value exceeding the price.

A key business concern must then be how to attract users prior to reaching critical mass. One way is to rely on extrinsic motivation, such as a payment, a fee waiver, or a request for friends to sign up. A more natural strategy is to build a system that has enough value "without" network effects, at least to early adopters. Then, as the number of users increases, the system becomes even more valuable and is able to attract a wider user base.

Beyond critical mass, the increasing number of subscribers generally cannot continue indefinitely. After a certain point, most networks become either congested or saturated, stopping future uptake. Congestion occurs due to overuse. The applicable analogy is that of a telephone network. While the number of users is below the congestion point, each additional user adds additional value to every other customer. However, at some point, the addition of an extra user exceeds the capacity of the existing system. After this point, each additional user decreases the value obtained by every other user. In practical terms, each additional user increases the total system load, leading to busy signals, the inability to get a dial tone, and poor customer support. Assuming the congestion point is below the potential market size, the next critical point is where the value obtained again equals the price paid. The network will cease to grow at this point if system capacity is not improved. Peer-to-peer (P2P) systems are networks designed to distribute load among their user pool. This theoretically allows P2P networks to scale indefinitely. The P2P based telephony service Skype benefits from this effect and its growth is limited primarily by market saturation.

Network effects are commonly mistaken for economies of scale, which result from business size rather than interoperability. To help clarify the distinction, people speak of demand side vs. supply side economies of scale. Classical economies of scale are on the production side, while network effects arise on the demand side. Network effects are also mistaken for economies of scope. Because of the positive feedback often associated with the network effect, system dynamics can be used as a modelling method to describe the phenomena. Word of mouth and the Bass diffusion model are also potentially applicable.

If some existing technology or company whose benefits are largely based on network effects starts to lose market share against a challenger such as a disruptive technology or open standards based competition, the benefits of network effects will reduce for the incumbent, and increase for the challenger. In this model, a tipping point is eventually reached at which the network effects of the challenger dominate those of the former incumbent, and the incumbent is forced into an accelerating decline, whilst the challenger takes over the incumbent's former position.

Network effects are notorious for causing lock-in with the most-cited examples being Microsoft products and the QWERTY keyboard. Vendor lock-in can be mitigated by opening the standards upon which users depend, allowing competition between implementations. This does not, however, mitigate industry-wide lock-in to the standard itself. Indeed, as there are now multiple vendors driving down the price and increasing the quality, more users are likely to adopt the standard, thereby creating greater industry-wide lock-in to the standard.

Broadly, there are two kinds of networks effects:

Additionally, there are two sources of economic value that are relevant when analyzing products that display network effects:

Negative network externalities, in the mathematical sense, are those that have a negative effect compared to normal (positive) network effects. Just as positive network externalities (network effects) cause positive feedback and exponential growth, negative network externalities create negative feedback and exponential decay. In nature, negative network externalities are the forces that pull towards equilibrium, are responsible for stability, and represent physical limitations keeping systems bounded.

Congestion occurs when the efficiency of a network decreases as more people use it, and this reduces the value to people already using it. Traffic congestion that overloads the freeway and network congestion on connections with limited bandwidth both display negative network externalities.

Braess' paradox suggests that adding paths through a network can have a negative effect on performance of the network.

Interoperability has the effect of making the network bigger and thus increases the external value of the network to consumers. Interoperability achieves this primarily by increasing potential connections and secondarily by attracting new participants to the network. Other benefits of interoperability include reduced uncertainty, reduced lock-in, commoditization and competition based on price.

Interoperability can be achieved through standardization or other cooperation. Companies involved in fostering interoperability face a tension between cooperating with their competitors to grow the potential market for products and competing for market share.

In communication and information technologies, open standards and interfaces are often developed through the participation of multiple companies and are usually perceived to provide mutual benefit. But, in cases in which the relevant communication protocols or interfaces are closed standards, the network effect can give the company controlling those standards monopoly power. The Microsoft corporation is widely seen by computer professionals as maintaining its monopoly through these means. One observed method Microsoft uses to put the network effect to its advantage is called Embrace, extend and extinguish.

Mirabilis is an Israeli start-up which pioneered instant messaging (IM) and was bought by America Online. By giving away their ICQ product for free and preventing interoperability between their client software and other products, they were able to temporarily dominate the market for instant messaging. Because of the network effect, new IM users gained much more value by choosing to use the Mirabilis system (and join its large network of users) than they would using a competing system. As was typical for that era, the company never made any attempt to generate profits from its dominant position before selling the company.

Stock exchanges and derivatives exchanges feature a network effect. Market liquidity is a major determinant of transaction cost in the sale or purchase of a security, as a bid–ask spread exists between the price at which a purchase can be made versus the price at which the sale of the same security can be made. As the number of buyers and sellers on an exchange increases, liquidity increases, and transaction costs decrease. This then attracts a larger number of buyers and sellers to the exchange.

The network advantage of financial exchanges is apparent in the difficulty that startup exchanges have in dislodging a dominant exchange. For example, the Chicago Board of Trade has retained overwhelming dominance of trading in US Treasury bond futures despite the startup of Eurex US trading of identical futures contracts. Similarly, the Chicago Mercantile Exchange has maintained dominance in trading of Eurobond interest rate futures despite a challenge from Euronext.Liffe.

There are very strong network effects operating in the market for widely used computer software.

For many people choosing an office suite, prime considerations include how much value having learned that office suite will prove to potential employers, and how well the software interoperates with other users. That is, since learning to use an office suite takes many hours, users want to invest that time learning the office suite that will make them most attractive to potential employers and clients. Similarly, finding already-trained employees is a big concern for employers when deciding which office suite to purchase.

In 2007 Apple released the iPhone followed by the app store. Most iPhone apps rely heavily on the existence of strong network effects. This enables the software to grow in popularity very quickly and spread to a large userbase with very limited marketing needed. The Freemium business model has evolved to take advantage of these network effects by releasing a free version that will not limit the adoption or any users and then charge for premium features as the primary source of revenue.

Many web sites benefit from a network effect. One example is web marketplaces and exchanges. For example, eBay would not be a particularly useful site if auctions were not competitive. As the number of users grows on eBay, auctions grow more competitive, pushing up the prices of bids on items. This makes it more worthwhile to sell on eBay and brings more sellers onto eBay, which, in turn, drives prices down again due to increased supply. Increased supply brings even more buyers to eBay. Essentially, as the number of users of eBay grows, prices fall and supply increases, and more and more people find the site to be useful.

Network effects were used as justification in business models by some of the dot-com companies in the late 1990s. These firms operated under the belief that when a new market comes into being which contains strong network effects, firms should care more about growing their market share than about becoming profitable. The justification was that market share would determine which firm could set technical and marketing standards and giving these companies a first-mover advantage.

Social networking websites are good examples. The more people register onto a social networking website, the more useful the website is to its registrants.

Alexa Internet uses a technology that tracks users' surfing patterns; thus Alexa's Related Sites results improve as more users use the technology. Alexa's network relies heavily on a small number of browser software relationships, which makes the network more vulnerable to competition.

Google has also attempted to create a network effect in its advertising business with its Google AdSense service. Google AdSense places ads on many small sites, such as blogs, using Google technology to determine which ads are relevant to which blogs. Thus, the service appears to aim to serve as an exchange (or ad network) for matching many advertisers with many small sites (such as blogs). In general, the more blogs Google AdSense can reach, the more advertisers it will attract, making it the most attractive option for more blogs, and so on, making the network more valuable for all participants.

By contrast, the value of a news site is primarily proportional to the quality of the articles, not to the number of other people using the site. Similarly, the first generation of search sites experienced little network effect, as the value of the site was based on the value of the search results. This allowed Google to win users away from Yahoo! without much trouble, once users believed that Google's search results were superior. Some commentators mistook the value of the Yahoo! brand (which does increase as more people know of it) for a network effect protecting its advertising business.

There are strong network effects in the initial choice of rail gauge, and in gauge conversion decisions. Even when placing isolated rails not connected to any other lines, track layers usually choose a standard rail gauge so they can use off-the-shelf rolling stock. Although a few manufacturers make rolling stock that can adjust to different rail gauges, most manufacturers make rolling stock that only works with one of the standard rail gauges.



</doc>
<doc id="22054" url="https://en.wikipedia.org/wiki?curid=22054" title="Nuclear fission">
Nuclear fission

In nuclear physics and nuclear chemistry, nuclear fission is a nuclear reaction or a radioactive decay process in which the nucleus of an atom splits into two or more smaller, lighter nuclei. The fission process often produces gamma photons, and releases a very large amount of energy even by the energetic standards of radioactive decay.

Nuclear fission of heavy elements was discovered on December 17, 1938 by German Otto Hahn and his assistant Fritz Strassmann, and explained theoretically in January 1939 by Lise Meitner and her nephew Otto Robert Frisch. Frisch named the process by analogy with biological fission of living cells. For heavy nuclides, it is an exothermic reaction which can release large amounts of energy both as electromagnetic radiation and as kinetic energy of the fragments (heating the bulk material where fission takes place). Like nuclear fusion, in order for fission to produce energy, the total binding energy of the resulting elements must have a greater binding energy than that of the starting element.

Fission is a form of nuclear transmutation because the resulting fragments are not the same element as the original atom. The two (or more) nuclei produced are most often of comparable but slightly different sizes, typically with a mass ratio of products of about 3 to 2, for common fissile isotopes. Most fissions are binary fissions (producing two charged fragments), but occasionally (2 to 4 times per 1000 events), "three" positively charged fragments are produced, in a ternary fission. The smallest of these fragments in ternary processes ranges in size from a proton to an argon nucleus.

Apart from fission induced by a neutron, harnessed and exploited by humans, a natural form of spontaneous radioactive decay (not requiring a neutron) is also referred to as fission, and occurs especially in very high-mass-number isotopes. Spontaneous fission was discovered in 1940 by Flyorov, Petrzhak, and Kurchatov in Moscow, when they confirmed that, without bombardment by neutrons, the fission rate of uranium was indeed negligible, as predicted by Niels Bohr; it was not.

The unpredictable composition of the products (which vary in a broad probabilistic and somewhat chaotic manner) distinguishes fission from purely quantum tunneling processes such as proton emission, alpha decay, and cluster decay, which give the same products each time. Nuclear fission produces energy for nuclear power and drives the explosion of nuclear weapons. Both uses are possible because certain substances called nuclear fuels undergo fission when struck by fission neutrons, and in turn emit neutrons when they break apart. This makes a self-sustaining nuclear chain reaction possible, releasing energy at a controlled rate in a nuclear reactor or at a very rapid, uncontrolled rate in a nuclear weapon.

The amount of free energy contained in nuclear fuel is millions of times the amount of free energy contained in a similar mass of chemical fuel such as gasoline, making nuclear fission a very dense source of energy. The products of nuclear fission, however, are on average far more radioactive than the heavy elements which are normally fissioned as fuel, and remain so for significant amounts of time, giving rise to a nuclear waste problem. Concerns over nuclear waste accumulation and over the destructive potential of nuclear weapons are a counterbalance to the peaceful desire to use fission as an energy source.

Nuclear fission can occur without neutron bombardment as a type of radioactive decay. This type of fission (called spontaneous fission) is rare except in a few heavy isotopes.

In engineered nuclear devices, essentially all nuclear fission occurs as a "nuclear reaction" — a bombardment-driven process that results from the collision of two subatomic particles. In nuclear reactions, a subatomic particle collides with an atomic nucleus and causes changes to it. Nuclear reactions are thus driven by the mechanics of bombardment, not by the relatively constant exponential decay and half-life characteristic of spontaneous radioactive processes.

Many types of nuclear reactions are currently known. Nuclear fission differs importantly from other types of nuclear reactions, in that it can be amplified and sometimes controlled via a nuclear chain reaction (one type of general chain reaction). In such a reaction, free neutrons released by each fission event can trigger yet more events, which in turn release more neutrons and cause more fission. 

The chemical element isotopes that can sustain a fission chain reaction are called nuclear fuels, and are said to be "fissile". The most common nuclear fuels are U (the isotope of uranium with mass number 235 and of use in nuclear reactors) and Pu (the isotope of plutonium with mass number 239). These fuels break apart into a bimodal range of chemical elements with atomic masses centering near 95 and 135 u (fission products). Most nuclear fuels undergo spontaneous fission only very slowly, decaying instead mainly via an alpha-beta decay chain over periods of millennia to eons. In a nuclear reactor or nuclear weapon, the overwhelming majority of fission events are induced by bombardment with another particle, a neutron, which is itself produced by prior fission events.

Nuclear fission in fissile fuels is the result of the nuclear excitation energy produced when a fissile nucleus captures a neutron. This energy, resulting from the neutron capture, is a result of the attractive nuclear force acting between the neutron and nucleus. It is enough to deform the nucleus into a double-lobed "drop", to the point that nuclear fragments exceed the distances at which the nuclear force can hold two groups of charged nucleons together and, when this happens, the two fragments complete their separation and then are driven further apart by their mutually repulsive charges, in a process which becomes irreversible with greater and greater distance. A similar process occurs in fissionable isotopes (such as uranium-238), but in order to fission, these isotopes require additional energy provided by fast neutrons (such as those produced by nuclear fusion in thermonuclear weapons).

The liquid drop model of the atomic nucleus predicts equal-sized fission products as an outcome of nuclear deformation. The more sophisticated nuclear shell model is needed to mechanistically explain the route to the more energetically favorable outcome, in which one fission product is slightly smaller than the other. A theory of fission based on the shell model has been formulated by Maria Goeppert Mayer.

The most common fission process is binary fission, and it produces the fission products noted above, at 95±15 and 135±15 u. However, the binary process happens merely because it is the most probable. In anywhere from 2 to 4 fissions per 1000 in a nuclear reactor, a process called ternary fission produces three positively charged fragments (plus neutrons) and the smallest of these may range from so small a charge and mass as a proton ("Z" = 1), to as large a fragment as argon ("Z" = 18). The most common small fragments, however, are composed of 90% helium-4 nuclei with more energy than alpha particles from alpha decay (so-called "long range alphas" at ~ 16 MeV), plus helium-6 nuclei, and tritons (the nuclei of tritium). The ternary process is less common, but still ends up producing significant helium-4 and tritium gas buildup in the fuel rods of modern nuclear reactors.

The fission of a heavy nucleus requires a total input energy of about 7 to 8 million electron volts (MeV) to initially overcome the nuclear force which holds the nucleus into a spherical or nearly spherical shape, and from there, deform it into a two-lobed ("peanut") shape in which the lobes are able to continue to separate from each other, pushed by their mutual positive charge, in the most common process of binary fission (two positively charged fission products + neutrons). Once the nuclear lobes have been pushed to a critical distance, beyond which the short range strong force can no longer hold them together, the process of their separation proceeds from the energy of the (longer range) electromagnetic repulsion between the fragments. The result is two fission fragments moving away from each other, at high energy.

About 6 MeV of the fission-input energy is supplied by the simple binding of an extra neutron to the heavy nucleus via the strong force; however, in many fissionable isotopes, this amount of energy is not enough for fission. Uranium-238, for example, has a near-zero fission cross section for neutrons of less than one MeV energy. If no additional energy is supplied by any other mechanism, the nucleus will not fission, but will merely absorb the neutron, as happens when U-238 absorbs slow and even some fraction of fast neutrons, to become U-239. The remaining energy to initiate fission can be supplied by two other mechanisms: one of these is more kinetic energy of the incoming neutron, which is increasingly able to fission a fissionable heavy nucleus as it exceeds a kinetic energy of one MeV or more (so-called fast neutrons). Such high energy neutrons are able to fission U-238 directly (see thermonuclear weapon for application, where the fast neutrons are supplied by nuclear fusion). However, this process cannot happen to a great extent in a nuclear reactor, as too small a fraction of the fission neutrons produced by any type of fission have enough energy to efficiently fission U-238 (fission neutrons have a mode energy of 2 MeV, but a median of only 0.75 MeV, meaning half of them have less than this insufficient energy).

Among the heavy actinide elements, however, those isotopes that have an odd number of neutrons (such as U-235 with 143 neutrons) bind an extra neutron with an additional 1 to 2 MeV of energy over an isotope of the same element with an even number of neutrons (such as U-238 with 146 neutrons). This extra binding energy is made available as a result of the mechanism of neutron pairing effects. This extra energy results from the Pauli exclusion principle allowing an extra neutron to occupy the same nuclear orbital as the last neutron in the nucleus, so that the two form a pair. In such isotopes, therefore, no neutron kinetic energy is needed, for all the necessary energy is supplied by absorption of any neutron, either of the slow or fast variety (the former are used in moderated nuclear reactors, and the latter are used in fast neutron reactors, and in weapons). As noted above, the subgroup of fissionable elements that may be fissioned efficiently with their own fission neutrons (thus potentially causing a nuclear chain reaction in relatively small amounts of the pure material) are termed "fissile." Examples of fissile isotopes are uranium-235 and plutonium-239.

Typical fission events release about two hundred million eV (200 MeV) of energy, the equivalent of roughly >2 trillion Kelvin, for each fission event. The exact isotope which is fissioned, and whether or not it is fissionable or fissile, has only a small impact on the amount of energy released. This can be easily seen by examining the curve of binding energy (image below), and noting that the average binding energy of the actinide nuclides beginning with uranium is around 7.6 MeV per nucleon. Looking further left on the curve of binding energy, where the fission products cluster, it is easily observed that the binding energy of the fission products tends to center around 8.5 MeV per nucleon. Thus, in any fission event of an isotope in the actinide's range of mass, roughly 0.9 MeV is released per nucleon of the starting element. The fission of U235 by a slow neutron yields nearly identical energy to the fission of U238 by a fast neutron. This energy release profile holds true for thorium and the various minor actinides as well.

By contrast, most chemical oxidation reactions (such as burning coal or TNT) release at most a few eV per event. So, nuclear fuel contains at least ten million times more usable energy per unit mass than does chemical fuel. The energy of nuclear fission is released as kinetic energy of the fission products and fragments, and as electromagnetic radiation in the form of gamma rays; in a nuclear reactor, the energy is converted to heat as the particles and gamma rays collide with the atoms that make up the reactor and its working fluid, usually water or occasionally heavy water or molten salts.
When a uranium nucleus fissions into two daughter nuclei fragments, about 0.1 percent of the mass of the uranium nucleus appears as the fission energy of ~200 MeV. For uranium-235 (total mean fission energy 202.79 MeV), typically ~169 MeV appears as the kinetic energy of the daughter nuclei, which fly apart at about 3% of the speed of light, due to Coulomb repulsion. Also, an average of 2.5 neutrons are emitted, with a mean kinetic energy per neutron of ~2 MeV (total of 4.8 MeV). The fission reaction also releases ~7 MeV in prompt gamma ray photons. The latter figure means that a nuclear fission explosion or criticality accident emits about 3.5% of its energy as gamma rays, less than 2.5% of its energy as fast neutrons (total of both types of radiation ~ 6%), and the rest as kinetic energy of fission fragments (this appears almost immediately when the fragments impact surrounding matter, as simple heat). In an atomic bomb, this heat may serve to raise the temperature of the bomb core to 100 million kelvin and cause secondary emission of soft X-rays, which convert some of this energy to ionizing radiation. However, in nuclear reactors, the fission fragment kinetic energy remains as low-temperature heat, which itself causes little or no ionization.

So-called neutron bombs (enhanced radiation weapons) have been constructed which release a larger fraction of their energy as ionizing radiation (specifically, neutrons), but these are all thermonuclear devices which rely on the nuclear fusion stage to produce the extra radiation. The energy dynamics of pure fission bombs always remain at about 6% yield of the total in radiation, as a prompt result of fission.

The total "prompt fission" energy amounts to about 181 MeV, or ~ 89% of the total energy which is eventually released by fission over time. The remaining ~ 11% is released in beta decays which have various half-lives, but begin as a process in the fission products immediately; and in delayed gamma emissions associated with these beta decays. For example, in uranium-235 this delayed energy is divided into about 6.5 MeV in betas, 8.8 MeV in antineutrinos (released at the same time as the betas), and finally, an additional 6.3 MeV in delayed gamma emission from the excited beta-decay products (for a mean total of ~10 gamma ray emissions per fission, in all). Thus, about 6.5% of the total energy of fission is released some time after the event, as non-prompt or delayed ionizing radiation, and the delayed ionizing energy is about evenly divided between gamma and beta ray energy.

In a reactor that has been operating for some time, the radioactive fission products will have built up to steady state concentrations such that their rate of decay is equal to their rate of formation, so that their fractional total contribution to reactor heat (via beta decay) is the same as these radioisotopic fractional contributions to the energy of fission. Under these conditions, the 6.5% of fission which appears as delayed ionizing radiation (delayed gammas and betas from radioactive fission products) contributes to the steady-state reactor heat production under power. It is this output fraction which remains when the reactor is suddenly shut down (undergoes scram). For this reason, the reactor decay heat output begins at 6.5% of the full reactor steady state fission power, once the reactor is shut down. However, within hours, due to decay of these isotopes, the decay power output is far less. See decay heat for detail.

The remainder of the delayed energy (8.8 MeV/202.5 MeV = 4.3% of total fission energy) is emitted as antineutrinos, which as a practical matter, are not considered "ionizing radiation." The reason is that energy released as antineutrinos is not captured by the reactor material as heat, and escapes directly through all materials (including the Earth) at nearly the speed of light, and into interplanetary space (the amount absorbed is minuscule). Neutrino radiation is ordinarily not classed as ionizing radiation, because it is almost entirely not absorbed and therefore does not produce effects (although the very rare neutrino event is ionizing). Almost all of the rest of the radiation (6.5% delayed beta and gamma radiation) is eventually converted to heat in a reactor core or its shielding.

Some processes involving neutrons are notable for absorbing or finally yielding energy — for example neutron kinetic energy does not yield heat immediately if the neutron is captured by a uranium-238 atom to breed plutonium-239, but this energy is emitted if the plutonium-239 is later fissioned. On the other hand, so-called delayed neutrons emitted as radioactive decay products with half-lives up to several minutes, from fission-daughters, are very important to reactor control, because they give a characteristic "reaction" time for the total nuclear reaction to double in size, if the reaction is run in a "delayed-critical" zone which deliberately relies on these neutrons for a supercritical chain-reaction (one in which each fission cycle yields more neutrons than it absorbs). Without their existence, the nuclear chain-reaction would be prompt critical and increase in size faster than it could be controlled by human intervention. In this case, the first experimental atomic reactors would have run away to a dangerous and messy "prompt critical reaction" before their operators could have manually shut them down (for this reason, designer Enrico Fermi included radiation-counter-triggered control rods, suspended by electromagnets, which could automatically drop into the center of Chicago Pile-1). If these delayed neutrons are captured without producing fissions, they produce heat as well.

In fission there is a preference to yield fragments with even proton numbers, which is called the odd-even effect on the fragments' charge distribution. However, no odd-even effect is observed on fragment mass number distribution. This result is attributed to nucleon pair breaking.

In nuclear fission events the nuclei may break into any combination of lighter nuclei, but the most common event is not fission to equal mass nuclei of about mass 120; the most common event (depending on isotope and process) is a slightly unequal fission in which one daughter nucleus has a mass of about 90 to 100 u and the other the remaining 130 to 140 u. Unequal fissions are energetically more favorable because this allows one product to be closer to the energetic minimum near mass 60 u (only a quarter of the average fissionable mass), while the other nucleus with mass 135 u is still not far out of the range of the most tightly bound nuclei (another statement of this, is that the atomic binding energy curve is slightly steeper to the left of mass 120 u than to the right of it).

Nuclear fission of heavy elements produces exploitable energy because the specific binding energy (binding energy per mass) of intermediate-mass nuclei with atomic numbers and atomic masses close to Ni and Fe is greater than the nucleon-specific binding energy of very heavy nuclei, so that energy is released when heavy nuclei are broken apart. The total rest masses of the fission products (Mp) from a single reaction is less than the mass of the original fuel nucleus (M). The excess mass Δm = M – Mp is the invariant mass of the energy that is released as photons (gamma rays) and kinetic energy of the fission fragments, according to the mass-energy equivalence formula "E" = "mc".

The variation in specific binding energy with atomic number is due to the interplay of the two fundamental forces acting on the component nucleons (protons and neutrons) that make up the nucleus. Nuclei are bound by an attractive nuclear force between nucleons, which overcomes the electrostatic repulsion between protons. However, the nuclear force acts only over relatively short ranges (a few nucleon diameters), since it follows an exponentially decaying Yukawa potential which makes it insignificant at longer distances. The electrostatic repulsion is of longer range, since it decays by an inverse-square rule, so that nuclei larger than about 12 nucleons in diameter reach a point that the total electrostatic repulsion overcomes the nuclear force and causes them to be spontaneously unstable. For the same reason, larger nuclei (more than about eight nucleons in diameter) are less tightly bound per unit mass than are smaller nuclei; breaking a large nucleus into two or more intermediate-sized nuclei releases energy. 

Also because of the short range of the strong binding force, large stable nuclei must contain proportionally more neutrons than do the lightest elements, which are most stable with a 1 to 1 ratio of protons and neutrons. Nuclei which have more than 20 protons cannot be stable unless they have more than an equal number of neutrons. Extra neutrons stabilize heavy elements because they add to strong-force binding (which acts between all nucleons) without adding to proton–proton repulsion. Fission products have, on average, about the same ratio of neutrons and protons as their parent nucleus, and are therefore usually unstable to beta decay (which changes neutrons to protons) because they have proportionally too many neutrons compared to stable isotopes of similar mass.

This tendency for fission product nuclei to undergo beta decay is the fundamental cause of the problem of radioactive high-level waste from nuclear reactors. Fission products tend to be beta emitters, emitting fast-moving electrons to conserve electric charge, as excess neutrons convert to protons in the fission-product atoms. See Fission products (by element) for a description of fission products sorted by element.

Several heavy elements, such as uranium, thorium, and plutonium, undergo both spontaneous fission, a form of radioactive decay and "induced fission", a form of nuclear reaction. Elemental isotopes that undergo induced fission when struck by a free neutron are called fissionable; isotopes that undergo fission when struck by a slow-moving thermal neutron are also called fissile. A few particularly fissile and readily obtainable isotopes (notably U, U and Pu) are called nuclear fuels because they can sustain a chain reaction and can be obtained in large enough quantities to be useful.

All fissionable and fissile isotopes undergo a small amount of spontaneous fission which releases a few free neutrons into any sample of nuclear fuel. Such neutrons would escape rapidly from the fuel and become a free neutron, with a mean lifetime of about 15 minutes before decaying to protons and beta particles. However, neutrons almost invariably impact and are absorbed by other nuclei in the vicinity long before this happens (newly created fission neutrons move at about 7% of the speed of light, and even moderated neutrons move at about 8 times the speed of sound). Some neutrons will impact fuel nuclei and induce further fissions, releasing yet more neutrons. If enough nuclear fuel is assembled in one place, or if the escaping neutrons are sufficiently contained, then these freshly emitted neutrons outnumber the neutrons that escape from the assembly, and a "sustained nuclear chain reaction" will take place.

An assembly that supports a sustained nuclear chain reaction is called a critical assembly or, if the assembly is almost entirely made of a nuclear fuel, a critical mass. The word "critical" refers to a cusp in the behavior of the differential equation that governs the number of free neutrons present in the fuel: if less than a critical mass is present, then the amount of neutrons is determined by radioactive decay, but if a critical mass or more is present, then the amount of neutrons is controlled instead by the physics of the chain reaction. The actual mass of a "critical mass" of nuclear fuel depends strongly on the geometry and surrounding materials.

Not all fissionable isotopes can sustain a chain reaction. For example, U, the most abundant form of uranium, is fissionable but not fissile: it undergoes induced fission when impacted by an energetic neutron with over 1 MeV of kinetic energy. However, too few of the neutrons produced by U fission are energetic enough to induce further fissions in U, so no chain reaction is possible with this isotope. Instead, bombarding U with slow neutrons causes it to absorb them (becoming U) and decay by beta emission to Np which then decays again by the same process to Pu; that process is used to manufacture Pu in breeder reactors. In-situ plutonium production also contributes to the neutron chain reaction in other types of reactors after sufficient plutonium-239 has been produced, since plutonium-239 is also a fissile element which serves as fuel. It is estimated that up to half of the power produced by a standard "non-breeder" reactor is produced by the fission of plutonium-239 produced in place, over the total life-cycle of a fuel load.

Fissionable, non-fissile isotopes can be used as fission energy source even without a chain reaction. Bombarding U with fast neutrons induces fissions, releasing energy as long as the external neutron source is present. This is an important effect in all reactors where fast neutrons from the fissile isotope can cause the fission of nearby U nuclei, which means that some small part of the U is "burned-up" in all nuclear fuels, especially in fast breeder reactors that operate with higher-energy neutrons. That same fast-fission effect is used to augment the energy released by modern thermonuclear weapons, by jacketing the weapon with U to react with neutrons released by nuclear fusion at the center of the device. But the explosive effects of nuclear fission chain reactions can be reduced by using substances like moderators which slow down the speed of secondary neutrons.

Critical fission reactors are the most common type of nuclear reactor. In a critical fission reactor, neutrons produced by fission of fuel atoms are used to induce yet more fissions, to sustain a controllable amount of energy release. Devices that produce engineered but non-self-sustaining fission reactions are subcritical fission reactors. Such devices use radioactive decay or particle accelerators to trigger fissions.

Critical fission reactors are built for three primary purposes, which typically involve different engineering trade-offs to take advantage of either the heat or the neutrons produced by the fission chain reaction:

While, in principle, all fission reactors can act in all three capacities, in practice the tasks lead to conflicting engineering goals and most reactors have been built with only one of the above tasks in mind. (There are several early counter-examples, such as the Hanford N reactor, now decommissioned). Power reactors generally convert the kinetic energy of fission products into heat, which is used to heat a working fluid and drive a heat engine that generates mechanical or electrical power. The working fluid is usually water with a steam turbine, but some designs use other materials such as gaseous helium. Research reactors produce neutrons that are used in various ways, with the heat of fission being treated as an unavoidable waste product. Breeder reactors are a specialized form of research reactor, with the caveat that the sample being irradiated is usually the fuel itself, a mixture of U and U.
For a more detailed description of the physics and operating principles of critical fission reactors, see nuclear reactor physics. For a description of their social, political, and environmental aspects, see nuclear power.

One class of nuclear weapon, a "fission bomb" (not to be confused with the "fusion bomb"), otherwise known as an "atomic bomb" or "atom bomb", is a fission reactor designed to liberate as much energy as possible as rapidly as possible, before the released energy causes the reactor to explode (and the chain reaction to stop). Development of nuclear weapons was the motivation behind early research into nuclear fission which the Manhattan Project during World War II (September 1, 1939 – September 2, 1945) carried out most of the early scientific work on fission chain reactions, culminating in the three events involving fission bombs that occurred during the war. The first fission bomb, codenamed "The Gadget", was detonated during the Trinity Test in the desert of New Mexico on July 16, 1945. Two other fission bombs, codenamed "Little Boy" and "Fat Man", were used in combat against the Japanese cities of Hiroshima and Nagasaki in on August 6 and 9, 1945 respectively.

Even the first fission bombs were thousands of times more explosive than a comparable mass of chemical explosive. For example, Little Boy weighed a total of about four tons (of which 60 kg was nuclear fuel) and was long; it also yielded an explosion equivalent to about 15 kilotons of TNT, destroying a large part of the city of Hiroshima. Modern nuclear weapons (which include a thermonuclear "fusion" as well as one or more fission stages) are hundreds of times more energetic for their weight than the first pure fission atomic bombs (see nuclear weapon yield), so that a modern single missile warhead bomb weighing less than 1/8 as much as Little Boy (see for example W88) has a yield of 475 kilotons of TNT, and could bring destruction to about 10 times the city area.

While the fundamental physics of the fission chain reaction in a nuclear weapon is similar to the physics of a controlled nuclear reactor, the two types of device must be engineered quite differently (see nuclear reactor physics). A nuclear bomb is designed to release all its energy at once, while a reactor is designed to generate a steady supply of useful power. While overheating of a reactor can lead to, and has led to, meltdown and steam explosions, the much lower uranium enrichment makes it impossible for a nuclear reactor to explode with the same destructive power as a nuclear weapon. It is also difficult to extract useful power from a nuclear bomb, although at least one rocket propulsion system, Project Orion, was intended to work by exploding fission bombs behind a massively padded and shielded spacecraft.

The strategic importance of nuclear weapons is a major reason why the technology of nuclear fission is politically sensitive. Viable fission bomb designs are, arguably, within the capabilities of many, being relatively simple from an engineering viewpoint. However, the difficulty of obtaining fissile nuclear material to realize the designs is the key to the relative unavailability of nuclear weapons to all but modern industrialized governments with special programs to produce fissile materials (see uranium enrichment and nuclear fuel cycle).

The discovery of nuclear fission occurred in 1938 in the buildings of Kaiser Wilhelm Society for Chemistry, today part of the Free University of Berlin, following over four decades of work on the science of radioactivity and the elaboration of new nuclear physics that described the components of atoms. In 1911, Ernest Rutherford proposed a model of the atom in which a very small, dense and positively charged nucleus of protons was surrounded by orbiting, negatively charged electrons (the Rutherford model). Niels Bohr improved upon this in 1913 by reconciling the quantum behavior of electrons (the Bohr model). Work by Henri Becquerel, Marie Curie, Pierre Curie, and Rutherford further elaborated that the nucleus, though tightly bound, could undergo different forms of radioactive decay, and thereby transmute into other elements. (For example, by alpha decay: the emission of an alpha particle—two protons and two neutrons bound together into a particle identical to a helium nucleus.)

Some work in nuclear transmutation had been done. In 1917, Rutherford was able to accomplish transmutation of nitrogen into oxygen, using alpha particles directed at nitrogen N + α → O + p.  This was the first observation of a nuclear reaction, that is, a reaction in which particles from one decay are used to transform another atomic nucleus. Eventually, in 1932, a fully artificial nuclear reaction and nuclear transmutation was achieved by Rutherford's colleagues Ernest Walton and John Cockcroft, who used artificially accelerated protons against lithium-7, to split this nucleus into two alpha particles. The feat was popularly known as "splitting the atom", and would win them the 1951 Nobel Prize in Physics for ""Transmutation of atomic nuclei by artificially accelerated atomic particles"", although it was not the nuclear fission reaction later discovered in heavy elements. 

After English physicist James Chadwick discovered the neutron in 1932, Enrico Fermi and his colleagues in Rome studied the results of bombarding uranium with neutrons in 1934. Fermi concluded that his experiments had created new elements with 93 and 94 protons, which the group dubbed ausonium and hesperium. However, not all were convinced by Fermi's analysis of his results, though he would win the 1938 Nobel Prize in Physics for his "demonstrations of the existence of new radioactive elements produced by neutron irradiation, and for his related discovery of nuclear reactions brought about by slow neutrons". The German chemist Ida Noddack notably suggested in print in 1934 that instead of creating a new, heavier element 93, that "it is conceivable that the nucleus breaks up into several large fragments." However, Noddack's conclusion was not pursued at the time.
After the Fermi publication, Otto Hahn, Lise Meitner, and Fritz Strassmann began performing similar experiments in Berlin. Meitner, an Austrian Jew, lost her Austrian citizenship with the "Anschluss", the union of Austria with Germany in March 1938, but she fled in July 1938 to Sweden and started a correspondence by mail with Hahn in Berlin. By coincidence, her nephew Otto Robert Frisch, also a refugee, was also in Sweden when Meitner received a letter from Hahn dated 19 December describing his chemical proof that some of the product of the bombardment of uranium with neutrons was barium. Hahn suggested a "bursting" of the nucleus, but he was unsure of what the physical basis for the results were. Barium had an atomic mass 40% less than uranium, and no previously known methods of radioactive decay could account for such a large difference in the mass of the nucleus. Frisch was skeptical, but Meitner trusted Hahn's ability as a chemist. Marie Curie had been separating barium from radium for many years, and the techniques were well-known. Meitner and Frisch then correctly interpreted Hahn's results to mean that the nucleus of uranium had split roughly in half. Frisch suggested the process be named "nuclear fission", by analogy to the process of living cell division into two cells, which was then called binary fission. Just as the term nuclear "chain reaction" would later be borrowed from chemistry, so the term "fission" was borrowed from biology.
News spread quickly of the new discovery, which was correctly seen as an entirely novel physical effect with great scientific—and potentially practical—possibilities. Meitner's and Frisch's interpretation of the discovery of Hahn and Strassmann crossed the Atlantic Ocean with Niels Bohr, who was to lecture at Princeton University. I.I. Rabi and Willis Lamb, two Columbia University physicists working at Princeton, heard the news and carried it back to Columbia. Rabi said he told Enrico Fermi; Fermi gave credit to Lamb. Bohr soon thereafter went from Princeton to Columbia to see Fermi. Not finding Fermi in his office, Bohr went down to the cyclotron area and found Herbert L. Anderson. Bohr grabbed him by the shoulder and said: “Young man, let me explain to you about something new and exciting in physics.” It was clear to a number of scientists at Columbia that they should try to detect the energy released in the nuclear fission of uranium from neutron bombardment. On 25 January 1939, a Columbia University team conducted the first nuclear fission experiment in the United States, which was done in the basement of Pupin Hall. The experiment involved placing uranium oxide inside of an ionization chamber and irradiating it with neutrons, and measuring the energy thus released. The results confirmed that fission was occurring and hinted strongly that it was the isotope uranium 235 in particular that was fissioning. The next day, the Fifth Washington Conference on Theoretical Physics began in Washington, D.C. under the joint auspices of the George Washington University and the Carnegie Institution of Washington. There, the news on nuclear fission was spread even further, which fostered many more experimental demonstrations.

During this period the Hungarian physicist Leó Szilárd, realized that the neutron-driven fission of heavy atoms could be used to create a nuclear chain reaction. Such a reaction using neutrons was an idea he had first formulated in 1933, upon reading Rutherford's disparaging remarks about generating power from his team's 1932 experiment using protons to split lithium. However, Szilárd had not been able to achieve a neutron-driven chain reaction with neutron-rich light atoms. In theory, if in a neutron-driven chain reaction the number of secondary neutrons produced was greater than one, then each such reaction could trigger multiple additional reactions, producing an exponentially increasing number of reactions. It was thus a possibility that the fission of uranium could yield vast amounts of energy for civilian or military purposes (i.e., electric power generation or atomic bombs).

Szilard now urged Fermi (in New York) and Frédéric Joliot-Curie (in Paris) to refrain from publishing on the possibility of a chain reaction, lest the Nazi government become aware of the possibilities on the eve of what would later be known as World War II. With some hesitation Fermi agreed to self-censor. But Joliot-Curie did not, and in April 1939 his team in Paris, including Hans von Halban and Lew Kowarski, reported in the journal "Nature" that the number of neutrons emitted with nuclear fission of uranium was then reported at 3.5 per fission. (They later corrected this to 2.6 per fission.) Simultaneous work by Szilard and Walter Zinn confirmed these results. The results suggested the possibility of building nuclear reactors (first called "neutronic reactors" by Szilard and Fermi) and even nuclear bombs. However, much was still unknown about fission and chain reaction systems.
Chain reactions at that time were a known phenomenon in "chemistry", but the analogous process in nuclear physics, using neutrons, had been foreseen as early as 1933 by Szilárd, although Szilárd at that time had no idea with what materials the process might be initiated. Szilárd considered that neutrons would be ideal for such a situation, since they lacked an electrostatic charge.

With the news of fission neutrons from uranium fission, Szilárd immediately understood the possibility of a nuclear chain reaction using uranium. In the summer, Fermi and Szilard proposed the idea of a nuclear reactor (pile) to mediate this process. The pile would use natural uranium as fuel. Fermi had shown much earlier that neutrons were far more effectively captured by atoms if they were of low energy (so-called "slow" or "thermal" neutrons), because for quantum reasons it made the atoms look like much larger targets to the neutrons. Thus to slow down the secondary neutrons released by the fissioning uranium nuclei, Fermi and Szilard proposed a graphite "moderator", against which the fast, high-energy secondary neutrons would collide, effectively slowing them down. With enough uranium, and with pure-enough graphite, their "pile" could theoretically sustain a slow-neutron chain reaction. This would result in the production of heat, as well as the creation of radioactive fission products.

In August 1939, Szilard and fellow Hungarian refugee physicists Teller and Wigner thought that the Germans might make use of the fission chain reaction and were spurred to attempt to attract the attention of the United States government to the issue. Towards this, they persuaded German-Jewish refugee Albert Einstein to lend his name to a letter directed to President Franklin Roosevelt. The Einstein–Szilárd letter suggested the possibility of a uranium bomb deliverable by ship, which would destroy "an entire harbor and much of the surrounding countryside." The President received the letter on 11 October 1939 — shortly after World War II began in Europe, but two years before U.S. entry into it. Roosevelt ordered that a scientific committee be authorized for overseeing uranium work and allocated a small sum of money for pile research.

In England, James Chadwick proposed an atomic bomb utilizing natural uranium, based on a paper by Rudolf Peierls with the mass needed for critical state being 30–40 tons. In America, J. Robert Oppenheimer thought that a cube of uranium deuteride 10 cm on a side (about 11 kg of uranium) might "blow itself to hell." In this design it was still thought that a moderator would need to be used for nuclear bomb fission (this turned out not to be the case if the fissile isotope was separated). In December, Werner Heisenberg delivered a report to the German Ministry of War on the possibility of a uranium bomb. Most of these models were still under the assumption that the bombs would be powered by slow neutron reactions—and thus be similar to a reactor undergoing a critical power excursion.

In Birmingham, England, Frisch teamed up with Peierls, a fellow German-Jewish refugee. They had the idea of using a purified mass of the uranium isotope U, which had a cross section not yet determined, but which was believe to be much larger than that of U or natural uranium (which is 99.3% the latter isotope). Assuming that the cross section for fast-neutron fission of U was the same as for slow neutron fission, they determined that a pure U bomb could have a critical mass of only 6 kg instead of tons, and that the resulting explosion would be tremendous. (The amount actually turned out to be 15 kg, although several times this amount was used in the actual uranium (Little Boy) bomb). In February 1940 they delivered the Frisch–Peierls memorandum. Ironically, they were still officially considered "enemy aliens" at the time. Glenn Seaborg, Joseph W. Kennedy, Arthur Wahl, and Italian-Jewish refugee Emilio Segrè shortly thereafter discovered Pu in the decay products of U produced by bombarding U with neutrons, and determined it to be a fissile material, like U.

The possibility of isolating uranium-235 was technically daunting, because uranium-235 and uranium-238 are chemically identical, and vary in their mass by only the weight of three neutrons. However, if a sufficient quantity of uranium-235 could be isolated, it would allow for a fast neutron fission chain reaction. This would be extremely explosive, a true "atomic bomb." The discovery that plutonium-239 could be produced in a nuclear reactor pointed towards another approach to a fast neutron fission bomb. Both approaches were extremely novel and not yet well understood, and there was considerable scientific skepticism at the idea that they could be developed in a short amount of time.

On June 28, 1941, the Office of Scientific Research and Development was formed in the U.S. to mobilize scientific resources and apply the results of research to national defense. In September, Fermi assembled his first nuclear "pile" or reactor, in an attempt to create a slow neutron-induced chain reaction in uranium, but the experiment failed to achieve criticality, due to lack of proper materials, or not enough of the proper materials which were available.

Producing a fission chain reaction in natural uranium fuel was found to be far from trivial. Early nuclear reactors did not use isotopically enriched uranium, and in consequence they were required to use large quantities of highly purified graphite as neutron moderation materials. Use of ordinary water (as opposed to heavy water) in nuclear reactors requires enriched fuel — the partial separation and relative enrichment of the rare U isotope from the far more common U isotope. Typically, reactors also require inclusion of extremely chemically pure neutron moderator materials such as deuterium (in heavy water), helium, beryllium, or carbon, the latter usually as graphite. (The high purity for carbon is required because many chemical impurities such as the boron-10 component of natural boron, are very strong neutron absorbers and thus poison the chain reaction and end it prematurely.)

Production of such materials at industrial scale had to be solved for nuclear power generation and weapons production to be accomplished. Up to 1940, the total amount of uranium metal produced in the USA was not more than a few grams, and even this was of doubtful purity; of metallic beryllium not more than a few kilograms; and concentrated deuterium oxide (heavy water) not more than a few kilograms. Finally, carbon had never been produced in quantity with anything like the purity required of a moderator.

The problem of producing large amounts of high purity uranium was solved by Frank Spedding using the thermite or "Ames" process. Ames Laboratory was established in 1942 to produce the large amounts of natural (unenriched) uranium metal that would be necessary for the research to come. The critical nuclear chain-reaction success of the Chicago Pile-1 (December 2, 1942) which used unenriched (natural) uranium, like all of the atomic "piles" which produced the plutonium for the atomic bomb, was also due specifically to Szilard's realization that very pure graphite could be used for the moderator of even natural uranium "piles". In wartime Germany, failure to appreciate the qualities of very pure graphite led to reactor designs dependent on heavy water, which in turn was denied the Germans by Allied attacks in Norway, where heavy water was produced. These difficulties—among many others— prevented the Nazis from building a nuclear reactor capable of criticality during the war, although they never put as much effort as the United States into nuclear research, focusing on other technologies (see German nuclear energy project for more details).

In the United States, an all-out effort for making atomic weapons was begun in late 1942. This work was taken over by the U.S. Army Corps of Engineers in 1943, and known as the Manhattan Engineer District. The top-secret Manhattan Project, as it was colloquially known, was led by General Leslie R. Groves. Among the project's dozens of sites were: Hanford Site in Washington, which had the first industrial-scale nuclear reactors and produced plutonium; Oak Ridge, Tennessee, which was primarily concerned with uranium enrichment; and Los Alamos, in New Mexico, which was the scientific hub for research on bomb development and design. Other sites, notably the Berkeley Radiation Laboratory and the Metallurgical Laboratory at the University of Chicago, played important contributing roles. Overall scientific direction of the project was managed by the physicist J. Robert Oppenheimer.

In July 1945, the first atomic explosive device, dubbed "Trinity", was detonated in the New Mexico desert. It was fueled by plutonium created at Hanford. In August 1945, two more atomic devices – "Little Boy", a uranium-235 bomb, and "Fat Man", a plutonium bomb – were used against the Japanese cities of Hiroshima and Nagasaki.

In the years after World War II, many countries were involved in the further development of nuclear fission for the purposes of nuclear reactors and nuclear weapons. The UK opened the first commercial nuclear power plant in 1956. By 2013, there were 437 reactors in 31 countries.

Criticality in nature is uncommon. At three ore deposits at Oklo in Gabon, sixteen sites (the so-called Oklo Fossil Reactors) have been discovered at which self-sustaining nuclear fission took place approximately 2 billion years ago. Unknown until 1972 (but postulated by Paul Kuroda in 1956), when French physicist Francis Perrin discovered the Oklo Fossil Reactors, it was realized that nature had beaten humans to the punch. Large-scale natural uranium fission chain reactions, moderated by normal water, had occurred far in the past and would not be possible now. This ancient process was able to use normal water as a moderator only because 2 billion years before the present, natural uranium was richer in the shorter-lived fissile isotope U (about 3%), than natural uranium available today (which is only 0.7%, and must be enriched to 3% to be usable in light-water reactors).





</doc>
<doc id="22055" url="https://en.wikipedia.org/wiki?curid=22055" title="Neil Gaiman">
Neil Gaiman

Neil Richard MacKinnon Gaiman (; born Neil Richard Gaiman, 10 November 1960) is an English author of short fiction, novels, comic books, graphic novels, nonfiction, audio theatre, and films. His works include the comic book series "The Sandman" and novels "Stardust", "American Gods", "Coraline", and "The Graveyard Book". He has won numerous awards, including the Hugo, Nebula, and Bram Stoker awards, as well as the Newbery and Carnegie medals. He is the first author to win both the Newbery and the Carnegie medals for the same work, "The Graveyard Book" (2008). In 2013, "The Ocean at the End of the Lane" was voted Book of the Year in the British National Book Awards.

Gaiman's family is of Polish Jewish and other Eastern European Jewish origins. His great-grandfather emigrated from Antwerp, Belgium, to the UK before 1914 and his grandfather eventually settled in the south of England in the Hampshire city of Portsmouth and established a chain of grocery stores. Gaiman's grandfather changed his original family name of Chaiman to Gaiman. His father, David Bernard Gaiman, worked in the same chain of stores; his mother, Sheila Gaiman (née Goldman), was a pharmacist. He has two younger sisters, Claire and Lizzy.

After living for a period in the nearby town of Portchester, Hampshire, where Neil was born in 1960, the Gaimans moved in 1965 to the West Sussex town of East Grinstead, where his parents studied Dianetics at the Scientology centre in the town; one of Gaiman's sisters works for the Church of Scientology in Los Angeles. His other sister, Lizzy Calcioli, has said, "Most of our social activities were involved with Scientology or our Jewish family. It would get very confusing when people would ask my religion as a kid. I'd say, 'I'm a Jewish Scientologist. Gaiman says that he is not a Scientologist, and that like Judaism, Scientology is his family's religion. About his personal views, Gaiman has stated, "I think we can say that God exists in the DC Universe. I would not stand up and beat the drum for the existence of God in this universe. I don't know, I think there's probably a 50/50 chance. It doesn't really matter to me."

Gaiman was able to read at the age of four. He said, "I was a reader. I loved reading. Reading things gave me pleasure. I was very good at most subjects in school, not because I had any particular aptitude in them, but because normally on the first day of school they'd hand out schoolbooks, and I'd read them—which would mean that I'd know what was coming up, because I'd read it." When he was about ten years old, he read his way through the works of Dennis Wheatley, where especially "The Ka of Gifford Hillary" and "The Haunting of Toby Jugg" made an impact on him. One work that made a particular impression on him was J. R. R. Tolkien's "The Lord of the Rings" from his school library. Although the library only had the first two of the novel's three volumes, Neil consistently checked them out and read them. He later won the school English prize and the school reading prize, enabling him to finally acquire the third volume.

For his seventh birthday, Gaiman received C. S. Lewis's "The Chronicles of Narnia" series. He later recalled that "I admired his use of parenthetical statements to the reader, where he would just talk to you ... I'd think, 'Oh, my gosh, that is so cool! I want to do that! When I become an author, I want to be able to do things in parentheses.' I liked the power of putting things in brackets." "Narnia" also introduced him to literary awards, specifically the 1956 Carnegie Medal won by the concluding volume. When Gaiman won the 2010 Medal himself, the press reported him recalling, "it had to be the most important literary award there ever was" and observing, "if you can make yourself aged seven happy, you're really doing well – it's like writing a letter to yourself aged seven."

Lewis Carroll's "Alice's Adventures in Wonderland" was another childhood favourite, and "a favourite forever. Alice was default reading to the point where I knew it by heart." He also enjoyed Batman comics as a child.

Gaiman was educated at several Church of England schools, including Fonthill School in East Grinstead, Ardingly College (1970–74), and Whitgift School in Croydon (1974–77). His father's position as a public relations official of the Church of Scientology was the cause of the seven-year-old Gaiman being forced to withdraw from Fonthill School and remain at the school that he had previously been attending. He lived in East Grinstead for many years, from 1965 to 1980 and again from 1984 to 1987. He met his first wife, Mary McGrath, while she was studying Scientology and living in a house in East Grinstead that was owned by his father. The couple were married in 1985 after having their first child, Michael.

As a child and a teenager, Gaiman read the works of C. S. Lewis, J. R. R. Tolkien, Lewis Carroll, Mary Shelley, Rudyard Kipling, Edgar Allan Poe, Michael Moorcock, Alan Moore, Steve Ditko, Will Eisner, Ursula K. Le Guin, Harlan Ellison, Lord Dunsany and G. K. Chesterton. A lifetime fan of the Monty Python comedy troupe, as a teenager he owned a copy of "Monty Python's Big Red Book". When he was 19–20 years old, he contacted his favourite science fiction writer, R. A. Lafferty, whom he discovered when he was nine, and asked for advice on becoming an author along with a Lafferty pastiche he had written. The writer sent Gaiman an encouraging and informative letter back, along with literary advice.

Gaiman has said Roger Zelazny was the author who influenced him the most, with this influence particularly seen in Gaiman's literary style and the topics he writes about. Other authors Gaiman says "furnished the inside of my mind and set me to writing" include Moorcock, Ellison, Samuel R. Delany, Angela Carter, Lafferty and Le Guin. Neil Gaiman has also taken inspiration from the folk tales tradition, citing Otta F Swire's book on the legends of the Isle of Skye as his inspiration for The Truth Is a Cave in the Black Mountains.

In the early 1980s, Gaiman pursued journalism, conducting interviews and writing book reviews, as a means to learn about the world and to make connections that he hoped would later assist him in getting published. He wrote and reviewed extensively for the British Fantasy Society. His first professional short story publication was "Featherquest", a fantasy story, in "Imagine Magazine" in May 1984.

When waiting for a train at London's Victoria Station in 1984, Gaiman noticed a copy of "Swamp Thing" written by Alan Moore, and carefully read it. Moore's fresh and vigorous approach to comics had such an impact on Gaiman that he later wrote "that was the final straw, what was left of my resistance crumbled. I proceeded to make regular and frequent visits to London's Forbidden Planet shop to buy comics".

In 1984, he wrote his first book, a biography of the band Duran Duran, as well as "Ghastly Beyond Belief", a book of quotations, with Kim Newman. Even though Gaiman thought he had done a terrible job, the book's first edition sold out very quickly. When he went to relinquish his rights to the book, he discovered the publisher had gone bankrupt. After this, he was offered a job by "Penthouse". He refused the offer.

He also wrote interviews and articles for many British magazines, including "Knave." During this he sometimes wrote under pseudonyms, including Gerry Musgrave, Richard Grey, and "a couple of house names". Gaiman has said he ended his journalism career in 1987 because British newspapers regularly publish untruths as fact.
In the late 1980s, he wrote "" in what he calls a "classic English humour" style. Following this he wrote the opening of what became his collaboration with fellow English author Terry Pratchett on the comic novel "Good Omens", about the impending apocalypse.

After forming a friendship with comic-book writer Alan Moore, Gaiman started writing comic books, picking up "Miracleman" after Moore finished his run on the series. Gaiman and artist Mark Buckingham collaborated on several issues of the series before its publisher, Eclipse Comics, collapsed, leaving the series unfinished. His first published comic strips were four short "Future Shocks" for "2000 AD" in 1986–87. He wrote three graphic novels with his favourite collaborator and long-time friend Dave McKean: "Violent Cases", "Signal to Noise", and "The Tragical Comedy or Comical Tragedy of Mr. Punch". Impressed with his work, DC Comics hired him in February 1987, and he wrote the limited series "Black Orchid". Karen Berger, who later became head of DC Comics's Vertigo, read "Black Orchid" and offered Gaiman a job: to re-write an old character, The Sandman, but to put his own spin on him.

"The Sandman" tells the tale of the ageless, anthropomorphic personification of Dream that is known by many names, including Morpheus. The series began in January 1989 and concluded in March 1996. In the eighth issue of "The Sandman", Gaiman and artist Mike Dringenberg introduced Death, the older sister of Dream, who became as popular as the series' title character. The limited series "" launched DC's Vertigo line in 1993. The 75 issues of the regular series, along with an illustrated prose text and a special containing seven short stories, have been collected into 12 volumes that remain in print, 14 if the "Death: The High Cost of Living" and "" spin-offs are included. Artists include Sam Kieth, Mike Dringenberg, Jill Thompson, Shawn McManus, Marc Hempel and Michael Zulli, lettering by Todd Klein, colours by Daniel Vozzo, and covers by Dave McKean. The series became one of DC's top selling titles, eclipsing even "Batman" and "Superman". Comics historian Les Daniels called Gaiman's work "astonishing" and noted that "The Sandman" was "a mixture of fantasy, horror, and ironic humor such as comic books had never seen before". DC Comics writer and executive Paul Levitz observed that ""The Sandman" became the first extraordinary success as a series of graphic novel collections, reaching out and converting new readers to the medium, particularly young women on college campuses, and making Gaiman himself into an iconic cultural figure."

Gaiman and Jamie Delano were to become co-writers of the "Swamp Thing" series following Rick Veitch. An editorial decision by DC to censor Veitch's final storyline caused both Gaiman and Delano to withdraw from the title.

Gaiman produced two stories for DC's "Secret Origins" series in 1989. A Poison Ivy tale drawn by Mark Buckingham and a Riddler story illustrated by Bernie Mireault and Matt Wagner. A story that Gaiman originally wrote for "Action Comics Weekly" in 1989 was shelved due to editorial concerns but it was finally published in 2000 as "".

In 1990, Gaiman wrote "The Books of Magic", a four-part mini-series that provided a tour of the mythological and magical parts of the DC Universe through a frame story about an English teenager who discovers that he is destined to be the world's greatest wizard. The miniseries was popular, and sired an ongoing series written by John Ney Rieber.

Gaiman's adaptation of "Sweeney Todd", illustrated by Michael Zulli for Stephen R. Bissette's publication "Taboo", was stopped when the anthology itself was discontinued.

In the mid-1990s, he also created a number of new characters and a setting that was to be featured in a title published by Tekno Comix. The concepts were then altered and split between three titles set in the same continuity: "Lady Justice", "Mr. Hero the Newmatic Man", and "Teknophage", and tie-ins. Although Gaiman's name appeared prominently as creator of the characters, he was not involved in writing any of the above-mentioned books.

Gaiman wrote a semi-autobiographical story about a boy's fascination with Michael Moorcock's anti-hero Elric of Melniboné for Ed Kramer's anthology "Tales of the White Wolf." In 1996, Gaiman and Ed Kramer co-edited "". Nominated for the British Fantasy Award, the original fiction anthology featured stories and contributions by Tori Amos, Clive Barker, Gene Wolfe, Tad Williams, and others.

Asked why he likes comics more than other forms of storytelling, Gaiman said: "One of the joys of comics has always been the knowledge that it was, in many ways, untouched ground. It was virgin territory. When I was working on "Sandman", I felt a lot of the time that I was actually picking up a machete and heading out into the jungle. I got to write in places and do things that nobody had ever done before. When I'm writing novels I'm painfully aware that I'm working in a medium that people have been writing absolutely jaw-droppingly brilliant things for, you know, three-four thousand years now. You know, you can go back. We have things like "The Golden Ass". And you go, well, I don't know that I'm as good as that and that's two and a half thousand years old. But with comics I felt like – I can do stuff nobody has ever done. I can do stuff nobody has ever thought of. And I could and it was enormously fun."

Gaiman wrote two series for Marvel Comics. "Marvel 1602" was an eight-issue limited series published from November 2003 to June 2004 with art by Andy Kubert and Richard Isanove. "The Eternals" was a seven-issue limited series drawn by John Romita Jr., which was published from August 2006 to March 2007.

In 2009, Gaiman wrote a two-part Batman story for DC Comics to follow "Batman R.I.P." titled "" a play-off of the classic Superman story "" by Alan Moore. He contributed a twelve-part Metamorpho serial drawn by Mike Allred for "Wednesday Comics", a weekly newspaper-style series. Gaiman and Paul Cornell co-wrote "Action Comics" #894 (December 2010), which featured an appearance by Death. In October 2013, DC Comics released "" with art by J. H. Williams III. Gaiman's Angela character was introduced into the Marvel Universe in the last issue of the "Age of Ultron" miniseries in 2013.

Gaiman is overseeing "The Sandman Universe", a line of comic books published by Vertigo. The four new ongoing series — "House of Whispers", "Lucifer", "The Books of Magic", and "The Dreaming" — are written by new creative teams. The line launched on 8 August 2018.

In a collaboration with author Terry Pratchett, best known for his series of "Discworld" novels, Gaiman's first novel "Good Omens" was published in 1990. In 2011 Pratchett said that while the entire novel was a collaborative effort and most of the ideas could be credited to both of them, Pratchett did a larger portion of writing and editing if for no other reason than Gaiman's scheduled involvement with "Sandman".

The 1996 novelisation of Gaiman's teleplay for the BBC mini-series "Neverwhere" was his first solo novel. The novel was released in tandem with the television series though it presents some notable differences from the television series. Gaiman has since revised the novel twice, the first time for an American audience unfamiliar with the London Underground, the second time because he felt unsatisfied with the original.

In 1999, first printings of his fantasy novel "Stardust" were released. The novel has been released both as a standard novel and in an illustrated text edition. This novel was highly influenced by Victorian fairytales and culture.

"American Gods" became one of Gaiman's best-selling and multi-award-winning novels upon its release in 2001. A special 10th Anniversary edition was released, with the "author's preferred text" 12,000 words longer than the original mass-market editions.

Gaiman has not written a direct sequel to "American Gods" but he has revisited the characters. A glimpse at Shadow's travels in Europe is found in a short story which finds him in Scotland, applying the same concepts developed in "American Gods" to the story of "Beowulf". The 2005 novel "Anansi Boys" deals with Anansi ('Mr. Nancy'), tracing the relationship of his two sons, one semi-divine and the other an unassuming Englishman, as they explore their common heritage. It debuted at number one on "The New York Times" Best Seller list.

In late 2008, Gaiman released a new children's book, "The Graveyard Book". It follows the adventures of a boy named Bod after his family is murdered and he is left to be brought up by a graveyard. It is heavily influenced by Rudyard Kipling's "The Jungle Book". , it had been on "The New York Times" Bestseller children's list for fifteen weeks.

In 2013, "The Ocean at the End of the Lane" was voted Book of the Year in the British National Book Awards. The novel follows an unnamed man who returns to his hometown for a funeral and remembers events that began forty years earlier. Themes include the search for self-identity and the "disconnect between childhood and adulthood".

In September 2016, Neil Gaiman announced that he had been working for some years on retellings of Norse mythology. "Norse Mythology" was released in February 2017.

Gaiman wrote the 1996 BBC dark fantasy television series "Neverwhere". He cowrote the screenplay for the movie "MirrorMask" with his old friend Dave McKean for McKean to direct. In addition, he wrote the localised English language script to the anime movie "Princess Mononoke", based on a translation of the Japanese script.

He cowrote the script for Robert Zemeckis's "Beowulf" with Roger Avary, a collaboration that has proved productive for both writers. Gaiman has expressed interest in collaborating on a film adaptation of the "Epic of Gilgamesh".
He was the only person other than J. Michael Straczynski to write a "Babylon 5" script in the last three seasons, contributing the season five episode "Day of the Dead".

Gaiman has also written at least three drafts of a screenplay adaptation of Nicholson Baker's novel "The Fermata" for director Robert Zemeckis, although the project was stalled while Zemeckis made "The Polar Express" and the Gaiman-Roger Avary written "Beowulf" film.

Neil Gaiman was featured in the "History Channel" documentary "Comic Book Superheroes Unmasked".

Several of Gaiman's original works have been optioned or greenlighted for film adaptation, most notably "Stardust", which premiered in August 2007 and stars Charlie Cox, Robert De Niro, Michelle Pfeiffer, Claire Danes and Mark Strong, directed by Matthew Vaughn. A stop-motion version of "Coraline" was released on 6 February 2009, with Henry Selick directing and Dakota Fanning and Teri Hatcher in the leading voice-actor roles.

In 2007, Gaiman it was announced that after ten years in development, the feature film of "" would finally begin production with a screenplay by Gaiman that he would direct for Warner Independent. Don Murphy and Susan Montford are the producers, and Guillermo del Toro is the film's executive producer. By 2010 it had been reported that it was no longer in production.

Seeing Ear Theatre performed two of Gaiman's audio theatre plays, "Snow, Glass, Apples", Gaiman's retelling of Snow White and "Murder Mysteries", a story of heaven before the Fall in which the first crime is committed. Both audio plays were published in the collection "Smoke and Mirrors" in 1998.

Gaiman's 2009 Newbery Medal winning book "The Graveyard Book" will be made into a movie, with Ron Howard as the director.

Gaiman wrote an episode of the long-running BBC science fiction series "Doctor Who", broadcast in 2011 during Matt Smith's second series as the Doctor. Shooting began in August 2010 for this episode, the original title of which was "The House of Nothing" but which was eventually transmitted as "The Doctor's Wife". The episode won the 2012 Hugo Award for Best Dramatic Presentation (Short Form). Gaiman made his return to "Doctor Who" with an episode titled "Nightmare in Silver", broadcast on 11 May 2013.

In 2011, it was announced that Gaiman would be writing the script to a new film version of "Journey to the West".

Gaiman appeared as himself on "The Simpsons" episode "The Book Job", which broadcast on 20 November 2011.

In 2015, Starz greenlighted a series adaptation of Gaiman's novel "American Gods". Bryan Fuller and Michael Green wrote and showrun the series.

In 2020, Gaiman received a Hugo Award for Best Dramatic Presentation, Long Form for the tv miniseries adaption of Good Omens, for which he wrote the screenplay.

A six-part radio play of "Neverwhere" was broadcast in March 2013, adapted by Dirk Maggs for BBC Radio 4 and Radio 4 Extra. Featured stars include James McAvoy as Richard, Natalie Dormer, Benedict Cumberbatch, Christopher Lee, Bernard Cribbens and Johnny Vegas.

In September 2014, Gaiman and Terry Pratchett joined forces with BBC Radio 4 to make the first ever dramatisation of their co-penned novel "Good Omens", which was broadcast in December in five half-hour episodes and culminated in an hour-long final apocalyptic showdown.

Gaiman frequently performs public readings from his stories and poetry, and has toured with his wife, musician Amanda Palmer. In some of these performances he has also sung songs, in "a novelist's version of singing", despite having "no kind of singing voice".

In 2015, Gaiman delivered a 100-minute lecture for the Long Now Foundation entitled "How Stories Last" about the nature of storytelling and how stories persist in human culture. In April 2018 Gaiman made a guest appearance on the television show "The Big Bang Theory", and his tweet about the show's fictional comic book store becomes the central theme of the episode "The Comet Polarization".

In February 2001, when Gaiman had completed writing "American Gods", his publishers set up a promotional website featuring a weblog in which Gaiman described the day-to-day process of revising, publishing, and promoting the novel. After the novel was published, the website evolved into a more general Official Neil Gaiman Website.

Gaiman generally posts to the blog describing the day-to-day process of being Neil Gaiman and writing, revising, publishing, or promoting whatever the current project is. He also posts reader emails and answers questions, which gives him unusually direct and immediate interaction with fans. One of his answers on why he writes the blog is "because writing is, like death, a lonely business."

The original "American Gods" blog was extracted for publication in the NESFA Press collection of Gaiman miscellany, "Adventures in the Dream Trade".

To celebrate the seventh anniversary of the blog, the novel "American Gods" was provided free of charge online for a month.

Gaiman is an active user of the social networking site Twitter with over 2.7 million followers , using the username "@neilhimself". In 2013, Gaiman was named by IGN as one of "The Best Tweeters in Comics", describing his posts as "sublime." Gaiman also runs a Tumblr account on which he primarily answers fan questions.

Gaiman is a dedicated user of fountain pens and has said that he writes the first draft of all his books with one. He started this practice with "Stardust" which he wrote in fountain pen in order to capture the feeling of the 1920s. He is most closely associated with the Pilot 823, one of which he has said he has used for giving over one million signatures.

Gaiman has lived near Menomonie, Wisconsin, since 1992. Gaiman moved there to be close to the family of his then-wife, Mary McGrath, with whom he has three children. , Gaiman also resides in Cambridge, Massachusetts. In 2014, he took up a five-year appointment as professor in the arts at Bard College, in Annandale-on-Hudson, New York.

Gaiman is married to songwriter and performer Amanda Palmer, with whom he has an open marriage. The couple announced that they were dating in June 2009, and announced their engagement on Twitter on 1 January 2010. On 16 November 2010, Palmer hosted a non-legally binding flash mob wedding for Gaiman's birthday in New Orleans. They were legally married on 2 January 2011. The wedding took place in the parlour of writers Ayelet Waldman and Michael Chabon. On marrying Palmer, he took her middle name, MacKinnon, as one of his names. In September 2015, they had a son. In May 2020, Palmer announced their separation; Gaiman relocated to the UK, and Palmer stayed in New Zealand.

In May 2020, he traveled from New Zealand to his holiday home on the Isle of Skye, breaking lockdown rules imposed during the COVID-19 pandemic. Ross, Skye and Lochaber MP Ian Blackford described his behaviour as unacceptable and dangerous. Gaiman published an apology on his website, saying he had endangered the local community.

In 2016, Gaiman, as well as Cate Blanchett, Chiwetel Ejiofor, Peter Capaldi, Douglas Booth, Jesse Eisenberg, Keira Knightley, Juliet Stevenson, Kit Harington, and Stanley Tucci, appeared in the video "What They Took With Them", from the United Nations' refugee agency UNHCR, to help raise awareness of the issue of global refugees.

Gaiman is a supporter of the Comic Book Legal Defense Fund and has served on its board of directors. In 2013, Gaiman was named co-chair of the organization's newly-formed Advisory Board.

One of Gaiman's most commented-upon friendships is with the musician Tori Amos, a "Sandman" fan who became friends with Gaiman after making a reference to "Neil and the Dream King" on her 1991 demo tape. He included her in turn as a character (a talking tree) in his novel "Stardust". Amos also mentions Gaiman in her songs, "Tear in Your Hand" ("If you need me, me and Neil'll be hangin' out with the dream king. Neil says hi by the way"), "Space Dog" ("Where's Neil when you need him?"), "Horses" ("But will you find me if Neil makes me a tree?"), "Carbon" ("Get me Neil on the line, no I can't hold. Have him read, 'Snow, Glass, Apples' where nothing is what it seems"), "Sweet Dreams" ("You're forgetting to fly, darling, when you sleep"), and "Not Dying Today" ("Neil is thrilled he can claim he's mammalian, 'but the bad news,' he said, 'girl you're a dandelion'"). He also wrote stories for the tour book of "Boys for Pele" and "Scarlet's Walk", a letter for the tour book of "American Doll Posse", and the stories behind each girl in her album "Strange Little Girls". Amos penned the introduction for his novel "Death: the High Cost of Living", and posed for the cover. She also wrote a song called "Sister Named Desire" based on his "Sandman" character, which was included on his anthology, "Where's Neil When You Need Him?".

Gaiman is godfather to Tori Amos's daughter Tash, and wrote a poem called "Blueberry Girl" for Tori and Tash. The poem has been turned into a book by the illustrator Charles Vess. Gaiman read the poem aloud to an audience at the Sundance Kabuki Theater in San Francisco on 5 October 2008 during his book reading tour for "The Graveyard Book". It was published in March 2009 with the title "Blueberry Girl".

In 1993, Gaiman was contracted by Todd McFarlane to write a single issue of "Spawn", a popular title at the newly created Image Comics company. McFarlane was promoting his new title by having guest authors Gaiman, Alan Moore, Frank Miller, and Dave Sim each write a single issue.

In issue No. 9 of the series, Gaiman introduced the characters Angela, Cogliostro, and Medieval Spawn. Prior to this issue, Spawn was an assassin who worked for the government and came back as a reluctant agent of Hell but had no real direction in his actions. In Angela, a cruel and malicious angel, Gaiman introduced a character who threatened Spawn's existence, as well as providing a moral opposite. Cogliostro was introduced as a mentor character for exposition and instruction, providing guidance. Medieval Spawn introduced a history and precedent that not all Spawns were self-serving or evil, giving additional character development to Malebolgia, the demon that creates Hellspawn.

As intended, all three characters were used repeatedly throughout the next decade by Todd McFarlane within the wider Spawn universe. In papers filed by Gaiman in early 2002, however, he claimed that the characters were jointly owned by their scripter (himself) and artist (McFarlane), not merely by McFarlane in his role as the creator of the series. Disagreement over who owned the rights to a character was the primary motivation for McFarlane and other artists to form Image Comics (although that argument related more towards disagreements between writers and artists as character creators). As McFarlane used the characters without Gaiman's permission or royalty payments, Gaiman believed his copyrighted work was being infringed upon, which violated their original oral agreement. McFarlane initially agreed that Gaiman had not signed away any rights to the characters, and negotiated with Gaiman to effectively 'swap' McFarlane's interest in the character Marvelman. McFarlane had purchased interest in the character when Eclipse Comics was liquidated while Gaiman was interested in being able to continue his aborted run of the Marvelman title. McFarlane later changed his initial position, claiming that Gaiman's work had only been work-for-hire and that McFarlane owned all of Gaiman's creations entirely. The presiding judge, however, ruled against their agreement being work for hire, based in large part on the legal requirement that "copyright assignments must be in writing."

The Seventh Circuit Court of Appeals upheld the district court ruling in February 2004 granting joint ownership of the characters to Gaiman and McFarlane. On the specific issue of Cogliostro, presiding Judge John C. Shabaz proclaimed, "The expressive work that is the comic-book character Count Nicholas Cogliostro was the joint work of Gaiman and McFarlane—their contributions strike us as quite equal—and both are entitled to ownership of the copyright". Similar analysis led to similar results for the other two characters, Angela and Medieval Spawn.

This legal battle was brought by Gaiman and the specifically formed Marvels and Miracles, LLC, which Gaiman had previously created to help sort out the legal rights surrounding Marvelman. Gaiman had written "Marvel 1602 "in 2003 to help fund this project and all of Gaiman's profits for the original issues of the series were donated to Marvels and Miracles. Marvelman was eventually purchased by Marvel Comics in 2009.

Gaiman returned to court again over the Spawn characters Dark Ages Spawn, Domina and Tiffany, claiming that they were "derivative of the three he co-created with McFarlane." The judge ruled that Gaiman was right in these claims as well and gave McFarlane until the beginning of September 2010 to settle the matter.

Gaiman's work is known for a high degree of allusiveness. Dr. Meredith Collins, for instance, has commented upon the degree to which his novel "Stardust" depends on allusions to Victorian fairy tales and culture. Particularly in "The Sandman", literary figures and characters appear often; the character of Fiddler's Green is modelled visually on G. K. Chesterton, both William Shakespeare and Geoffrey Chaucer appear as characters, as do several characters from within "A Midsummer Night's Dream" and "The Tempest". The comic also draws from numerous mythologies and historical periods.

Analyzing Gaiman's "The Graveyard Book", bibliographer and librarian Richard Bleiler detects patterns of and allusions to the Gothic novel, from Horace Walpole's "The Castle of Otranto" to Shirley Jackson's "The Haunting of Hill House". He concludes that Gaiman is "utilizing works, characters, themes, and settings that generations of scholars have identified and classified as Gothic, ... [yet] subverts them and develops the novel by focusing on the positive aspects of maturation, concentrating on the values of learning, friendship, and sacrifice." Regarding another work's assumed connection and allusions to this form, Gaiman himself quipped: "I've never been able to figure out whether "Sandman" is a gothic."

Clay Smith has argued that this sort of allusiveness serves to situate Gaiman as a strong authorial presence in his own works, often to the exclusion of his collaborators. However, Smith's viewpoint is in the minority: to many, if there is a problem with Gaiman scholarship and intertextuality it is that "... his literary merit and vast popularity have propelled him into the nascent comics canon so quickly that there is not yet a basis of critical scholarship about his work."

David Rudd takes a more generous view in his study of the novel "Coraline", where he argues that the work plays and riffs productively on Sigmund Freud's notion of the Uncanny, or the "Unheimlich".

Though Gaiman's work is frequently seen as exemplifying the monomyth structure laid out in Joseph Campbell's "The Hero with a Thousand Faces", Gaiman says that he started reading "The Hero with a Thousand Faces" but refused to finish it: "I think I got about half way through "The Hero with a Thousand Faces" and found myself thinking if this is true – I don't want to know. I really would rather not know this stuff. I'd rather do it because it's true and because I accidentally wind up creating something that falls into this pattern than be told what the pattern is."



</doc>
<doc id="22058" url="https://en.wikipedia.org/wiki?curid=22058" title="Nymph">
Nymph

A nymph (, ; Ancient: , Modern: ) in ancient Greek folklore is a minor female nature deity. Different from Greek goddesses, nymphs are generally regarded as personifications of nature, are typically tied to a specific place or landform, and are usually depicted as beautiful maidens. They were not necessarily immortal, but lived much longer than humans before they died.

They are often divided into various broad subgroups, such as the Meliae (ash tree nymphs), the Naiads (freshwater nymphs), the Nereids (sea nymphs), and the Oreads (mountain nymphs).

Nymphs often feature in many classic works of art, literature, mythology, and fiction. Since medieval times, nymphs are sometimes popularly associated or even confused with fairies.
The Greek word has the primary meaning of "young woman; bride, young wife" but is not usually associated with deities in particular. Yet the etymology of the noun remains uncertain. The Doric and Aeolic (Homeric) form is .

Modern usage more often applies to young women at the peak of their attractiveness, contrasting with "parthenos" () "a virgin (of any age)", and generically as "kore" ( < ) "maiden, girl". The term is sometimes used by women to address each other and remains the regular Modern Greek term for "bride".

Nymphs were sometimes beloved by many and dwelt in specific areas related to the natural environment, e.g. mountainous regions, forests, springs. Other nymphs were part of the retinue of a god, such as Dionysus, Hermes, or Pan, or a goddess, generally the huntress Artemis. 

The Greek nymphs were also spirits invariably bound to places, not unlike the Latin "genius loci", and sometimes this produced complicated myths like the cult of Arethusa to Sicily. In some of the works of the Greek-educated Latin poets, the nymphs gradually absorbed into their ranks the indigenous Italian divinities of springs and streams (Juturna, Egeria, Carmentis, Fontus) while the Lymphae (originally Lumpae), Italian water goddesses, owing to the accidental similarity of their names, could be identified with the Greek Nymphae. The classical mythologies of the Roman poets were unlikely to have affected the rites and cults of individual nymphs venerated by country people in the springs and clefts of Latium. Among the Roman literate class, their sphere of influence was restricted and they appear almost exclusively as divinities of the watery element.

The ancient Greek belief in nymphs survived in many parts of the country into the early years of the twentieth century when they were usually known as "nereids". Often nymphs tended to frequent areas distant from humans but could be encountered by lone travelers outside the village, where their music might be heard, and the traveler could spy on their dancing or bathing in a stream or pool, either during the noon heat or in the middle of the night. They might appear in a whirlwind. Such encounters could be dangerous, bringing dumbness, besotted infatuation, madness or stroke to the unfortunate human. When parents believed their child to be nereid-struck, they would pray to Saint Artemidos.

Nymphs often feature or are depicted in many classic works across art, literature, mythology, and fiction. They are often associated with the medieval romances or Renaissance literature of the elusive fairies or elves.

A motif that entered European art during the Renaissance was the idea of a statue of a nymph sleeping in a grotto or spring. This motif supposedly came from an Italian report of a Roman sculpture of a nymph at a fountain above the River Danube. The report, and an accompanying poem supposedly on the fountain describing the sleeping nymph, are now generally concluded to be a fifteenth-century forgery, but the motif proved influential among artists and landscape gardeners for several centuries after, with copies seen at neoclassical gardens such as the grotto at Stourhead.

All the names for various classes of nymphs have plural feminine adjectives, most agreeing with the substantive numbers and groups of nymphai. There is no single adopted classification that could be seen as canonical and exhaustive. Some classes of nymphs tend to overlap, which complicates the task of precise classification. e.g. Dryads and hamadryads as nymphs of trees generally, "meliai" as nymphs of ash trees, and naiads as nymphs of water, but no others specifically.

The following is not the authentic Greek classification, but is intended simply as a guide:
The following is a list of groups of nymphs associated with this or that particular location. Nymphs in such groupings could belong to any of the classes mentioned above (Naiades, Oreades, and so on).
The following is a selection of names of the nymphs whose class was not specified in the source texts. For lists of Naiads, Oceanids, Dryades etc. see respective articles.







</doc>
<doc id="22059" url="https://en.wikipedia.org/wiki?curid=22059" title="Norse">
Norse

Norse is demonym for Norsemen, a medieval North Germanic ethnolinguistic group ancestral to modern Scandinavians, defined as speakers of Old Norse language from about the 9th to the 13th centuries.

Norse may also refer to:







</doc>
<doc id="22063" url="https://en.wikipedia.org/wiki?curid=22063" title="Natural law">
Natural law

Natural law (, "lex naturalis") is law as seen as being independent of, and pre-existent to, the positive law of any given political order, society or nation-state. Such genesis is seen as determined by nature (whether that reflects creation, evolution, or random chance), and a notional law of nature treated as objective fact that is universally applicable; that is, it exists and is recognizable, without any dependence on human understanding, or on the positive law of any given state, political order, or legislature — and even of society at large. Historically, natural law refers to the use of reason to analyze human nature in deducing binding rules of moral behavior, via (dominant or insurgent) accounts of observed and/or posited aspects of reality and of "the human condition". The concept of natural law was documented in ancient Greek philosophy, including Aristotle, and was referred to in ancient Roman philosophy by Cicero. References to it are also to be found in the Old and New Testaments of the Bible, and were later expounded upon in the Middle Ages by Christian philosophers such as Albert the Great and Thomas Aquinas. The School of Salamanca made notable contributions during the Renaissance. 

Modern natural law theories were greatly developed in the Age of Enlightenment, combining inspiration from Roman law with philosophies like social contract theory. It was used in challenging theory of the divine right of kings, and became an alternative justification for the establishment of a social contract, positive law, and government—and thus legal rights—in the form of classical republicanism. Conversely, the concept of natural rights is used by others to challenge the legitimacy of all such establishments. In the early decades of the 21st century, the concept of natural law is closely related to the concept of natural rights. Indeed, many philosophers, jurists and scholars use natural law synonymously with natural rights (), or natural justice, though others distinguish between natural law and natural right.

Because of the intersection between natural law and natural rights, natural law has been claimed or attributed as a key component in the "Declaration of Independence" (1776) of the United States, the "Declaration of the Rights of Man and of the Citizen" (1789) of France, the "Universal Declaration of Human Rights" (1948) of the United Nations, as well as the "European Convention on Human Rights" (1953) of the Council of Europe.

Although Plato did not have an explicit theory of natural law (he rarely used the phrase 'natural law' except in "Gorgias" 484 and "Timaeus" 83e), his concept of nature, according to John Wild, contains some of the elements found in many natural law theories. According to Plato, we live in an orderly universe. The basis of this orderly universe or nature are the forms, most fundamentally the Form of the Good, which Plato describes as "the brightest region of Being". The Form of the Good is the cause of all things, and when it is seen it leads a person to act wisely. In the "Symposium", the Good is closely identified with the Beautiful. In the "Symposium", Plato describes how the experience of the Beautiful by Socrates enabled him to resist the temptations of wealth and sex. In the "Republic", the ideal community is "a city which would be established in accordance with nature".

Greek philosophy emphasized the distinction between "nature" ("physis", "φúσις") on the one hand and "law", "custom", or "convention" ("nomos", "νóμος") on the other. What the law commanded would be expected to vary from place to place, but what was "by nature" should be the same everywhere. A "law of nature" would therefore have the flavor more of a paradox than something that obviously existed. Against the conventionalism that the distinction between nature and custom could engender, Socrates and his philosophic heirs, Plato and Aristotle, posited the existence of natural justice or natural right ("dikaion physikon", "δίκαιον φυσικόν", Latin "ius naturale"). Of these, Aristotle is often said to be the father of natural law.

Aristotle's association with natural law may be due to the interpretation given to his works by Thomas Aquinas. But whether Aquinas correctly read Aristotle is in dispute. According to some, Aquinas conflates natural law and natural right, the latter of which Aristotle posits in Book V of the "Nicomachean Ethics" (Book IV of the "Eudemian Ethics"). According to this interpretation, Aquinas's influence was such as to affect a number of early translations of these passages in an unfortunate manner, though more recent translations render those more literally. Aristotle notes that natural justice is a species of political justice, specifically the scheme of distributive and corrective justice that would be established under the best political community; were this to take the form of law, this could be called a natural law, though Aristotle does not discuss this and suggests in the "Politics" that the best regime may not rule by law at all.

The best evidence of Aristotle's having thought there was a natural law comes from the "Rhetoric", where Aristotle notes that, aside from the "particular" laws that each people has set up for itself, there is a "common" law that is according to nature. Specifically, he quotes Sophocles and Empedocles:

Universal law is the law of Nature. For there really is, as every one to some extent divines, a natural justice and injustice that is binding on all men, even on those who have no association or covenant with each other. It is this that Sophocles' Antigone clearly means when she says that the burial of Polyneices was a just act in spite of the prohibition: she means that it was just by nature:

And so Empedocles, when he bids us kill no living creature, he is saying that to do this is not just for some people, while unjust for others:

Some critics believe that the context of this remark suggests only that Aristotle advised that it could be rhetorically advantageous to appeal to such a law, especially when the "particular" law of one's own city was averse to the case being made, not that there actually was such a law; Moreover, they claim that Aristotle considered two of the three candidates for a universally valid, natural law provided in this passage to be wrong. Aristotle's paternity of natural law tradition is consequently disputed.

The development of this tradition of natural justice into one of natural law is usually attributed to the Stoics. The rise of natural law as a universal system coincided with the rise of large empires and kingdoms in the Greek world. Whereas the "higher" law that Aristotle suggested one could appeal to was emphatically natural, in contradistinction to being the result of divine positive legislation, the Stoic natural law was indifferent to either the natural or divine source of the law: the Stoics asserted the existence of a rational and purposeful order to the universe (a divine or eternal law), and the means by which a rational being lived in accordance with this order was the natural law, which inspired actions that accorded with virtue.

As the English historian A. J. Carlyle (1861–1943) notes:

There is no change in political theory so startling in its completeness as the change from the theory of Aristotle to the later philosophical view represented by Cicero and Seneca ... We think that this cannot be better exemplified than with regard to the theory of the equality of human nature." Charles H. McIlwain likewise observes that "the idea of the equality of men is the most profound contribution of the Stoics to political thought" and that "its greatest influence is in the changed conception of law that in part resulted from it.
Natural law first appeared among the stoics who believed that God is everywhere and in everyone (see classical pantheism). According to this belief, within humans there is a "divine spark" which helps them to live in accordance with nature. The stoics felt that there was a way in which the universe had been designed, and that natural law helped us to harmonise with this.

Cicero wrote in his De Legibus that both justice and law originate from what nature has given to humanity, from what the human mind embraces, from the function of humanity, and from what serves to unite humanity. For Cicero, natural law obliges us to contribute to the general good of the larger society. The purpose of positive laws is to provide for "the safety of citizens, the preservation of states, and the tranquility and happiness of human life." In this view, "wicked and unjust statutes" are "anything but 'laws,'" because "in the very definition of the term 'law' there inheres the idea and principle of choosing what is just and true." Law, for Cicero, "ought to be a reformer of vice and an incentive to virtue." Cicero expressed the view that "the virtues which we ought to cultivate, always tend to our own happiness, and that the best means of promoting them consists in living with men in that perfect union and charity which are cemented by mutual benefits."

In De Re Publica, he writes:
Cicero influenced the discussion of natural law for many centuries to come, up through the era of the American Revolution. The jurisprudence of the Roman Empire was rooted in Cicero, who held "an extraordinary grip ... upon the imagination of posterity" as "the medium for the propagation of those ideas which informed the law and institutions of the empire." Cicero's conception of natural law "found its way to later centuries notably through the writings of Saint Isidore of Seville and the Decretum of Gratian." Thomas Aquinas, in his summary of medieval natural law, quoted Cicero's statement that "nature" and "custom" were the sources of a society's laws.

The Renaissance Italian historian Leonardo Bruni praised Cicero as the person "who carried philosophy from Greece to Italy, and nourished it with the golden river of his eloquence." The legal culture of Elizabethan England, exemplified by Sir Edward Coke, was "steeped in Ciceronian rhetoric." The Scottish moral philosopher Francis Hutcheson, as a student at Glasgow, "was attracted most by Cicero, for whom he always professed the greatest admiration." More generally in eighteenth-century Great Britain, Cicero's name was a household word among educated people. Likewise, "in the admiration of early Americans Cicero took pride of place as orator, political theorist, stylist, and moralist."

The British polemicist Thomas Gordon "incorporated Cicero into the radical ideological tradition that travelled from the mother country to the colonies in the course of the eighteenth century and decisively shaped early American political culture." Cicero's description of the immutable, eternal, and universal natural law was quoted by Burlamaqui and later by the American revolutionary legal scholar James Wilson. Cicero became John Adams's "foremost model of public service, republican virtue, and forensic eloquence." Adams wrote of Cicero that "as all the ages of the world have not produced a greater statesman and philosopher united in the same character, his authority should have great weight." Thomas Jefferson "first encountered Cicero as a schoolboy while learning Latin, and continued to read his letters and discourses throughout his life. He admired him as a patriot, valued his opinions as a moral philosopher, and there is little doubt that he looked upon Cicero's life, with his love of study and aristocratic country life, as a model for his own." Jefferson described Cicero as "the father of eloquence and philosophy."

The New Testament carries a further exposition on the Abrahamic dialogue and links to the later Greek exposition on the subject, when Paul's Epistle to the Romans states: "For when the Gentiles, which have not the law, do by nature the things contained in the law, these, having not the law, are a law unto themselves: Which shew the work of the law written in their hearts, their conscience also bearing witness, and their thoughts the meanwhile accusing or else excusing one another." The intellectual historian A. J. Carlyle has commented on this passage, "There can be little doubt that St Paul's words imply some conception analogous to the 'natural law' in Cicero, a law written in men's hearts, recognized by man's reason, a law distinct from the positive law of any State, or from what St Paul recognized as the revealed law of God. It is in this sense that St Paul's words are taken by the Fathers of the fourth and fifth centuries like St Hilary of Poitiers, St Ambrose, and St Augustine, and there seems no reason to doubt the correctness of their interpretation."

Because of its origins in the Old Testament, early Church Fathers, especially those in the West, saw natural law as part of the natural foundation of Christianity. The most notable among these was Augustine of Hippo, who equated natural law with humanity's prelapsarian state; as such, a life according to unbroken human nature was no longer possible and persons needed instead to seek healing and salvation through the divine law and grace of Jesus Christ.

The natural law was inherently teleological, however, it is most assuredly not deontological. For Christians, natural law is how human beings manifest the divine image in their life. This mimicry of God's own life is impossible to accomplish except by means of the power of grace. Thus, whereas deontological systems merely require certain duties be performed, Christianity explicitly states that no one can, in fact, perform any duties if grace is lacking. For Christians, natural law flows not from divine commands, but from the fact that humanity is made in God's image, humanity is empowered by God's grace. Living the natural law is how humanity displays the gifts of life and grace, the gifts of all that is good. Consequences are in God's hands, consequences are generally not within human control, thus in natural law, actions are judged by three things: (1) the person's intent, (2) the circumstances of the act and (3) the nature of the act. The apparent good or evil consequence resulting from the moral act is not relevant to the act itself. The specific content of the natural law is therefore determined by how each person's acts mirror God's internal life of love. Insofar as one lives the natural law, temporal satisfaction may or may not be attained, but salvation will be attained. The state, in being bound by the natural law, is conceived as an institution whose purpose is to assist in bringing its subjects to true happiness. True happiness derives from living in harmony with the mind of God as an image of the living God.

After the Protestant Reformation, some Protestant denominations maintained parts of the Catholic concept of natural law. The English theologian Richard Hooker from the Church of England adapted Thomistic notions of natural law to Anglicanism five principles: to live, to learn, to reproduce, to worship God, and to live in an ordered society.

In the twelfth century, Gratian equated the natural law with divine law. Albertus Magnus would address the subject a century later, and his pupil, St. Thomas Aquinas, in his "Summa Theologica" I-II qq. 90–106, restored Natural Law to its independent state, asserting natural law as the rational creature's participation in the eternal law. Yet, since human reason could not fully comprehend the Eternal law, it needed to be supplemented by revealed Divine law. (See also Biblical law in Christianity.) Meanwhile, Aquinas taught that all human or positive laws were to be judged by their conformity to the natural law. An unjust law is not a law, in the full sense of the word. It retains merely the 'appearance' of law insofar as it is duly constituted and enforced in the same way a just law is, but is itself a 'perversion of law.' At this point, the natural law was not only used to pass judgment on the moral worth of various laws, but also to determine what those laws meant in the first place. This principle laid the seed for possible societal tension with reference to tyrants.

The Catholic Church holds the view of natural law introduced by Albertus Magnus and elaborated by Thomas Aquinas, particularly in his "Summa Theologiae", and often as filtered through the School of Salamanca. This view is also shared by some Protestants, and was delineated by Anglican writer C. S. Lewis in his works "Mere Christianity" and "The Abolition of Man.

The Catholic Church understands human beings to consist of body and mind, the physical and the non-physical (or soul perhaps), and that the two are inextricably linked. Humans are capable of discerning the difference between good and evil because they have a conscience. There are many manifestations of the good that we can pursue. Some, like procreation, are common to other animals, while others, like the pursuit of truth, are inclinations peculiar to the capacities of human beings.

To know what is right, one must use one's reason and apply it to Thomas Aquinas' precepts. This reason is believed to be embodied, in its most abstract form, in the concept of a primary precept: "Good is to be sought, evil avoided." St. Thomas explains that:
there belongs to the natural law, first, certain most general precepts, that are known to all;
However, while the primary and immediate precepts cannot be "blotted out", the secondary precepts can be. Therefore, for a deontological ethical theory they are open to a surprisingly large amount of interpretation and flexibility. Any rule that helps humanity to live up to the primary or subsidiary precepts can be a secondary precept, for example:

Natural moral law is concerned with both exterior and interior acts, also known as action and motive. Simply doing the right thing is not enough; to be truly moral one's motive must be right as well. For example, helping an old lady across the road (good exterior act) to impress someone (bad interior act) is wrong. However, good intentions don't always lead to good actions. The motive must coincide with the cardinal or theological virtues. Cardinal virtues are acquired through reason applied to nature; they are:

The theological virtues are:


According to Aquinas, to lack any of these virtues is to lack the ability to make a moral choice. For example, consider a person who possesses the virtues of justice, prudence, and fortitude, yet lacks temperance. Due to their lack of self-control and desire for pleasure, despite their good intentions, they will find themself swaying from the moral path.

In the 16th century, the School of Salamanca (Francisco Suárez, Francisco de Vitoria, etc.) further developed a philosophy of natural law.

Abū Rayhān al-Bīrūnī, a medieval scholar, scientist, and polymath, understood "natural law" as the survival of the fittest. He argued that the antagonism between human beings can be overcome only through a divine law, which he believed to have been sent through prophets. This is also said to be the general position of the Ashari school, the largest school of Sunni theology, as well as Ibn Hazm. Conceptualized thus, all "laws" are viewed as originating from subjective attitudes actuated by cultural conceptions and individual preferences, and so the notion of "divine revelation" is justified as some kind of "divine intervention" that replaces human positive laws, which are criticized as being relative, with a single divine positive law. This, however, also entails that anything may be included in "the divine law" as it would in "human laws", but unlike the latter, "God's law" is seen as binding regardless of the nature of the commands by virtue of "God's might": since God is not subject to human laws and conventions, He may command what He wills just as He may do what He wills.

The Maturidi school, the second-largest school of Sunni theology, as well as the Mu'tazilites, posits the existence of a form of natural, or "objective," law that humans can comprehend. Abu Mansur al-Maturidi stated that the human mind could know of the existence of God and the major forms of "good" and "evil" without the help of revelation. Al-Maturidi gives the example of stealing, which, he believes, is known to be evil by reason alone due to people's working hard for their property. Similarly, killing, fornication, and drunkenness are all "discernible evils" that the human mind could know of according to al-Maturidi. Likewise, Averroes (Ibn Rushd), in his treatise on "Justice and Jihad" and his commentary on Plato's "Republic", writes that the human mind can know of the unlawfulness of killing and stealing and thus of the five maqasid or higher intents of the Islamic sharia, or the protection of religion, life, property, offspring, and reason. His Aristotelian commentaries also influenced the subsequent Averroist movement and the writings of Thomas Aquinas.

Ibn Qayyim Al-Jawziyya also posited that human reason could discern between "great sins" and "good deeds". Nonetheless, he, like Ibn Taymiyah, emphasized the authority of "divine revelation" and asserted that it must be followed even if it "seems" to contradict human reason, though he stressed that most, if not all, of "God's commands" are both sensible (that is, rationalizable) and advantageous to humans in both "this life" and "the hereafter".

The concept of "Istislah" in Islamic law bears some similarities to the natural law tradition in the West, as exemplified by Thomas Aquinas. However, whereas natural law deems good what is self-evidently good, according as it tends towards the fulfillment of the person, "istislah" typically calls good whatever is related to one of five "basic goods". Many jurists, theologians, and philosophers attempted to abstract these "basic and fundamental goods" from legal precepts. Al-Ghazali, for instance, defined them as religion, life, reason, lineage, and property, while others add "honor" also.

Early Irish law, An Senchus Mor (The Great Tradition) mentions in a number of places "recht aicned" or natural law. This is a concept predating European legal theory, and reflects a type of law that is universal and may be determined by reason and observation of natural action. Neil McLeod identifies concepts that law must accord with: fír (truth) and dliged (right or entitlement). These two terms occur frequently, though Irish law never strictly defines them. Similarly, the term córus (law in accordance with proper order) occurs in some places, and even in the titles of certain texts. These were two very real concepts to the jurists and the value of a given judgment with respect to them was apparently ascertainable. McLeod has also suggested that most of the specific laws mentioned have passed the test of time and thus their truth has been confirmed, while other provisions are justified in other ways because they are younger and have not been tested over time The laws were written in the oldest dialect of the Irish language, called Bérla Féini [Bairla-faina], which even at the time was so difficult that persons about to become brehons had to be specially instructed in it, the length of time from beginning to becoming a learned Brehon was usually 20 years. Although under the law any third person could fulfill the duty if both parties agreed, and both were sane. It has been included in an Ethno-Celtic breakaway subculture, as it has religious undertones and freedom of religious expression allows it to once again be used as a valid system in Western Europe.

Heinrich A. Rommen remarked upon "the tenacity with which the spirit of the English common law retained the conceptions of natural law and equity which it had assimilated during the Catholic Middle Ages, thanks especially to the influence of Henry de Bracton (d. 1268) and Sir John Fortescue (d. cir. 1476)." Bracton's translator notes that Bracton "was a trained jurist with the principles and distinctions of Roman jurisprudence firmly in mind"; but Bracton adapted such principles to English purposes rather than copying slavishly. In particular, Bracton turned the imperial Roman maxim that "the will of the prince is law" on its head, insisting that the king is "under" the law. The legal historian Charles F. Mullett has noted Bracton's "ethical definition of law, his recognition of justice, and finally his devotion to natural rights." Bracton considered justice to be the "fountain-head" from which "all rights arise." For his definition of justice, Bracton quoted the twelfth-century Italian jurist Azo: "'Justice is the constant and unfailing will to give to each his right.'" Bracton's work was the second legal treatise studied by the young apprentice lawyer Thomas Jefferson.

Fortescue stressed "the supreme importance of the law of God and of nature" in works that "profoundly influenced the course of legal development in the following centuries." The legal scholar Ellis Sandoz has noted that "the historically ancient and the ontologically higher law—eternal, divine, natural—are woven together to compose a single harmonious texture in Fortescue's account of English law." As the legal historian Norman Doe explains: "Fortescue follows the general pattern set by Aquinas. The objective of every legislator is to dispose people to virtue. It is by means of law that this is accomplished. Fortescue's definition of law (also found in Accursius and Bracton), after all, was 'a sacred sanction commanding what is virtuous ["honesta"] and forbidding the contrary.'" Fortescue cited the great Italian Leonardo Bruni for his statement that "virtue alone produces happiness."

Christopher St. Germain's "Doctor and Student" was a classic of English jurisprudence, and it was thoroughly annotated by Thomas Jefferson. St. Germain informs his readers that English lawyers generally don't use the phrase "law of nature", but rather use "reason" as the preferred synonym. Norman Doe notes that St. Germain's view "is essentially Thomist," quoting Thomas Aquinas's definition of law as "an ordinance of reason made for the common good by him who has charge of the community, and promulgated".

Sir Edward Coke was the preeminent jurist of his time. Coke's preeminence extended across the ocean: "For the American revolutionary leaders, 'law' meant Sir Edward Coke's custom and right reason." Coke defined law as "perfect reason, which commands those things that are proper and necessary and which prohibits contrary things". For Coke, human nature determined the purpose of law; and law was superior to any one person's reason or will. Coke's discussion of natural law appears in his report of "Calvin's Case" (1608): "The law of nature is that which God at the time of creation of the nature of man infused into his heart, for his preservation and direction." In this case the judges found that "the ligeance or faith of the subject is due unto the King by the law of nature: secondly, that the law of nature is part of the law of England: thirdly, that the law of nature was before any judicial or municipal law: fourthly, that the law of nature is immutable." To support these findings, the assembled judges (as reported by Coke, who was one of them) cited as authorities Aristotle, Cicero, and the Apostle Paul; as well as Bracton, Fortescue, and St. Germain.

After Coke, the most famous common law jurist of the seventeenth century is Sir Matthew Hale. Hale wrote a treatise on natural law that circulated among English lawyers in the eighteenth century and survives in three manuscript copies. This natural-law treatise has been published as "Of the Law of Nature" (2015). Hale's definition of the natural law reads: "It is the Law of Almighty God given by him to Man with his Nature discovering the morall good and moral evill of Moral Actions, commanding the former, and forbidding the latter by the secret voice or dictate of his implanted nature, his reason, and his concience." He viewed natural law as antecedent, preparatory, and subsequent to civil government, and stated that human law "cannot forbid what the Law of Nature injoins, nor Command what the Law of Nature prohibits." He cited as authorities Plato, Aristotle, Cicero, Seneca, Epictetus, and the Apostle Paul. He was critical of Hobbes's reduction of natural law to self-preservation and Hobbes's account of the state of nature, but drew positively on Hugo Grotius's "De jure belli ac pacis", Francisco Suárez's "Tractatus de legibus ac deo legislatore", and John Selden's "De jure naturali et gentium juxta disciplinam Ebraeorum".

As early as the thirteenth century, it was held that "the law of nature...is the ground of all laws" and by the Chancellor and Judges that "it is required by the law of nature that every person, before he can be punish'd, ought to be present; and if absent by contumacy, he ought to be summoned and make default". Further, in 1824, we find it held that "proceedings in our Courts are founded upon the law of England, and that law is again founded upon the law of nature and the revealed law of God. If the right sought to be enforced is inconsistent with either of these, the English municipal courts cannot recognize it."

By the 17th century, the medieval teleological view came under intense criticism from some quarters. Thomas Hobbes instead founded a contractarian theory of legal positivism on what all men could agree upon: what they sought (happiness) was subject to contention, but a broad consensus could form around what they feared (violent death at the hands of another). The natural law was how a rational human being, seeking to survive and prosper, would act. Natural law, therefore, was discovered by considering humankind's natural rights, whereas previously it could be said that natural rights were discovered by considering the natural law. In Hobbes' opinion, the only way natural law could prevail was for men to submit to the commands of the sovereign. Because the ultimate source of law now comes from the sovereign, and the sovereign's decisions need not be grounded in morality, legal positivism is born. Jeremy Bentham's modifications on legal positivism further developed the theory.

As used by Thomas Hobbes in his treatises "Leviathan" and "De Cive", natural law is "a precept, or general rule, found out by reason, by which a man is forbidden to do that which is destructive of his life, or takes away the means of preserving the same; and to omit that by which he thinks it may best be preserved."

According to Hobbes, there are nineteen Laws. The first two are expounded in chapter XIV of Leviathan ("of the first and second natural laws; and of contracts"); the others in chapter XV ("of other laws of nature").

Hobbes's philosophy includes a frontal assault on the founding principles of the earlier natural legal tradition, disregarding the traditional association of virtue with happiness, and likewise re-defining "law" to remove any notion of the promotion of the common good. Hobbes has no use for Aristotle's association of nature with human perfection, inverting Aristotle's use of the word "nature." Hobbes posits a primitive, unconnected state of nature in which men, having a "natural proclivity...to hurt each other" also have "a Right to every thing, even to one anothers body"; and "nothing can be Unjust" in this "warre of every man against every man" in which human life is "solitary, poore, nasty, brutish, and short." Rejecting Cicero's view that people join in society primarily through "a certain social spirit which nature has implanted in man," Hobbes declares that men join in society simply for the purpose of "getting themselves out from that miserable condition of Warre, which is necessarily consequent...to the naturall Passions of men, when there is no visible Power to keep them in awe." As part of his campaign against the classical idea of natural human sociability, Hobbes inverts that fundamental natural legal maxim, the Golden Rule. Hobbes's version is ""Do not that to another, which thou wouldst not have done to thy selfe.""

The English cleric Richard Cumberland wrote a lengthy and influential attack on Hobbes's depiction of individual self-interest as the essential feature of human motivation. Historian Knud Haakonssen has noted that in the eighteenth century, Cumberland was commonly placed alongside Alberico Gentili, Hugo Grotius and Samuel Pufendorf "in the triumvirate of seventeenth-century founders of the 'modern' school of natural law." The eighteenth-century philosophers Shaftesbury and Hutcheson "were obviously inspired in part by Cumberland." Historian Jon Parkin likewise describes Cumberland's work as "one of the most important works of ethical and political theory of the seventeenth century." Parkin observes that much of Cumberland's material "is derived from Roman Stoicism, particularly from the work of Cicero, as "Cumberland deliberately cast his engagement with Hobbes in the mould of Cicero's debate between the Stoics, who believed that nature could provide an objective morality, and Epicureans, who argued that morality was human, conventional and self-interested." In doing so, Cumberland de-emphasized the overlay of Christian dogma (in particular, the doctrine of "original sin" and the corresponding presumption that humans are incapable of "perfecting" themselves without divine intervention) that had accreted to natural law in the Middle Ages.

By way of contrast to Hobbes's multiplicity of laws, Cumberland states in the very first sentence of his "Treatise of the Laws of Nature" that "all the Laws of Nature are reduc'd to that one, of Benevolence toward all Rationals." He later clarifies: "By the name "Rationals" I beg leave to understand, as well "God" as "Man"; and I do it upon the Authority of Cicero." Cumberland argues that the mature development ("perfection") of human nature involves the individual human willing and acting for the common good. For Cumberland, human interdependence precludes Hobbes's natural right of each individual to wage war against all the rest for personal survival. However, Haakonssen warns against reading Cumberland as a proponent of "enlightened self-interest." Rather, the "proper moral love of humanity" is "a disinterested love of God through love of humanity in ourselves as well as others." Cumberland concludes that actions "principally conducive to our Happiness" are those that promote "the Honour and Glory of God" and also "Charity and Justice towards men." Cumberland emphasizes that desiring the well-being of our fellow humans is essential to the "pursuit of our own Happiness." He cites "reason" as the authority for his conclusion that happiness consists in "the most extensive Benevolence," but he also mentions as "Essential Ingredients of Happiness" the "Benevolent Affections," meaning "Love and Benevolence towards others," as well as "that Joy, which arises from their Happiness."

The U.S. Declaration of Independence states that it has become necessary for the people of the United States to assume "the separate and equal station to which the Laws of Nature and of Nature's God entitle them". Some early American lawyers and judges perceived natural law as too tenuous, amorphous, and evanescent a legal basis for grounding concrete rights and governmental limitations. Natural law did, however, serve as authority for legal claims and rights in some judicial decisions, legislative acts, and legal pronouncements. Robert Lowry Clinton argues that the U.S. Constitution rests on a common law foundation and the common law, in turn, rests on a classical natural law foundation.

Liberal natural law grew out of the medieval Christian natural law theories and out of Hobbes' revision of natural law, sometimes in an uneasy balance of the two.

Sir Alberico Gentili and Hugo Grotius based their philosophies of international law on natural law. In particular, his writings on freedom of the seas and just war theory directly appealed to natural law. About natural law itself, he wrote that "even the will of an omnipotent being cannot change or abrogate" natural law, which "would maintain its objective validity even if we should assume the impossible, that there is no God or that he does not care for human affairs." ("De iure belli ac pacis", Prolegomeni XI). This is the famous argument "etiamsi daremus" ("non esse Deum"), that made natural law no longer dependent on theology. However, German church-historians Ernst Wolf and M. Elze disagreed and claimed that Grotius' concept of natural law did have a theological basis. In Grotius' view, the Old Testament contained moral precepts (e.g. the Decalogue) which Christ confirmed and therefore were still valid. Moreover, they were useful in explaining the content of natural law. Both biblical revelation and natural law originated in God and could therefore not contradict each other.

In a similar way, Samuel Pufendorf gave natural law a theological foundation and applied it to his concepts of government and international law.

John Locke incorporated natural law into many of his theories and philosophy, especially in "Two Treatises of Government". There is considerable debate about whether his conception of natural law was more akin to that of Aquinas (filtered through Richard Hooker) or Hobbes' radical reinterpretation, though the effect of Locke's understanding is usually phrased in terms of a revision of Hobbes upon Hobbesian contractarian grounds. Locke turned Hobbes' prescription around, saying that if the ruler went against natural law and failed to protect "life, liberty, and property," people could justifiably overthrow the existing state and create a new one.

While Locke spoke in the language of natural law, the content of this law was by and large protective of natural rights, and it was this language that later liberal thinkers preferred. Political philosopher Jeremy Waldron has pointed out that Locke's political thought was based on "a particular set of Protestant Christian assumptions." To Locke, the content of natural law was identical with biblical ethics as laid down especially in the Decalogue, Christ's teaching and exemplary life, and St. Paul's admonitions. Locke derived the concept of basic human equality, including the equality of the sexes ("Adam and Eve"), from Genesis 1, 26–28, the starting-point of the theological doctrine of Imago Dei. One of the consequences is that as all humans are created equally free, governments need the consent of the governed. Thomas Jefferson, arguably echoing Locke, appealed to unalienable rights in the "Declaration of Independence", "We hold these truths to be self-evident, that all men are "created" equal, that they are endowed by their "Creator" with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness." The Lockean idea that governments need the consent of the governed was also fundamental to the Declaration of Independence, as the American Revolutionaries used it as justification for their separation from the British crown.

The Belgian philosopher of law Frank van Dun is one among those who are elaborating a secular conception of natural law in the liberal tradition. Libertarian theorist Murray Rothbard argues that "the very existence of a natural law discoverable by reason is a potentially powerful threat to the status quo and a standing reproach to the reign of blindly traditional custom or the arbitrary will of the State apparatus." Ludwig von Mises states that he relaid the general sociological and economic foundations of the liberal doctrine upon utilitarianism, rather than natural law, but R. A. Gonce argues that "the reality of the argument constituting his system overwhelms his denial." Murray Rothbard, however, says that Gonce makes a lot of errors and distortions in the analysis of Mises's works, including making confusions about the term which Mises uses to refer to scientific laws, "laws of nature", saying it characterizes Mises as a natural law philosopher. David Gordon notes, "When most people speak of natural law, what they have in mind is the contention that morality can be derived from human nature. If human beings are rational animals of such-and-such a sort, then the moral virtues are...(filling in the blanks is the difficult part)."

Economist and philosopher F. A. Hayek said that, originally, "the term 'natural' was used to describe an orderliness or regularity that was not the product of deliberate human will. Together with 'organism' it was one of the two terms generally understood to refer to the spontaneously grown in contrast to the invented or designed. Its use in this sense had been inherited from the stoic philosophy, had been revived in the twelfth century, and it was finally under its flag that the late Spanish Schoolmen developed the foundations of the genesis and functioning of spontaneously formed social institutions." The idea that 'natural' was "the product of designing reason" is a product of a seventeenth century rationalist reinterpretation of the law of nature. Luis Molina, for example, when referred to the 'natural' price, explained that it is "so called because 'it results from the thing itself without regard to laws and decrees, but is dependent on many circumstances which alter it, such as the sentiments of men, their estimation of different uses, often even in consequence of whims and pleasures". And even John Locke, when talking about the foundations of natural law and explaining what he thought when citing "reason", said: "By reason, however, I do not think is meant here that faculty of the understanding which forms traint of thought and deduces proofs, but certain definite principles of action from which spring all virtues and whatever is necessary for the proper moulding of morals."

This anti-rationalist approach to human affairs, for Hayek, was the same which guided Scottish enlightenment thinkers, such as Adam Smith, David Hume and Adam Ferguson, to make their case for liberty. For them, no one can have the knowledge necessary to plan society, and this "natural" or "spontaneous" order of society shows how it can efficiently "plan" bottom-up. Also, the idea that law is just a product of deliberate design, denied by natural law and linked to legal positivism, can easily generate totalitarianism: "If law is wholly the product of deliberate design, whatever the designer decrees to be law is just by definition and unjust law becomes a contradiction in terms. The will of the duly authorized legislator is then wholly unfettered and guided solely by his concrete interests". This idea is wrong because law cannot be just a product of "reason": "no system of articulated law can be applied except within a framework of generally recognized but often unarticulated rules of justice".

However, a secular critique of the natural law doctrine was stated by Pierre Charron in his "De la sagesse" (1601): "The sign of a natural law must be the universal respect in which it is held, for if there was anything that nature had truly commanded us to do, we would undoubtedly obey it universally: not only would every nation respect it, but every individual. Instead there is nothing in the world that is not subject to contradiction and dispute, nothing that is not rejected, not just by one nation, but by many; equally, there is nothing that is strange and (in the opinion of many) unnatural that is not approved in many countries, and authorized by their customs."

One modern articulation of the concept of natural laws was given by Belina and Dzudzek:
"By constant repetition, those practices develop into structures in the form of discourses which can become so natural that we abstract from their societal origins, that the latter are forgotten and seem to be natural laws."

In jurisprudence, "natural law" can refer to the several doctrines:

Whereas legal positivism would say that a law can be unjust without it being any less a law, a natural law jurisprudence would say that there is something legally deficient about an unjust norm.

Besides utilitarianism and Kantianism, natural law jurisprudence has in common with virtue ethics that it is a live option for a first principles ethics theory in analytic philosophy.

The concept of natural law was very important in the development of the English common law. In the struggles between Parliament and the monarch, Parliament often made reference to the Fundamental Laws of England, which were at times said to embody natural law principles since time immemorial and set limits on the power of the monarchy. According to William Blackstone, however, natural law might be useful in determining the content of the common law and in deciding cases of equity, but was not itself identical with the laws of England. Nonetheless, the implication of natural law in the common law tradition has meant that the great opponents of natural law and advocates of legal positivism, like Jeremy Bentham, have also been staunch critics of the common law.

Natural law jurisprudence is currently undergoing a period of reformulation (as is legal positivism). The most prominent contemporary natural law jurist, Australian John Finnis, is based in Oxford, but there are also Americans Germain Grisez, Robert P. George, and Canadian Joseph Boyle and Brazilian Emídio Brasileiro. All have tried to construct a new version of natural law. The 19th-century anarchist and legal theorist, Lysander Spooner, was also a figure in the expression of modern natural law.

"New Natural Law" as it is sometimes called, originated with Grisez. It focuses on "basic human goods", such as human life, knowledge, and aesthetic experience, which are self-evidently and intrinsically worthwhile, and states that these goods reveal themselves as being incommensurable with one another.

The tensions between the natural law and the positive law have played, and continue to play, a key role in the development of international law.



</doc>
<doc id="22065" url="https://en.wikipedia.org/wiki?curid=22065" title="Nestorianism">
Nestorianism

Nestorianism is a Christian theological doctrine that upholds several distinctive teachings in the fields of Christology and Mariology. It opposes the concept of hypostatic union and emphasizes that the two natures (human and divine) of Jesus Christ were joined by will rather than personhood. This Christological position is defined as "radical dyophysitism". Nestorianism was named after Christian theologian Nestorius (386–450), Patriarch of Constantinople from 428 to 431, who was influenced by Christological teachings of Theodore of Mopsuestia at the School of Antioch.

Nestorius' teachings brought him into conflict with other prominent church leaders, most notably Cyril of Alexandria, who criticized especially his rejection of the title "Theotokos" ("God-bearer") for Mary, the mother of Jesus, and issued 12 anathemas against him at a council in Rome in 430. Nestorius and his teachings were eventually condemned as heretical at the Council of Ephesus in 431, and again at the Council of Chalcedon in 451, which led to the Nestorian Schism; churches supporting Nestorian teachings broke with the rest of the Christian Church.

Following that, many of Nestorius's supporters relocated to the Sasanian Empire, where they affiliated with the local Christian community, known as the Church of the East. However, some such as Sebastian Brock consider referring to the Assyrian Church of the East as the "Nestorian Church" to be "inappropriate and misleading."

Nestorianism is a form of dyophysitism, differing from orthodox dyophysitism on several points, mainly by opposition to the concept of hypostatic union. It can be seen as the antithesis to Eutchyan Monophysitism, which emerged in reaction to Nestorianism. Where Nestorianism holds that Christ had two loosely united natures, divine and human, Monophysitism holds that he had but a single nature, his human nature being absorbed into his divinity. A brief definition of Nestorian Christology can be given as: "Jesus Christ, who is not identical with the Son but personally united with the Son, who lives in him, is one hypostasis and one nature: human." This contrasts with Nestorius' own teaching that the Word, which is eternal, and the Flesh, which is not, came together in a hypostatic union, 'Jesus Christ', Jesus thus being both fully man and God, of two "ousia" () but of one "prosopon". Both Nestorianism and Monophysitism were condemned as heretical at the Council of Chalcedon.

Nestorianism was condemned as heresy at the Council of Ephesus. The Armenian Church rejected the Council of Chalcedon (451) because they believed Chalcedonian Definition was too similar to Nestorianism. The Persian Nestorian Church, on the other hand, supported the spread of Nestorianism in Persarmenia. The Armenian Church and other eastern churches saw the rise of Nestorianism as a threat to the independence of their Church. Peter the Iberian, a Georgian prince, also strongly opposed the Chalcedonian Creed. Thus, in 491, Catholicos Babken I of Armenia, along with the Albanian and Iberian bishops met in Vagharshapat and issued a condemnation of the Chalcedonian Definition.

Nestorians held that the Council of Chalcedon proved the orthodoxy of their faith and had started persecuting non-Chalcedonian or Monophysite Syrian Christians during the reign of Peroz I. In response to pleas for assistance from the Syrian Church, Armenian prelates issued a letter addressed to Persian Christians reaffirming their condemnation of the Nestorianism as heresy.

Following the exodus to Persia, scholars expanded on the teachings of Nestorius and his mentors, particularly after the relocation of the School of Edessa to the (then) Persian city of Nisibis (modern-day Nusaybin in Turkey) in 489, where it became known as the School of Nisibis. Nestorian monasteries propagating the teachings of the Nisibis school flourished in 6th century Persarmenia.

Despite this initial Eastern expansion, the Nestorians' missionary success was eventually deterred. David J. Bosch observes, "By the end of the fourteenth century, however, the Nestorian and other churches—which at one time had dotted the landscape of all of Central and even parts of East Asia—were all but wiped out. Isolated pockets of Christianity survived only in India. The religious victors on the vast Central Asian mission field of the Nestorians were Islam and Buddhism".

Nestorius developed his Christological views as an attempt to understand and explain rationally the incarnation of the divine Logos, the Second Person of the Holy Trinity as the man Jesus. He had studied at the School of Antioch where his mentor had been Theodore of Mopsuestia; Theodore and other Antioch theologians had long taught a literalist interpretation of the Bible and stressed the distinctiveness of the human and divine natures of Jesus. Nestorius took his Antiochene leanings with him when he was appointed Patriarch of Constantinople by Byzantine emperor Theodosius II in 428.

Nestorius's teachings became the root of controversy when he publicly challenged the long-used title "Theotokos" ("God-Bearer") for Mary. He suggested that the title denied Christ's full humanity, arguing instead that Jesus had two persons (dyoprosopism), the divine Logos and the human Jesus. As a result of this prosopic duality, he proposed "Christotokos" (Christ-Bearer) as a more suitable title for Mary.

Nestorius' opponents found his teaching too close to the heresy of adoptionism – the idea that Christ had been born a man who had later been "adopted" as God's son. Nestorius was especially criticized by Cyril, Patriarch of Alexandria, who argued that Nestorius's teachings undermined the unity of Christ's divine and human natures at the Incarnation. Some of Nestorius's opponents argued that he put too much emphasis on the human nature of Christ, and others debated that the difference that Nestorius implied between the human nature and the divine nature created a fracture in the singularity of Christ, thus creating two Christ figures. Nestorius himself always insisted that his views were orthodox, though they were deemed heretical at the Council of Ephesus in 431, leading to the Nestorian Schism, when churches supportive of Nestorius and the rest of the Christian Church separated. A more elaborate Nestorian theology developed from there, which came to see Christ as having two natures united, or hypostases, the divine Logos and the human Christ. However, this formulation was never adopted by all churches termed "Nestorian". Indeed, the modern Assyrian Church of the East, which reveres Nestorius, does not fully subscribe to Nestorian doctrine, though it does not employ the title "Theotokos".

Nestorianism became a distinct sect following the Nestorian Schism, beginning in the 430s. Nestorius had come under fire from Western theologians, most notably Cyril of Alexandria. Cyril had both theological and political reasons for attacking Nestorius; on top of feeling that Nestorianism was an error against true belief, he also wanted to denigrate the head of a competing patriarchate. Cyril and Nestorius asked Pope Celestine I to weigh in on the matter. Celestine found that the title "Theotokos" was orthodox, and authorized Cyril to ask Nestorius to recant. Cyril, however, used the opportunity to further attack Nestorius, who pleaded with Emperor Theodosius II to call a council so that all grievances could be aired.

In 431 Theodosius called the Council of Ephesus. However, the council ultimately sided with Cyril, who held that the Christ contained two natures in one divine person ("hypostasis", unity of subsistence), and that the Virgin Mary, conceiving and bearing this divine person, is truly called the Mother of God ("Theotokos", meaning, God-bearer). The council accused Nestorius of heresy, and deposed him as patriarch. Upon returning to his monastery in 436, he was banished to Upper Egypt. Nestorianism was officially anathematized, a ruling reiterated at the Council of Chalcedon in 451. However, a number of churches, particularly those associated with the School of Edessa, supported Nestorius – though not necessarily his doctrine – and broke with the churches of the West. Many of Nestorius' supporters relocated to the Sasanian Empire of Iran, home to a vibrant but persecuted Christian minority. In Upper Egypt, Nestorius wrote his "Book of Heraclides", responding to the two councils at Ephesus (431, 449).

Persia had long been home to Christian communities that had been persecuted by the Zoroastrian majority, which had accused local Christians of pro-Roman leanings. In 424, the Church in Persia declared itself independent of the Byzantine Church and all other churches, in order to ward off allegations of foreign allegiance. Following the Nestorian Schism, the Persian Church increasingly aligned itself with the Nestorians, a measure encouraged by the Zoroastrian ruling class. The Persian Church became increasingly Nestorian in doctrine over the next decades, furthering the divide between Chalcedonian Christianity and the Nestorians. In 486 the Metropolitan of Nisibis, Barsauma, publicly accepted Nestorius' mentor, Theodore of Mopsuestia, as a spiritual authority. In 489 when the School of Edessa in Mesopotamia was closed by Byzantine Emperor Zeno for its Nestorian teachings, the school relocated to its original home of Nisibis, becoming again the School of Nisibis, leading to a wave of Nestorian immigration into Persia. The Persian patriarch Babai (497–502) reiterated and expanded upon the church's esteem for Theodore, solidifying the church's adoption of Nestorianism.

Now firmly established in Iran, with centers in Nisibis, Ctesiphon, and Gundeshapur, and several "metropoleis", the Nestorian Persian Church began to branch out beyond the Sasanian Empire. However, through the sixth century, the church was frequently beset with internal strife and persecution by Zoroastrians. The infighting led to a schism, which lasted from 521 until around 539 when the issues were resolved. However, immediately afterward Roman-Persian conflict led to the persecution of the church by the Sassanid emperor Khosrow I; this ended in 545. The church survived these trials under the guidance of Patriarch Aba I, who had converted to Christianity from Zoroastrianism.

The church emerged stronger after this period of ordeal, and increased missionary efforts farther afield. Missionaries established dioceses in the Arabian Peninsula and India (the Saint Thomas Christians). They made some advances in Egypt, despite the strong miaphysite presence there. Missionaries entered Central Asia and had significant success converting local Turkic tribes. Nestorian missionaries were firmly established in China during the early part of the Tang dynasty (618–907); the Chinese source known as the Nestorian Stele records a mission under a Persian proselyte named Alopen as introducing Nestorian Christianity to China in 635. Following the Arab conquest of Persia, completed in 644, the Persian Church became a "dhimmi" community under the Rashidun Caliphate. The church and its communities abroad grew larger under the Caliphate. By the 10th century it had 15 metropolitan sees within the Caliphate's territories, and another five elsewhere, including in China and India. After that time, however, Nestorianism went into decline.

In a 1996 article published in the Bulletin of the John Rylands Library, Fellow of the British Academy Sebastian Brock wrote: "...the term 'Nestorian Church' has become the standard designation for the ancient oriental church which in the past called itself 'The Church of the East', but which today prefers the fuller title 'The Assyrian Church of the East'. Such a designation ['Nestorian Church'] is not only discourteous to modern members of this venerable church, but also--as this paper aims to show--both inappropriate and misleading." The Common Christological Declaration between the Catholic Church and the Assyrian Church of the East signed by Pope John Paul II and Mar Dinkha IV underlines the Chalcedonian Christological formulation as the expression of the common faith of these Churches and recognizes the legitimacy of the title "Theotokos".

In a 2017 paper, Mar Awa Royel, Bishop of the Assyrian Church, stated the position of that church: "After the Council of Ephesus (431), when the Nestorius the patriarch of Constantinople was condemned for his views on the unity of the Godhead and the humanity in Christ, the Church of the East was branded as 'Nestorian' on account of its refusal to anathematize the patriarch."




</doc>
<doc id="22066" url="https://en.wikipedia.org/wiki?curid=22066" title="NCR">
NCR

NCR may refer to:




</doc>
<doc id="22068" url="https://en.wikipedia.org/wiki?curid=22068" title="Naomi Klein">
Naomi Klein

Naomi Klein (born May 8, 1970) is a Canadian author, social activist, and filmmaker known for her political analyses and criticism of corporate globalization and of capitalism. On a three-year appointment from September 2018, she is the Gloria Steinem Chair in Media, Culture, and Feminist Studies at Rutgers University.

Klein first became known internationally for her book "No Logo" (1999); "The Take" (2004), a documentary film about Argentina's occupied factories, written by her, and directed by her husband Avi Lewis; and significantly for "The Shock Doctrine" (2007), a critical analysis of the history of neoliberal economics that was adapted into a six-minute companion film by Alfonso and Jonás Cuarón, as well as a feature-length documentary by Michael Winterbottom.

Klein's "This Changes Everything: Capitalism vs. the Climate" (2014) was a "New York Times" Best Seller list non-fiction bestseller and the winner of the Hilary Weston Writers' Trust Prize for Nonfiction in its year. In 2016, Klein was awarded the Sydney Peace Prize for her activism on climate justice. Klein frequently appears on global and national lists of top influential thinkers, including the 2014 Thought Leaders ranking compiled by the Gottlieb Duttweiler Institute, "Prospect" magazine's world thinkers 2014 poll, and Maclean's 2014 Power List. She is a member of the board of directors of the climate activist group 350.org.

Naomi Klein was born in Montreal, Quebec, and brought up in a Jewish family with a history of peace activism. Her parents were self-described "hippies" who emigrated from the United States in 1967 as war resisters to the Vietnam War. Her mother, documentary film-maker Bonnie Sherr Klein, is best known for her anti-pornography film "". Her father, Michael Klein, is a physician and a member of Physicians for Social Responsibility. Her brother, Seth Klein, is director of the British Columbian office of the Canadian Centre for Policy Alternatives.

Before World War II, her paternal grandparents were communists, but they began to turn against the Soviet Union after the Molotov–Ribbentrop Pact in 1939. In 1942, her grandfather, an animator at Disney, was fired after the 1941 strike, and had to switch to working in a shipyard instead. By 1956, they had abandoned communism. Klein's father grew up surrounded by ideas of social justice and racial equality, but found it "difficult and frightening to be the child of Communists", a so-called red diaper baby.

Klein's husband, Avi Lewis, was born into a well-connected political and journalistic family; he works as a TV journalist and documentary filmmaker. The couple's only child, son Toma, was born on June 13, 2012.

Klein spent much of her teenage years in shopping malls, obsessed with designer labels. As a child and teenager, she found it "very oppressive to have a very public feminist mother" and she rejected politics, instead embracing "full-on consumerism".

She has attributed her change in worldview to two catalysts. One was when she was 17 and preparing for the University of Toronto, her mother had a stroke and became severely disabled. Naomi, her father, and her brother took care of Bonnie through the period in hospital and at home, making educational sacrifices to do so. That year off prevented her "from being such a brat". The next year, after beginning her studies at the University of Toronto, the second catalyst occurred: the 1989 École Polytechnique massacre of female engineering students, which proved to be a wake-up call to feminism.

Klein's writing career began with contributions to "The Varsity", a student newspaper, where she served as editor-in-chief. After her third year at the University of Toronto, she dropped out of university to take a job at "The Globe and Mail", followed by an editorship at "This Magazine". In 1995, she returned to the University of Toronto with the intention of finishing her degree but left academia for a journalism internship before acquiring the final credits required to complete her degree.

In 1999, Klein published the book "No Logo", which for many became a manifesto of the anti-globalization movement. In it, she attacks brand-oriented consumer culture and the operations of large corporations. She also accuses several such corporations of unethically exploiting workers in the world's poorest countries in pursuit of greater profits. In this book, Klein criticized Nike so severely that Nike published a point-by-point response. "No Logo" became an international bestseller, selling over one million copies in over 28 languages.

Klein's "Fences and Windows" (2002) is a collection of her articles and speeches written on behalf of the anti-globalization movement (all proceeds from the book go to benefit activist organizations through The Fences and Windows Fund).

"The Take" (2004), a documentary film collaboration by Klein and Lewis, concerns factory workers in Argentina who took over a closed plant and resumed production, operating as a collective. The first African screening was in the Kennedy Road shack settlement in the South African city of Durban, where the Abahlali baseMjondolo movement began.

An article in "Z Communications" criticized "The Take" for its portrayal of the Argentine general and politician Juan Domingo Perón arguing that he was falsely portrayed as a social democrat.

Klein's third book, "The Shock Doctrine: The Rise of Disaster Capitalism", was published on September 4, 2007. The book argues that the free market policies of Nobel Laureate Milton Friedman and the Chicago School of Economics have risen to prominence in countries such as Chile, under Pinochet, Poland, Russia, under Yeltsin. The book also argues that policy initiatives (for instance, the privatization of Iraq's economy under the Coalition Provisional Authority) were rushed through while the citizens of these countries were in shock from disasters, upheavals, or invasion. The book became an international and "New York Times" bestseller and was translated into 28 languages.

Central to the book's thesis is the contention that those who wish to implement unpopular free market policies now routinely do so by taking advantage of certain features of the aftermath of major disasters, be they economic, political, military or natural. The suggestion is that when a society experiences a major 'shock' there is a widespread desire for a rapid and decisive response to correct the situation; this desire for bold and immediate action provides an opportunity for unscrupulous actors to implement policies which go far beyond a legitimate response to disaster. The book suggests that when the rush to act means the specifics of a response will go unscrutinized, that is the moment when unpopular and unrelated policies will intentionally be rushed into effect. The book appears to claim that these shocks are in some cases intentionally encouraged or even manufactured.

Klein identifies the "shock doctrine", elaborating on Joseph Schumpeter, as the latest in capitalism's phases of "creative destruction".

"The Shock Doctrine" was adapted into a short film of the same name, released onto YouTube. The original is no longer available on the site, however, a duplicate was published in 2008. The film was directed by Jonás Cuarón, produced and co-written by his father Alfonso Cuarón. The original video was viewed over one million times.

The publication of "The Shock Doctrine" increased Klein's prominence, with "The New Yorker" judging her "the most visible and influential figure on the American left—what Howard Zinn and Noam Chomsky were thirty years ago." On February 24, 2009, the book was awarded the inaugural Warwick Prize for Writing from the University of Warwick in England. The prize carried a cash award of £50,000.

Klein's fourth book, "This Changes Everything: Capitalism vs. the Climate" was published in September 2014. The book puts forth the argument that the hegemony of neoliberal market fundamentalism is blocking any serious reforms to halt climate change and protect the environment. Questioned about Klein's claim that capitalism and controlling climate change were incompatible, Benoit Blarel, manager of the Environment and Natural Resources global practice at the World Bank, said that the write-off of fossil fuels necessary to control climate change "will have a huge impact all over" and that the World Bank was "starting work on this". The book won the 2014 Hilary Weston Writers' Trust Prize for Nonfiction, and was a shortlisted nominee for the 2015 Shaughnessy Cohen Prize for Political Writing.

Klein's fifth book, "No Is Not Enough: Resisting Trump's Shock Politics and Winning the World We Need" was published in June 2017. It has also been published Internationally with the alternative subtitle "Defeating the New Shock Politics".

Released in June 2018 as paperback and e-book, "The Battle For Paradise: Puerto Rico Takes on the Disaster Capitalists" covers what San Juan Mayor Carmen Yulín Cruz refers to as the post-Hurricane Maria unmasked colonialism leading to inequality and "creating a fierce humanitarian crisis."<ref name="Haymarket Books/The Battle for Paradise official page"></ref>

In April 2019, Simon & Schuster announced they would be publishing Klein's seventh book, "On Fire: The (Burning) Case for a Green New Deal", which was published on September 17, 2019. "On Fire" is a collection of essays focusing on climate change and the urgent actions needed to preserve the world. Klein relates her meeting with Greta Thunberg in the opening essay in which she discusses the entrance of young people into those speaking out for climate awareness and change. She supports the Green New Deal throughout the book and in the final essay she discusses the 2020 U.S. election stating: "The stakes of the election are almost unbearably high. It’s why I wrote the book and decided to put it out now and why I’ll be doing whatever I can to help push people toward supporting a candidate with the most ambitious Green New Deal platform—so that they win the primaries and then the general."

Klein has written about the Iraq War. In "Baghdad Year Zero" ("Harper's Magazine", September 2004), Klein argues that, contrary to popular belief, the George W. Bush administration "did" have a clear plan for post-invasion Iraq: to build a completely unconstrained free market economy. She describes plans to allow foreigners to extract wealth from Iraq and the methods used to achieve those goals. Her "Baghdad Year Zero" was one of the inspirations for the 2008 film "War, Inc."

Klein's "Bring Najaf to New York" ("The Nation", August 2004) argued that Muqtada Al Sadr's Mahdi Army "represents the overwhelmingly mainstream sentiment in Iraq" and that, if he were elected, "Sadr would try to turn Iraq into a theocracy like Iran," although his immediate demands were for "direct elections and an end to foreign occupation". Marc Cooper, a former "Nation" columnist, attacked the assertion that Al Sadr represented mainstream Iraqi sentiment and that American forces had brought the war to the holy city of Najaf. "Klein should know better," he wrote. "All enemies of the U.S. occupation she opposes are not her friends. Or ours. Or those of the Iraqi people. I don’t think that Mullah Al Sadr, in any case, is much desirous of support issuing from secular Jewish feminist-socialists."

Klein signed a 2004 petition entitled "We would vote for Hugo Chávez". In 2007, she described Venezuela under the Chávez government as a country where "citizens had renewed their faith in the power of democracy to improve their lives," and described Venezuela as a place sheltered by Chávez's policies from the economic shocks produced by capitalism. Rather, according to Klein, Chávez protected his country from financial crisis by building “a zone of relative economic calm and predictability.” According to reviewer Todd Gitlin, who described the overall argument of Klein's book "The Shock Doctrine" (2007) as "more right than wrong," Klein is "a romantic," who expected that the Chávez government would produce a bright future in which worker-controlled co-operatives would run the economy. "The Shock Doctrine" was consistent with her prior thinking about globalization, and in that book she describes Chávez' policies as an example of public control of some sectors of the economy as protecting poor people from harm caused by globalization. After the collapse of the Venezuelan economy and alleged erosion of its democratic institutions under Chávez' successor Nicolás Maduro, Klein and other people who had supported Chávez were criticized by writers such as James Kirchick and Mark Milke.

In March 2008, Klein was the keynote speaker at the first national conference of the Alliance of Concerned Jewish Canadians. In January 2009, during the Gaza War, Klein supported the Boycott, Divestment and Sanctions (BDS) campaign against Israel, arguing that "the best strategy to end the increasingly bloody occupation is for Israel to become the target of the kind of global movement that put an end to apartheid in South Africa."

In summer 2009, on the occasion of the publication of the Hebrew translation of her book "The Shock Doctrine", Klein visited Israel, the West Bank, and Gaza, combining the promotion of her book and the BDS campaign. In an interview to the Israeli newspaper "Haaretz" she emphasized that it is important to her "not to boycott Israelis but rather to boycott the normalization of Israel and the conflict." In a speech in Ramallah on June 27, she apologized to the Palestinians for not joining the BDS campaign earlier. Her remarks, particularly that "[Some Jews] even think we get one get-away-with-genocide-free card" were characterized by Noam Schimmel, an op-ed columnist in "The Jerusalem Post", as "violent" and "unethical", and as the "most perverse of aspersions on Jews, an age-old stereotype of Jews as intrinsically evil and malicious."

Klein was also a spokesperson for the protest against the spotlight on Tel Aviv at the 2009 Toronto International Film Festival, a spotlight that Klein said was a very selective and misleading portrait of Israel.

Since 2009, Klein's attention has turned to environmentalism, with particular focus on climate change, the subject of her book "This Changes Everything" (2014). According to her website, the book and its accompanying film (released in 2015) will be about "how the climate crisis can spur economic and political transformation." She sits on the board of directors of campaign group 350.org and took part in their "Do the Math" tour in 2013, encouraging a divestment movement.

She has encouraged the Occupy movement to join forces with the environmental movement, saying the financial crisis and the climate crisis have the same root—unrestrained corporate greed. She gave a speech at Occupy Wall Street where she described the world as "upside down", where we act as if "there is no end to what is actually finite—fossil fuels and the atmospheric space to absorb their emissions," and as if there are "limits to what is actually bountiful—the financial resources to build the kind of society we need."

She has been a particularly vocal critic of the Athabasca oil sands in Alberta, describing it in a TED talk as a form of "terrestrial skinning." On September 2, 2011, she attended the demonstration against the Keystone XL pipeline outside the White House and was arrested. Klein celebrated Obama's decision to postpone a decision on the Keystone pipeline until 2013 pending an environmental review as a victory for the environmental movement.

She attended the Copenhagen Climate Summit of 2009. She put the blame for the failure of Copenhagen on President Barack Obama, and described her own country, Canada, as a "climate criminal." She presented the Angry Mermaid Award (a satirical award designed to recognise the corporations who have best sabotaged the climate negotiations) to Monsanto.

Writing in the wake of Hurricane Sandy, she warned that the climate crisis constitutes a massive opportunity for disaster capitalists and corporations seeking to profit from crisis. But equally, the climate crisis "can be a historic moment to usher in the next great wave of progressive change," or a so-called "People's Shock."

On November 9, 2016, following the election of Donald Trump as the 45th President of the United States, Klein called for an international campaign to impose economic sanctions on the United States if his administration refuses to abide by the terms of the Paris Agreement.

Klein contributes to "The Nation", "In These Times", "The Globe and Mail", "This Magazine", "Harper's Magazine", and "The Guardian", and is a senior contributor for "The Intercept". She is a former Miliband Fellow and lectured at the London School of Economics on the anti-globalization movement. Her appointment as the inaugural Gloria Steinem Endowed Chair in Media, Culture and Feminist Studies at Rutgers University–New Brunswick began in October 2018 and runs for 3 years. The position is funded by foundations, endowments and individuals.

Klein ranked 11th in an internet poll of the top global intellectuals of 2005, a list of the world's top 100 public intellectuals compiled by the "Prospect" magazine in conjunction with "Foreign Policy" magazine. She was involved in 2010 G-20 Toronto summit protests, condemning police force and brutality. She spoke to a rally seeking the release of protesters in front of police headquarters on June 28, 2010.

On October 6, 2011, she visited Occupy Wall Street and gave a speech declaring the protest movement "the most important thing in the world". On November 10, 2011, she participated in a panel discussion about the future of Occupy Wall Street with four other panelists, including Michael Moore, William Greider, and Rinku Sen, in which she stressed the crucial nature of the evolving movement.
Klein also made an appearance in the British radio show "Desert Island Discs" on BBC Radio 4 in 2017. In November 2017, the Democracy in Europe Movement 2025 announced that Klein had been appointed to their Advisory Panel.

In November 2019, along with other public figures, Klein signed a letter supporting Labour Party leader Jeremy Corbyn describing him as "a beacon of hope in the struggle against emergent far-right nationalism, xenophobia and racism in much of the democratic world" and endorsed him in the 2019 UK general election.








</doc>
<doc id="22071" url="https://en.wikipedia.org/wiki?curid=22071" title="Nonsteroidal anti-inflammatory drug">
Nonsteroidal anti-inflammatory drug

Nonsteroidal anti-inflammatory drugs (NSAIDs) are members of a drug class that reduces pain, decreases fever, prevents blood clots, and in higher doses, decreases inflammation. Side effects depend on the specific drug but largely include an increased risk of gastrointestinal ulcers and bleeds, heart attack, and kidney disease.

The term "nonsteroidal" distinguishes these drugs from steroids, which while having a similar eicosanoid-depressing, anti-inflammatory action, have a broad range of other effects. First used in 1960, the term served to distance these medications from steroids, which were particularly stigmatised at the time due to the connotations with anabolic steroid abuse.

NSAIDs work by inhibiting the activity of cyclooxygenase enzymes (COX-1 or COX-2). In cells, these enzymes are involved in the synthesis of key biological mediators, namely prostaglandins, which are involved in inflammation, and thromboxanes, which are involved in blood clotting.

There are two types of NSAIDs available: non-selective and COX-2 selective. Most NSAIDs are non-selective and inhibit the activity of both COX-1 and COX-2. These NSAIDs, while reducing inflammation, also inhibit platelet aggregation (especially aspirin) and increase the risk of gastrointestinal ulcers/bleeds. COX-2 selective inhibitors have less gastrointestinal side effects but promote thrombosis and substantially increase the risk of heart attack. As a result, COX-2 selective inhibitors are generally contraindicated due to the high risk of undiagnosed vascular disease. These differential effects are due to the different roles and tissue localisations of each COX isoenzyme. By inhibiting physiological COX activity, all NSAIDs increase the risk of kidney disease and through a related mechanism, heart attack.
In addition, NSAIDs can blunt the production of erythropoietin resulting in anaemia, since haemoglobin needs this hormone to be produced. Prolonged use is dangerous and case studies have shown the health risk with celecoxib.

The most prominent NSAIDs are aspirin, ibuprofen, and naproxen, all available over the counter (OTC) in most countries. Paracetamol (acetaminophen) is generally not considered an NSAID because it has only minor anti-inflammatory activity. Acetaminophen treats pain mainly by blocking COX-2 and inhibiting endocannabinoid reuptake almost exclusively within the brain, but not much in the rest of the body.

NSAIDs are usually used for the treatment of acute or chronic conditions where pain and inflammation are present.

NSAIDs are generally used for the symptomatic relief of the following conditions:

Aspirin, the only NSAID able to irreversibly inhibit COX-1, is also indicated for antithrombosis through inhibition of platelet aggregation. This is useful for the management of arterial thrombosis and prevention of adverse cardiovascular events like heart attacks. Aspirin inhibits platelet aggregation by inhibiting the action of thromboxane A.

In a more specific application, the reduction in prostaglandins is used to close a patent ductus arteriosus in neonates if it has not done so physiologically after 24 hours.

NSAIDs are useful in the management of post-operative dental pain following invasive dental procedures such as dental extraction. When not contra-indicated they are favoured over the use of paracetamol alone due to the anti-inflammatory effect they provide. When used in combination with paracetamol the analgesic effect has been proven to be improved. There is weak evidence suggesting that taking pre-operative analgesia can reduce the length of post operative pain associated with placing orthodontic spacers under local anaesthetic. Combination of NSAIDs with pregabalin as preemptive analgesia has shown promising results for decreasing post operative pain intensity.

The effectiveness of NSAIDs for treating non-cancer chronic pain and cancer-related pain in children and adolescents is not clear. There have not been sufficient numbers of high-quality randomized controlled trials conducted.

Differences in anti-inflammatory activity between NSAIDs are small, but there is considerable variation in individual response and tolerance to these drugs. About 60% of patients will respond to any NSAID; of the others, those who do not respond to one may well respond to another. Pain relief starts soon after taking the first dose and a full analgesic effect should normally be obtained within a week, whereas an anti-inflammatory effect may not be achieved (or may not be clinically assessable) for up to 3 weeks. If appropriate responses are not obtained within these times, another NSAID should be tried.

NSAIDs may be used with caution by people with the following conditions:

NSAIDs should usually be avoided by people with the following conditions:

The widespread use of NSAIDs has meant that the adverse effects of these drugs have become increasingly common. Use of NSAIDs increases risk of a range of gastrointestinal (GI) problems, kidney disease and adverse cardiovascular events. As commonly used for post-operative pain, there is evidence of increased risk of kidney complications. Their use following gastrointestinal surgery remains controversial, given mixed evidence of increased risk of leakage from any bowel anastomosis created.

An estimated 10–20% of people taking NSAIDs experience indigestion. In the 1990s high doses of prescription NSAIDs were associated with serious upper gastrointestinal adverse events, including bleeding. Over the past decade, deaths associated with gastric bleeding have declined.

NSAIDs, like all medications, may interact with other medications. For example, concurrent use of NSAIDs and quinolone antibiotics may increase the risk of quinolones' adverse central nervous system effects, including seizure.

There is an argument over the benefits and risks of NSAIDs for treating chronic musculoskeletal pain. Each drug has a benefit-risk profile and balancing the risk of no treatment with the competing potential risks of various therapies is the clinician's responsibility.

If a COX-2 inhibitor is taken, a traditional NSAID (prescription or over-the-counter) should not be taken at the same time. In addition, people on daily aspirin therapy (e.g., for reducing cardiovascular risk) must be careful if they also use other NSAIDs, as these may inhibit the cardioprotective effects of aspirin.

Rofecoxib (Vioxx) was shown to produce significantly fewer gastrointestinal adverse drug reactions (ADRs) compared with naproxen. The study, the VIGOR trial, raised the issue of the cardiovascular safety of the coxibs. A statistically significant increase in the incidence of myocardial infarctions was observed in patients on rofecoxib. Further data, from the APPROVe trial, showed a statistically significant relative risk of cardiovascular events of 1.97 versus placebo—which caused a worldwide withdrawal of rofecoxib in October 2004.

Use of methotrexate together with NSAIDs in rheumatoid arthritis is safe, if adequate monitoring is done.

NSAIDs, aside from aspirin, increase the risk of myocardial infarction and stroke. This occurs at least within a week of use. They are not recommended in those who have had a previous heart attack as they increase the risk of death or recurrent MI. Evidence indicates that naproxen may be the least harmful out of these.

NSAIDs aside from (low-dose) aspirin are associated with a doubled risk of heart failure in people without a history of cardiac disease. In people with such a history, use of NSAIDs (aside from low-dose aspirin) was associated with a more than 10-fold increase in heart failure. If this link is proven causal, researchers estimate that NSAIDs would be responsible for up to 20 percent of hospital admissions for congestive heart failure. In people with heart failure, NSAIDs increase mortality risk (hazard ratio) by approximately 1.2–1.3 for naproxen and ibuprofen, 1.7 for rofecoxib and celecoxib, and 2.1 for diclofenac.

On 9 July 2015, the Food and Drug Administration (FDA) toughened warnings of increased heart attack and stroke risk associated with nonsteroidal anti-inflammatory drugs (NSAIDs) "other than aspirin".

A 2005 Finnish study linked long term (over 3 months) use of NSAIDs with an increased risk of erectile dysfunction. The study was correlational only, and depended solely on self-reports (questionnaires).

A 2011 publication in "The Journal of Urology" received widespread publicity. According to the study, men who used NSAIDs regularly were at significantly increased risk of erectile dysfunction. A link between NSAID use and erectile dysfunction still existed after controlling for several conditions. However, the study was observational and not controlled, with low original participation rate, potential participation bias, and other uncontrolled factors. The authors warned against drawing any conclusion regarding cause.

The main adverse drug reactions (ADRs) associated with NSAID use relate to direct and indirect irritation of the gastrointestinal (GI) tract. NSAIDs cause a dual assault on the GI tract: the acidic molecules directly irritate the gastric mucosa, and inhibition of COX-1 and COX-2 reduces the levels of protective prostaglandins. Inhibition of prostaglandin synthesis in the GI tract causes increased gastric acid secretion, diminished bicarbonate secretion, diminished mucus secretion and diminished trophic effects on the epithelial mucosa.

Common gastrointestinal side effects include:

Clinical NSAID ulcers are related to the systemic effects of NSAID administration. Such damage occurs irrespective of the route of administration of the NSAID (e.g., oral, rectal, or parenteral) and can occur even in people who have achlorhydria.

Ulceration risk increases with therapy duration, and with higher doses. To minimize GI side effects, it is prudent to use the lowest effective dose for the shortest period of time—a practice that studies show is often not followed. Over 50% of patients who take NSAIDs have sustained some mucosal damage to their small intestine.

The risk and rate of gastric adverse effects is different depending on the type of NSAID medication a person is taking. Indomethacin, ketoprofen, and piroxicam use appear to lead to the highest rate of gastric adverse effects, while ibuprofen (lower doses) and diclofenac appear to have lower rates.

Certain NSAIDs, such as aspirin, have been marketed in enteric-coated formulations that manufacturers claim reduce the incidence of gastrointestinal ADRs. Similarly, some believe that rectal formulations may reduce gastrointestinal ADRs. However, consistent with the systemic mechanism of such ADRs, and in clinical practice, these formulations have not demonstrated a reduced risk of GI ulceration.

Numerous "gastro-protective" drugs have been developed with the goal of preventing gastrointestinal toxicity in people who need to take NSAIDs on a regular basis. Gastric adverse effects may be reduced by taking medications that suppress acid production such as proton pump inhibitors (e.g.: omeprazole and esomeprazole), or by treatment with a drug that mimics prostaglandin in order to restore the lining of the GI tract (e.g.: a prostaglandin analog misoprostol). Diarrhea is a common side effect of misoprostol, however, higher doses of misoprostol have been shown to reduce the risk of a person having a complication related to a gastric ulcer while taking NSAIDs. While these techniques may be effective, they are expensive for maintenance therapy.

Hydrogen sulfide NSAID hybrids prevent the gastric ulceration/bleeding associated with taking the NSAIDs alone. Hydrogen sulphide is known to have a protective effect on the cardiovascular and gastrointestinal system.

NSAIDs should be used with caution in individuals with inflammatory bowel disease (e.g., Crohn's disease or ulcerative colitis) due to their tendency to cause gastric bleeding and form ulceration in the gastric lining.

NSAIDs are also associated with a fairly high incidence of adverse drug reactions (ADRs) on the kidney and over time can lead to chronic kidney disease. The mechanism of these kidney ADRs is due to changes in kidney blood flow. Prostaglandins normally dilate the afferent arterioles of the glomeruli. This helps maintain normal glomerular perfusion and glomerular filtration rate (GFR), an indicator of kidney function. This is particularly important in kidney failure where the kidney is trying to maintain renal perfusion pressure by elevated angiotensin II levels. At these elevated levels, angiotensin II also constricts the afferent arteriole into the glomerulus in addition to the efferent arteriole it normally constricts. Since NSAIDs block this prostaglandin-mediated effect of afferent arteriole dilation, particularly in kidney failure, NSAIDs cause unopposed constriction of the afferent arteriole and decreased RPF (renal perfusion flow) and GFR.

Common ADRs associated with altered kidney function include:

These agents may also cause kidney impairment, especially in combination with other nephrotoxic agents. Kidney failure is especially a risk if the patient is also concomitantly taking an ACE inhibitor (which removes angiotensin II's vasoconstriction of the efferent arteriole) and a diuretic (which drops plasma volume, and thereby RPF)—the so-called "triple whammy" effect.

In rarer instances NSAIDs may also cause more severe kidney conditions:

NSAIDs in combination with excessive use of phenacetin or paracetamol (acetaminophen) may lead to analgesic nephropathy.

Photosensitivity is a commonly overlooked adverse effect of many of the NSAIDs. The 2-arylpropionic acids are the most likely to produce photosensitivity reactions, but other NSAIDs have also been implicated including piroxicam, diclofenac, and benzydamine.

Benoxaprofen, since withdrawn due to its liver toxicity, was the most photoactive NSAID observed. The mechanism of photosensitivity, responsible for the high photoactivity of the 2-arylpropionic acids, is the ready decarboxylation of the carboxylic acid moiety. The specific absorbance characteristics of the different chromophoric 2-aryl substituents, affects the decarboxylation mechanism.

NSAIDs are not recommended during pregnancy, particularly during the third trimester. While NSAIDs as a class are not direct teratogens, they may cause premature closure of the fetal ductus arteriosus and kidney ADRs in the fetus. Additionally, they are linked with premature birth and miscarriage. Aspirin, however, is used together with heparin in pregnant women with antiphospholipid syndrome. Additionally, indomethacin is used in pregnancy to treat polyhydramnios by reducing fetal urine production via inhibiting fetal kidney blood flow.

In contrast, paracetamol (acetaminophen) is regarded as being safe and well tolerated during pregnancy, but Leffers et al. released a study in 2010 indicating that there may be associated male infertility in the unborn. Doses should be taken as prescribed, due to risk of liver toxicity with overdoses.

In France, the country's health agency contraindicates the use of NSAIDs, including aspirin, after the sixth month of pregnancy.

A variety of allergic or allergic-like NSAID hypersensitivity reactions follow the ingestion of NSAIDs. These hypersensitivity reactions differ from the other adverse reactions listed here which are toxicity reactions, i.e. unwanted reactions that result from the pharmacological action of a drug, are dose-related, and can occur in any treated individual; hypersensitivity reactions are idiosyncratic reactions to a drug. Some NSAID hypersensitivity reactions are truly allergic in origin: 1) repetitive IgE-mediated urticarial skin eruptions, angioedema, and anaphylaxis following immediately to hours after ingesting one structural type of NSAID but not after ingesting structurally unrelated NSAIDs; and 2) Comparatively mild to moderately severe T cell-mediated delayed onset (usually more than 24 hour), skin reactions such as maculopapular rash, fixed drug eruptions, photosensitivity reactions, delayed urticaria, and contact dermatitis; or 3) far more severe and potentially life-threatening t-cell-mediated delayed systemic reactions such as the DRESS syndrome, acute generalized exanthematous pustulosis, the Stevens–Johnson syndrome, and toxic epidermal necrolysis. Other NSAID hypersensitivity reactions are allergy-like symptoms but do not involve true allergic mechanisms; rather, they appear due to the ability of NSAIDs to alter the metabolism of arachidonic acid in favor of forming metabolites that promote allergic symptoms. Afflicted individuals may be abnormally sensitive to these provocative metabolites or overproduce them and typically are susceptible to a wide range of structurally dissimilar NSAIDs, particularly those that inhibit COX1. Symptoms, which develop immediately to hours after ingesting any of various NSAIDs that inhibit COX-1, are: 1) exacerbations of asthmatic and rhinitis (see aspirin-induced asthma) symptoms in individuals with a history of asthma or rhinitis and 2) exacerbation or first-time development of wheals or angioedema in individuals with or without a history of chronic urticarial lesions or angioedema.

It has been hypothesized that NSAIDs may delay healing from bone and soft-tissue injuries by inhibiting inflammation. On the other hand, it has also been hypothesized that NSAIDs might speed recovery from soft tissue injuries by preventing inflammatory processes from damaging adjacent, non-injured muscles.

There is moderate evidence that they delay bone healing. Their overall effect on soft-tissue healing is unclear.

The use of NSAIDs for analgesia following gastrointestinal surgery remains controversial, given mixed evidence of an increased risk of leakage from any bowel anastomosis created. This risk may vary according to the class of NSAID prescribed.

Common adverse drug reactions (ADR), other than listed above, include: raised liver enzymes, headache, dizziness. Uncommon ADRs include an abnormally high level of potassium in the blood, confusion, spasm of the airways, and rash. Ibuprofen may also rarely cause irritable bowel syndrome symptoms. NSAIDs are also implicated in some cases of Stevens–Johnson syndrome.

Most NSAIDs penetrate poorly into the central nervous system (CNS). However, the COX enzymes are expressed constitutively in some areas of the CNS, meaning that even limited penetration may cause adverse effects such as somnolence and dizziness.

NSAIDs may increase the risk of bleeding in patients with Dengue fever For this reason, NSAIDs are only available with a prescription in India.

In very rare cases, ibuprofen can cause aseptic meningitis.

As with other drugs, allergies to NSAIDs might exist. While many allergies are specific to one NSAID, up to 1 in 5 people may have unpredictable cross-reactive allergic responses to other NSAIDs as well.

NSAIDs reduce kidney blood flow and thereby decrease the efficacy of diuretics, and inhibit the elimination of lithium and methotrexate.

NSAIDs cause decreased ability to form blood clots, which can increase the risk of bleeding when combined with other drugs that also decrease blood clotting, such as warfarin.

NSAIDs may aggravate hypertension (high blood pressure) and thereby antagonize the effect of antihypertensives, such as ACE inhibitors.

NSAIDs may interfere and reduce efficiency of SSRI antidepressants. NSAIDs, when used in combination with SSRIs, increases the risk of adverse gastrointestinal effects. NSAIDs, when used in combination with SSRIs, increases the risk of internal bleeding and brain hemorrhages.

Various widely used nonsteroidal anti-inflammatory drugs (NSAIDs) enhance endocannabinoid signaling by blocking the anandamide-degrading membrane enzyme fatty acid amide hydrolase (FAAH).

NSAIDs may reduce the effectiveness of antibiotics. Tests on cultured bacteria found that antibiotic effectiveness was reduced by 18-30% on average compared to tests which did not include NSAIDs.

Although small doses generally have little to no effect on the immune system, large doses of NSAIDs significantly suppress the production of immune cells. As NSAIDs affect prostaglandins, they affect the production of most fast growing cells. This includes immune cells. Unlike corticosteroids, they do not directly suppress the immune system and so their effect on the immune system is not immediately obvious. They suppress the production of new immune cells, but leave existing immune cells functional. Large doses slowly reduce the immune response as the immune cells are renewed at a much lower rate. Causing a gradual reduction of the immune system, much slower and less noticeable than the immediate effect of Corticosteroids. The effect significantly increases with dosage, in a nearly exponential rate. Doubling of dose reduced cells by nearly four times. Increasing dose by five times reduced cell counts to only a few percent of normal levels. This is likely why the effect was not immediately obvious in low dose trials, as the effect is not apparent until much higher dosages are tested.

Most NSAIDs act as nonselective inhibitors of the cyclooxygenase (COX) enzymes, inhibiting both the cyclooxygenase-1 (COX-1) and cyclooxygenase-2 (COX-2) isoenzymes. This inhibition is competitively reversible (albeit at varying degrees of reversibility), as opposed to the mechanism of aspirin, which is irreversible inhibition. COX catalyzes the formation of prostaglandins and thromboxane from arachidonic acid (itself derived from the cellular phospholipid bilayer by phospholipase A). Prostaglandins act (among other things) as messenger molecules in the process of inflammation. This mechanism of action was elucidated in 1970 by John Vane (1927–2004), who received a Nobel Prize for his work (see Mechanism of action of aspirin).

COX-1 is a constitutively expressed enzyme with a "house-keeping" role in regulating many normal physiological processes. One of these is in the stomach lining, where prostaglandins serve a protective role, preventing the stomach mucosa from being eroded by its own acid. COX-2 is an enzyme facultatively expressed in inflammation, and it is inhibition of COX-2 that produces the desirable effects of NSAIDs.

When nonselective COX-1/COX-2 inhibitors (such as aspirin, ibuprofen, and naproxen) lower stomach prostaglandin levels, ulcers of the stomach or duodenum and internal bleeding can result.

NSAIDs have been studied in various assays to understand how they affect each of these enzymes. While the assays reveal differences, unfortunately, different assays provide differing ratios.

The discovery of COX-2 led to research to the development of selective COX-2 inhibiting drugs that do not cause gastric problems characteristic of older NSAIDs.

Paracetamol (acetaminophen) is not considered an NSAID because it has little anti-inflammatory activity. It treats pain mainly by blocking COX-2 mostly in the central nervous system, but not much in the rest of the body.

However, many aspects of the mechanism of action of NSAIDs remain unexplained, and for this reason, further COX pathways are hypothesized. The COX-3 pathway was believed to fill some of this gap but recent findings make it appear unlikely that it plays any significant role in humans and alternative explanation models are proposed.

NSAIDs interact with the endocannabinoid system and its endocannabinoids, as COX2 have been shown to utilize endocannabinoids as substrates, and may have a key role in both the therapeutic effects and adverse effects of NSAIDs, as well as in NSAID-induced placebo responses.

NSAIDs are also used in the acute pain caused by gout because they inhibit urate crystal phagocytosis besides inhibition of prostaglandin synthase.

NSAIDs have antipyretic activity and can be used to treat fever. Fever is caused by elevated levels of prostaglandin E2, which alters the firing rate of neurons within the hypothalamus that control thermoregulation. Antipyretics work by inhibiting the enzyme COX, which causes the general inhibition of prostanoid biosynthesis (PGE2) within the hypothalamus. PGE2 signals to the hypothalamus to increase the body's thermal setpoint. Ibuprofen has been shown more effective as an antipyretic than paracetamol (acetaminophen).
Arachidonic acid is the precursor substrate for cyclooxygenase leading to the production of prostaglandins F, D, and E.

NSAIDs can be classified based on their chemical structure or mechanism of action. Older NSAIDs were known long before their mechanism of action was elucidated and were for this reason classified by chemical structure or origin. Newer substances are more often classified by mechanism of action.

The following NSAIDs are derived from fenamic acid. which is a derivative of anthranilic acid, which in turn is a nitrogen isostere of salicylic acid, which is the active metabolite of aspirin.



Most NSAIDs are chiral molecules; diclofenac is a notable exception. However, the majority are prepared as racemic mixtures. Typically, only a single enantiomer is pharmacologically active. For some drugs (typically profens), an isomerase enzyme "in vivo" converts the inactive enantiomer into the active form, although its activity varies widely in individuals. This phenomenon is likely responsible for the poor correlation between NSAID efficacy and plasma concentration observed in older studies when specific analysis of the active enantiomer was not performed.

Ibuprofen and ketoprofen are now available in single-enantiomer preparations (dexibuprofen and dexketoprofen), which purport to offer quicker onset and an improved side-effect profile. Naproxen has always been marketed as the single active enantiomer.

NSAIDs within a group tend to have similar characteristics and tolerability. There is little difference in clinical efficacy among the NSAIDs when used at equivalent doses. Rather, differences among compounds usually relate to dosing regimens (related to the compound's elimination half-life), route of administration, and tolerability profile.

Regarding adverse effects, selective COX-2 inhibitors have lower risk of gastrointestinal bleeding. With the exception of naproxen, nonselective NSAIDs increase the risk of having a heart attack. Some data also supports that the partially selective nabumetone is less likely to cause gastrointestinal events.

A consumer report noted that ibuprofen, naproxen, and salsalate are less expensive than other NSAIDs, and essentially as effective and safe when used appropriately to treat osteoarthritis and pain.

Most nonsteroidal anti-inflammatory drugs are weak acids, with a pKa of 3–5. They are absorbed well from the stomach and intestinal mucosa. They are highly protein-bound in plasma (typically >95%), usually to albumin, so that their volume of distribution typically approximates to plasma volume. Most NSAIDs are metabolized in the liver by oxidation and conjugation to inactive metabolites that typically are excreted in the urine, though some drugs are partially excreted in bile. Metabolism may be abnormal in certain disease states, and accumulation may occur even with normal dosage.

Ibuprofen and diclofenac have short half-lives (2–3 hours). Some NSAIDs (typically oxicams) have very long half-lives (e.g. 20–60 hours).

From the era of Greek medicine to the mid-19th century, the discovery of medicinal agents was classed as an empirical art; folklore and mythological guidance were combined in deploying the vegetable and mineral products that made up the expansive pharmacopeia of the time. Myrtle leaves were in use by 1500 BCE. Hippocrates (460–377 BCE) first reported using willow bark and in 30 BCE Celsus described the signs of inflammation and also used willow bark to mitigate them. On 25 April 1763, Edward Stone wrote to the Royal Society describing his observations on the use of willow bark-based medicines in febrile patients. The active ingredient of willow bark, a glycoside called salicin, was first isolated by Johann Andreas Buchner in 1827. By 1829, French chemist Henri Leroux had improved the extraction process to obtain about 30g of purified salicin from 1.5kg of bark.

By hydrolysis, salicin releases glucose and salicyl alcohol which can be converted into salicylic acid, both in vivo and through chemical methods. The acid is more effective than salicin and, in addition to its fever-reducing properties, is anti-inflammatory and analgesic. In 1869, Hermann Kolbe synthesised salicylate, although it was too acidic for the gastric mucosa. The reaction used to synthesise aromatic acid from a phenol in the presence of CO2 is known as the Kolbe-Schmitt reaction.
By 1897 the German chemist Felix Hoffmann and the Bayer company prompted a new age of pharmacology by converting salicylic acid into acetylsalicylic acid—named aspirin by Heinrich Dreser. Other NSAIDs like ibuprofen were developed from the 1950s forward.
In 2001, NSAIDs accounted for 70,000,000 prescriptions and 30billion over-the-counter doses sold annually in the United States.

While studies have been conducted to see if various NSAIDs can improve behavior in transgenic mouse models of Alzheimer's disease and observational studies in humans have shown promise, there is no good evidence from randomized clinical trials that NSAIDs can treat or prevent Alzheimer's in humans; clinical trials of NSAIDs for treatment of Alzheimer's have found more harm than benefit. NSAIDs coordinate with metal ions affecting cellular function.

Research supports the use of NSAIDs for the control of pain associated with veterinary procedures such as dehorning and castration of calves. The best effect is obtained by combining a short-term local anesthetic such as lidocaine with an NSAID acting as a longer term analgesic. However, as different species have varying reactions to different medications in the NSAID family, little of the existing research data can be extrapolated to animal species other than those specifically studied, and the relevant government agency in one area sometimes prohibits uses approved in other jurisdictions.

For example, ketoprofen's effects have been studied in horses more than in ruminants but, due to controversy over its use in racehorses, veterinarians who treat livestock in the United States more commonly prescribe flunixin meglumine, which, while labeled for use in such animals, is not indicated for post-operative pain.

In the United States, meloxicam is approved for use only in canines, whereas (due to concerns about liver damage) it carries warnings against its use in cats except for one-time use during surgery. In spite of these warnings, meloxicam is frequently prescribed "off-label" for non-canine animals including cats and livestock species. In other countries, for example The European Union (EU), there is a label claim for use in cats.



</doc>
<doc id="22073" url="https://en.wikipedia.org/wiki?curid=22073" title="NC (complexity)">
NC (complexity)

In computational complexity theory, the class NC (for "Nick's Class") is the set of decision problems decidable in polylogarithmic time on a parallel computer with a polynomial number of processors. In other words, a problem is in NC if there exist constants "c" and "k" such that it can be solved in time using parallel processors. Stephen Cook coined the name "Nick's class" after Nick Pippenger, who had done extensive research on circuits with polylogarithmic depth and polynomial size.

Just as the class P can be thought of as the tractable problems (Cobham's thesis), so NC can be thought of as the problems that can be efficiently solved on a parallel computer. NC is a subset of P because polylogarithmic parallel computations can be simulated by polynomial-time sequential ones. It is unknown whether NC = P, but most researchers suspect this to be false, meaning that there are probably some tractable problems that are "inherently sequential" and cannot significantly be sped up by using parallelism. Just as the class NP-complete can be thought of as "probably intractable", so the class P-complete, when using NC reductions, can be thought of as "probably not parallelizable" or "probably inherently sequential".

The parallel computer in the definition can be assumed to be a "parallel, random-access machine" (PRAM). That is a parallel computer with a central pool of memory, and any processor can access any bit of memory in constant time. The definition of NC is not affected by the choice of how the PRAM handles simultaneous access to a single bit by more than one processor. It can be CRCW, CREW, or EREW. See PRAM for descriptions of those models.

Equivalently, NC can be defined as those decision problems decidable by a uniform Boolean circuit (which can be calculated from the length of the input, for NC, we suppose we can compute the Boolean circuit of size "n" in logarithmic space in "n") with polylogarithmic depth and a polynomial number of gates.

RNC is a class extending NC with access to randomness.

As with P, by a slight abuse of language, one might classify function problems and search problems as being in NC. NC is known to include many problems, including

Often algorithms for those problems had to be separately invented and could not be naïvely adapted from well-known algorithms – Gaussian elimination and Euclidean algorithm rely on operations performed in sequence. One might contrast ripple carry adder with a carry-lookahead adder.

NC is the class of decision problems decidable by uniform boolean circuits with a polynomial number of gates of at most two inputs and depth , or the class of decision problems solvable in time "O"(log "n") on a parallel computer with a polynomial number of processors. Clearly, we have

which forms the NC-hierarchy.

We can relate the NC classes to the space classes L and NL and AC.

The NC classes are related to the AC classes, which are defined similarly, but with gates having unbounded fan-in. For each "i", we have

As an immediate consequence of this, we have that NC = AC.
It is known that both inclusions are strict for "i" = 0.

Similarly, we have that NC is equivalent to the problems solvable on an alternating Turing machine restricted to at most two options at each step with "O"(log "n") space and formula_4 alternations.

One major open question in complexity theory is whether or not every containment in the NC hierarchy is proper. It was observed by Papadimitriou that, if NC = NC for some "i", then NC = NC for all "j" ≥ "i", and as a result, NC = NC. This observation is known as NC-hierarchy collapse because even a single equality in the chain of containments
implies that the entire NC hierarchy "collapses" down to some level "i". Thus, there are 2 possibilities:


It is widely believed that (1) is the case, although no proof as to the truth of either statement has yet been discovered.

A branching program with "n" variables of width "k" and length "m" consists of a sequence of "m" instructions. Each of the instructions is a tuple ("i", "p", "q") where "i" is the index of variable to check (1 ≤ "i" ≤ "n"), and "p" and "q" are functions from {1, 2, ..., "k"} to {1, 2, ..., "k"}. Numbers 1, 2, ..., "k" are called states of the branching program. The program initially starts in state 1, and each instruction ("i", "p", "q") changes the state from "x" to "p"("x") or "q"("x"), depending on whether the "i"th variable is 0 or 1.

A family of branching programs consists of a branching program with "n" variables for each "n".

It is easy to show that every language "L" on {0,1} can be recognized by a family of branching programs of width 5 and exponential length, or by a family of exponential width and linear length.

Every regular language on {0,1} can be recognized by a family of branching programs of constant width and linear number of instructions (since a DFA can be converted to a branching program). BWBP denotes the class of languages recognizable by a family of branching programs of bounded width and polynomial length.

Barrington's theorem says that BWBP is exactly nonuniform NC. The proof uses the nonsolvability of the symmetric group S.

The theorem is rather surprising. For instance, it implies that the majority function can be computed by a family of branching programs of constant width and polynomial size, while intuition might suggest that to achieve polynomial size, one needs a linear number of states.

A branching program of constant width and polynomial size can be easily converted (via divide-and-conquer) to a circuit in NC.

Conversely, suppose a circuit in NC is given. Without loss of generality, assume it uses only AND and NOT gates.

Lemma 1: If there exists a branching program that sometimes works as a permutation "P" and sometimes as a permutation "Q", by right-multiplying permutations in the first instruction by α, and in the last instruction left-multiplying by β, we can make a circuit of the same length that behaves as β"P"α or β"Q"α, respectively.

Call a branching program α-computing a circuit "C" if it works as identity when C's output is 0, and as α when C's output is 1.

As a consequence of Lemma 1 and the fact that all cycles of length 5 are conjugate, for any two 5-cycles α, β, if there exists a branching program α-computing a circuit "C", then there exists a branching program β-computing the circuit "C", of the same length.

Lemma 2: There exist 5-cycles γ, δ such that their commutator ε=γδγδ is a 5-cycle. For example, γ = (1 2 3 4 5), δ = (1 3 5 4 2) giving ε = (1 3 2 5 4).

We will now prove Barrington's theorem by induction:

Suppose we have a circuit "C" which takes inputs "x"...,"x" and assume that for all subcircuits "D" of "C" and 5-cycles α, there exists a branching program α-computing "D". We will show that for all 5-cycles α, there exists a branching program α-computing "C".


By assuming the subcircuits have branching programs so that they are α-computing for all 5-cycles α∈"S", we have shown "C" also has this property, as required.

The size of the branching program is at most 4, where "d" is the depth of the circuit. If the circuit has logarithmic depth, the branching program has polynomial length.



</doc>
<doc id="22076" url="https://en.wikipedia.org/wiki?curid=22076" title="Nori">
Nori

The finished dried sheets are made by a shredding and rack-drying process that resembles papermaking. They are sold in packs in grocery stores for culinary purposes. Since "nori" sheets easily absorb water from the air and degrade, a desiccant is needed when storing "nori" for any significant time.

Originally, the term "nori" was generic and referred to seaweeds, including "hijiki". One of the oldest descriptions of nori is dated to around the 8th century. In the Taihō Code enacted in 701, "nori" was already included in the form of taxation. Local people have been described as drying nori in Hitachi Province fudoki (721–721), and harvesting of nori was mentioned in Izumo Province fudoki (713–733), showing that nori was used as food from ancient times. In "Utsubo Monogatari", written around 987, "nori" was recognized as a common food. Nori had been consumed as paste form until the sheet form was invented in Asakusa, Edo (contemporary Tokyo), around 1750 in the Edo period through the method of Japanese paper-making.

The word ""nori"" first appeared in an English-language publication in "C. P. Thunberg's Trav.", published in 1796. It was used in conjugation as ""Awa nori"", probably referring to what is now called aonori.

The Japanese nori industry was in decline after WWII, when Japan was in need of all food that could be produced. The decline was due to a lack of understanding of nori's three-stage life cycle, such that local people did not understand why traditional cultivation methods were not effective. The industry was rescued by knowledge deriving from the work of British phycologist Kathleen Mary Drew-Baker, who had been researching the organism "Porphyria umbilicalis", which grew in the seas around Wales and was harvested for food (bara lafwr or bara lawr), as in Japan. Her work was discovered by Japanese scientists who applied it to artificial methods of seeding and growing the nori, rescuing the industry. Kathleen Baker was hailed as the "Mother of the Sea" in Japan and a statue erected in her memory; she is still revered as the savior of the Japanese nori industry.

In the 21st century, the Japanese nori industry faces a new decline due to increased competition from seaweed producers in China and Korea and domestic sales tax hikes.

The word "nori" started to be used widely in the United States, and the product (imported in dry form from Japan) became widely available at natural food stores and Asian-American grocery stores in the 1960s due to the macrobiotic movement and in the 1970s with the increase of sushi bars and Japanese restaurants.

Production and processing of "nori" is an advanced form of agriculture. The biology of "Pyropia", although complicated, is well understood, and this knowledge is used to control the production process. Farming takes place in the sea where the "Pyropia" plants grow attached to nets suspended at the sea surface and where the farmers operate from boats. The plants grow rapidly, requiring about 45 days from "seeding" until the first harvest. Multiple harvests can be taken from a single seeding, typically at about ten-day intervals. Harvesting is accomplished using mechanical harvesters of a variety of configurations. Processing of raw product is mostly accomplished by highly automated machines that accurately duplicate traditional manual processing steps, but with much improved efficiency and consistency. The final product is a paper-thin, black, dried sheet of approximately and in weight.

Several grades of "nori" are available in the United States. The most common, and least expensive, grades are imported from China, costing about six cents per sheet. At the high end, ranging up to 90 cents per sheet, are "delicate "shin-nori"" ("nori" from the first of the year's several harvests) cultivated in Ariake Sea, off the island of Kyushu in Japan.

In Japan, over of coastal waters are given to producing of "nori", worth over a billion dollars. China produces about a third of this amount.

"Nori" is commonly used as a wrap for sushi and "onigiri". It is also a garnish or flavoring in noodle preparations and soups. It is most typically toasted prior to consumption ("yaki-nori"). A common secondary product is toasted and flavored "nori" ("ajitsuke-nori"), in which a flavoring mixture (variable, but typically soy sauce, sugar, sake, mirin, and seasonings) is applied in combination with the toasting process. It is also eaten by making it into a soy sauce-flavored paste, "nori no tsukudani" (). "Nori" is sometimes also used as a form of food decoration.

A related product, prepared from the unrelated green algae "Monostroma" and "Enteromorpha", is called "aonori" ( literally blue/green "nori") and is used like herbs on everyday meals, such as "okonomiyaki" and "yakisoba".

Raw seaweed is 85% water, 6% protein, 5% carbohydrates, and has negligible fat (table). In a 100 gram reference amount, seaweed is a rich source (20% or more of the Daily Value, DV) of vitamin A, vitamin C, riboflavin, and folate (table). Seaweed is a moderate source (less than 20% DV) of niacin, iron, and zinc. Seaweed has a high content of iodine, providing a substantial amount in just one gram. A 2014 study reported that dried purple laver ("nori") contains vitamin B12 in sufficient quantities to meet the RDA requirement (Vitamin B12 content: 77.6 μg /100 g dry weight). By contrast, a 2017 review concluded that vitamin B12 may be destroyed during metabolism or is converted into inactive B12 analogs during drying and storage. The Academy of Nutrition and Dietetics stated in 2016 that nori is not an adequate source of vitamin B12 for humans.

Nori contains toxic metals (arsenic and cadmium), whose levels are highly variable among nori products. It also contains amphipod allergens that can cause serious allergic reactions, especially in highly sensitized crustacean-allergic people. Therefore, daily consumption of high amounts of dried nori is discouraged.




</doc>
<doc id="22081" url="https://en.wikipedia.org/wiki?curid=22081" title="Normative ethics">
Normative ethics

Normative ethics is the study of ethical behaviour, and is the branch of philosophical ethics that investigates the questions that arise regarding how one ought to act, in a moral sense. 

Normative ethics is distinct from meta-ethics in that the former examines standards for the rightness and wrongness of actions, whereas the latter studies the meaning of moral language and the metaphysics of moral facts. Likewise, normative ethics is distinct from applied ethics in that the former is more concerned with 'who ought one be' rather than the ethics of a specific issue (e.g. if, or when, abortion is acceptable).

Normative ethics is also distinct from descriptive ethics, as the latter is an empirical investigation of people’s moral beliefs. In this context normative ethics is sometimes called "prescriptive", as opposed to "descriptive" ethics. However, on certain versions of the meta-ethical view of moral realism, moral facts are both descriptive and prescriptive at the same time.

Most traditional moral theories rest on principles that determine whether an action is right or wrong. Classical theories in this vein include utilitarianism, Kantianism, and some forms of contractarianism. These theories mainly offered the use of overarching moral principles to resolve difficult moral decisions.

There are disagreements about what precisely gives an action, rule, or disposition its ethical force. There are three competing views on how moral questions should be answered, along with hybrid positions that combine some elements of each: 


The former focuses on the character of those who are acting. In contrast, both deontological ethics and consequentialism focus on the status of the action, rule, or disposition itself, and come in various forms.

Virtue ethics, advocated by Aristotle with some aspects being supported by Saint Thomas Aquinas, focuses on the inherent character of a person rather than on specific actions. There has been a significant revival of virtue ethics in the past half-century, through the work of such philosophers as G. E. M. Anscombe, Philippa Foot, Alasdair Macintyre, Mortimer J. Adler, Jacques Maritain, Yves Simon, and Rosalind Hursthouse.

Deontology argues that decisions should be made considering the factors of one's duties and one's rights. Some deontological theories include:


Consequentialism argues that the morality of an action is contingent on the action's outcome or result. Consequentialist theories, varying in what they consider to be valuable (i.e., axiology), include:



It can be unclear what it means to say that a person "ought to do X because it is moral, whether they like it or not." Morality is sometimes presumed to have some kind of special binding force on behaviour, though some philosophers believe that, used this way, the word "ought" seems to wrongly attribute magic powers to morality. For instance, G. E. M. Anscombe worries that "ought" has become "a word of mere mesmeric force." 
British ethicist Philippa Foot elaborates that morality does not seem to have any special binding force, and she clarifies that people only behave morally when motivated by other factors. Foot says "People talk, for instance, about the 'binding force' of morality, but it is not clear what this means if not that we feel ourselves unable to escape." The idea is that, faced with an opportunity to steal a book because we can get away with it, moral obligation itself has no power to stop us unless we "feel" an obligation. Morality may therefore have no binding force beyond regular human motivations, and people must be motivated to behave morally. The question then arises: what role does reason play in motivating moral behaviour?
The categorical imperative perspective suggests that proper reason always leads to particular moral behaviour. As mentioned above, Foot instead believes that humans are actually motivated by desires. Proper reason, on this view, allows humans to discover actions that get them what they want (i.e., hypothetical imperatives)—not necessarily actions that are moral.

Social structure and motivation can make morality binding in a sense, but only because it makes moral norms feel inescapable, according to Foot.

John Stuart Mill adds that external pressures, to please others for instance, also influence this felt binding force, which he calls human "conscience." Mill says that humans must first reason about what is moral, then try to bring the feelings of our conscience in line with our reason. At the same time, Mill says that a good moral system (in his case, utilitarianism) ultimately appeals to aspects of human nature—which, must themselves be nurtured during upbringing. Mill explains:
This firm foundation is that of the social feelings of mankind; the desire to be in unity with our fellow creatures, which is already a powerful principle in human nature, and happily one of those which tend to become stronger, even without express inculcation, from the influences of advancing civilisation.
Mill thus believes that it is important to appreciate that it is feelings that drive moral behavior, but also that they may not be present in some people (e.g. psychopaths). Mill goes on to describe factors that help ensure people develop a conscience and behave morally.

Popular texts such as Joseph Daleiden's "The Science of Morality: The Individual, Community, and Future Generations" (1998) describe how societies can use science to figure out how to make people more likely to be good.



</doc>
<doc id="22083" url="https://en.wikipedia.org/wiki?curid=22083" title="Negotiation">
Negotiation

Negotiation is a dialogue between two or more people or parties intended to reach a beneficial outcome over one or more issues where a conflict exists with respect to at least one of these issues. Negotiation is an interaction and process between entities who compromise to agree on matters of mutual interest, while optimizing their individual utilities. This beneficial outcome can be for all of the parties involved, or just for one or some of them. Negotiators need to understand the negotiation process and other negotiators to increase their chances to close deals, avoid conflicts, establishing relationship with other parties and gain profit.

It is aimed to resolve points of difference, to gain advantage for an individual or collective, or to craft outcomes to satisfy various interests. It is often conducted by putting forward a position and making concessions to achieve an agreement. The degree to which the negotiating parties trust each other to implement the negotiated solution is a major factor in determining whether negotiations are successful.

People negotiate daily, often without considering it a negotiation. Negotiation occurs in organizations, including businesses, non-profits, and within and between governments as well as in sales and legal proceedings, and in personal situations such as marriage, divorce, parenting, etc. Professional negotiators are often specialized, such as union negotiators, leverage buyout negotiators, peace negotiator, or hostage negotiators. They may also work under other titles, such as diplomats, legislators, or brokers. There is also negotiation conducted by algorithms or machines known as autonomous negotiation. For automation, the negotiation participants and process have to be modeled correctly.

Negotiation can take a wide variety of forms, from a multilateral conference of all United Nations members to establish a new international norm (such as the UN Convention on the Law of the Sea) to a meeting of parties to a conflict to end violence or resolve the underlying issue (such as constitutional negotiations in South Africa in 1990-1994 or in Colombia with the FARC in 2012-2015) to a business encounter to make a deal to a face-off between parents (or between parent and child) over the child's proper behavior. Mediation is a form of negotiation with a third-party catalyst who helps the conflicting parties negotiate when they cannot do so by themselves. Negotiation can be contrasted with arbitration, where the decision lies with the third party, which the conflicting parties are committed to accept.

Negotiation theorists generally distinguish between two types of negotiation The difference in the usage of the two type depends on the mindset of the negotiator but also on the situation: one-off encounters where lasting relationships do not obtain are more likely to produce distributive negotiations whereas lasting relationships are more likely to require integrative negotiating Different theorists use different labels for the two general types and distinguish them in different ways.

Distributive negotiation is also sometimes called positional or hard-bargaining negotiation and attempts to distribute a "fixed pie" of benefits. Distributive negotiation operates under zero-sum conditions and implies that any gain one party makes is at the expense of the other and vice versa. For this reason, distributive negotiation is also sometimes called "win-lose" because of the assumption that one person's gain is another person's loss. Distributive negotiation examples include haggling prices on an open market, including the negotiation of the price of a car or a home.

In a distributive negotiation, each side often adopts an extreme or fixed position, knowing it will not be accepted—and then seeks to cede as little as possible before reaching a deal. Distributive bargainers conceive of negotiation as a process of distributing a fixed amount of value. A distributive negotiation often involves people who have never had a previous interactive relationship, nor are they likely to do so again in the near future, although all negotiations usually have a distributive element.

In the distributive approach each negotiator fights for the largest possible piece of the pie, so parties tend to regard each other more as an adversary than a partner and to take a harder line. Since Prospect Theory indicates that people value losses more than gains and are more risk-averse about losses, concession-convergence bargaining is likely to be more acrimonious and less productive of an agreement

Integrative negotiation is also called interest-based, merit-based, or principled negotiation. It is a set of techniques that attempts to improve the quality and likelihood of negotiated agreement by taking advantage of the fact that different parties often value various outcomes differently. While distributive negotiation assumes there is a fixed amount of value (a "fixed pie") to be divided between the parties, integrative negotiation attempts to create value in the course of the negotiation ("expand the pie") by either "compensating" loss of one item with gains from another ("trade-offs" or logrolling), or by constructing or reframing the issues of the conflict in such a way that both parties benefit ("win-win" negotiation).

However, even integrative negotiation is likely to have some distributive elements, especially when the different parties both value different items to the same degree or when details are left to be allocated at the end of the negotiation. While concession is mandatory for negotiations, research shows that people who concede more quickly, are less likely to explore all integrative and mutually beneficial solutions. Therefore, early conceding reduces the chance of an integrative negotiation.

Integrative negotiation often involves a higher degree of trust and the formation of a relationship. It can also involve creative problem-solving that aims to achieve mutual gains. It sees a good agreement as not one with maximum individual gain, but one that provides optimum gain for all parties. Gains in this scenario are not at the expense of the Other, but with it. Each seeks to accord the Other enough benefit that it will hold to the agreement that gives the first party an agreeable outcome, and vice versa.

Productive negotiation focuses on the underlying interests of the parties rather than their starting positions, approaches negotiation as a shared problem-solving rather than a personalized battle, and insists upon adherence to objective, principled criteria as the basis for agreement.

However, negotiators need not sacrifice effective negotiation in favor of a positive relationship between parties. Rather than conceding, each side can appreciate that the other has emotions and motivations of their own and use this to their advantage in discussing the issue. In fact, perspective-taking can help move parties toward a more integrative solution. Fisher et al. illustrate a few techniques that effectively improve perspective-taking in their book "Getting to Yes", and through the following, negotiators can separate people from the problem itself.


Additionally, negotiators can use certain communication techniques to build a stronger relationship and develop more meaningful negotiation solution.


"Integrated negotiation" is a strategic approach to influence that maximizes value in any single negotiation through the astute linking and sequencing of other negotiations and decisions related to one's operating activities.

This approach in complex settings is best executed by mapping out all potentially relevant negotiations, conflicts and operating decisions in order to integrate helpful connections among them, while minimizing any potentially harmful connections (see examples below).

"Integrated negotiation" is not to be confused with "integrative negotiation", a different concept (as outlined above) related to a non-zero-sum approach to creating value in negotiations.

Integrated negotiation was first identified and labeled by international negotiator and author Peter Johnston in his book "Negotiating with Giants".

One of the examples cited in Johnston's book is that of J. D. Rockefeller deciding where to build his first major oil refinery. Instead of taking the easier, cheaper route from the oil fields to refine his petroleum in Pittsburgh, Rockefeller chose to build his refinery in Cleveland. Why? Because rail companies would be transporting his refined oil to market. Pittsburgh had just one major railroad, meaning it could dictate prices in negotiations, while Cleveland had three railroads that Rockefeller knew would compete for his business, potentially reducing his costs significantly. The leverage gained in these rail negotiations more than offset the additional operating costs of sending his oil to Cleveland for refining, helping establish Rockefeller's empire, while undermining his competitors who failed to integrate their core operating decisions with their negotiation strategies.

Other examples of integrated negotiation include the following:

When a party pretends to negotiate, but secretly has no intention of compromising, the party is considered negotiating in bad faith. Bad faith is a concept in negotiation theory whereby parties pretend to reason to reach settlement, but have no intention to do so, for example, one political party may pretend to negotiate, with no intention to compromise, for political effect.

Bad faith negotiations are often used in political science and political psychology to refer to negotiating strategies in which there is no real intention to reach compromise, or a model of information processing. The "inherent bad faith model" of information processing is a theory in political psychology that was first put forth by Ole Holsti to explain the relationship between John Foster Dulles' beliefs and his model of information processing. It is the most widely studied model of one's opponent. A state is presumed implacably hostile, and contra-indicators of this are ignored. They are dismissed as propaganda ploys or signs of weakness. Examples are John Foster Dulles' position regarding the Soviet Union, or Hamas's position on the state of Israel.

The total of advantages and disadvantages to be distributed in a negotiation is illustrated with the term negotiation pie. The course of the negotiation can either lead to an increase, shrinking, or stagnation of these values. If the negotiation parties are able to expand the total pie a win-win situation is possible assuming that both parties profit from the expansion of the pie. In practice, however, this maximisation approach is oftentimes impeded by the so-called small pie bias, i.e. the psychological underestimation of the negotiation pie's size. Likewise, the possibility to increase the pie may be underestimated due to the so-called incompatibility bias. Contrary to enlarging the pie, the pie may also shrink during negotiations e.g. due to (excessive) negotiation costs.

There are many different ways to categorize the essential elements of negotiation.

One view of negotiation involves three basic elements: "process", "behavior" and "substance". The process refers to how the parties negotiate: the context of the negotiations, the parties to the negotiations, the tactics used by the parties, and the sequence and stages in which all of these play out. Behavior refers to the relationships among these parties, the communication between them and the styles they adopt. The substance refers to what the parties negotiate over: the agenda, the issues (positions and – more helpfully – interests), the options, and the agreement(s) reached at the end.

Another view of negotiation comprises four elements: "strategy", "process", "tools", and "tactics". Strategy comprises the top level goals – typically including relationship and the final outcome. Processes and tools include the steps to follow and roles to take in preparing for and negotiating with the other parties. Tactics include more detailed statements and actions and responses to others' statements and actions. Some add to this "persuasion and influence", asserting that these have become integral to modern day negotiation success, and so should not be omitted.

A skilled negotiator may serve as an advocate for one party to the negotiation. The advocate attempts to obtain the most favorable outcomes possible for that party. In this process the negotiator attempts to determine the minimum outcome(s) the other party is (or parties are) willing to accept, then adjusts their demands accordingly. A "successful" negotiation in the advocacy approach is when the negotiator is able to obtain all or most of the outcomes their party desires, but without driving the other party to permanently break off negotiations.

Skilled negotiators may use a variety of tactics ranging from negotiation hypnosis, to a straightforward presentation of demands or setting of preconditions, to more deceptive approaches such as cherry picking. Intimidation and salami tactics may also play a part in swaying the outcome of negotiations.

Another negotiation tactic is bad guy/good guy. Bad guy/good guy is when one negotiator acts as a bad guy by using anger and threats. The other negotiator acts as a good guy by being considerate and understanding. The good guy blames the bad guy for all the difficulties while trying to get concessions and agreement from the opponent.

The best alternative to a negotiated agreement, or BATNA, is the most advantageous alternative course of action a negotiator can take should the current negotiation end without reaching agreement. The quality of a BATNA has the potential to improve a party's negotiation outcome. Understanding one's BATNA can empower an individual and allow him or her to set higher goals when moving forward. Alternatives need to be actual and actionable to be of value. Negotiators may also consider the other party's BATNA and how it compares to what they are offering during the negotiation.

Kenneth W. Thomas identified five styles or responses to negotiation. These five strategies have been frequently described in the literature and are based on the dual-concern model. The dual concern model of conflict resolution is a perspective that assumes individuals' preferred method of dealing with conflict is based on two themes or dimensions:


Based on this model, individuals balance the concern for personal needs and interests with the needs and interests of others. The following five styles can be used based on individuals' preferences depending on their pro-self or pro-social goals. These styles can change over time, and individuals can have strong dispositions towards numerous styles.

Three basic kinds of negotiators have been identified by researchers involved in The Harvard Negotiation Project. These types of negotiators are: soft bargainers, hard bargainers, and principled bargainers.


Researchers from The Harvard Negotiation Project recommend that negotiators explore a number of alternatives to the problems they face in order to reach the best solution, but this is often not the case (as when you may be dealing with an individual using soft or hard bargaining tactics) (Forsyth, 2010).

Tactics are always an important part of the negotiating process. More often than not they are subtle, difficult to identify and used for multiple purposes. Tactics are more frequently used in distributive negotiations and when the focus in on taking as much value off the table as possible. Many negotiation tactics exist. Below are a few commonly used tactics.

Auction:
The bidding process is designed to create competition. When multiple parties want the same thing, pit them against one another. When people know that they may lose out on something, they want it even more. Not only do they want the thing that is being bid on, they also want to win, just to win. Taking advantage of someone's competitive nature can drive up the price.

Brinksmanship:
One party aggressively pursues a set of terms to the point where the other negotiating party must either agree or walk away. Brinkmanship is a type of "hard nut" approach to bargaining in which one party pushes the other party to the "brink" or edge of what that party is willing to accommodate. Successful brinksmanship convinces the other party they have no choice but to accept the offer and there is no acceptable alternative to the proposed agreement.

Bogey:
Negotiators use the bogey tactic to pretend that an issue of little or no importance is very important. Then, later in the negotiation, the issue can be traded for a major concession of actual importance.

Calling a higher authority: To mitigate too far reaching concessions, deescalate, or overcome a deadlock situation, one party makes the further negotiation process dependent on the decision of a decision maker, not present at the negotiation table.

Chicken:
Negotiators propose extreme measures, often bluffs, to force the other party to chicken out and give them what they want. This tactic can be dangerous when parties are unwilling to back down and go through with the extreme measure.

Defence in Depth:
Several layers of decision-making authority is used to allow further concessions each time the agreement goes through a different level of authority. In other words, each time the offer goes to a decision maker, that decision maker asks to add another concession to close the deal.

Deadlines:
Give the other party a deadline forcing them to make a decision. This method uses time to apply pressure to the other party. Deadlines given can be actual or artificial.

Flinch:
Flinching is showing a strong negative physical reaction to a proposal. Common examples of flinching are gasping for air, or a visible expression of surprise or shock. The flinch can be done consciously or unconsciously. The flinch signals to the opposite party that you think the offer or proposal is absurd in hopes the other party will lower their aspirations. Seeing a physical reaction is more believable than hearing someone saying, "I'm shocked."

Good Guy/Bad Guy:
Within the tactic of good guy/bad guy (synonyms are good cop/bad cop or black hat/white hat) oftentimes positive and unpleasant tasks are divided between two negotiators on the same negotiation side or unpleasant tasks or decisions are allocated to an (real or fictitious) outsider. The good guy supports the conclusion of the contract and emphasises positive aspects of the negotiation (mutual interests). The bad guy criticises negative aspects (opposing interests). The division of the two roles allows more consistent behaviour and credibility of the individual negotiators. As the good guy promotes the contract, he/she can build trust with the other side.

Highball/Lowball or Ambit claim:
Depending on whether selling or buying, sellers or buyers use a ridiculously high, or ridiculously low opening offer that is not achievable. The theory is that the extreme offer makes the other party reevaluate their own opening offer and move close to the resistance point (as far as you are willing to go to reach an agreement). Another advantage is that the party giving the extreme demand appears more flexible when they make concessions toward a more reasonable outcome. A danger of this tactic is that the opposite party may think negotiating is a waste of time.

The Nibble:
Also known under salami tactic or quivering quill, nibbling is the demand of proportionally small concessions that haven't been discussed previously just before closing the deal. This method takes advantage of the other party's desire to close by adding "just one more thing."

Snow Job:
Negotiators overwhelm the other party with so much information that they have difficulty determining what information is important, and what is a diversion. Negotiators may also use technical language or jargon to mask a simple answer to a question asked by a non-expert.

Mirroring:
When people get on well, the outcome of a negotiation is likely to be more positive. To create trust and a rapport, a negotiator may mimic or mirror the opponent's behavior and repeat what they say. Mirroring refers to a person repeating the core content of what another person just said, or repeating a certain expression. It indicates attention to the subject of negotiation and acknowledges the other party's point or statement. Mirroring can help create trust and establish a relationship.

Communication is a key element of negotiation. Effective negotiation requires that participants effectively convey and interpret information. Participants in a negotiation communicate information not only verbally but non-verbally through body language and gestures. By understanding how nonverbal communication works, a negotiator is better equipped to interpret the information other participants are leaking non-verbally while keeping secret those things that would inhibit his/her ability to negotiate.

Non-verbal "anchoring"
In a negotiation, a person can gain the advantage by verbally expressing a position first. By anchoring one's position, one establishes the position from which the negotiation proceeds. In a like manner, one can "anchor" and gain advantage with nonverbal (body language) cues.


Reading non-verbal communication
Being able to read the non-verbal communication of another person can significantly aid in the communication process. By being aware of inconsistencies between a person's verbal and non-verbal communication and reconciling them, negotiators can to come to better resolutions. Examples of incongruity in body language include:


Conveying receptivity
The way negotiation partners position their bodies relative to each other may influence how receptive each is to the other person's message and ideas.


Receptive negotiators tend to appear relaxed with their hands open and palms visibly displayed.


Emotions play an important part in the negotiation process, although it is only in recent years that their effect is being studied. Emotions have the potential to play either a positive or negative role in negotiation. During negotiations, the decision as to whether or not to settle rests in part on emotional factors. Negative emotions can cause intense and even irrational behavior, and can cause conflicts to escalate and negotiations to break down, but may be instrumental in attaining concessions. On the other hand, positive emotions often facilitate reaching an agreement and help to maximize joint gains, but can also be instrumental in attaining concessions. Positive and negative discrete emotions can be strategically displayed to influence task and relational outcomes and may play out differently across cultural boundaries.

Dispositions for affects affect various stages of negotiation: which strategies to use, which strategies are actually chosen, the way the other party and their intentions are perceived, their willingness to reach an agreement and the final negotiated outcomes. Positive affectivity (PA) and negative affectivity (NA) of one or more of the negotiating sides can lead to very different outcomes.

Even before the negotiation process starts, people in a positive mood have more confidence, and higher tendencies to plan to use a cooperative strategy. During the negotiation, negotiators who are in a positive mood tend to enjoy the interaction more, show less contentious behavior, use less aggressive tactics and more cooperative strategies. This in turn increases the likelihood that parties will reach their instrumental goals, and enhance the ability to find integrative gains. Indeed, compared with negotiators with negative or natural affectivity, negotiators with positive affectivity reached more agreements and tended to honor those agreements more. Those favorable outcomes are due to better decision making processes, such as flexible thinking, creative problem solving, respect for others' perspectives, willingness to take risks and higher confidence. Post-negotiation positive affect has beneficial consequences as well. It increases satisfaction with achieved outcome and influences one's desire for future interactions. The PA aroused by reaching an agreement facilitates the dyadic relationship, which brings commitment that sets the stage for subsequent interactions. PA also has its drawbacks: it distorts perception of self performance, such that performance is judged to be relatively better than it actually is. Thus, studies involving self reports on achieved outcomes might be biased.

"Don't fear to negotiate don't negotiate out of fear" JFK. 

Negative affect has detrimental effects on various stages in the negotiation process. Although various negative emotions affect negotiation outcomes, by far the most researched is anger. Angry negotiators plan to use more competitive strategies and to cooperate less, even before the negotiation starts. These competitive strategies are related to reduced joint outcomes.
During negotiations, anger disrupts the process by reducing the level of trust, clouding parties' judgment, narrowing parties' focus of attention and changing their central goal from reaching agreement to retaliating against the other side. Angry negotiators pay less attention to opponent's interests and are less accurate in judging their interests, thus achieve lower joint gains. Moreover, because anger makes negotiators more self-centered in their preferences, it increases the likelihood that they will reject profitable offers. Opponents who get really angry (or cry, or otherwise lose control) are more likely to make errors: make sure they are in your favor.
Anger does not help achieve negotiation goals either: it reduces joint gains and does not boost personal gains, as angry negotiators do not succeed. Moreover, negative emotions lead to acceptance of settlements that are not in the positive utility function but rather have a negative utility. However, expression of negative emotions during negotiation can sometimes be beneficial: legitimately expressed anger can be an effective way to show one's commitment, sincerity, and needs. Moreover, although NA reduces gains in integrative tasks, it is a better strategy than PA in distributive tasks (such as zero-sum). In his work on negative affect arousal and white noise, Seidner found support for the existence of a negative affect arousal mechanism through observations regarding the devaluation of speakers from other ethnic origins. Negotiation may be negatively affected, in turn, by submerged hostility toward an ethnic or gender group.

Research indicates that negotiator's emotions do not necessarily affect the negotiation process.
Albarracın et al. (2003) suggested that there are two conditions for emotional affect, both related to the ability (presence of environmental or cognitive disturbances) and the motivation:


According to this model, emotions affect negotiations only when one is high and the other is low. When both ability and motivation are low, the affect is identified, and when both are high the affect is identified but discounted as irrelevant to judgment.
A possible implication of this model is, for example, that the positive effects PA has on negotiations (as described above) is seen only when either motivation or ability are low.

Most studies on emotion in negotiations focus on the effect of the negotiator's own emotions on the process. However, what the other party feels might be just as important, as group emotions are known to affect processes both at the group and the personal levels.
When it comes to negotiations, trust in the other party is a necessary condition for its emotion to affect, and visibility enhances the effect.
Emotions contribute to negotiation processes by signaling what one feels and thinks and can thus prevent the other party from engaging in destructive behaviors and to indicate what steps should be taken next: PA signals to keep in the same way, while NA points that mental or behavioral adjustments are needed.
Partner's emotions can have two basic effects on negotiator's emotions and behavior: mimetic/ reciprocal or complementary. For example, disappointment or sadness might lead to compassion and more cooperation. In a study by Butt et al. (2005) that simulated real multi-phase negotiation, most people reacted to the partner's emotions in reciprocal, rather than complementary, manner. Specific emotions were found to have different effects on the opponent's feelings and strategies chosen:



Negotiation is a rather complex interaction. Capturing all its complexity is a very difficult task, let alone isolating and controlling only certain aspects of it. For this reason most negotiation studies are done under laboratory conditions, and focus only on some aspects. Although lab studies have their advantages, they do have major drawbacks when studying emotions:


While negotiations involving more than two parties is less often researched, some results from two-party negotiations still apply with more than two parties. One such result is that in negotiations it is common to see language similarity arise between the two negotiating parties. In three-party negotiations, language similarity still arose, and results were particularly efficient when the party with the most to gain from the negotiation adopted language similarities from the other parties.

Due to globalization and growing business trends, negotiation in the form of teams is becoming widely adopted. Teams can effectively collaborate to break down a complex negotiation. There is more knowledge and wisdom dispersed in a team than in a single mind. Writing, listening, and talking, are specific roles team members must satisfy. The capacity base of a team reduces the amount of blunder, and increases familiarity in a negotiation.

However, unless a team can appropriately utilize the full capacity of its potential, effectiveness can suffer. One factor in the effectiveness of team negotiation is a problem that occurs through solidarity behavior. Solidarity behavior occurs when one team member reduces his or her own utility (benefit) in order to increase the benefits of other team members. This behavior is likely to occur when interest conflicts rise. When the utility/needs of the negotiation opponent does not align with every team member's interests, team members begin to make concessions and balance the benefits gained among the team.

Intuitively, this may feel like a cooperative approach. However, though a team may aim to negotiate in a cooperative or collaborative nature, the outcome may be less successful than is possible, especially when integration is possible. Integrative potential is possible when different negotiation issues are of different importance to each team member. Integrative potential is often missed due to the lack of awareness of each member's interests and preferences. Ultimately, this leads to a poorer negotiation result.

Thus, a team can perform more effectively if each member discloses his or her preferences prior to the negotiation. This step will allow the team to recognize and organize the team's joint priorities, which they can take into consideration when engaging with the opposing negotiation party. Because a team is more likely to discuss shared information and common interests, teams must make an active effort to foster and incorporate unique viewpoints from experts from different fields. Research by Daniel Thiemann, which largely focused on computer-supported collaborative tasks, found that the Preference Awareness method is an effective tool for fostering the knowledge about joint priorities and further helps the team judge which negotiation issues were of highest importance.

Many of the strategies in negotiation vary across genders, and this leads to variations in outcomes for different genders, often with women experiencing less success in negotiations as a consequence. This is due to a number of factors, including that it has been shown that it is more difficult for women to be self-advocating when they are negotiating. Many of the implications of these findings have strong financial impacts in addition to the social backlash faced by self-advocating women in negotiations, as compared to other advocating women, self-advocating men, and other advocating men. Research in this area has been studied across platforms, in addition to more specific areas like women as physician assistants. The backlash associated with this type of behavior is attributed to the fact that to be self-advocated is considered masculine, whereas the alternative, being accommodating, is considered more feminine. Males, however, do not appear to face any type of backlash for not being self-advocating.

This research has been supported by multiple studies, including one which evaluated candidates participating in a negotiation regarding compensation. This study showed that women who initiated negotiations were evaluated more poorly than men who initiated negotiations. In another variation of this particular setup, men and women evaluated videos of men and women either accepting a compensation package or initiating negotiations. Men evaluated women more poorly for initiating negotiations, while women evaluated both men and women more poorly for initiating negotiations. In this particular experiment, women were less likely to initiate a negotiation with a male, citing nervousness, but there was no variation with the negotiation was initiated with another female.

Research also supports the notion that the way individuals respond in a negotiation varies depending on the gender of the opposite party. In all-male groups, the use of deception showed no variation upon the level of trust between negotiating parties, however in mixed-sex groups there was an increase in deceptive tactics when it was perceived that the opposite party was using an accommodating strategy. In all-female groups, there were many shifts in when individuals did and did not employ deception in their negotiation tactics.

The academic world contains a unique management system, wherein faculty members, some of which have tenure, reside in academic units (e.g. departments) and are overseen by chairs, or heads. These chairs/heads are in turn supervised by deans of the college where their academic unit resides. Negotiation is an area where faculty, chairs/heads and their deans have little preparation; their doctoral degrees are typically in a highly specialized area according to their academic expertise. However, the academic environment frequently presents with situations where negotiation takes place. For example, many faculty are hired with an expectation that they will conduct research and publish scholarly works. For these faculty, where their research requires equipment, space, and/or funding, negotiation of a "start-up" package is critical for their success and future promotion. Also, department chairs often find themselves in situations, typically involving resource redistribution where they must negotiate with their dean, on behalf of their unit. And deans oversee colleges where they must optimize limited resources, such as research space or operating funds while at the same time creating an environment that fosters student success, research accomplishments and more.

Integrative negotiation is the type predominately found in academic negotiation – where trust and long-term relationships between personnel are valued. Techniques found to be particularly useful in academic settings include: (1) doing your homework – grounding your request in facts; (2) knowing your value; (3) listening actively and acknowledging what is being said, (4) putting yourself in their shoes, (5) asking – negotiation begins with an ask, (6) not committing immediately, (7) managing emotion and (8) keeping in mind the principle of a "wise agreement", with its associated emphasis on meeting the interests of both parties to the extent possible as a key working point. The articles by Callahan, et al. and Amekudzi-Kennedy, et al. contain several case studies of academic negotiations.

The word "negotiation" originated in the early 15th century from the Old French "negociacion" from Latin "negotiatio" from "neg"- "no" and "otium" "leisure". These terms mean "business, trade, traffic". By the late 1570s negotiation had the definition, "to communicate in search of mutual agreement." With this new introduction and this meaning, it showed a shift in "doing business" to "bargaining about" business.



</doc>
<doc id="22085" url="https://en.wikipedia.org/wiki?curid=22085" title="Fertility awareness">
Fertility awareness

Fertility awareness (FA) refers to a set of practices used to determine the fertile and infertile phases of a woman's menstrual cycle. Fertility awareness methods may be used to avoid pregnancy, to achieve pregnancy, or as a way to monitor gynecological health.

Methods of identifying infertile days have been known since antiquity, but scientific knowledge gained during the past century has increased the number, variety, and especially accuracy of methods.

Systems of fertility awareness rely on observation of changes in one or more of the primary fertility signs (basal body temperature, cervical mucus, and cervical position), tracking menstrual cycle length and identifying the fertile window based on this information, or both. Other signs may also be observed: these include breast tenderness and mittelschmerz (ovulation pains), urine analysis strips known as ovulation predictor kits (OPKs), and microscopic examination of saliva or cervical fluid. Also available are computerized fertility monitors.

Symptoms-based methods involve tracking one or more of the three primary fertility signs: basal body temperature, cervical mucus, and cervical position. Systems relying exclusively on cervical mucus include the Billings Ovulation Method, the Creighton Model, and the Two-Day Method. Symptothermal methods combine observations of basal body temperature (BBT), cervical mucus, and sometimes cervical position. Calendar-based methods rely on tracking a woman's cycle and identifying her fertile window based on the lengths of her cycles. The best known of these methods is the Standard Days Method. The Calendar-Rhythm method is also considered a calendar-based method, though it is not well defined and has many different meanings to different people.

Systems of fertility awareness may be referred to as fertility awareness–based methods (FAB methods); the term Fertility Awareness Method (FAM) refers specifically to the system taught by Toni Weschler. The term natural family planning (NFP) is sometimes used to refer to any use of FA methods, the Lactational amenorrhea method and periodic abstinence during fertile times. A method of FA may be used by NFP users to identify these fertile times.

Women who are breastfeeding a child and wish to avoid pregnancy may be able to practice the lactational amenorrhea method (LAM). LAM is distinct from fertility awareness, but because it also does not involve contraceptives, it is often presented alongside FA as a method of "natural" birth control.

Within the Catholic Church and some Protestant denominations, the term Natural Family Planning is often used to refer to Fertility Awareness pointing out it is the only method of Family Planning approved by the Church.

It is not known exactly when it was first discovered that women have predictable periods of fertility and infertility. It is already clearly stated in the Talmud tractate Niddah, that a woman only becomes pregnant in specific periods in the month, which seemingly refers to ovulation. St. Augustine wrote about periodic abstinence to avoid pregnancy in the year 388 (the Manichaeans attempted to use this method to remain childfree, and Augustine condemned their use of periodic abstinence). One book states that periodic abstinence was recommended ""by a few secular thinkers since the mid-nineteenth century,"" but the dominant force in the twentieth century popularization of fertility awareness-based methods was the Roman Catholic Church.

In 1905 Theodoor Hendrik van de Velde, a Dutch gynecologist, showed that women only ovulate once per menstrual cycle. In the 1920s, Kyusaku Ogino, a Japanese gynecologist, and Hermann Knaus, from Austria, independently discovered that ovulation occurs about fourteen days before the next menstrual period. Ogino used his discovery to develop a formula for use in aiding infertile women to time intercourse to achieve pregnancy. In 1930, John Smulders, Roman Catholic physician from the Netherlands, used this discovery to create a method for "avoiding" pregnancy. Smulders published his work with the Dutch Roman Catholic medical association, and this was the first formalized system for periodic abstinence: the rhythm method.

In the 1930s, Reverend Wilhelm Hillebrand, a Catholic priest in Germany, developed a system for avoiding pregnancy based on basal body temperature. This temperature method was found to be more effective at helping women avoid pregnancy than were calendar-based methods. Over the next few decades, both systems became widely used among Catholic women. Two speeches delivered by Pope Pius XII in 1951 gave the highest form of recognition to the Catholic Church's approval—for couples who needed to avoid pregnancy—of these systems. In the early 1950s, John Billings discovered the relationship between cervical mucus and fertility while working for the Melbourne Catholic Family Welfare Bureau. Billings and several other physicians, including his wife, Dr. Evelyn Billings, studied this sign for a number of years, and by the late 1960s had performed clinical trials and begun to set up teaching centers around the world.

While Dr. Billings initially taught both the temperature and mucus signs, they encountered problems in teaching the temperature sign to largely illiterate populations in developing countries. In the 1970s they modified the method to rely on only mucus. The international organization founded by Dr. Billings is now known as the World Organization Ovulation Method Billings (WOOMB).

The first organization to teach a symptothermal method was founded in 1971. John and Sheila Kippley, lay Catholics, joined with Dr. Konald Prem in teaching an observational method that relied on all three signs: temperature, mucus, and cervical position. Their organization is now called Couple to Couple League International. The next decade saw the founding of other now-large Catholic organizations, Family of the Americas (1977), teaching the Billings method, and the Pope Paul VI Institute (1985), teaching a new mucus-only system called the Creighton Model.

Up until the 1980s, information about fertility awareness was only available from Catholic sources. The first secular teaching organization was the Fertility Awareness Center in New York, founded in 1981. Toni Weschler started teaching in 1982 and published the bestselling book "Taking Charge of Your Fertility" in 1995. Justisse was founded in 1987 in Edmonton, Canada. These secular organizations all teach symptothermal methods. Although the Catholic organizations are significantly larger than the secular fertility awareness movement, independent secular teachers have become increasingly common since the 1990s.

Development of fertility awareness methods is ongoing. In the late 1990s, the Institute for Reproductive Health at Georgetown University introduced two new methods. The Two-Day Method, a mucus-only system, and CycleBeads and iCycleBeads (the digital version), based on the Standard Days Method, are designed to be both effective and simple to teach, learn, and use. In 2019, Urrutia et al. released a study as well as interactive graph over-viewing all studied fertility awareness based methods. Femtech companies such as Dot and Natural Cycles have also produced new studies and apps to help women avoid pregnancy. Natural Cycles is the first app of its kind to receive FDA approval.

Most menstrual cycles have several days at the beginning that are infertile (pre-ovulatory infertility), a period of fertility, and then several days just before the next menstruation that are infertile (post-ovulatory infertility). The first day of red bleeding is considered day one of the menstrual cycle. Different systems of fertility awareness calculate the fertile period in slightly different ways, using primary fertility signs, cycle history, or both.

The three primary signs of fertility are "basal body temperature" (BBT), "cervical mucus", and "cervical position". A woman practicing symptoms-based fertility awareness may choose to observe one sign, two signs, or all three. Many women experience secondary fertility signs that correlate with certain phases of the menstrual cycle, such as abdominal pain and heaviness, back pain, breast tenderness, and mittelschmerz (ovulation pains).

This usually refers to a temperature reading collected when a person first wakes up in the morning (or after their longest sleep period of the day). The true BBT can only be obtained by continuous temperature monitoring through internally worn temperature sensors. In women, ovulation will trigger a rise in BBT between 0.2º and 0.5 °C. (0.5 and 1.°F) that lasts approximately until the next menstruation. This temperature shift may be used to determine the onset of post-ovulatory infertility. (See ref. 30)

The appearance of cervical mucus and vulvar sensation are generally described together as two ways of observing the same sign. Cervical mucus is produced by the cervix, which connects the uterus to the vaginal canal. Fertile cervical mucus promotes sperm life by decreasing the acidity of the vagina, and also it helps guide sperm through the cervix and into the uterus. The production of fertile cervical mucus is caused by estrogen, the same hormone that prepares a woman's body for ovulation. By observing her cervical mucus and paying attention to the sensation as it passes the vulva, a woman can detect when her body is gearing up for ovulation, and also when ovulation has passed. When ovulation occurs, estrogen production drops slightly and progesterone starts to rise. The rise in progesterone causes a distinct change in the quantity and quality of mucus observed at the vulva.

The cervix changes position in response to the same hormones that cause cervical mucus to be produced and to dry up. When a woman is in an infertile phase of her cycle, the cervix will be low in the vaginal canal; it will feel firm to the touch (like the tip of a person's nose); and the os—the opening in the cervix—will be relatively small, or "closed". As a woman becomes more fertile, the cervix will rise higher in the vaginal canal, it will become softer to the touch (more like a person's lips), and the os will become more open. After ovulation has occurred, the cervix will revert to its infertile position.

Calendar-based systems determine both pre-ovulatory and post-ovulatory infertility based on cycle history. When used to avoid pregnancy, these systems have higher perfect-use failure rates than symptoms-based systems, but are still comparable with barrier methods, such as diaphragms and cervical caps.

Mucus- and temperature-based methods used to determine post-ovulatory infertility, when used to avoid conception, result in very low perfect-use pregnancy rates. However, mucus and temperature systems have certain limitations in determining pre-ovulatory infertility. A temperature record alone provides no guide to fertility or infertility before ovulation occurs. Determination of pre-ovulatory infertility may be done by observing the absence of fertile cervical mucus; however, this results in a higher failure rate than that seen in the period of post-ovulatory infertility. Relying only on mucus observation also means that unprotected sexual intercourse is not allowed during menstruation, since any mucus would be obscured.

Use of certain calendar rules to determine the length of the pre-ovulatory infertile phase allows unprotected intercourse during the first few days of the menstrual cycle while maintaining a very low risk of pregnancy. With mucus-only methods, there is a possibility of incorrectly identifying mid-cycle or anovulatory bleeding as menstruation. Keeping a BBT chart enables accurate identification of menstruation, when pre-ovulatory calendar rules may be reliably applied. In temperature-only systems, a calendar rule may be relied on alone to determine pre-ovulatory infertility. In symptothermal systems, the calendar rule is cross-checked by mucus records: observation of fertile cervical mucus overrides any calendar-determined infertility.

Calendar rules may set a standard number of days, specifying that (depending on a woman's past cycle lengths) the first three to six days of each menstrual cycle are considered infertile. Or, a calendar rule may require calculation, for example holding that the length of the pre-ovulatory infertile phase is equal to the length of a woman's shortest cycle minus 21 days. Rather than being tied to cycle length, a calendar rule may be determined from the cycle day on which a woman observes a thermal shift. One system has the length of the pre-ovulatory infertile phase equal to a woman's earliest historical day of temperature rise minus seven days.

Ovulation predictor kits (OPKs) can detect imminent ovulation from the concentration of lutenizing hormone (LH) in a woman's urine. A positive OPK is usually followed by ovulation within 12–36 hours.

Saliva microscopes, when correctly used, can detect ferning structures in the saliva that precede ovulation. Ferning is usually detected beginning three days before ovulation, and continuing until ovulation has occurred. During this window, ferning structures occur in cervical mucus as well as saliva.

Computerized fertility monitors, such as Lady-Comp, are available under various brand names. These monitors may use BBT-only systems, they may analyze urine test strips, they may use symptothermal observations, they may monitor the electrical resistance of saliva and vaginal fluids, or a combination of any of these factors.

A symptohormonal method of FAM developed at Marquette University uses the ClearBlue Easy fertility monitor to determine the fertile window. The monitor measures estrogen and LH to determine the peak day. This method is also applicable during postpartum, breastfeeding, and perimenopause, and requires less abstinence than other FAM methods. Some couples prefer this method because the monitor reading is objective and is not affected by sleep quality as BBT can be.

Fertility awareness has a number of unique characteristics:


By restricting unprotected sexual intercourse to the infertile portion of the menstrual cycle, a woman and her partner can prevent pregnancy. During the fertile portion of the menstrual cycle, the couple may use barrier contraception or abstain from sexual intercourse.



The effectiveness of fertility awareness, as of most forms of contraception, can be assessed two ways. "Perfect use" or "method" effectiveness rates only include people who follow all observational rules, correctly identify the fertile phase, and refrain from unprotected intercourse on days identified as fertile. "Actual use" or "typical use" effectiveness rates include all women relying on fertility awareness to avoid pregnancy, including those who fail to meet the "perfect use" criteria. Rates are generally presented for the first year of use. Most commonly, the Pearl Index is used to calculate effectiveness rates, but some studies use decrement tables.

The failure rate of fertility awareness varies widely depending on the system used to identify fertile days, the instructional method, and the population being studied. Some studies have found actual failure rates of 25% per year or higher. At least one study has found a failure rate of less than 1% per year with continuous intensive coaching and monthly review, and several studies have found actual failure rates of 2%–3% per year.

When used correctly and consistently (i.e., with perfect use) with ongoing coaching, under study conditions some studies have found some forms of FA to be 99% effective.

From "Contraceptive Technology":


Several factors account for typical-use effectiveness being lower than perfect-use effectiveness:

The most common reason for the lower actual effectiveness is not mistakes on the part of instructors or users, but conscious user non-compliance—that is, the couple knowing that the woman is likely to be fertile at the time but engaging in sexual intercourse nonetheless. This is similar to failures of barrier methods, which are primarily caused by non-use of the method.

A 2015 review found insufficient evidence to draw any conclusions about the effect of timing intercourse on the rate of live births or pregnancies, compared to regular intercourse.

A study by Barrett and Marshall has shown that random acts of intercourse achieve a 24% pregnancy rate per cycle. That study also found that timed intercourse based on information from a BBT-only method of FA increased pregnancy rates to 31%–68%.

Studies of cervical-mucus methods of fertility awareness have found pregnancy rates of 67–81% in the first cycle if intercourse occurred on the Peak Day of the mucus sign.

Because of high rates of very early miscarriage (25% of pregnancies are lost within the first six weeks since the woman's last menstrual period, or LMP), the methods used to detect pregnancy may lead to bias in conception rates. Less-sensitive methods will detect lower conception rates, because they miss the conceptions that resulted in early pregnancy loss. A Chinese study of couples practicing random intercourse to achieve pregnancy used very sensitive pregnancy tests to detect pregnancy. It found a 40% conception rate per cycle over the 12-month study period.

Pregnancy rates for sexual intercourse are also affected by several other factors. Regarding frequency, there are recommendations of sexual intercourse every 1 or 2 days, or every 2 or 3 days. Studies have shown no significant difference between different sex positions and pregnancy rate, as long as it results in ejaculation into the vagina.

Regular menstrual cycles are sometimes taken as evidence that a woman is ovulating normally, and irregular cycles as evidence she is not. However, many women with irregular cycles do ovulate normally, and some with regular cycles are actually annovulatory or have a luteal phase defect. Records of basal body temperatures, especially, but also of cervical mucus and position, can be used to accurately determine if a woman is ovulating, and if the length of the post-ovulatory (luteal) phase of her menstrual cycle is sufficient to sustain a pregnancy.

Fertile cervical mucus is important in creating an environment that allows sperm to pass through the cervix and into the fallopian tubes where they wait for ovulation. Fertility charts can help diagnose hostile cervical mucus, a common cause of infertility. If this condition is diagnosed, some sources suggest taking guaifenesin in the few days before ovulation to thin out the mucus.

Pregnancy tests are not accurate until 1–2 weeks after ovulation. Knowing an estimated date of ovulation can prevent a woman from getting false negative results due to testing too early. Also, 18 consecutive days of elevated temperatures means a woman is almost certainly pregnant.

Estimated ovulation dates from fertility charts are a more accurate method of estimating gestational age than the traditional pregnancy wheel or last menstrual period (LMP) method of tracking menstrual periods.




</doc>
<doc id="22087" url="https://en.wikipedia.org/wiki?curid=22087" title="Nicaragua Canal">
Nicaragua Canal

The Nicaraguan Canal (), formally the Nicaraguan Canal and Development Project (also referred to as the Nicaragua Grand Canal, or the Grand Interoceanic Canal) was a proposed shipping route through Nicaragua to connect the Caribbean Sea (and therefore the Atlantic Ocean) with the Pacific Ocean. Scientists were concerned about the project's environmental impact, as Lake Nicaragua is Central America's key freshwater reservoir while the project's viability was questioned by shipping experts and engineers.

Construction of a canal using the San Juan River as an access route to Lake Nicaragua was first proposed in the early colonial era. The United States abandoned plans to construct a waterway in Nicaragua in the early 20th century after it purchased the French interests in the Panama Canal.

In June 2013, Nicaragua's National Assembly approved a bill to grant a 50-year concession to finance and manage the project to the HK Nicaragua Canal Development Investment (HKND) headed by Wang Jing, a Chinese billionaire. The concession could have been extended for another 50 years once the waterway was operational.

In 2015, media reports suggested the project would be delayed and possibly cancelled because Wang's personal wealth declined greatly as a result of the 2015–16 Chinese stock market crash. "Major works" such as dredging were to take place after the finishing of a Pacific Ocean wharf, whose construction was planned to start in late 2016. The Nicaraguan government failed to present reliable information about whether or not the project can be financed, thus casting doubt over whether it would be completed. The HKND Group stated that financing would come from debt and equity sales and a potential initial public offering (IPO).

By May 2017, no concrete action had been reportedly taken constructing the canal and further doubts were expressed about its financing. In February 2018, analysts widely viewed the project as defunct, though the head of the project insisted work was on-going and HKND retained the legal rights to the concession for the canal as well as side projects. Despite HKND vanishing, the Nicaraguan government indicates that it will go ahead with the 908 km dry land expropriations anywhere within Nicaragua, under land expropriation Canal Law 840.

The idea of constructing a man-made waterway through Central America has been thought about throughout history. The colonial administration of New Spain conducted preliminary surveys. The routes suggested usually ran across Nicaragua, Panama, or the Isthmus of Tehuantepec in Mexico.

The history of attempts to build a Nicaragua canal connecting the Caribbean Sea and thus the Atlantic Ocean and the Pacific Ocean goes back at least to 1825 when the Federal Republic of Central America hired surveyors to study a route via Lake Nicaragua, above sea level. Many other proposals have followed. Despite the operation of the Panama Canal, which opened in 1914, interest in a Nicaragua canal has continued. With emergence of globalization, an increase in commerce and the cost of fuel, and the limitations of the Panama Canal, the concept of a second canal across the American land bridge became more attractive, and in 2006 the president of Nicaragua, Enrique Bolaños, announced an intention to proceed with such a project. Even with the Panama Canal expansion project, which began commercial operation to allow modern New Panamax vessels on 26 June 2016, some ships would be too big for the Panama Canal.

On 26 September 2012, the Nicaraguan Government and the newly formed Hong Kong Nicaragua Canal Development Group (HKND) signed a memorandum of understanding that committed HKND to financing and building the "Nicaraguan Canal and Development Project". HKND Group is a private enterprise.

The Nicaraguan government subsequently approved the "Master Concession Agreement" with HKND on 13 June 2013 thereby granting "the sole rights to the HKND Group to plan, design, construct and thereafter to operate and manage the Nicaragua Grand Canal and other related projects, including ports, a free trade zone, an international airport and other infrastructure development projects." The agreement would have lasted for 50 years and was renewable for another 50 years. HKND would have paid the Government of Nicaragua US$10M annually for 10 years, and thereafter a portion of the revenue starting at 1% and increasing later.
Stratfor indicated that after 10 years, ownership shares would periodically be handed over to Nicaragua, so that after 50 years Nicaragua would be the majority shareholder.

HKND Group performed a preliminary study phase of development to assess the technological and economic feasibility of constructing a canal in Nicaragua, as well as the potential environmental, social, and regional implications of various routes. The canal and other associated projects would be financed by investors throughout the world and would generate jobs for Nicaragua and other Central American countries.

Initial findings of the commercial analysis conducted by HKND Group indicate that the combined effect of growth in east–west trade and in ship sizes could provide a compelling argument for the construction of a second canal, substantially larger than the expanded Panama Canal, across Central America. In the 2020s, growth in global maritime trade is expected to cause congestion and delays in transit through the Panama Canal without a complementary route through the isthmus, and by 2030, the volume of trade that a Nicaragua Canal could serve would have grown by 240%.

On 10 June 2013, The Associated Press reported that the National Assembly's Infrastructure Committee voted nearly unanimously in favor of the project, with four members abstaining. On 13 June, Nicaragua's legislature passed the legislation granting the concession. On 15 June, Nicaraguan President Daniel Ortega and the billionaire chairman of HKND Group, Wang Jing, signed the concession agreement giving HKND Group the rights to construct and manage the canal and associated projects for 50 years. An HKND Group press release read, "HKND Group Successfully Obtains Exclusive Right to Develop and Manage Nicaragua Grand Canal for 100 Years." Under the exclusive contract, Wang can skip building the canal (and making any payments to Nicaragua) and instead simply operate lucrative tax-free side projects.

Wang announced at a press briefing in June 2013 that he had successfully attracted global investors to the $40 billion project.
In January 2014, Wang and President Ortega issued a statement that the project's construction would begin in December 2014, and that it would be completed in 2019.

On 7 July 2014, a route for the Nicaragua Canal was approved. The route starts from the mouth of the Brito River on the Pacific side, passes through Lake Nicaragua, and ends in the Punta Gorda River on the Caribbean. The proposed canal would be between 230 meters and 520 meters (754.6 feet and 1,706 feet) wide and deep. The "Toronto Star" noted that Chinese engineer Dong Yung Song said the canal's design called for the creation of a artificial lake. The water to fill the canal's giant locks would come from the artificial lake, not from Lake Nicaragua.

Daniel Ortega whose government approved the agreement within one week in June 2013, reportedly perceived the canal as the second phase of the Nicaraguan Revolution, predicting that it would pull Nicaragua out of poverty and lead to the creation of 250,000 jobs, but HKND said the project would create 50,000 jobs, though about half would come from abroad, mainly China.

"The Moscow Times" reported in 2014 that Russia was willing to help build the Nicaragua Canal, viewing the project in part as an opportunity to pursue strategic interests in the region. Construction was to begin on 29 December 2014, and officially started a week earlier. However, owing to Nicaragua's volatile climate and seismic activity, feasibility concerns emerged over the project's future. In November 2015, HKND announced that there would be a delay in the construction of locks and excavations until late 2016 in order to fine-tune the design.

The Nicaragua canal project saw business rivalry greatly intensify in late 2014. China Harbor Engineering Company, an experienced construction company, offered to design, construct, and finance a fourth set of locks in Panama, where it opened a regional headquarters. If built to the width of the proposed Nicaragua Canal, it would cut across far fewer kilometers, and still cost only $10 billion, according to the firm. Panama is in a much better financial situation than Nicaragua to afford taking on such debt and already has a stream of income from its existing canals.

Alternative motives have been explored and other projects have taken priority against the water transportation venture. Bloomberg reported in 2015 that "conspiracy theories abound" including the project was a land grab by Ortega, an attempt by Ortega to "whip up" support in elections, and part of a Chinese plan to gain influence in the region.

By November 2016, the president of the canal commission, Manual Coronel Kautz said "According to our schedule, we should initiate major works by the end of the year." However, Carlos Fernando Chamorro, editor of the Confidencial newspaper, said "If the People's Republic of China does not step forward, it won't happen. Wang Jing does not have the reputation to push this through. If it is just him, then the chances of this happening are zero. If the PRC steps in, then it is a big possibility."

Following financial difficulties, HKND finally closed its Headquarters offices in China in April 2018, leaving no forwarding address or telephone numbers to be reached.

Protests against the canal's construction occurred shortly after the official ceremony marking its beginning. Farmers feared it could cause their eviction and land expropriation.

Opposition leader Eliseo Nuñez has called the deal "part of one of the biggest international scams in the world". Legal challenges that the deal violates constitutional rights were rejected by the Supreme Court of Nicaragua and a retrospective rewriting of the Constitution of Nicaragua placed HKND beyond legal challenge. HKND has been granted the right to expropriate land within on each side of the canal and pay only cadastral value, not market value, for property. Wang, however, promised to pay fair market value. The estimates of the number of people who would be displaced range from 29,000 to more than 100,000. There are indications of local opposition to intended expropriations. Thus, according to an activist leader, an unrest in Rivas in December 2014, in opposition to the canal, left two protesters dead, although no evidence was ever produced to justify his claim. The CIDH, Nicaragua's Human Rights Commission, has strongly criticized the government for not looking into the project's effect on citizens, amid claims that citizens were not involved in decision-making. The British firm ERM, who carried out the Environmental Impact Assessment, claims it held consultations with around 6,000 people in the communities along its planned route, and estimated that the property of about 30,000 people would be affected. National opinion polls show that support for the project is about 70%.

Investor Wang had financial setbacks unrelated to the Nicaragua project, losing 80% of his net worth during the 2015–16 Chinese stock market turbulence. In March 2017, the "Havana Times" reported that the public relations agency handling Wang's interests in Nicaragua had been let go, in absence of any developments on the project to report, and Wang had not been in the country in more than two years. In May 2017, the "PanAm Post" indicated that "no concrete action has been taken to begin the project" and suggested that the project was either "paralyzed, or nonexistent." In September 2017 Agence France-Presse reported that the work had been "pushed back indefinitely," although the government renewed the project's environmental permit in April 2017.

In February 2018, Manuel Coronel Kautz, head of Interoceanic Grand Canal Authority of Nicaragua, told Agence France Presse work on the canal was still ongoing, but by that point analysts and activists widely viewed the canal project as defunct, with China having shifted its investment focus to Panama, the main competitor to a Nicaraguan canal. Following financial difficulties, HKND finally closed its offices in April 2018, leaving no forwarding address or telephone numbers to be reached.
Absent a 60% vote to revoke the legislation, HKND maintains the legal concessions established by the 2013 law, including for other infrastructures projects in Nicaragua, including ports, roads, railway and an airport.

The construction company provided a project description for review on open source, dated December 2014. The canal as planned would have been and would have three sections. The West Canal runs from Brito on the Pacific Ocean up the Rio Brito valley, crosses the continental divide, and after passing through the Rio Las Lajas valley enters Lake Nicaragua; its length would be . The Nicaragua Lake section measures and runs from south of San Jorge to south of San Miguelito. The Eastern Canal would be the longest section at and would be built along the Rio Tule valley through the Caribbean highland to the Rio Punta Gorda valley to meet the Caribbean Sea. A channel would have to be dug in the lake bottom, as it is not deep enough for large vessels to transit the canal.

Both the West Canal and the East Canal would each have one lock with 3 consecutive chambers to raise ships to the level of Lake Nicaragua that has an average water elevation of 31.3 m, range 30.2–33.0 m. The western Brito Lock would be inland from the Pacific, and the eastern Camilo Lock would be inland from the Caribbean Sea. The dimensions of each of the locks' chambers are long, wide, and threshold depth. As locks generally define the limit on the size of ships that can be handled, the Nicaragua Canal would have allowed passage for larger ships than those that pass through the Panama Canal. For comparison, the new third set of locks in the Panama expansion will only be long, wide, and deep.

No water from Lake Nicaragua was planned to be used to flood the locks; water would have come from local rivers and recycling using water-saving basins. The Camilo lock would have been built adjacent to a new dam of the upper Punta Gorda River that creates a reservoir. This Atlanta Reservoir (or Lake Atlanta) would have a surface area of 395 km. West of the Atlanta reservoir, the Rio Agua Zarca would have been dammed to create a second reservoir. This reservoir would have had a surface area of 48.5 km and hold 1,100 gigalitres. A hydropower facility would be built at the dam and would have generated over 10 megawatts of power to be used for Camilo Lock operations. Both locks would also be connected to the country's power grid and have back-up generator facilities. It was estimated that each lock would have used about 9 megawatts of power.

At each oceanic canal entrance, breakwaters and port facilities would have been constructed. The Pacific port would be named Brito Port and the Caribbean one Aguila Port. Initially these two ports would have helped during construction and later become international ports. Their design capacity was 1.68 million TEU/year and 2.5 million TEU/year, respectively. Existing port facilities at Corinto and Bluefields would have been improved to allow for shipment of material to the entry ports under construction. Fuel storage sites would be placed at the two port sites. Four lighthouses would be constructed at the entrances to the East and West Canals. In addition, the channel entrance on sea would have been be marked on both sides with a large sailing buoy about offshore and 2 light buoys would mark the passage through Lake Nicaragua.

A free trade zone with commercial facilities as well as tourist hotels and an international airport at Rivas were planned to be built when canal construction was advanced.

Appropriate road improvements were planned. The Pan-American Highway would have crossed the canal via a bridge. Nicaragua Route 25 (Acoyapa-San Carlos) on the eastern side of Lake Nicaragua would have gotten a ferry service. Both ports would get public road connections. HKND plans to construct a private gravel maintenance road on both sides of the canal.

The estimate for the workforce in 2020 was 3,700 people, and 12,700 in 2050 when traffic had increased.

Transit time would have been about 30 hours. It was projected that by 2020 3,576 ships would have transited the canal annually. The transit rate was expected to increase to 4,138 by 2030, and to 5,097 by 2050. For comparison, the Panama Canal handled 12,855 transits in 2009.

No significant construction took place. No "major works" such as dredging were planned to take place until after a Pacific Ocean wharf was built.

The apparent lack of experience of Wang and his HKND Group in large-scale engineering was cited as a risk.

On December 22, 2014, Wang announced construction started in Rivas, Nicaragua. Wang spoke during the starting ceremony of the first works of the Interoceanic Grand Canal in Brito town. Construction of the new waterway would have been by HKND Group—Hong Kong–based HK Nicaragua Canal Development Investment Co Ltd., which is controlled by Wang. According to HKND's announced plans in 2015, the project entailed the canal's development and building, and a supporting infrastructure. There would have been four main phases. The preconstruction phase included getting permits, acquiring land and machinery, and finalizing designs and plans. The early construction phase, started in December 2014, lasted through September 2015; it secured access to construction sites, but it did not provide the critical infrastructure nor mobilized the workforce. During the construction phase from September 2015 to March 2020, the canal would have been dug and the locks built along with accompanying infrastructure. The commissioning phase projected from April 2020 to June 2020 included lock testing and lock and tug boat operator training.

HKND described the project as the largest civil earth-moving operation in history. Most of this would have consisted of dry excavation to form the canal with an estimate of 4,019 million cubic metres of rock and soil. There would have been 739 MCM of freshwater dredging (Lake Nicaragua) and 241 MCM of marine dredging. Marine dredging of the oceanic access canal would be required on the Pacific side for 1.7 km and on the Caribbean Sea for 14.4 km. Disposal of excavation material would have been done along the canal in designated disposal areas typically within 3 km of the canal.

Two concrete plants and a steel plant were planned to support the project. While cement would have likely been imported, construction aggregate would have come from local quarries near the two locks.

HKND estimates that about 50,000 people would be employed during the five-year construction, about half of them from Nicaragua, 25% from China, and the remainder from various other countries. 1,400 workers would be in office or administrative positions and the rest in the field. The management offices would be rented or purchased near Rivas. Workers would live in one of nine camps, which besides food and shelter would also provide health care and security. These are “closed” camps—that is, workers cannot leave the camp unless part of an organized activity. The work schedule calls for 12-hour shifts for seven days a week. Domestic workers work two weeks and get one week off, while foreign workers are six weeks on and get two weeks off (management) or 22 weeks on, four weeks off (blue collar workers).

On 2 September 2015, Pang Wai Kwok (executive VP of HKND Group) was interviewed by Nicaraguan journalist Carlos Solis and said up to 3,000 people might be employed on the canal project within the year. However, the labor force depends on the contract bid's winner and Kwok said anyone in the world is eligible to work on the canal.

Project costs were estimated in the region of $40 billion to $50 billion Beside private money provided by Wang at the start-up, further influx of financial support was expected from investors. An IPO was reported to be in preparation by the end of 2014. XCMG, a state-owned Chinese construction company would have provided machinery and take 1.5% to 3% of HKND shares in return.

By the end of 2014, no major investors had been named. There had been speculation that the Chinese government would provide financial backing for the project, but China, as well as Wang, denied this. Wang lost nearly 85% of his wealth during the 2015 Chinese stock market crash, according to the Bloomberg Billionaires Index. In addition, Wang has had a string of setbacks for projects around the world since 2014. The economic development potential for the canal project is relatively measurable with Panama; however, the World Bank describes the country of Nicaragua as the second poorest in Latin America and the Caribbean. The World Bank has compiled a data list of projects that the impoverished nation has on record and the majority of the efforts are geared towards infrastructure and agricultural needs, but there is no explicit title project that would support the canal line of effort.

Wang admitted that the project has financial, political, and engineering risks. With the high cost of the project that independently has been estimated to be about $100 billion, it was not fully funded. The project was expected in 2014 to be completed in 2020, but Stratfor, an analyst agency, stated then that was an "unrealistic goal."

While the Nicaraguan National Bank reserves served as collateral on the part of Nicaragua, HKND had no such potential liability.

Following financial difficulties, HKND finally closed its Headquarter offices in China in April 2018, leaving no forwarding address or telephone numbers to be reached.

Some of the natural habitat of at least 22 endangered species would be destroyed in the construction. Another major environmental concern is the project's impact on Lake Nicaragua, the largest source of freshwater in Nicaragua. An oil spill would have serious and lasting consequences. Other problems include the possibility of dredging bringing up toxic sediments, the disruption of migration patterns of animal species, and the potential to introduce invasive species to the Lake. Environmental studies had not been released by HKND when the project officially started in December 2014. The Nicaraguan Academy of Sciences noted that hundreds of thousands of hectares of pristine forests and wetlands would be destroyed and pointed out that the environmental study performed for the canal was not independent.

President Daniel Ortega stated that he is "not concerned about harming the lake because it is already contaminated." Protesters fear that the canal would bring massive environmental destruction to Lake Nicaragua and the Atlantic Autonomous Regions. 400,000 hectares of tropical rain forest and wetlands would be destroyed. It would also encroach upon the habitats of animals such as Baird's tapir, the spider monkey, and the jaguar.

Richard Condit, from the Smithsonian Tropical Research Institute, believes that the project could be used as leverage for forest protection in a country that currently lacks "institutional capacity" to meet conservation needs. A Canadian pilot was the first fatality during the canal project. Atkinson was flying alone on the western side of Lake Nicaragua during an aerial survey.

The survey site was on the same side as NicarAgua–Dulce, which is the only ecotourism group in Nicaragua that is affiliated with The International Ecotourism Society, and it is located north of the proposed canal site. Falling in line with ecotourism, Nicaragua's Ministry of Environment and Natural Resources has promoted formal workshops at each level of education (primary, secondary, and post-secondary); however, there is no curriculum relevant to the pending canal project. The American-led Foundation for Sustainable Development is another partner that provides training initiatives to Nicaraguans that cannot access formal education. One of FSD's support sites is located at Tola, which is within close proximity of the proposed Brito–Pacific canal opening.

As the original Panama Canal still has capacity for Panamax-sized shipping and Panama has completed its Panama Canal expansion project, adding more capacity and allowing transit for even larger New Panamax size ships, projections for the Nicaragua canal's traffic may be optimistic. While the proposed Nicaragua Canal would be wide enough to accommodate Triple E class of mega container ships, which are too wide for the expanded Panama Canal, few ports are able to handle these ships at the present. Further, a coast-to-coast railway line may be built by China in Honduras and could affect utilization of the Nicaragua Canal. Also, North American land bridges in Mexico and the United States will compete in the traffic between Asia and the U.S. east coast. Thus, competition may undermine the Nicaragua Canal's economic viability if it was ever built.

The canal would affect neighboring economies, like Honduras and El Salvador, as they are part of the commercial treaty known as North Triangle of Central America (Triángulo Norte de Centroamérica). The GDP of each nation would be influenced by expanded export/import operations and trade cooperation through agencies like the promotion authority in El Salvador.

According to the official Environmental Impact Assessment carried out by ERM, the canal would require the relocation of around 30,000 people. However, according to human rights group Amnesty International it would "forcibly displace an estimated 120,000 people, including Rama and Creole communities from protected indigenous territories on the Caribbean coast." The report claims that communities established in the area of canals have been visited by foreigners, guarded by Nicaraguan authorities, measuring the lands of the inhabitants, and that laws passed by the Ortega government "authorizes HKND to expropriate whatever land it wants, while denying displaced families the right to appeal." Amnesty International also states that excessive forces and unjust arrests have been performed by Nicaraguan officials. However, the 2015 Nicaraguan government's report on the canal states: "The Nicaraguan government and HKND will guarantee that persons and families on the route of the canal's construction will have living conditions superior to those they currently have [without the canal]."





</doc>
<doc id="22090" url="https://en.wikipedia.org/wiki?curid=22090" title="Nu metal">
Nu metal

Nu metal (sometimes stylized as nü-metal) is a subgenre of that combines elements of with elements of other music genres such as hip hop, alternative rock, funk, industrial, and grunge. bands have drawn elements and influences from a variety of musical styles, including multiple genres of heavy metal. rarely features guitar solos or other displays of technical competence; the genre is heavily syncopated and based on guitar riffs. Many nu metal guitarists use that are down-tuned to play a heavier sound. DJs are occasionally featured in nu metal to provide instrumentation such as sampling, turntable scratching and electronic backgrounds. Vocal styles in include singing, rapping, screaming and growling. Nu metal is one of the key genres of the new wave of American heavy metal.

Nu metal became popular in the late 1990s with bands and artists such as Korn, Limp Bizkit, and Kid Rock all releasing albums that sold millions of copies. Nu metal's popularity continued during the early 2000s, with bands such as Papa Roach, Staind, and P.O.D. all selling multi-platinum albums, and came to a peak with Linkin Park's diamond-selling album "Hybrid Theory". However, by the the oversaturation of bands combined with the under-performance of a number of releases led to nu metal's decline, leading to the rise of metalcore and many nu metal bands disbanding or abandoning their established sound in favor of other genres.

During the 2010s, there was a nu metal revival; many bands that combine nu metal with other genres (for example, metalcore and deathcore) emerged and some nu metal bands from the 1990s and early 2000s returned to the nu metal sound. Bands like Staind, Linkin Park and Papa Roach went back to making nu metal songs after abandoning the genre. Bands like Of Mice & Men, Emmure, Issues and My Ticket Home would combine nu metal with metalcore or deathcore. In the 2010s, nu metal bands like From Ashes to New, Islander and Ded emerged. Nu metal received criticism from many fans of heavy metal and nu metal was often labelled with pejorative words like "mallcore". Some nu metal musicians did not view their own music as heavy metal while other nu metal musicians rejected the nu metal label.

Nu metal is also known as nü-metal and aggro-metal. It is a subgenre of alternative metal. MTV states that the early nu metal group Korn "arrived in 1993 into the burgeoning alternative metal scene, which would morph into nü-metal the way college rock became alternative rock." "Stereogum" has similarly claimed that nu metal was a "weird outgrowth of the Lollapalooza-era alt-metal scene". Nu metal merges elements of heavy metal music with elements of other music genres such as grunge, hip hop, and alternative rock.

Nu metal bands have been influenced by and have used elements of a variety of musical genres, including electronic music, funk, gothic rock, hardcore punk, punk rock, dance music, new wave, jazz, post-punk, symphonic rock and synth-pop. Nu metal bands also are influenced by and use elements of genres of heavy metal music such as death metal, rap metal, groove metal, funk metal, and thrash metal. Some nu metal bands, such as Static-X and Dope, made nu metal music with elements of industrial metal. In contrast with other heavy metal subgenres, nu metal tends to use the same structure of verses, choruses and bridges as those in pop music.

Nu metal is heavily syncopated and is based mostly on guitar riffs. Mid-song bridges and a general lack of guitar solos contrasts it with other genres of heavy metal. Kory Grow of "Revolver" wrote, "... [i]n its efforts to tune down and simplify riffs, effectively drove a stake through the heart of the guitar solo". Another contrast with other heavy metal genres is nu metal's emphasis on rhythm, rather than on complexity or mood, often its rhythm sounds like that of groove metal. The wah pedal is occasionally featured in nu metal music. Nu metal guitar riffs occasionally are similar to those of death metal.

Nu metal bassists and drummers are often influenced by funk and hip hop, respectively, adding to nu metal's rhythmic nature. Blast beats, which are common in heavy metal subgenres such as black metal and death metal, are extremely rare in nu metal. Nu metal's similarities with many heavy metal subgenres include its use of common time, distorted guitars, power chords and note structures primarily revolving around Dorian, Aeolian or Phrygian modes. While loud and heavily distorted electric guitars are a core feature of all metal genres, nu metal guitarists took the sounds of "violence and destruction" to new levels with their overdriven guitar tone, which music journalists Kitts and Tolinski compared to the "...sound [of] a Mack truck being crushed by a collapsing skyscraper."

Some nu metal bands use seven-string guitars that are generally down-tuned, rather than traditional Likewise, some bass guitarists use five-string and six-string instruments. in nu metal often features an emphasis on funk elements. In nu metal music, DJs are sometimes featured to provide instrumentation such as sampling, turntable scratching and electronic backgrounds. tends to have hip hop grooves and rhythms.

Vocal styles used in nu metal music include singing, rapping, screaming and growling. Vocals in nu metal are often rhythmic and influenced by hip hop. While some nu metal bands, such as Limp Bizkit and Linkin Park have rapping in their music, other nu metal bands, such as Godsmack and Staind, do not.

Nu metal bands occasionally feature hip hop musicians as guests in their songs; Korn's song "Children of the Korn" features the rapper Ice Cube, who performed on the band's 1998 Family Values Tour. The hip hop musician Nas was featured on Korn's song "Play Me", which is on the band's album "Take a Look in the Mirror". Limp Bizkit has recorded with multiple hip hop musicians including Method Man, Lil Wayne, Xzibit, Redman, DMX and Snoop Dogg. Linkin Park collaborated with hip hop musician Jay Z on their 2004 extended play "Collision Course". Kid Rock has recorded with hip hop musicians Eminem and Snoop Dogg. Trevor Baker of "The Guardian" wrote, "Bands such as Linkin Park, Korn and even the much reviled Limp Bizkit ... did far more to break down the artificial barriers between 'urban music' and rock than any of their more critically acceptable counterparts."

Lyrics in nu metal songs are often angry or nihilistic; many of the genre's lyrics focus on topics such as pain, angst, bullying, emotional issues, abandonment, betrayal, and personal alienation, in a way similar to those of grunge. Many nu metal lyrics that are about these topics tend to be in a very direct tone. However, some songs have lyrics that are about other topics. P.O.D. have used positive lyrics about promise and hope. The nu metal song "Bodies" by Drowning Pool is about moshing. Saliva guitarist Wayne Swinny said that the band's song "Badass" was "meant to be one of those 'sports anthem kind of songs'". "The Michigan Daily" wrote about Limp Bizkit's lyrics, writing that the band "used the nu-metal sound as a way to spin testosterone fueled fantasies into snarky white-boy rap. Oddly, audiences took frontman Fred Durst more seriously than he wanted, failing to see the intentional silliness in many of his songs". Limp Bizkit's lyrics also have been described as misogynistic. Dope's lyrics are usually about sex, drugs, parties, women, violence and relationships. According to Josh Chesler of the "Phoenix New Times", the lyrics of Deftones, who were once a nu metal band, "tend to have complex allusions and leave the songs open to many different interpretations."

Nu metal clothing typically consists of baggy pants, shirts, and shorts, JNCO jeans, Adidas tracksuits, sports jerseys, baseball caps, baggy hoodies, cargo pants, and sweatpants. Nu metal hairstyles and facial hairstyles include dreadlocks, Braids, spiky hair, chin beards, bald heads, goatees, frosted tips, and bleached or dyed hair. Common accessories in nu metal fashion include wallet chains, tattoos, and piercings, especially facial piercings. Nu metal fashion has been compared to hip hop fashion.

Some nu metal bands such as Motograter, Mushroomhead, Mudvayne, and Slipknot wear masks, jumpsuits, costumes, face paint, corpse paint or body paint. A few nu metal bands, such as Coal Chamber, Evanescence, and Kittie, are known for having gothic appearances.

Many heavy metal, alternative metal, industrial, funk metal, alternative rock, rap metal, and industrial metal artists and bands of the 1980s and early 1990s have been credited with laying groundwork for the development of nu metal by combining heavy guitar riffs with pop music structures and drawing influences from subgenres of heavy metal and other music genres; Faith No More, Primus, Helmet, Boo-Yaa T.R.I.B.E., Tool, Fear Factory, 24-7 Spyz, Hot Dawgz, Fishbone, Biohazard, Suicidal Tendencies, Infectious Grooves, Godflesh, Red Hot Chili Peppers, Nine Inch Nails, White Zombie, Mr. Bungle, Prong, Rage Against the Machine, and Ministry all have been highlighted as examples of this.

Groove metal and thrash metal bands of the same period such as Machine Head, Sepultura, Metallica, Pantera, Slayer, and Anthrax all have been cited as influential to nu metal as well. For example, Anthrax pioneered the rap metal genre by combining hip hop and rap with heavy metal on their 1987 EP "I'm the Man", which laid groundwork for development. Korn's lead vocalist Jonathan Davis said about Pantera guitarist Dimebag Darrell, "if there was no Dimebag Darrell, there would be no Korn".

In the 1990s, bands described as "neo-metal" by the author Garry Sharpe-Young emerged; these bands include Pantera, Strapping Young Lad, Machine Head, Biohazard and Fear Factory. Sharpe-Young wrote that these bands "had chosen to strip metal down to its raw, primal element" and that "neo-metal paved the way for nu-metal".

Nu metal is often influenced by hip hop. hip hop musicians Dr. Dre and Ice Cube have been a big influence on nu metal creators and pioneers Korn; guitarist Munky said the band were trying to emulate the samples of Dr. Dre's 1992 album "The Chronic". Munky and fellow Korn guitarist Head also said they tried to emulate samples by the hip hop group Cypress Hill. Both the Geto Boys and N.W.A. also have been a major influence on Korn. Fred Durst of Limp Bizkit has cited the hip hop group The Fat Boys as a major influence on him. The nu metal band Papa Roach cited rapper Nas and hip hop groups and Fugees as influences. Shifty Shellshock of the nu metal band Crazy Town cited Run–D.M.C. and Beastie Boys as influences. Josey Scott of the nu metal band Saliva cited LL Cool J, Beastie Boys, Public Enemy, N.W.A., Chuck D, Doug E. Fresh, and Whodini as influences. Sonny Sandoval of the nu metal band P.O.D. cited hip hop groups Boogie Down Productions and Run–D.M.C. as influences. Linkin Park member Mike Shinoda's hip hop influences include Boogie Down Productions, Public Enemy, N.W.A., and the Juice Crew. Chester Bennington, another member of Linkin Park, cited A Tribe Called Quest, KRS-One, Run–D.M.C., Public Enemy, N.W.A., Beastie Boys, and Rob Base as influences. Beastie Boys are a hip hop music group that influenced nu metal. Hip hop group Run–DMC was one of the first groups to combine rap with rock, paving the way for nu metal.

Joel McIver acknowledged Korn as the band that created and pioneered the nu metal genre with its demo "Neidermayer's Mind", which was released in 1993. McIver also acknowledged Korn as the band that started the new wave of American heavy metal, which is a heavy metal music movement that started in the 1990s. The aggressive riffs of Korn, the rapping of Limp Bizkit, and the melodic ballads of Staind created the sonic template for nu metal. The origins of the term "nu metal" are often attributed to the work of producer Ross Robinson, who has been called "The Godfather of Nu Metal" between producers. Robinson has produced for nu metal bands such as Korn, Limp Bizkit and Slipknot. Many of the first nu metal bands, such as Korn and Deftones, came from California; however, the genre soon spread across the United States and many bands arose from various states, including Limp Bizkit from Florida, Staind from Massachusetts, and Slipknot from Iowa. In the book "Brave Nu World", Tommy Udo wrote about the nu metal band Coal Chamber, "There's some evidence to suggest that Coal Chamber were the first band to whom the tag 'nu metal' was actually applied, in a live review in Spin magazine."

In 1994, Korn released their self-titled debut album, which is widely considered the first popular nu metal album. Korn had experienced underground popularity at this time; their debut album peaked at number 72 on the "Billboard" 200. However, earlier the same year, P.O.D.'s album "Snuff the Punk" was also released, which was later recognized as the first nu metal album. In 1995, the band Sugar Ray released its debut studio album "Lemonade and Brownies", an album described as nu metal. In 1995, Deftones released their debut album "Adrenaline". The album peaked at number 23 on the Heatseekers Albums chart on October 5, 1996. Deftones also were temporarily controversial in 1996 when their vocalist Chino Moreno was blamed by TV news reports for a riot that occurred at the 1996 U-Fest festival. Deftones' 1997 album "Around the Fur" peaked at number 29 on the "Billboard" 200 on November 15, 1997. Both "Adrenaline" and "Around the Fur" were certified gold by the Recording Industry Association of America (RIAA) in the summer of 1999."Adrenaline" and "Around the Fur" were certified platinum by the RIAA in September 2008 and June 2011, respectively.

Sepultura's 1996 album "Roots" features nu metal elements that were considered influential to the genre, while "Roots" itself was influenced by Korn's self-titled debut album. Few bands were playing nu metal until 1997 when bands such as Coal Chamber, Limp Bizkit, and Papa Roach all released their debut albums. Attention through MTV and Ozzy Osbourne's 1995 introduction of Ozzfest was integral to the launching of the careers of many nu metal bands, including Limp Bizkit in 1998.

Nu metal began to rise in popularity when Korn's 1996 album "Life Is Peachy" peaked at number 3 on the "Billboard" 200 and sold 106,000 copies in its first week of release. In 1997, Sugar Ray released its second studio album "Floored". The album achieved mainstream success very quickly and was certified 2x platinum by the RIAA on February 20, 1998. Although "Floored" is a nu metal album, the only song from the album that achieved chart success was the song "Fly", which is instead a reggae song. Although Sugar Ray continued to be extremely popular, the band abandoned the nu metal genre and became a pop rock band with its 1999 studio album "".

In 1998, nu metal became one of the most mainstream genres of music when Korn's third album "Follow the Leader" peaked at number 1 on the "Billboard" 200, was certified 5x platinum by the RIAA, and paved the way for other nu metal bands. At this point, many nu metal bands were signed to major record labels, and were playing combinations of heavy metal, hip hop, industrial, grunge and hardcore punk styles. Hip hop artists Vanilla Ice and Cypress Hill, along with heavy metal bands Sepultura, Primus, Fear Factory, Machine Head, and Slayer released albums that draw from the nu metal genre.

In 1999, Korn's fourth studio album "Issues" peaked at number 1 on the "Billboard" 200. The album was certified 3× platinum in one month. The album sold at least 573,000 copies in its first week of release and its first single "Falling Away From Me" peaked at number 8 on the Bubbling Under Hot 100 Singles chart. A little before the album was released, Korn appeared on an episode of "South Park" titled "Korn's Groovy Pirate Ghost Mystery", in which "Falling Away from Me" was premiered. During the late 1990s and early 2000s, multiple nu metal bands such as Korn, Limp Bizkit and P.O.D. appeared repeatedly on MTV's "Total Request Live".

The Woodstock 1999 festival featured multiple nu metal artists and bands such as Korn, Kid Rock, Godsmack, Limp Bizkit and Sevendust. During and after Limp Bizkit's performance at the festival, violence occurred and people tore plywood from the walls during the performance of the band's song "Break Stuff". Several sexual assaults were reported to have happened during the festival; a rape that was reported during Limp Bizkit's performance, and gang rape was reported to have occurred during Korn's set at the festival. Despite the incidents at the festival, Limp Bizkit's popularity and the sales of their then-recent album "Significant Other" were not affected. The album peaked at number 1 on the "Billboard" 200, selling 643,874 copies in its first week of release, topping over one million sold in two weeks, and eventually being certified 7x platinum in 2001. "Significant Other" sold at least 7,237,123 copies in the United States.

Orgy became popular in the late 1990s with their album "Candyass", which was certified platinum by the RIAA in July 1999. The band's cover of "Blue Monday" by New Order peaked at number 56 on the "Billboard" Hot 100. Godsmack's was released in 1998 and was certified 4× platinum in December 2001. In April 1999, Kid Rock's album "Devil Without a Cause" was certified by gold by the RIAA. The following month, "Devil Without a Cause", as Kid Rock predicted, went platinum. The album sold at least 9,300,000 copies in the United States and was certified 11x platinum. In 1999, Slipknot emerged with an extremely heavy nu metal sound, releasing their self-titled album, which was certified platinum in 2000 and 2x platinum in 2005. In a review of the band's self-titled album, Rick Anderson of AllMusic wrote about Slipknot, "You thought Limp Bizkit was hard? They're the Osmonds. These guys are something else entirely."

In 1999, Staind's second album "Dysfunction" was released; the track "Mudshovel" peaked at number 10 on the Mainstream Rock chart. "Dysfunction" was certified 2x platinum by the RIAA. In 2000, Limp Bizkit's third studio album "Chocolate Starfish and the Hot Dog Flavored Water" set a record for highest week-one sales of a rock album, selling over 1,000,000 copies in the United States in its first week of release—400,000 of which sold on its first day of release, making it the fastest-selling rock album ever and breaking the world record held for seven years by Pearl Jam's "Vs." "Chocolate Starfish and the Hot Dog Flavored Water" by Limp Bizkit was certified 6x platinum and sold at least 8,000,000 copies in the United States. That same year, both Papa Roach's second studio album "Infest" and Disturbed's debut studio album "The Sickness" were released. The RIAA certified "The Sickness" 4× platinum and "Infest" 3× platinum. Disturbed's song "Down with the Sickness" was certified platinum by the RIAA. Papa Roach's song "Last Resort" peaked at number 57 on the "Billboard" Hot 100 and at number 1 on the Modern Rock Tracks chart. In 2000, P.O.D.'s album "The Fundamental Elements of Southtown" went platinum in the United States and was the 143rd best-selling album of 2000. The album's song "Rock the Party (Off the Hook)" went to number 1 on MTV's "Total Request Live". In 2000, the hip hop group Cypress Hill released their fifth studio album "Skull & Bones", which features a and rap metal style. The album went platinum in the United States in two months. During the early 2000s, the nu metal band Incubus was very popular and made the albums "Make Yourself" and "Morning View", which both were certified 2x platinum by the RIAA.

Late in 2000, Linkin Park released their debut album "Hybrid Theory", which was the best-selling debut album by any artist of any genre in the 21st century. The album was also the best-selling album of 2001, selling more than albums such as "Celebrity" by NSYNC and "Hot Shot" by Shaggy. Linkin Park earned a Grammy Award for their second single "Crawling". Their fourth single, "In the End", was released late in 2001 and peaked at number 2 on the "Billboard" Hot 100 in March 2002. In 2001, Linkin Park's album "Hybrid Theory" sold 4,800,000 copies in the United States, making it the highest-selling album of the year. Linkin Park's album "Hybrid Theory" was certified diamond by the RIAA and sold at least 10,222,000 copies in the United States. In 2000, Godsmack released their second studio album "Awake", which was certified 2x platinum in March 2002. The album's title track peaked at number 1 on the Mainstream Rock chart. Both the album's title track and the song "Sick of Life" have been featured on the United States Navy's television commercials.

Crazy Town's debut album "The Gift of Game" peaked at number 9 on the "Billboard" 200, went platinum in February 2001, and sold at least 1,500,000 copies in the United States. Worldwide, the album sold at least 2,500,000 copies. Staind's 2001 album "Break the Cycle" debuted at number 1 on the Billboard 200 with at least 716,000 copies sold in its first week of release, selling more than albums such as "Survivor" by Destiny's Child, "Lateralus" by Tool and "Miss E... So Addictive" by Missy Elliott. "Break the Cycle" by Staind was certified 5x platinum by the RIAA in 2003. In March 2001, Saliva released their second album "Every Six Seconds" and the album was certified platinum. The album's song "Click Click Boom" was used as the theme song for WWE's No Mercy event of 2001. "Click Click Boom" also has been played during football games. Saliva's song "Your Disease" peaked at number 7 on "Billboard" Modern Rock Tracks chart and peaked at number 3 on "Billboard" Mainstream Rock chart.

In August 2001, Slipknot released their album "Iowa", which peaked at number 3 on the "Billboard" 200 and went platinum in October 2001. Critic John Mulvey called the album the "absolute triumph of nu metal". P.O.D.'s 2001 album "Satellite" went and peaked at number 6 on the "Billboard" 200. P.O.D.'s popularity continued in the year 2002. On June 5, 2001, Drowning Pool released a nu metal album titled "Sinner", which features the song "Bodies". The album went platinum on August 23, 2001 and its song "Bodies" became one of the most frequently played videos on MTV for new bands. "Bodies" went to number 6 on the Mainstream Rock chart and was used by Boston Red Sox closer Jonathan Papelbon as his theme song.

Alien Ant Farm's album "Anthology", which was released in 2001, sold at least 1,900,000 copies in the United States and was certified platinum by the RIAA the same year. Alien Ant Farm's cover of Michael Jackson's song "Smooth Criminal" peaked at number 23 on the "Billboard" Hot 100. In 2001, System of a Down's album "Toxicity" peaked at number 1 on the "Billboard" 200. In November 2002, "Toxicity" was certified 3x platinum by the RIAA. In 2002, the soundtrack album for the film "The Scorpion King" was released and peaked at number 1 on the Top Soundtracks chart; it features multiple nu metal bands such as Drowning Pool, Coal Chamber, Lifer, Sevendust, Flaw and Godsmack. Godsmack's track "I Stand Alone" was the most played active rock song in 2002 for fourteen consecutive weeks. "I Stand Alone" also peaked at number 1 on the Mainstream Rock chart.

In 2003, MTV wrote that nu metal's mainstream popularity was declining, citing that Korn's fifth album "Untouchables" and Papa Roach's third album "Lovehatetragedy" both sold less than the bands' previous releases. Korn's lead vocalist Jonathan Davis blamed music piracy for the amount of sales of "Untouchables" because the album had been leaked to the Internet more than four months before its official release date. MTV also wrote that nu metal bands were played less frequently on radio stations and MTV began focusing on other musical genres. MTV wrote that Papa Roach's third album "Lovehatetragedy" has less hip hop elements than the band's previous album "Infest" and also said that Saliva's 2002 album "Back into Your System" has less elements than the band's 2001 album "Every Six Seconds". MTV also wrote that Crazy Town's second album "Darkhorse" had no hit singles and sold less than the band's previous album "The Gift of Game". MTV wrote that although Kid Rock's album "Cocky" had characteristics of the musician's 1998 album "Devil Without a Cause", "Cocky" song "Forever", which featured the style of Kid Rock's song "Bawitdaba", was not as popular as "Cocky" country song "Picture". MTV also wrote, "Another cause for nü-metal and rap-rock's slip from the spotlight could be a diluted talent pool caused by so many similar-sounding bands. American Head Charge, Primer 55, Adema, Cold, the Union Underground, Dope, Apartment 26, Hed (Planet Earth) and Skrape—all of whom released albums between 2000 and 2001—left more of a collective impression than individual ones".

Despite what MTV wrote, the RIAA certified Korn's album "Untouchables" platinum in July 2002, and one of the album's singles, "Here to Stay", peaked at number 72 on the "Billboard" Hot 100, won a Grammy, received much radio play, and peaked at number one on MTV's "Total Request Live" twice. "Untouchables" sold at least 434,000 copies in first week of release and peaked at number 2 on the Billboard 200. "Thoughtless", another single from Korn's album "Untouchables", also was successful; the single reached number 11 on the "Billboard" Modern Rock Tracks chart and number 6 on the "Billboard" Mainstream Rock chart. However, "Untouchables" still did not sell as many copies as Korn's most commercially successful album, "Follow the Leader". Papa Roach's song "She Loves Me Not", which is from the band's 2002 album "Lovehatetragedy", peaked at number 76 on the "Billboard" Hot 100.

Despite the MTV report that nu metal was declining, nu metal remained extremely popular with bands such as Linkin Park, Godsmack, Trapt, and Evanescence. Linkin Park's remix album "Reanimation" was released in July 2002 and sold more than a million copies that year, which MTV described as "impressive for a remix album". Trapt's 2002 song "Headstrong" launched the band into the mainstream; the song peaked at number 16 on the "Billboard" Hot 100, number 4 on the Mainstream Top 40 chart and number 1 on the "Billboard" Mainstream Rock Tracks chart. Trapt's song "Still Frame" peaked at number 69 on the "Billboard" Hot 100. The band's self-titled album was certified platinum by the RIAA in 2003. Evanescence's debut album "Fallen" was released in March 2003. Johnny Loftus of AllMusic noted the nu metal sound of the album. "Fallen" Grammy Award-winning lead single "Bring Me to Life" peaked at number 5 on the "Billboard" Hot 100 chart and number 1 on the Mainstream Top 40 chart. In 2003, Linkin Park's album "Meteora" peaked at number 1 on the "Billboard" 200 and sold at least 810,000 copies in its first week of being released. "Meteora" by Linkin Park and "Fallen" by Evanescence ranked third and fourth respectively on the best-selling albums of 2003. Both Linkin Park and Evanescence released high-charting singles throughout 2003 to "Fallen" by Evanescence sold at least 7,600,000 copies in the United States and "Meteora" by Linkin Park sold at least 6,100,000 copies in the United States. In 2003, Korn released a song called "Did My Time", which peaked at number 38 on the "Billboard" Hot 100. That same year, Godsmack released their third studio album "Faceless", which peaked at number 1 on the "Billboard" 200 and was certified platinum by the RIAA in its first five weeks of being released.

Most of nu metal's mainstream popularity sharply declined in 2003 and 2004. After a period of mainstream success with bands such as Godsmack, Trapt, Linkin Park and Evanescence, nu metal declined in popularity. Limp Bizkit's 2003 album "Results May Vary", which features alternative rock music and peaked at number 3 on the "Billboard" 200, with sales of at least 325,000 copies in its first week of being released. In three weeks of being released, the album had sold at least 500,000 copies. In 2004, Blabbermouth.net reported that, according to Nielsen SoundScan, "Results May Vary" sold 1,337,356 copies in the United States. However, the album garnered very poor critical reception and consequently performed much weaker than previous Limp Bizkit albums such as "Significant Other" and "Chocolate Starfish and the Hot Dog Flavored Water". Although Korn's album "Take a Look in the Mirror" song "Did My Time" peaked at number 38 on the "Billboard" Hot 100, the album sold less than previous Korn albums "Issues" and "Untouchables". In 2004, post-punk revival bands such as Jet and The Darkness were achieving mainstream success as the popularity of nu metal declined. During the the popularity of emo exceeded the declining popularity of nu metal. Also, during the metalcore, a fusion of extreme metal and hardcore punk, became one of the most popular genres in the new wave of American heavy metal.

In the mid-to-late 2000s, many nu metal bands experimented with other genres and sounds. Linkin Park's third studio album "Minutes to Midnight", released in 2007, was noted for its complete departure from the band's nu metal sound. Nu metal bands such as Disturbed and Drowning Pool moved to a hard rock or standard heavy metal sound. Slipknot also departed from their nu metal sound and included elements of groove metal, death metal and thrash metal into their music. Staind and Papa Roach moved to lighter sounds. Staind's 2003 album "14 Shades Of Grey" does not express as much anger as the band's previous albums and shows the band's departure from heavy metal elements and a movement towards a lighter sound. Papa Roach abandoned the nu metal genre with their 2004 album "Getting Away with Murder", moving to a hard rock style.

Soulfly moved away from the nu metal style and moved to styles such as death metal and thrash metal. Kittie abandoned the style and started making music with elements of genres such as black metal and death metal. Korn and Mudvayne continued being mainstream during the mid-2000s. Nonetheless, they did not completely abandon the nu metal style. Korn combined their earlier sound with influences from other genres, such as industrial. Korn's songs "Coming Undone" and "Twisted Transistor", which both are on their 2005 album "See You on the Other Side", both reached the "Billboard" Hot 100; Pop music producers The Matrix helped produce the album. Mudvayne's 2005 album "Lost and Found" was seen as gravitating towards a more accessible sound. The album's song "Happy?" peaked at number 89 on the "Billboard" Hot 100 and at number 91 on "Billboard" Pop 100 chart. In 2005, Limp Bizkit released a record called "The Unquestionable Truth (Part 1)" without promoting and advertising the record. The album was not very popular; its sales fell 67% during its second week of release. In 2006, Limp Bizkit went on hiatus.

During the 2010s, there was a discussion within media of a possible nu metal revival because of bands fusing nu metal with other genres, the return of nu metal bands, formerly nu metal bands going back to the nu metal genre and nu metal bands forming. Despite the lack of radio play and popularity, some nu metal bands recaptured some of their former popularity as they released albums in a nu metal style. Korn's 2010 studio album "" sold 63,000 copies during its first week of release and peaked at number 2 on the "Billboard" 200. As of December 6, 2011, the album had sold at least 185,000 units in the United States. Korn's vocalist Jonathan Davis said with their new album the band "want to go back to that old-school vibe". He also said "It's gonna be very raw, it's gonna be old school like the first Korn records".

In 2011, Limp Bizkit's sixth studio album "Gold Cobra" was released; it sold 27,000 copies during its first week in the United States and peaked at number 16 on the "Billboard" 200. That same year, Staind's self-titled album was released; it shows the band returning to their heavier nu metal style. The album debuted at number 5 on the "Billboard" 200, selling 47,000 copies in its first week of release, making it the band's fifth consecutive top-five album. In October 2011, Evanescence's self-titled album debuted at number 1 on the "Billboard" 200 and other United States charts and sold over 127,000 copies in the first week. In December that year, Korn released their album "The Path of Totality", which sold 55,000 copies in its first week. The album combines nu metal with dubstep. Both the "Phoenix New Times" and the "LA Weekly" cited "The Path of Totality" as a new direction for nu metal. The album won a Revolver Golden God award for "Album of the Year".

In 2014, Linkin Park returned to their nu-metal roots with their sixth studio album "The Hunting Party". The album peaked at number three on the "Billboard" 200, with first-week sales of 110,000 copies in the United States. In 2014, Slipknot released its fifth studio album "". With ".5: The Gray Chapter", Slipknot returned to the nu metal genre. ".5: The Gray Chapter" peaked at number one on the "Billboard" 200.

Many metalcore and deathcore groups such as My Ticket Home, Stray from the Path, Emmure, Of Mice & Men, Suicide Silence, and Issues, all gained moderate popularity in the 2010s and used elements from nu metal. This fusion has sometimes been referred to as "nu metalcore". Suicide Silence's 2011 album "The Black Crown", which features elements of nu metal and deathcore, peaked at number 28 on the "Billboard" 200. In 2014, Issues' self-titled debut album peaked at number 9 on the same chart. The album features elements of metalcore, nu metal, pop and R&B. Of Mice & Men's 2014 album "Restoring Force", which features elements of nu metal, peaked at number 4 on the "Billboard" 200. Bring Me the Horizon, previously known for a much heavier style of music, released their fifth album "That's the Spirit", which peaked at number 2 on the "Billboard" 200, in 2015. The album draws from multiple genres, including nu metal; however, the band completely abandoned their metalcore style. In the 2010s, nu metal bands like From Ashes to New, Ded, and Islander emerged. The idea of a revival of the genre has been explicitly mentioned by journalists. The likes of Islander, My Ticket Home, Sworn In, DangerKids, Stray from the Path, and Issues have been mentioned as examples of this musical movement. In the mid–late 2010s, genres like emo rap and trap metal emerged.

Despite its popularity in the late 1990s and early 2000s, nu metal has often been criticized by many fans of heavy metal music, often being labelled with derogatory terms such as "mallcore" and "whinecore". Gregory Heaney of AllMusic called nu metal "one of metal's more unfortunate pushes into the mainstream". Lucy Jones of "NME" called nu metal "the worst genre of all time". In "Metal: The Definitive Guide : Heavy, NWOBH, Progressive, Thrash, Death ... ", Garry Sharpe-Young described as "a dumbed-down and—thankfully short[-]lived exercise". When Machine Head moved to the nu metal genre with their album "The Burning Red" and their vocalist Robb Flynn spiked his hair in the fashion of many nu metal musicians, the band were accused of "selling out" and many fans criticized their change of appearance and musical style. Machine Head's drummer Dave McClain said, "Pissing people off isn't a bad thing, you know? For people to be narrow-minded is bad ... [i]t doesn't bother us at all, we know we're going to piss people off with this record, but some people hopefully will actually sit down and listen to the whole record". Robb Flynn, Machine Head's vocalist, said 

Jonathan Davis, the vocalist of Korn, spoke about the criticism of nu metal from heavy metal fans, saying Lamb of God's vocalist Randy Blythe criticized the nu metal genre and spoke about its loss of popularity in 2004, saying, "Nu-metal sucks, so that's why that's dying off. And I think ... ... people are ready for angrier music. I think people are ready for something that's real, not, you know, 'I did it all for the nookie.'" Megadeth frontman Dave Mustaine said he would "rather have his eyelids pulled out" than listen to nu metal. Guitarist Gary Holt of Exodus and Slayer said that he "was so glad about" the decline of .

Some musicians who influenced nu metal have tried to distance themselves from the subgenre and its bands. Mike Patton, the vocalist of Faith No More and Mr. Bungle, tried to distance himself from the subgenre and criticized it, even though he is featured on the song "Lookaway" on heavy metal band Sepultura's album "Roots", which also features Jonathan Davis. Patton said of his music's influence on nu metal, "I feel no responsibility for that, it's their mothers' fault, not mine". Helmet member Page Hamilton said, "It's frustrating that people write [us] off because we're affiliated with or credited with or discredited with creating and rap metal ... which we sound nothing like". However, Page Hamilton appeared on the song "All for Nothing" on Linkin Park's album "The Hunting Party".

Although Trent Reznor of Nine Inch Nails has said he knows some Korn members and that he thinks they are "cool guys", he also criticized nu metal, saying:
In response to reports that Fred Durst, lead singer of Limp Bizkit, is a big fan of Tool, the latter's vocalist Maynard James Keenan said, "If the lunch-lady in high school hits on you, you appreciate the compliment, but you're not really gonna start dating the lunch-lady, are ya?" While Durst has cited Rage Against the Machine as a major influence, Rage Against the Machine's bassist Tim Commerford is open about his hatred of Limp Bizkit, describing them as "one of the dumbest bands in the history of music". At the 2000 MTV Video Music Awards, Limp Bizkit won the Best Rock Video category for their song "Break Stuff", beating Rage Against the Machine's "Sleep Now in the Fire". When Limp Bizkit accepted their award, Commerford went on stage and climbed up a backdrop, rocking back and forth. After the incident, Commerford was arrested and spent a night in jail. Commerford said in 2015, "I do apologize for Limp Bizkit. I really do. I feel really bad that we inspired such bullshit ... They're gone, though. That's the beautiful thing."

Some nu metal musicians have rejected the label nu metal and have tried to distance themselves from it. Slipknot prefer to distance themselves from other nu metal groups, describing their own music as "metal metal" and equate their link to nu metal as a coincidence of their time of emergence.

Jonathan Davis has rejected the nu metal label, saying "We're not 'rap rock,' we're not 'nu-metal ... We might have invented a new genre of heavy music or rock, but I believe the term 'nu-metal' was made up for all the bands that followed us. Those guys to me are nu-metal. And we're just Korn." In 2014, Davis spoke about the nu metal label, saying:

Staind's vocalist Aaron Lewis rejected the nu metal label, saying, "if we get called a 'nu metal' band one more time, I don't even know what I'm going to do!" Chino Moreno, vocalist of Deftones, rejected the nu metal label saying "We told motherfuckers not to lump us in with nu metal because when those bands go down we aren't going to be with them". As Deftones abandoned the nu metal sound of their early work, Moreno tried to distance himself from nu metal bands and began to criticize the bands and their albums, including Korn's 2002 album "Untouchables"; he said, "As Korn go on, it's the same things—bad childhoods and mean moms. It gets too old after a while. How old is Jonathan [Davis]? Thirty? How long has it been since he lived with his parents?" Davis responded saying, "Obviously, Chino hasn't listened to the words on the rest of my albums because they're nothing about my parents or my childhood." Moreno also said, "A big problem for me was opening for Limp Bizkit and Linkin Park, two bands that wouldn't exist if it weren't for me, straight up!". Mike Shinoda of Linkin Park spoke about the nu metal label in an interview with "NME", saying "We never held the flag for nu-metal—it was associated with frat rock. Arrogant, misogynistic, and full of testosterone; we were reacting against that." Wes Borland of Limp Bizkit said that he "never liked or condoned" the term "nu metal" in any way, and said he does not understand "how so many bands that sound nothing alike can be put into" the nu metal genre. Mike Wengren of Disturbed said that he doesn't think Disturbed "were ever a nu-metal band to begin with".

Jody MacGregor of FasterLouder called nu metal "music's most hated genre" conversely, he also wrote that nu metal is "not as bad as people think", praising several examples of the genre. Despite the fact that multiple nu metal musicians rejected the nu metal label, Limp Bizkit's vocalist Fred Durst defended it, saying "Nu metal let people open up and it meant something to people. It really did." Coal Chamber's vocalist Dez Fafara also defended nu metal. He said he is proud to be associated with the subgenre and that nu metal bands "broke new musical ground" saying, "I think 'hair metal' was cheesy. [But] I think 'nu metal' was different. I think what's beautiful about 'nu metal' is it's different. And you've got so many different influences." Chester Bennington of Linkin Park said he accepted the nu metal label, saying:

Jack Porter of "The Michigan Daily" defended , writing 

In addition to criticizing nu metal, many heavy metal musicians have rejected nu metal as a legitimate subgenre of heavy metal, saying it is not "true heavy metal". Some nu metal musicians have tried to distance themselves from being heavy metal at all. For example, Korn's Jonathan Davis rejected the "heavy metal" label. When talking with "Vice", Davis spoke about Korn being called a heavy metal band, saying, "I never thought of us to be metal to begin with. Yeah, we're heavy and downtuned, but metal, to me, is like Judas Priest and Iron Maiden. That's metal, man. I always thought of us as a funk band. That funky, groovy shit." Godsmack's vocalist Sully Erna also rejected the "heavy metal" label and said he views Godsmack as a hard rock band. Though he was originally more tolerant of the concept, Linkin Park's vocalist Chester Bennington later expressed some disagreement with his band being labeled a heavy metal group because he felt the term limited the scope of the band's actual style. He elaborated:




</doc>
<doc id="22091" url="https://en.wikipedia.org/wiki?curid=22091" title="Ncurses">
Ncurses

ncurses (new curses) is a programming library providing an application programming interface (API) that allows the programmer to write text-based user interfaces in a terminal-independent manner. It is a toolkit for developing "GUI-like" application software that runs under a terminal emulator. It also optimizes screen changes, in order to reduce the latency experienced when using remote shells.

There are bindings for ncurses in a variety of programming languages, including Ada, Python, Gambas, Ruby, PHP, JavaScript, and Perl.

As the new version, ncurses is a free-software emulation of the System V Release 4.0 (SVr4) curses, which was itself an enhancement over the discontinued 4.4 BSD curses. The XSI Curses standard issued by X/Open is explicitly and closely modeled on System V.

The first curses library was developed at the University of California at Berkeley, for a BSD operating system, around 1980 to support Rogue, a text-based adventure game. It originally used the termcap library, which was used in other programs, such as the vi editor.

The success of the BSD curses library prompted Bell Labs to release an enhanced curses library in their System V Release 2 Unix systems. This library was more powerful and instead of using termcap, it used terminfo. However, due to AT&T policy regarding source-code distribution, this improved curses library did not have much acceptance in the BSD community.

Around 1982, Pavel Curtis started work on a freeware clone of the Bell Labs curses, named pcurses, which was maintained by various people through 1986.

The pcurses library was further improved when Zeyd Ben-Halim took over the development effort in late 1991. The new library was released as ncurses in November 1993, with version 1.8.1 as the first major release. Subsequent work, through version 1.8.8 (M1995), was driven by Eric S. Raymond, who added the form and menu libraries written by Juergen Pfeifer. Since 1996, it has been maintained by Thomas E. Dickey.

Most ncurses calls can be easily ported to the old curses. System V curses implementations can support BSD curses programs with just a recompilation. However, a few areas are problematic, such as handling terminal resizing, since no counterpart exists in the old curses.

Ncurses can use either terminfo (with extensible data) or termcap. Other implementations of curses generally use terminfo; a minority use termcap. Few (mytinfo was an older exception) use both.

Ncurses is a part of the GNU Project. It is one of the few GNU files not distributed under the GNU GPL or LGPL; it is distributed under a permissive free software licence, similar to the MIT License. This is due to the agreement made with the Free Software Foundation at the time the developers assigned their copyright.

When the agreement was made to pass on the rights to the FSF, there was a clause that stated:

The Foundation promises that all distribution of the Package, or of any work "based on the Package", that takes place under the control of the Foundation or its agents or assignees, shall be on terms that explicitly and perpetually permit anyone possessing a copy of the work to which the terms apply, and possessing accurate notice of these terms, to redistribute copies of the work to anyone on the same terms.

According to the maintainer Thomas E. Dickey, this precludes relicensing to the GPL in any version, since it would place restrictions on the programs that will be able to link to the libraries.

There are hundreds of programs which use ncurses. Some, such as GNU Screen and w3m, use only the termcap interface and perform screen management themselves. Others, such as GNU Midnight Commander and YaST, use the curses programming interface.



</doc>
<doc id="22092" url="https://en.wikipedia.org/wiki?curid=22092" title="NBA (disambiguation)">
NBA (disambiguation)

The NBA is the National Basketball Association, a men's professional basketball league in North America.

NBA may also refer to:







</doc>
<doc id="22093" url="https://en.wikipedia.org/wiki?curid=22093" title="National Basketball Association">
National Basketball Association

The National Basketball Association (NBA) is an American men's professional basketball league. It is composed of 30 teams (29 in the United States and 1 in Canada) and is one of the four major professional sports leagues in the United States and Canada. It is the premier men's professional basketball league in the world.

The league was founded in New York City on June 6, 1946, as the Basketball Association of America (BAA). It changed its name to the National Basketball Association on August 3, 1949, after merging with the competing National Basketball League (NBL). The NBA's regular season runs from October to April, with each team playing 82 games. The league's playoff tournament extends into June. As of 2020, NBA players are the world's best paid athletes by average annual salary per player.

The NBA is an active member of USA Basketball (USAB), which is recognized by the FIBA (International Basketball Federation) as the national governing body for basketball in the United States. The league's several international as well as individual team offices are directed out of its head offices in Midtown Manhattan, while its NBA Entertainment and NBA TV studios are directed out of offices located in Secaucus, New Jersey.

The NBA is the third wealthiest professional sport league after the NFL and the MLB by revenue.

The Basketball Association of America was founded in 1946 by owners of the major ice hockey arenas in the Northeastern and Midwestern United States and Canada. On November 1, 1946, in Toronto, Ontario, Canada, the Toronto Huskies hosted the New York Knickerbockers at Maple Leaf Gardens, in a game the NBA now refers to as the first game played in NBA history. The first basket was made by Ossie Schectman of the Knickerbockers. Although there had been earlier attempts at professional basketball leagues, including the American Basketball League and the NBL, the BAA was the first league to attempt to play primarily in large arenas in major cities. During its early years, the quality of play in the BAA was not significantly better than in competing leagues or among leading independent clubs such as the Harlem Globetrotters. For instance, the 1948 ABL finalist Baltimore Bullets moved to the BAA and won that league's 1948 title, and the 1948 NBL champion Minneapolis Lakers won the 1949 BAA title. Prior to the 1948–49 season, however, NBL teams from Fort Wayne, Indianapolis, Minneapolis, and Rochester jumped to the BAA, which established the BAA as the league of choice for collegians looking to turn professional.

On August 3, 1949, the remaining NBL teams–Syracuse, Anderson, Tri-Cities, Sheboygan, Denver, and Waterloo–merged into the BAA. In deference to the merger and to avoid possible legal complications, the league name was changed to the present National Basketball Association, even though the merged league retained the BAA's governing body, including Maurice Podoloff as president. To this day, the NBA claims the BAA's history as its own. It now reckons the arrival of the NBL teams as an expansion, not a merger, and does not recognize NBL records and statistics.

The new league had seventeen franchises located in a mix of large and small cities, as well as large arenas and smaller gymnasiums and armories. In 1950, the NBA consolidated to eleven franchises, a process that continued until 1953–54, when the league reached its smallest size of eight franchises: the New York Knicks, Boston Celtics, Philadelphia Warriors, Minneapolis Lakers, Rochester Royals, Fort Wayne Pistons, Tri-Cities Blackhawks, and Syracuse Nationals, all of which remain in the league today. The process of contraction saw the league's smaller-city franchises move to larger cities. The Hawks shifted from the Tri-Cities to Milwaukee in 1951, and then to St. Louis in 1955. The Rochester Royals moved from Rochester, New York, to Cincinnati in 1957 and the Pistons moved from Fort Wayne, Indiana, to Detroit in 1957.

Japanese-American Wataru Misaka broke the NBA color barrier in the 1947–48 season when he played for the New York Knicks. He remained the only non-white player in league history prior to the first African-American, Harold Hunter, signing with the Washington Capitols in 1950. Hunter was cut from the team during training camp, but several African-American players did play in the league later that year, including Chuck Cooper with the Celtics, Nathaniel "Sweetwater" Clifton with the Knicks, and Earl Lloyd with the Washington Capitols. During this period, the Minneapolis Lakers, led by center George Mikan, won five NBA Championships and established themselves as the league's first dynasty. To encourage shooting and discourage stalling, the league introduced the 24-second shot clock in 1954. If a team does not attempt to score a field goal (or the ball fails to make contact with the rim) within 24 seconds of obtaining the ball, play is stopped and the ball given to its opponent.

In 1957, rookie center Bill Russell joined the Boston Celtics, which already featured guard Bob Cousy and coach Red Auerbach, and went on to lead the franchise to eleven NBA titles in thirteen seasons. Center Wilt Chamberlain entered the league with the Warriors in 1959 and became a dominant individual star of the 1960s, setting new single game records in scoring (100) and rebounding (55). Russell's rivalry with Chamberlain became one of the greatest rivalries in the history of American team sports.

The 1960s were dominated by the Celtics. Led by Russell, Cousy, and Auerbach, Boston won eight straight championships in the NBA from 1959 to 1966. This championship streak is the longest in NBA history. They did not win the title in 1966–67, but regained it in the 1967–68 season and repeated in 1969. The domination totaled nine of the ten championship banners of the 1960s.

Through this period, the NBA continued to evolve with the shift of the Minneapolis Lakers to Los Angeles, the Philadelphia Warriors to San Francisco, the Syracuse Nationals to Philadelphia to become the Philadelphia 76ers, and the St. Louis Hawks moving to Atlanta, as well as the addition of its first expansion franchises. The Chicago Packers (now Washington Wizards) became the ninth NBA team in 1961. From 1966 to 1968, the league expanded from 9 to 14 teams, introducing the Chicago Bulls, Seattle SuperSonics (now Oklahoma City Thunder), San Diego Rockets (who moved to Houston four years later), Milwaukee Bucks, and Phoenix Suns.

In 1967, the league faced a new external threat with the formation of the American Basketball Association (ABA). The leagues engaged in a bidding war. The NBA landed the most important college star of the era, Kareem Abdul-Jabbar (then known as Lew Alcindor). However, the NBA's leading scorer, Rick Barry, jumped to the ABA, as did four veteran referees—Norm Drucker, Earl Strom, John Vanak, and Joe Gushue.

In 1969, Alan Siegel, who oversaw the design of Jerry Dior's Major League Baseball logo a year prior, created the modern NBA logo inspired by the MLB's. It incorporates the silhouette of Jerry West, based on a photo by Wen Roberts, although NBA officials denied a particular player as being its influence because, according to Siegel, "They want to institutionalize it rather than individualize it. It's become such a ubiquitous, classic symbol and focal point of their identity and their licensing program that they don't necessarily want to identify it with one player." The iconic logo debuted in 1971 (with a small change to the typeface on the NBA wordmark in 2017) and would remain a fixture of the NBA brand.

The ABA succeeded in signing a number of major stars in the 1970s, including Julius Erving of the Virginia Squires, in part because it allowed teams to sign college undergraduates. The NBA expanded rapidly during this period, one purpose being to tie up the most viable cities. From 1966 to 1974, the NBA grew from nine franchises to 18. In 1970, the Portland Trail Blazers, Cleveland Cavaliers, and Buffalo Braves (now the Los Angeles Clippers) all made their debuts expanding the league to 17. The New Orleans Jazz (now in Utah) came aboard in 1974 bringing the total to 18. Following the 1976 season, the leagues reached a settlement that provided for the addition of four ABA franchises to the NBA, raising the number of franchises in the league at that time to 22. The franchises added were the San Antonio Spurs, Denver Nuggets, Indiana Pacers, and New York Nets (now the Brooklyn Nets). Some of the biggest stars of this era were Abdul-Jabbar, Barry, Dave Cowens, Erving, Elvin Hayes, Walt Frazier, Moses Malone, Artis Gilmore, George Gervin, Dan Issel, and Pete Maravich. The end of the decade, however, saw declining TV ratings, low attendance and drug-related player issues – both perceived and real – that threatened to derail the league.

The league added the ABA's three-point field goal beginning in 1979. That same year, rookies Larry Bird and Magic Johnson joined the Boston Celtics and Los Angeles Lakers respectively, initiating a period of significant growth in fan interest in the NBA. The two had faced each other in the 1979 NCAA Division I Basketball Championship Game, and they later played against each other in three NBA Finals (1984, 1985, and 1987). In the 10 seasons of the 1980s, Johnson led the Lakers to five titles while Bird led the Celtics to three titles. Also in the early 1980s, the NBA added one more expansion franchise, the Dallas Mavericks, bringing the total to 23 teams. Later on, Larry Bird won the first three three-point shooting contests. On February 1, 1984 David Stern became commissioner of the NBA. Stern has been recognized as playing a major role in the growth of the league during his career.

Michael Jordan entered the league in 1984 with the Chicago Bulls, spurring more interest in the league. In 1988 and 1989, four cities got their wishes as the Charlotte Hornets, Miami Heat, Orlando Magic, and Minnesota Timberwolves made their NBA debuts, bringing the total to 27 teams. The Detroit Pistons won the back-to-back NBA Championships in 1989 and 1990, led by coach Chuck Daly and guard Isiah Thomas. Jordan and Scottie Pippen led the Bulls to two three-peats in eight years during the 1991–1998 seasons. Hakeem Olajuwon won back-to-back titles with the Houston Rockets in 1994 and 1995.

The 1992 Olympic basketball Dream Team, the first to use current NBA stars, featured Michael Jordan as the anchor, along with Bird, Johnson, David Robinson, Patrick Ewing, Scottie Pippen, Clyde Drexler, Karl Malone, John Stockton, Chris Mullin, Charles Barkley, and star NCAA amateur Christian Laettner. The team was elected to the Naismith Memorial Basketball Hall of Fame, and 11 players and three coaches have been elected to the Hall of Fame as individuals.

In 1995, the NBA expanded to Canada with the addition of the Vancouver Grizzlies and the Toronto Raptors. In 1996, the NBA created a women's league, the Women's National Basketball Association (WNBA).

In 1998, the NBA owners began a lockout that suspended all league business until a new labor agreement could be reached, which led to the season being shortened in half. The San Antonio Spurs won the championship at the end of the 1998-99 season, becoming the first former ABA team to win the NBA championship.

After the breakup of the Chicago Bulls championship roster in the summer of 1998, the Western Conference has dominated. The Los Angeles Lakers of coach Phil Jackson and the San Antonio Spurs of Gregg Popovich combined to make 13 Finals in 16 seasons, with 10 titles. Tim Duncan and David Robinson won the 1999 championship with the Spurs, and Shaquille O'Neal and Kobe Bryant started the 2000s with three consecutive championships for the Lakers. The Spurs reclaimed the title in 2003 against the Nets. In 2004, the Lakers returned to the Finals, only to lose in five games to the Detroit Pistons.

The league's image was marred by a violent incident between players and fans in a November 2004 game between the Indiana Pacers and Detroit Pistons. In response, players were suspended for a total of 146 games with $11 million total lost in salary, and the league tightened security and limited the sale of alcohol.
After the Spurs won the championship again in 2005, the 2006 Finals featured two franchises making their inaugural Finals appearances. The Miami Heat, led by their star shooting guard, Dwyane Wade, and Shaquille O'Neal, who had been traded from the Lakers during summer 2004, won the series over the Dallas Mavericks. The Lakers/Spurs dominance continued in 2007 with a four-game sweep by the Spurs over the LeBron James-led Cleveland Cavaliers. The 2008 Finals saw a rematch of the league's highest profile rivalry, the Boston Celtics and Los Angeles Lakers, with the Celtics winning, for their 17th championship. The Lakers won back-to-back championships in 2009 and 2010, against the Orlando Magic and the Celtics. The 2010 NBA All-Star Game was held at Cowboys Stadium in front of the largest crowd ever, 108,713.

A referee lockout began on September 1, 2009, when the contract between the NBA and its referees expired. The first preseason games were played on October 1, 2009, and replacement referees from the WNBA and NBA Development League were used, the first time replacement referees had been used since the beginning of the 1995–96 season. The NBA and the regular referees reached a deal on October 23, 2009. 

At the start of the 2010-11 season, free agents LeBron James and Chris Bosh signed with the Miami Heat, joining Dwyane Wade to form the "Big Three." The Heat dominated the league, reaching the Finals for four straight years. In 2011, they faced a re-match with the Dallas Mavericks but lost to the Dirk Nowitzki-led team. They won back-to-back titles in 2012 and 2013 against the Oklahoma City Thunder and the Spurs, and lost a re-match to the Spurs in the 2014 Finals.

The 2011-12 season began with another lockout, the league's fourth. After the first few weeks of the season were canceled, the players and owners ratified a new collective bargaining agreement on December 8, 2011, setting up a shortened 66-game season. On February 1, 2014, commissioner David Stern retired after 30 years in the position, and was succeeded by his deputy, Adam Silver.

After four seasons with the Miami Heat, LeBron James returned to the Cleveland Cavaliers for the 2014-15 season. He led the team to their second Finals appearance with the help of Kyrie Irving and Kevin Love. The Golden State Warriors defeated the Cavaliers in six games, led by the "Splash Brothers" Stephen Curry and Klay Thompson. The Cavaliers and the Warriors faced each other in the Finals a record four consecutive times. In the 2015-16 season, the Warriors finished the season 73-9, the best season record in NBA history. However, the Cavaliers overcame a 3-1 deficit in the Finals to win their first championship that season. In the 2016–17 season, the Warriors benefited from the recruitment of free agent Kevin Durant. The Warriors won the 2017 and 2018 Finals against the Cavaliers. 

After the departure of James in free agency in 2018, the Cavaliers' streak of playoff and Finals appearances ended. The Warriors returned for a fifth consecutive Finals appearance in 2019, but lost to the Toronto Raptors, who won their first championship after signing free agent Kawhi Leonard.

The 2019-20 season was suspended indefinitely on March 11, 2020, due to the COVID-19 pandemic, after Utah Jazz center Rudy Gobert tested positive for the coronavirus. On June 4, 2020, the NBA Board of Governors voted to resume the season in a 22-team format with 8 seeding games per team and a regular playoffs format, with all games played in a "bubble" in Walt Disney World without any fans present.

Following pioneers like Vlade Divac (Serbia) and Dražen Petrović (Croatia) who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Since 2006, the NBA has faced EuroLeague teams in exhibition matches in the NBA Europe Live Tour, and since 2009, in the EuroLeague American Tour. The 2013–14 season opened with a record 92 international players on the opening night rosters, representing 39 countries and comprising over 20% of the league. The beginning of the 2017–18 season saw a record 108 international players representing 42 different countries marking 4 consecutive years of at least 100 international players and each team having at least one international player. In 2018, the Phoenix Suns hired Serbian coach Igor Kokoškov as their new head coach, replacing Canadian interim coach Jay Triano, making Kokoškov the first European coach to become a head coach for a team in the NBA.

In 2001, an affiliated minor league, the National Basketball Development League, now called the NBA G League, was created. 

Two years after the Hornets' move to New Orleans, the NBA returned to North Carolina, as the Charlotte Bobcats were formed as an expansion team in 2004.

The Hornets temporarily moved to Oklahoma City in 2005 for two seasons because of damage caused by Hurricane Katrina. The team returned to New Orleans in 2007.

A new official game ball was introduced on June 28, 2006, for the 2006–07 season, marking the first change to the ball in over 35 years and only the second ball in 60 seasons. Manufactured by Spalding, the new ball featured a new design and new synthetic material that Spalding claimed offered a better grip, feel, and consistency than the original ball. However, many players were vocal in their disdain for the new ball, saying that it was too sticky when dry, and too slippery when wet.

Commissioner Stern announced on December 11, 2006, that beginning January 1, 2007, the NBA would return to the traditional leather basketball in use prior to the 2006–07 season. The change was influenced by frequent player complaints and confirmed hand injuries (cuts) caused by the microfiber ball. The Players' Association had filed a suit on behalf of the players against the NBA over the new ball. As of the 2017–18 season, the NBA team jerseys are manufactured by Nike, replacing the previous supplier, Adidas. All teams will wear jerseys with the Nike logo except the Charlotte Hornets, whose jerseys will instead have the Jumpman logo associated with longtime Nike endorser Michael Jordan, who owns the Hornets.

The Federal Bureau of Investigation (FBI) began an investigation on July 19, 2007, over allegations that veteran NBA referee Tim Donaghy bet on basketball games he officiated over the past two seasons and that he made calls affecting the point spread in those games. On August 15, 2007, Donaghy pleaded guilty to two federal charges related to the investigation. Donaghy claimed in 2008 that certain referees were friendly with players and "company men" for the NBA, and he alleged that referees influenced the outcome of certain playoff and finals games in 2002 and 2005. NBA commissioner David Stern denied the allegations and said Donaghy was a convicted felon and a "singing, cooperating witness". Donaghy served 15 months in prison and was released in November 2009. According to an independent study by Ronald Beech of Game 6 of the 2002 Western Conference Finals between the Los Angeles Lakers and Sacramento Kings, although the refs increased the Lakers' chances of winning through foul calls during the game, there was no collusion to fix the game. On alleged "star treatment" during Game 6 by the referees toward certain players, Beech claimed, "there does seem to be issues with different standards and allowances for different players." 

The NBA Board of Governors approved the request of the Seattle SuperSonics to move to Oklahoma City on April 18, 2008. The team, however, could not move until it had settled a lawsuit filed by the city of Seattle, which was intended to keep the SuperSonics in Seattle for the remaining two seasons of the team's lease at KeyArena. Following a court case, the city of Seattle settled with the ownership group of the SuperSonics on July 2, 2008, allowing the team to move to Oklahoma City immediately in exchange for terminating the final two seasons of the team's lease at KeyArena. The Oklahoma City Thunder began playing in the 2008–09 season.

The first outdoor game in the modern era of the league was played at the Indian Wells Tennis Garden on October 11, 2008, between the Phoenix Suns and the Denver Nuggets.

The first official NBA league games on European ground took place in 2011. In two matchups, the New Jersey Nets faced the Toronto Raptors at the O2 Arena in London in front of over 20,000 fans.

After the 2012–13 season, the New Orleans Hornets were renamed the Pelicans. During the 2013–14 season, Stern retired as commissioner after 30 years, and deputy commissioner Adam Silver ascended to the position of commissioner. During that season's playoffs, the Bobcats officially reclaimed the Hornets name, and by agreement with the league and the Pelicans, also received sole ownership of all history, records, and statistics from the Pelicans' time in Charlotte. As a result, the Hornets are now officially considered to have been founded in 1988, suspended operations in 2002, and resumed in 2004 as the Bobcats, while the Pelicans are officially treated as a 2002 expansion team. (This is somewhat similar to the relationship between the Cleveland Browns and Baltimore Ravens in the NFL.)

Donald Sterling, who was then-owner of the Los Angeles Clippers, received a lifetime ban from the NBA on April 29, 2014 after racist remarks he made became public. Sterling was also fined US$2.5 million, the maximum allowed under the NBA Constitution.

Becky Hammon was hired by the San Antonio Spurs on August 5, 2014, as an assistant coach, becoming the second female coach in NBA history but the first full-time coach. This also makes her the first full-time female coach in any of the four major professional sports in North America.

The NBA announced on April 15, 2016, that it would allow all 30 of its teams to sell corporate sponsor advertisement patches on official game uniforms, beginning with the 2017–18 season. The sponsorship advertisement patches would appear on the left front of jerseys, opposite Nike's logo, marking the first time a manufacturer's logo would appear on NBA jerseys, and would measure approximately 2.5 by 2.5 inches. The NBA would become the first major North American professional sports league to allow corporate sponsorship logos on official team uniforms, and the last to have a uniform manufacturer logo appear on its team uniforms. The first team to announce a jersey sponsorship was the Philadelphia 76ers, who agreed to a deal with StubHub.

On July 6, 2017, the NBA unveiled an updated rendition of its logo; it was largely identical to the previous design, except with revised typography and a "richer" color scheme. The league began to phase in the updated logo across its properties during the 2017 NBA Summer League, but it will not immediately be used on equipment or uniforms due to lead time.

The NBA also officially released new Nike uniforms for all 30 teams beginning with the 2017–18 season. The league eliminated "home" and "away" uniform designations. Instead, each team would have four or six uniforms: the "Association" edition, which is the team's white uniform, the "Icon" edition, which is the team's color uniform, and the "Statement" and "City" uniforms, which most teams use as an alternate uniform. In 2018, the NBA also released the "Earned" uniform.

The NBA originated in 1946 with 11 teams, and through a sequence of team expansions, reductions, and relocations, currently consists of 30 teams. The United States is home to 29 teams; another is in Canada.

The current league organization divides 30 teams into two conferences of three divisions with five teams each. The current divisional alignment was introduced in the 2004–05 season. Reflecting the population distribution of the United States and Canada as a whole, most teams are in the eastern half of the country: 13 teams are in the Eastern Time Zone, nine in the Central, three in the Mountain, and five in the Pacific.


Following the summer break, teams begin training camps in late September. Training camps allow the coaching staff to evaluate players (especially rookies), scout the team's strengths and weaknesses, prepare the players for the rigorous regular season, and determine the 12-man active roster (and a 3-man inactive list) with which they will begin the regular season. Teams have the ability to assign players with less than two years of experience to the NBA G League. After training camp, a series of preseason exhibition games are held. Preseason matches are sometimes held in non-NBA cities, both in the United States and overseas. The NBA regular season begins in the last week of October.

During the regular season, each team plays 82 games, 41 each home and away. A team faces opponents in its own division four times a year (16 games). Each team plays six of the teams from the other two divisions in its conference four times (24 games), and the remaining four teams three times (12 games). Finally, each team plays all the teams in the other conference twice apiece (30 games). This asymmetrical structure means the strength of schedule will vary between teams (but not as significantly as the NFL or MLB). Over five seasons, each team will have played 80 games against their division (20 games against each opponent, 10 at home, 10 on the road), 180 games against the rest of their conference (18 games against each opponent, 9 at home, 9 on the road), and 150 games against the other conference (10 games against each team, 5 at home, 5 on the road).

The NBA is one of only two of the four major professional sports leagues in the United States and Canada in which teams play every other team during the regular season (the other being the National Hockey League). Each team hosts and visits every other team at least once every season. From 2005 to 2008, the NBA had the distinction of being the only one of the four major leagues in which all teams play every other team.

The NBA is also the only league that regularly schedules games on Christmas Day. The league has been playing games regularly on the holiday since 1947, though the first Christmas Day games were not televised until . Games played on this day have featured some of the best teams and players. Christmas is also notable for NBA on television, as the holiday is when the first NBA games air on network television each season. Games played on this day have been some of the highest-rated games during a particular season.

In February, the regular season pauses to celebrate the annual NBA All-Star Game. Fans vote throughout the United States, Canada, and on the Internet, and the top vote-getters in each conference are named captains. Fan votes determine the rest of the allstar starters. Coaches vote to choose the remaining 14 All-Stars. Then, the top vote-getters in each conference draft their own team from a player pool of allstars. The top vote-getter in the league earns first pick and so forth. The player with the best performance during the game is rewarded with a Game MVP award. Other attractions of the All-Star break include the Rising Stars Challenge (originally Rookie Challenge), where the top rookies and second-year players in the NBA play in a 5-on-5 basketball game, with the current format pitting U.S. players against those from the rest of the world; the Skills Challenge, where players compete to finish an obstacle course consisting of shooting, passing, and dribbling in the fastest time; the Three Point Contest, where players compete to score the highest number of three-point field goals in a given time; and the NBA Slam Dunk Contest, where players compete to dunk the ball in the most entertaining way according to the judges. These other attractions have varying names which include the names of the various sponsors who have paid for naming rights.

Shortly after the All-Star break is the trade deadline, which is set to fall on the 16th Thursday of the season (usually in February) at 3pm Eastern Time. After this date, teams are not allowed to exchange players with each other for the remainder of the season, although they may still sign and release players. Major trades are often completed right before the trading deadline, making that day a hectic time for general managers.

Around the middle of April, the regular season ends. It is during this time that voting begins for individual awards, as well as the selection of the honorary, league-wide, post-season teams. The Sixth Man of the Year Award is given to the best player coming off the bench (must have more games coming off the bench than actual games started). The Rookie of the Year Award is awarded to the most outstanding first-year player. The Most Improved Player Award is awarded to the player who is deemed to have shown the most improvement from the previous season. The Defensive Player of the Year Award is awarded to the league's best defender. The Coach of the Year Award is awarded to the coach that has made the most positive difference to a team. The Most Valuable Player Award is given to the player deemed the most valuable for (his team) that season. Additionally, "Sporting News" awards an unofficial (but widely recognized) Executive of the Year Award to the general manager who is adjudged to have performed the best job for the benefit of his franchise.

The post-season teams are the All-NBA Team, the All-Defensive Team, and the All-Rookie Team; each consists of five players. There are three All-NBA teams, consisting of the top players at each position, with first-team status being the most desirable. There are two All-Defensive teams, consisting of the top defenders at each position. There are also two All-Rookie teams, consisting of the top first-year players regardless of position.

The NBA playoffs begin in April after the conclusion of the regular season with the top eight teams in each conference, regardless of divisional alignment, competing for the league's championship title, the Larry O'Brien Championship Trophy. Seeds are awarded in strict order of regular season record (with a tiebreaker system used as needed).

Having a higher seed offers several advantages. Since the first seed begins the playoffs playing against the eighth seed, the second seed plays the seventh seed, the third seed plays the sixth seed, and the fourth seed plays the fifth seed, having a higher seed means a team faces a weaker team in the first round. The team in each series with the better record has home court advantage, including the First Round. Before the league changed its playoff determination format for the 2006–07 season, this meant that, for example, if the team that received the sixth seed had a better record than the team with the third seed (by virtue of a divisional championship), the sixth seed would have home court advantage, even though the other team had a higher seed. Therefore, the team with the best regular season record in the league is guaranteed home court advantage in every series it plays. For example, in 2006, the Denver Nuggets won 44 games and captured the Northwest Division and the third seed. Their opponent was the sixth-seeded Los Angeles Clippers, who won 47 games and finished second in the Pacific Division. Although Denver won its much weaker division, the Clippers had home-court advantage and won the series in 5.

The playoffs follow a tournament format. Each team plays an opponent in a best-of-seven series, with the first team to win four games advancing into the next round, while the other team is eliminated from the playoffs. In the next round, the successful team plays against another advancing team of the same conference. All but one team in each conference are eliminated from the playoffs. Since the NBA does not re-seed teams, the playoff bracket in each conference uses a traditional design, with the winner of the series matching the first- and eighth-seeded teams playing the winner of the series matching the fourth- and fifth-seeded teams, and the winner of the series matching the second- and seventh-seeded teams playing the winner of the series matching the third- and sixth-seeded teams. In every round, the best-of-7 series follows a 2–2–1–1–1 home-court pattern, meaning that one team will have home court in games 1, 2, 5, and 7, while the other plays at home in games 3, 4, and 6. From 1985 to 2013, the NBA Finals followed a 2–3–2 pattern, meaning that one team had home court in games 1, 2, 6, and 7, while the other played at home in games 3, 4, and 5.

The final playoff round, a best-of-seven series between the victors of both conferences, is known as the NBA Finals, and is held annually in June. The winner of the NBA Finals receives the Larry O'Brien Championship Trophy. Each player and major contributor—including coaches and the general manager—on the winning team receive a championship ring. In addition, the league awards the Bill Russell NBA Finals Most Valuable Player Award to the best performing player of the series.

The league began using its current format, with the top eight teams in each conference advancing regardless of divisional alignment, in the 2015–16 season. Previously, the top three seeds went to the division winners.

The Boston Celtics have won the most championships with 17 NBA Finals wins. The second most successful franchise is the Los Angeles Lakers, who have 16 overall championships (11 in Los Angeles, 5 in Minneapolis). Following the Lakers, are the Chicago Bulls and Golden State Warriors (2 in Philadelphia, 4 in Oakland) with six championships each. The San Antonio Spurs have five championships, all since 1999.

Current teams that have no NBA Finals appearances:


As one of the major sports leagues in North America, the NBA has a long history of partnerships with television networks in the United States. The NBA signed a contract with DuMont Television Network in its eighth season, the 1953–54 season, marking the first year the NBA had a national television broadcaster. Similar to the National Football League, the lack of television stations led to NBC taking over the rights from the 1954-55 season until April 7, 1962–NBC's first tenure with the NBA. Currently in the U.S., the NBA has a contract with ESPN and TNT through the 2024–25 season. Games that are not broadcast nationally are usually aired over regional sports networks specific to the area where the teams are located.

The National Basketball Association has sporadically participated in international club competitions. From 1987 to 1999 the NBA champions played against the continental champions of the FIBA in the McDonald's Championship. This tournament was won by the NBA invitee every year it was held.

In 2012, a ticket cost from $10 to $3,000 apiece, depending on the location of the seat and the success of the teams that were playing.

In 2020, ticket prices for the NBA All Star Game became more expensive than ever before, averaging around $2,600, and even more on the secondary market.

According to Nielsen's survey, in 2013 the NBA had the youngest audience, with 45 percent of its viewers under 35, but the least likely, along with Major League Baseball, to be watched by women, who make up only 30% of the viewership. It also has the highest share of black viewers with 45 percent of its viewers being black and only about 40 percent of viewers being white, making it the only top North American sport that does not have a white majority audience.

As of 2017, the NBA's popularity further declined among White Americans, who during the 2016–17 season, made up only 34% of the viewership. At the same time, the black viewership increased to 47 percent, while Hispanic (of any race) stood at 11% and Asian viewership stood at 8%. According to the same poll, the NBA was favored more strongly by Democrats than Republicans.

The NBA has been involved in a number of controversies over the years and has received a significant amount of criticism.



Following pioneers like Vlade Divac (Serbia) and Dražen Petrović (Croatia) who joined the NBA in the late 1980s, an increasing number of international players have moved directly from playing elsewhere in the world to starring in the NBA. Below is a short list of foreign players who have won NBA awards or have been otherwise recognized for their contributions to basketball, either currently or formerly active in the league:

On some occasions, young players, most but not all from the English-speaking world, have attended U.S. colleges before playing in the NBA. Notable examples are:

Since 2006, the NBA has faced EuroLeague teams in exhibition matches in the NBA Europe Live Tour, and since 2009 in the EuroLeague American Tour.

The 2013–14 season opened with a record 92 international players on the opening night rosters, representing 39 countries and comprising over 20% of the league. The NBA defines "international" players as those born outside the 50 United States and Washington, D.C. This means that:


The league has a global social responsibility program, NBA Cares, that is responsible for the league's stated mission of addressing important social issues worldwide.











</doc>
<doc id="22094" url="https://en.wikipedia.org/wiki?curid=22094" title="Nutation">
Nutation

Nutation (from Latin "nūtātiō", "nodding, swaying") is a rocking, swaying, or nodding motion in the axis of rotation of a largely axially symmetric object, such as a gyroscope, planet, or bullet in flight, or as an intended behaviour of a mechanism. In an appropriate reference frame it can be defined as a change in the second Euler angle. If it is not caused by forces external to the body, it is called "free nutation" or "Euler nutation". A "pure nutation" is a movement of a rotational axis such that the first Euler angle is constant. In spacecraft dynamics, precession (a change in the first Euler angle) is sometimes referred to as nutation.

If a top is set at a tilt on a horizontal surface and spun rapidly, its rotational axis starts precessing about the vertical. After a short interval, the top settles into a motion in which each point on its rotation axis follows a circular path. The vertical force of gravity produces a horizontal torque about the point of contact with the surface; the top rotates in the direction of this torque with an angular velocity such that at any moment

where is the instantaneous angular momentum of the top.

Initially, however, there is no precession, and the top falls straight downward. This gives rise to an imbalance in torques that starts the precession. In falling, the top overshoots the level at which it would precess steadily and then oscillates about this level. This oscillation is called "nutation". If the motion is damped, the oscillations will die down until the motion is a steady precession.

The physics of nutation in tops and gyroscopes can be explored using the model of a "heavy symmetrical top" with its tip fixed. (A symmetrical top is one with rotational symmetry, or more generally one in which two of the three principal moments of inertia are equal.) Initially, the effect of friction is ignored. The motion of the top can be described by three Euler angles: the tilt angle between the symmetry axis of the top and the vertical; the azimuth of the top about the vertical; and the rotation angle of the top about its own axis. Thus, precession is the change in and nutation is the change in .

If the top has mass and its center of mass is at a distance from the pivot point, its gravitational potential relative to the plane of the support is

In a coordinate system where the axis is the axis of symmetry, the top has angular velocities and moments of inertia about the , and axes. Since we are taking a symmetric top, we have =. The kinetic energy is

In terms of the Euler angles, this is

If the Euler–Lagrange equations are solved for this system, it is found that the motion depends on two constants and (each related to a constant of motion). The rate of precession is related to the tilt by

The tilt is determined by a differential equation for of the form

where is a cubic polynomial that depends on parameters and as well as constants that are related to the energy and the gravitational torque. The roots of are cosines of the angles at which the rate of change of is zero. One of these is not related to a physical angle; the other two determine the upper and lower bounds on the tilt angle, between which the gyroscope oscillates.

The nutation of a planet occurs because the gravitational effects of other bodies cause the speed of its axial precession to vary over time, so that the speed is not constant. English astronomer James Bradley discovered the nutation of Earth's axis in 1728.

Nutation subtly changes the axial tilt of Earth with respect to the ecliptic plane, shifting the major circles of latitude that are defined by the Earth's tilt (the tropical circles and the polar circles).

In the case of Earth, the principal sources of tidal force are the Sun and Moon, which continuously change location relative to each other and thus cause nutation in Earth's axis. The largest component of Earth's nutation has a period of 18.6 years, the same as that of the precession of the Moon's orbital nodes. However, there are other significant periodic terms that must be accounted for depending upon the desired accuracy of the result. A mathematical description (set of equations) that represents nutation is called a "theory of nutation". In the theory, parameters are adjusted in a more or less "ad hoc" method to obtain the best fit to data. Simple rigid body dynamics do not give the best theory; one has to account for deformations of the Earth, including mantle inelasticity and changes in the core–mantle boundary.

The principal term of nutation is due to the regression of the Moon's nodal line and has the same period of 6798 days (18.61 years). It reaches plus or minus 17″ in longitude and 9.2″ in obliquity. All other terms are much smaller; the next-largest, with a period of 183 days (0.5 year), has amplitudes 1.3″ and 0.6″ respectively. The periods of all terms larger than 0.0001″ (about as accurately as one can measure) lie between 5.5 and 6798 days; for some reason (as with ocean tidal periods) they seem to avoid the range from 34.8 to 91 days, so it is customary to split the nutation into long-period and short-period terms. The long-period terms are calculated and mentioned in the almanacs, while the additional correction due to the short-period terms is usually taken from a table. They can also be calculated from the Julian day according to IAU 2000B methodology.

In the 1961 disaster film "The Day the Earth Caught Fire", the near-simultaneous detonation of two super-hydrogen bombs near the poles causes a change in Earth's nutation, as well as an 11° shift in the axial tilt and a change in Earth's orbit around the Sun.




</doc>
<doc id="22096" url="https://en.wikipedia.org/wiki?curid=22096" title="NASCO">
NASCO

NASCO or Nasco may refer to:



</doc>
<doc id="22097" url="https://en.wikipedia.org/wiki?curid=22097" title="North Atlantic Salmon Conservation Organization">
North Atlantic Salmon Conservation Organization

The North Atlantic Salmon Conservation Organization (NASCO) is an international organization established under the Convention for the Conservation of Salmon in the North Atlantic Ocean from 1 October 1983.

The organization's mission is to contribute through consultation and cooperation to the conservation, restoration, enhancement and rational management of salmon stocks.

Its headquarters are in Edinburgh, United Kingdom.

It was established due to the failure of independent states to protect a global common such as the salmon population in this case. It was argued that international cooperation was necessary to prevent unsustainable over-fishing. The NASCO has established a handful of regulations and guidelines regarding the fishing of salmon, for example, countries are only able to fish within 12 nautical miles of their territory, prohibiting fishing in most of the North Atlantic.

In 2020, the NASCO operates with a budget of 636 630 GBP, with a little over 583 000 GBP coming from the member states.

Current participants (since 1984): Canada, Denmark (in respect of the Faroe Islands and Greenland), the European Union, Norway, Russian Federation, and the United States of America.

Former participants:

The NASCO also has 44 NGOs from the different member states that have observational status during the annual meetings.

Council

North American Commission

North-East Atlantic Commission

West Greenland Commission

International Atlantic Salmon Research Board (IASRB)

Secretariat

The secretariat currently has 5 full time employees based at the Headquarters in Edinburgh, Scotland.
In the council, each member state is represented and decisions are made based on a three quarter majority.

The main tasks of the council include:

Providing a forum for the study, analysis and exchange of information on salmon.

Coordinating the activities of the Commissions.

Establishing working arrangements with other fisheries and scientific organizations.

Making recommendations for scientific research. 



</doc>
<doc id="22099" url="https://en.wikipedia.org/wiki?curid=22099" title="Narcissus (mythology)">
Narcissus (mythology)

In Greek mythology, Narcissus (; Ancient Greek: Νάρκισσος "Nárkissos") was a hunter from Thespiae in Boeotia who was known for his beauty. According to Tzetzes, he was a Laconian hunter who loved everything beautiful. Narcissus was proud, in that he disdained those who loved him, causing some to take their own lives to prove their devotion to his striking beauty. Narcissus is the origin of the term "narcissism", a fixation with oneself and one's physical appearance or public perception.

The name is of uncertain etymology. According to R. S. P. Beekes, "[t]he suffix [-ισσος] clearly points to a Pre-Greek word." The word narcissus has come to be used for the daffodil, but there is no clarity on whether the flower is named for the myth, or the myth for the flower, or if there is any true connection at all. Pliny the Elder wrote that the plant was named for its fragrance ( , "I grow numb") not the youth.

Narcissus was the son of the river god Cephissus and nymph Liriope, while Nonnus instead has him as the son of the lunar goddess Selene and her mortal lover Endymion.

Several versions of the myth have survived from ancient sources. The classic version is by Ovid, found in book 3 of his "Metamorphoses" (completed 8 AD); this is the story of Echo and Narcissus. One day Narcissus was walking in the woods when Echo, an Oread (mountain nymph) saw him, fell deeply in love, and followed him. Narcissus sensed he was being followed and shouted "Who's there?". Echo repeated "Who's there?" She eventually revealed her identity and attempted to embrace him. He stepped away and told her to leave him alone. She was heartbroken and spent the rest of her life in lonely glens until nothing but an echo sound remained of her. Nemesis (as an aspect of Aphrodite), the goddess of revenge, noticed this behaviour after learning the story and decided to punish Narcissus. Once, during the summer, he was getting thirsty after hunting, and the goddess lured him to a pool where he leaned upon the water and saw himself in the bloom of youth. Narcissus did not realize it was merely his own reflection and fell deeply in love with it, as if it were somebody else. Unable to leave the allure of his image, he eventually realized that his love could not be reciprocated and he melted away from the fire of passion burning inside him, eventually turning into a gold and white flower.

An earlier version ascribed to the poet Parthenius of Nicaea, composed around 50 BC, was discovered in 2004 by Dr Benjamin Henry among the Oxyrhynchus papyri at Oxford. Unlike Ovid's version, it ended with Narcissus who lost his will to live and committed suicide. A version by Conon, a contemporary of Ovid, also ends in suicide ("Narrations," 24). In it, a young man named Ameinias fell in love with Narcissus, who had already spurned his male suitors. Narcissus also spurned him and gave him a sword. Ameinias committed suicide at Narcissus's doorstep. He had prayed to the gods to give Narcissus a lesson for all the pain he provoked. Narcissus walked by a pool of water and decided to drink some. He saw his reflection, became entranced by it, and killed himself because he could not have his object of desire. A century later the travel writer Pausanias recorded a novel variant of the story, in which Narcissus falls in love with his twin sister rather than himself ("Guide to Greece", 9.31.7). In all versions, his body disappears and all that is left is a narcissus flower.

In 1898 Havelock Ellis, an English sexologist, used the term "narcissus-like" in reference to excessive masturbation, whereby the person becomes his or her own sex object.

In 1899, Paul Näcke was the first person to use the term "narcissism" in a study of sexual perversions.

Otto Rank, in 1911, published the first psychoanalytical paper specifically concerned with narcissism, linking it to vanity and self-admiration.

Sigmund Freud published a paper exclusively devoted to narcissism in 1914, called "On Narcissism: An Introduction".

One of the personality disorders is called narcissistic personality disorder.

The myth of Narcissus has inspired artists for at least two thousand years, even before the Roman poet Ovid featured a version in book III of his "Metamorphoses". This was followed in more recent centuries by other poets (e.g. Keats and Alfred Edward Housman) and painters (Caravaggio, Poussin, Turner, Dalí (see "Metamorphosis of Narcissus"), and Waterhouse).

In Stendhal's novel "Le Rouge et le Noir" (1830), there is a classic narcissist in the character of Mathilde. Says Prince Korasoff to Julien Sorel, the protagonist, with respect to his beloved girl:

She looks at herself instead of looking at you, and so doesn't know you.
During the two or three little outbursts of passion she has allowed herself in your favor, she has, by a great effort of imagination, seen in you the hero of her dreams, and not yourself as you really are.<br>
(Page 401, 1953 Penguin Edition, trans. Margaret R.B. Shaw).

The myth had a decided influence on English Victorian homoerotic culture, via André Gide's study of the myth, "Le Traité du Narcisse" ('The Treatise of the Narcissus', 1891), and the only novel by Oscar Wilde, "The Picture of Dorian Gray".

Paulo Coelho's "The Alchemist" also starts with a story about Narcissus, found (we are told) by the alchemist in a book brought by someone in the caravan. The alchemist's (and Coelho's) source was very probably Hesketh Pearson's "The Life of Oscar Wilde" (1946) in which this story is recorded (Penguin edition, p. 217) as one of Wilde's inspired inventions. This version of the Narcissus story is based on Wilde's "The Disciple" from his "Poems in Prose (Wilde) ".

Author and poet Rainer Maria Rilke visits the character and symbolism of Narcissus in several of his poems.

Seamus Heaney references Narcissus in his poem "Personal Helicon" from his first collection "Death of a Naturalist":"To stare, big-eyed Narcissus, into some spring<br>
Is beneath all adult dignity."

In Rick Riordan's "Heroes of Olympus series," Narcissus appears as a minor antagonist in the third book "The Mark of Athena".

In the fantasy series "Harry Potter", Narcissa Malfoy, a minor antagonist, is named for Narcissus.

William Faulkner's character "Narcissa" in "Sanctuary", sister of Horace Benbow, was also named after Narcissus. Throughout the novel, she allows the arrogant, pompous pressures of high-class society to overrule the unconditional love that she should have for her brother.

Hermann Hesse's character "Narcissus" in "Narcissus and Goldmund" shares several of mythical Narcissus' traits, although his narcissism is based on his intellect rather than his physical beauty.

A. E. Housman refers to the 'Greek Lad', Narcissus, in his poem "Look not in my Eyes" from "A Shropshire Lad" set to music by several English composers including George Butterworth. At the end of the poem stands a jonquil, a variety of daffodil, Narcissus Jonquilla, which like Narcissus looks sadly down into the water.

Herman Melville references the myth of Narcissus in his novel Moby-Dick, in which Ishmael explains the myth as "the key to it all," referring to the greater theme of finding the essence of Truth through the physical world.

On Sophia de Mello Breyner Andresen's A Fada Oriana, the eponymous protagonist is punished with mortality for abandoning her duties in order to stare at herself in the surface of a river.

Joseph Conrad's novel The Nigger of the 'Narcissus' features a merchant ship named "Narcissus". An incident involving the ship, and the difficult decisions made by the crew, explore themes involving self-interest vs. altruism and humanitarianism.

Naomi Iizuka's play "Polaroid Stories", a contemporary rewrite of the Orpheus and Eurydice myth, features Narcissus as a character. In the play he is portrayed as a self obsessed, and drug addicted young man who was raised on the streets. He is alluded to being a member of the LGBT+ community and mentions his sexual endeavors with older men, some ending with the death of these men due to drug overdoses. He is accompanied by the character Echo who he continuously spurns.

In the TV series Boardwalk Empire, a Dr. Narcisse (Valentin Narcisse) is introduced as a condescending intellectual.

Scottish-Canadian animator Norman McLaren finished his career with a short film named "Narcissus", re-telling the Greek legend through ballet.

Narcissus appears in the Disney adaptation of "Hercules". In the film, he is portrayed as an Olympian god with purple skin.

In the film Bab'Aziz, directed by Nacer Khemir, a Narcissus like character was portrayed by an ancient prince who sat by a pond for days after days and looked at the reflection of his own soul. He was referred to as 'The prince who contemplated his soul'.

"Pink Narcissus" is an artistic film by James Bidgood about the fantasies of a hustler.

The escape craft Ripley boards in the 1979 Ridley Scott film Alien is called the Narcissus.

Narcissus is the name of Laurel and Hardy's goat in their 1940 film "Saps At Sea".

The Neon Demon, a 2016 psychological horror film by Nicolas Winding Refn, is loosely based on the story of Narcissus.

Narcissus is the name of the host club in the 2018 Japanese drama Todome no Kiss. The lead character, Otaro Dojima (Kento Yamazaki), works in the nightclub as a sought-after host under the stage name Eight and just like Narcissus, he is narcissistic and disregards the feelings of others; he uses women for money and power.

National Medal Of Arts recipient Morten Lauridsen wrote a choral work entitled "Dirait-on" based on the poem by Rainer Maria Rilke.

"Narcissus" is a popular melody from "Water Scenes" by American composer Ethelbert Nevin.

"Supper's Ready" by Genesis (ca. 1972), a near-23-minute epic song laden with religious and mythological imagery, refers to the myth of Narcissus as follows: "A young figure sits still by the pool / He's been stamped "Human Bacon" by some butchery tool / (He is you) / Social Security took care of this lad. / We watch in reverence, as Narcissus is turned to a flower. / A flower?". The movement is titled "How Dare I Be So Beautiful?".

Progressive metal band Threshold referenced the myth with an 11-minute epic titled "Narcissus", the closing track on their album "Hypothetical". Greek metal band Septic Flesh recorded a song about Narcissus (called "Narcissus") on their album "Communion".

The cerebral rock band "Glass Wave" retells the Narcissus story from the perspective of the nymph Echo in their song "Echo," from their self-titled album "Glass Wave" (2010).

"Narcissus in a Red Dress" by The Like was released on "The Like EP" and their album "Release Me". The Canadian band Hedley has written a song about Narcissus (called "Narcissist"). One line goes "He falls in love with his reflection in the glass / He can't resist who's staring back"

Composer Nikolai Tcherepnin wrote his ballet "Narcisse et Echo, Op. 40" in 1911 for Sergei Diaghilev's Ballets Russes and was danced by Nijinski. Uruguayan band El Cuarteto de Nos wrote the song "Me Amo" (I Love Myself) in which the chorus sings "como Narciso soy" (I am like Narcissus). In 2010, Swedish electronic artist pacific! released "Narcissus" an album and ballet staged in Gothenburg. In 1994, composer Mark Applebaum composed Narcissus: Strata/Panacea for marimba solo. This work comprised one movement of the larger Janus Cycle, for mixed instrumentation. In 1987, Thea Musgrave was commissioned by a consortium of four flutists for a solo work. She composed Narcissus for flute and digital delay.

German composer Matthias Pintscher composed his first cello concerto based on this mythology figure, titled "Reflections on Narcissus".

In Marilyn Manson's song Deep Six, the first verse mentions Zeus in conversation with Narcissus.

Alanis Morissette has a song named Narcissus on the album Under Rug Swept.

Narcissus has been a subject for many painters including: Caravaggio, Poussin, Turner, Dalí, Waterhouse, Carpioni, Lagrenée, and Roos.

Sculptors such as Paul Dubois, John Gibson, Henri-Léon Gréber, Benvenuto Cellini and Hubert Netzer have sculpted Narcissus.





</doc>
<doc id="22102" url="https://en.wikipedia.org/wiki?curid=22102" title="Naval mine">
Naval mine

A naval mine is a self-contained explosive device placed in water to damage or destroy surface ships or submarines. Unlike depth charges, mines are deposited and left to wait until they are triggered by the approach of, or contact with, any vessel. Naval mines can be used offensively, to hamper enemy shipping movements or lock vessels into a harbour; or defensively, to protect friendly vessels and create "safe" zones. Mines allow the minelaying force commander to concentrate warships or defensive assets in mine-free areas giving the adversary three choices: undertake an expensive and time-consuming minesweeping effort, accept the casualties of challenging the minefield, or use the unmined waters where the greatest concentration of enemy firepower will be encountered.

Modern mines containing high explosives detonated by complex electronic fuze mechanisms are much more effective than early gunpowder mines requiring physical ignition. Mines may be placed by aircraft, ships, submarines, or individual swimmers and boatmen. Although international law requires signatory nations to declare mined areas, precise locations remain secret; and non-complying individuals may not disclose minelaying. While mines threaten only those who choose to traverse waters which may be mined, the possibility of activating a mine is a powerful disincentive to shipping.

Mines can be laid in many ways: by purpose-built minelayers, refitted ships, submarines or aircraft—and even by dropping them into a harbour by hand. They can be inexpensive: some variants can cost as little as US$2000, though more sophisticated mines can cost millions of dollars, be equipped with several kinds of sensors and deliver a warhead by rocket or torpedo.
Their flexibility and cost-effectiveness make mines attractive to the less powerful belligerent in asymmetric warfare. The cost of producing and laying a mine is usually between 0.5% and 10% of the cost of removing it, and it can take up to 200 times as long to clear a minefield as to lay it. Parts of some World War II naval minefields still exist because they are too extensive and expensive to clear. Some 1940s-era mines may remain dangerous for many years.

Mines have been employed as offensive or defensive weapons in rivers, lakes, estuaries, seas and oceans, but they can also be used as tools of psychological warfare. Offensive mines are placed in enemy waters, outside harbours and across important shipping routes to sink both merchant and military vessels. Defensive minefields safeguard key stretches of coast from enemy ships and submarines, forcing them into more easily defended areas, or keeping them away from sensitive ones.

Ship owners are reluctant to send their ships though known minefields. Port authorities may attempt to clear a mined area, but those without effective minesweeping equipment may cease using the area. Transit of a mined area will be attempted only when strategic interests outweigh potential losses. The decision-maker's perception of the minefield is a critical factor. Minefields designed for psychological effect are usually placed on trade routes to stop ships from reaching an enemy nation. They are often spread thinly, to create an impression of minefields existing across large areas. A single mine inserted strategically on a shipping route can stop maritime movements for days while the entire area is swept. A mine's capability to sink ships makes it a credible threat, but minefields work more on the mind than on ships.

International law, specifically the Eighth Hague Convention of 1907, requires nations to declare when they mine an area, to make it easier for civil shipping to avoid the mines. The warnings do not have to be specific; for example, during World War II, Britain declared simply that it had mined the English Channel, North Sea and French coast.

Precursors to naval mines were first invented by Chinese innovators of Imperial China and were described in thorough detail by the early Ming dynasty artillery officer Jiao Yu, in his 14th century military treatise known as the "Huolongjing". Chinese records tell of naval explosives in the 16th century, used to fight against Japanese pirates ("wokou"). This kind of naval mine was loaded in a wooden box, sealed with putty. General Qi Jiguang made several timed, drifting explosives, to harass Japanese pirate ships. The "Tiangong Kaiwu" ("The Exploitation of the Works of Nature") treatise, written by Song Yingxing in 1637, describes naval mines with a rip cord pulled by hidden ambushers located on the nearby shore who rotated a steel wheellock flint mechanism to produce sparks and ignite the fuse of the naval mine. Although this is the rotating steel wheellock's first use in naval mines, Jiao Yu described their use for land mines in the 14th century.

The first plan for a sea mine in the West was by Ralph Rabbards, who presented his design to Queen Elizabeth I of England in 1574. The Dutch inventor Cornelius Drebbel was employed in the Office of Ordnance by King Charles I of England to make weapons, including the failed "floating petard". Weapons of this type were apparently tried by the English at the Siege of La Rochelle in 1627.
American David Bushnell developed the first American naval mine, for use against the British in the American War of Independence. It was a watertight keg filled with gunpowder that was floated toward the enemy, detonated by a sparking mechanism if it struck a ship. It was used on the Delaware River as a drift mine.

In 1812 Russian engineer Pavel Shilling exploded an underwater mine using an electrical circuit. In 1842 Samuel Colt used an electric detonator to destroy a moving vessel to demonstrate an underwater mine of his own design to the United States Navy and President John Tyler. However, opposition from former president John Quincy Adams, scuttled the project as "not fair and honest warfare". In 1854, during the unsuccessful attempt of the Anglo-French fleet to seize the Kronstadt fortress, British steamships HMS "Merlin" (9 June 1855, the first successful mining in history), HMS "Vulture" and HMS "Firefly" suffered damage due to the underwater explosions of Russian naval mines. Russian naval specialists set more than 1500 naval mines, or "infernal machines", designed by Moritz von Jacobi and by Immanuel Nobel, in the Gulf of Finland during the Crimean War of 1853–1856. The mining of "Vulcan" led to the world's first minesweeping operation. During the next 72 hours, 33 mines were swept.

The Jacobi mine was designed by German-born, Russian engineer Jacobi, in 1853. The mine was tied to the sea bottom by an anchor. A cable connected it to a galvanic cell which powered it from the shore, the power of its explosive charge was equal to of black powder. In the summer of 1853, the production of the mine was approved by the Committee for Mines of the Ministry of War of the Russian Empire. In 1854, 60 Jacobi mines were laid in the vicinity of the Forts Pavel and Alexander (Kronstadt), to deter the British Baltic Fleet from attacking them. It gradually phased out its direct competitor the Nobel mine on the insistence of Admiral Fyodor Litke. The Nobel mines were bought from Swedish industrialist Immanuel Nobel who had entered into collusion with Russian head of navy Alexander Sergeyevich Menshikov. Despite their high cost (100 Russian rubles) the Nobel mines proved to be faulty, exploding while being laid, failing to explode or detaching from their wires and drifting uncontrollably, at least 70 of them were subsequently disarmed by the British. In 1855, 301 more Jacobi mines were laid around Krostadt and Lisy Nos. British ships did not dare to approach them.

In the 19th century, mines were called torpedoes, a name probably conferred by Robert Fulton after the torpedo fish, which gives powerful electric shocks. A spar torpedo was a mine attached to a long pole and detonated when the ship carrying it rammed another one and withdrew a safe distance. The submarine used one to sink on 17 February 1864. A Harvey torpedo was a type of floating mine towed alongside a ship and was briefly in service in the Royal Navy in the 1870s. Other "torpedoes" were attached to ships or propelled themselves. One such weapon called the Whitehead torpedo after its inventor, caused the word "torpedo" to apply to self-propelled underwater missiles as well as to static devices. These mobile devices were also known as "fish torpedoes".

The American Civil War of 1861–1865 also saw the successful use of mines. The first ship sunk by a mine, , foundered in 1862 in the Yazoo River. Rear Admiral David Farragut's famous/apocryphal command during the Battle of Mobile Bay in 1864, "Damn the torpedoes, full speed ahead!" refers to a minefield laid at Mobile, Alabama.

After 1865 the United States adopted the mine as its primary weapon for coastal defense. In the decade following 1868, Major Henry Larcom Abbot carried out a lengthy set of experiments to design and test moored mines that could be exploded on contact or be detonated at will as enemy shipping passed near them. This initial development of mines in the United States took place under the purview of the U.S. Army Corps of Engineers, which trained officers and men in their use at the Engineer School of Application at Willets Point, New York (later named Fort Totten). In 1901 underwater minefields became the responsibility of the US Army's Artillery Corps, and in 1907 this was a founding responsibility of the United States Army Coast Artillery Corps.

The Imperial Russian Navy, a pioneer in mine warfare, successfully deployed mines against the Ottoman Navy during both the Crimean War and the Russo-Turkish War (1877-1878).

During the Battle of Tamsui (1884), in the Keelung Campaign of the Sino-French War, Chinese forces in Taiwan under Liu Mingchuan took measures to reinforce Tamsui against the French; they planted nine torpedo mines in the river and blocked the entrance.

During the Boxer Rebellion, Imperial Chinese forces deployed a command-detonated mine field at the mouth of the Peiho river before the Dagu forts, to prevent the western Allied forces from sending ships to attack.

The next major use of mines was during the Russo-Japanese War of 1904–1905. Two mines blew up when the struck them near Port Arthur, sending the holed vessel to the bottom and killing the fleet commander, Admiral Stepan Makarov, and most of his crew in the process. The toll inflicted by mines was not confined to the Russians, however. The Japanese Navy lost two battleships, four cruisers, two destroyers and a torpedo-boat to offensively laid mines during the war. Most famously, on 15 May 1904, the Russian minelayer "Amur" planted a 50-mine minefield off Port Arthur and succeeded in sinking the Japanese battleships and .

Following the end of the Russo-Japanese War, several nations attempted to have mines banned as weapons of war at the Hague Peace Conference (1907).

Many early mines were fragile and dangerous to handle, as they contained glass containers filled with nitroglycerin or mechanical devices that activated a blast upon tipping. Several mine-laying ships were destroyed when their cargo exploded.

Beginning around the start of the 20th century, submarine mines played a major role in the defense of U.S. harbors against enemy attack as part of the Endicott and Taft Programs. The mines employed were controlled mines, anchored to the bottoms of the harbors and detonated under control from large mine casemates on shore.

During World War I, mines were used extensively to defend coasts, coastal shipping, ports and naval bases around the globe. The Germans laid mines in shipping lanes to sink merchant and naval vessels serving Britain. The Allies targeted the German U-boats in the Strait of Dover and the Hebrides. In an attempt to seal up the northern exits of the North Sea, the Allies developed the North Sea Mine Barrage. During a period of five months from June 1918 almost 70,000 mines were laid spanning the North Sea's northern exits. The total number of mines laid in the North Sea, the British East Coast, Straits of Dover, and Heligoland Bight is estimated at 190,000 and the total number during the whole of WWI was 235,000 sea mines. Clearing the barrage after the war took 82 ships and five months, working around the clock. It was also during World War I, that the naval mine sunk its largest vessel ever, the British hospital ship, HMHS "Britannic", which was the sister ship of the RMS "Titanic."

During World War II, the U-boat fleet, which dominated much of the battle of the Atlantic, was small at the beginning of the war and much of the early action by German forces involved mining convoy routes and ports around Britain. German submarines also operated in the Mediterranean Sea, in the Caribbean Sea, and along the U.S. coast.

Initially, contact mines (requiring a ship to physically strike a mine to detonate it) were employed, usually tethered at the end of a cable just below the surface of the water. Contact mines usually blew a hole in ships' hulls. By the beginning of World War II, most nations had developed mines that could be dropped from aircraft, some of which floated on the surface, making it possible to lay them in enemy harbours. The use of dredging and nets was effective against this type of mine, but this consumed valuable time and resources, and required harbours to be closed.

Later, some ships survived mine blasts, limping into port with buckled plates and broken backs. This appeared to be due to a new type of mine, detecting ships by their proximity to the mine (an influence mine) and detonating at a distance, causing damage with the shock wave of the explosion. Ships that had successfully run the gantlet of the Atlantic crossing were sometimes destroyed entering freshly cleared British harbours. More shipping was being lost than could be replaced, and Churchill ordered the intact recovery of one of these new mines to be of the highest priority.

The British experienced a stroke of luck in November 1939, when a German mine was dropped from an aircraft onto the mud flats off Shoeburyness during low tide. Additionally, the land belonged to the army and a base with men and workshops was at hand. Experts were dispatched from HMS Vernon to investigate the mine. The Royal Navy knew that mines could use magnetic sensors, Britain having developed magnetic mines in World War I, so everyone removed all metal, including their buttons, and made tools of non-magnetic brass. They disarmed the mine and rushed it to the labs at HMS Vernon, where scientists discovered that the mine had a magnetic arming mechanism. A large ferrous object passing through the Earth's magnetic field will concentrate the field through it; the mine's detector was designed to trigger as a ship passed over, when the Earth's magnetic field was concentrated in the ship and away from the mine. The mine detected this loss of the magnetic field which caused it to detonate. The mechanism had an adjustable sensitivity, calibrated in milligauss. The U.S. began adding delay counters to their magnetic mines in June 1945.
From this data, known methods were used to clear these mines. Early methods included the use of large electromagnets dragged behind ships or below low-flying aircraft (a number of older bombers like the Vickers Wellington were used for this). Both of these methods had the disadvantage of "sweeping" only a small strip. A better solution was found in the "Double-L Sweep" using electrical cables dragged behind ships that passed large pulses of current through the seawater. This created a large magnetic field and swept the entire area between the two ships. The older methods continued to be used in smaller areas. The Suez Canal continued to be swept by aircraft, for instance.

While these methods were useful for clearing mines from local ports, they were of little or no use for enemy-controlled areas. These were typically visited by warships, and the majority of the fleet then underwent a massive degaussing process, where their hulls had a slight "south" bias induced into them which offset the concentration effect almost to zero.

Initially, major warships and large troopships had a copper "degaussing coil" fitted around the perimeter of the hull, energized by the ship's electrical system whenever in suspected magnetic-mined waters. Some of the first to be so fitted were the carrier HMS "Ark Royal" and the liners and . It was a photo of one of these liners in New York harbor, showing the degaussing coil, which revealed to German Naval Intelligence the fact that the British were using degaussing methods to combat their magnetic mines. This was felt to be impractical for smaller warships and merchant vessels, mainly because the ships lacked the generating capacity to energise such a coil. It was found that "wiping" a current-carrying cable up and down a ship's hull temporarily cancelled the ships' magnetic signature sufficiently to nullify the threat. This started in late 1939, and by 1940 merchant vessels and the smaller British warships were largely immune for a few months at a time until they once again built up a field.

The cruiser HMS Belfast is just one example of a ship which was struck by a magnetic mine during this time. On 21 November 1939, a mine broke her keel which damaged her engine and boiler rooms, as well as injuring 46 men with one man later dying from his injuries. She was towed to Rosyth for repairs. Incidents like this, resulted in many of the boats that sailed to Dunkirk being degaussed in a marathon four-day effort by degaussing stations.

The Allies and Germany deployed acoustic mines in WW II, against which even wooden-hulled ships (in particular minesweepers) remained vulnerable. Japan developed sonic generators to sweep these; the gear was not ready by war's end. The primary method Japan used was small air-delivered bombs. This was profligate and ineffectual; used against acoustic mines at Penang, 200 bombs were needed to detonate just 13 mines.

The Germans developed a pressure-activated mine and planned to deploy it as well, but they saved it for later use when it became clear the British had defeated the magnetic system. The U.S. also deployed these, adding "counters" which would allow a variable number of ships to pass unharmed before detonating. This made them a great deal harder to sweep.

Mining campaigns could have devastating consequences. The U.S. effort against Japan, for instance, closed major ports, such as Hiroshima, for days, and by the end of the Pacific War had cut the amount of freight passing through Kobe–Yokohama by 90%.

When the war ended, more than 25,000 U.S.-laid mines were still in place, and the Navy proved unable to sweep them all, limiting efforts to critical areas. After sweeping for almost a year, in May 1946, the Navy abandoned the effort with 13,000 mines still unswept. Over the next thirty years, more than 500 minesweepers (of a variety of types) were damaged or sunk clearing them.

Since World War II, mines have damaged 14 United States Navy ships, whereas air and missile attacks have damaged four. During the Korean War, mines laid by North Korean forces caused 70% of the casualties suffered by U.S. naval vessels and caused 4 sinkings.

During the Iran–Iraq War from 1980 to 1988, the belligerents mined several areas of the Persian Gulf and nearby waters. On 24 July 1987, the supertanker "SS" Bridgeton was mined by Iran near Farsi Island. On 14 April 1988, struck an Iranian M-08/39 mine in the central Persian Gulf shipping lane, wounding 10 sailors.

In the summer of 1984, magnetic sea mines damaged at least 19 ships in the Red Sea. The U.S. concluded Libya was probably responsible for the minelaying. In response the U.S., Britain, France, and three other nations launched Operation Intense Look, a minesweeping operation in the Red Sea involving more than 46 ships.

On the orders of the Reagan administration, the CIA mined Nicaragua's Sandino port in 1984 in support of the Contra guerrilla group. A Soviet tanker was among the ships damaged by these mines. In 1986, in the case of "Nicaragua v. United States", the International Court of Justice ruled that this mining was a violation of international law.

During the Gulf War, Iraqi naval mines severely damaged and . When the war concluded, eight countries conducted clearance operations.

Houthi forces in the Yemeni Civil War have made frequent use of naval mines, laying over 150 in the Red Sea throughout the conflict.

Naval mines may be classified into three major groups; contact, remote and influence mines.

The earliest mines were usually of this type. They are still used today, as they are extremely low cost compared to any other anti-ship weapon and are effective, both as a psychological weapon and as a method to sink enemy ships. Contact mines need to be touched by the target before they detonate, limiting the damage to the direct effects of the explosion and usually affecting only the vessel that triggers them.

Early mines had mechanical mechanisms to detonate them, but these were superseded in the 1870s by the "Hertz horn" (or "chemical horn"), which was found to work reliably even after the mine had been in the sea for several years. The mine's upper half is studded with hollow lead protuberances, each containing a glass vial filled with sulfuric acid. When a ship's hull crushes the metal horn, it cracks the vial inside it, allowing the acid to run down a tube and into a lead–acid battery which until then contained no acid electrolyte. This energizes the battery, which detonates the explosive.

Earlier forms of the detonator employed a vial of sulfuric acid surrounded by a mixture of potassium perchlorate and sugar. When the vial was crushed, the acid ignited the perchlorate-sugar mix, and the resulting flame ignited the gunpowder charge.

During the initial period of World War I, the Royal Navy used contact mines in the English Channel and later in large areas of the North Sea to hinder patrols by German submarines. Later, the American antenna mine was widely used because submarines could be at any depth from the surface to the seabed. This type of mine had a copper wire attached to a buoy that floated above the explosive charge which was weighted to the seabed with a steel cable. If a submarine's steel hull touched the copper wire, the slight voltage change caused by contact between two dissimilar metals was amplified and detonated the explosives.

Limpet mines are a special form of contact mine that are manually attached to the target by magnets and remain in place. They are named because of the similarity to the limpet, a mollusk.

Generally, this mine type is set to float just below the surface of the water or as deep as five meters. A steel cable connecting the mine to an anchor on the seabed prevents it from drifting away. The explosive and detonating mechanism is contained in a buoyant metal or plastic shell. The depth below the surface at which the mine floats can be set so that only deep draft vessels such as aircraft carriers, battleships or large cargo ships are at risk, saving the mine from being used on a less valuable target. In littoral waters it is important to ensure that the mine does not become visible when the sea level falls at low tide, so the cable length is adjusted to take account of tides. During WWII there were mines that could be moored in 300m-deep water.

Floating mines typically have a mass of around 200 kg, including 80 kg of explosives e.g. TNT, minol or amatol.

A special form of moored contact mines are those equipped with a plummet. When the mine is launched (1), the mine with the anchor floats first and the lead plummet sinks from it (2). In doing so, the plummet unwinds a wire, the deep line, which is used to set the depth of the mine below the water surface before it is launched (3). When the deep line has been unwound to a set length, the anchor is flooded and the mine is released from the anchor (4). The anchor begins to sink and the mooring cable unwinds until the plummet reaches the sea floor (5). Due to the decreasing tension on the deep line, the mooring cable is clamped. The anchor sinks further down to the bottom of the sea pulling the mine as deep below the water surface as the deep line has been unwound (6). Thus, even without knowing the exact depth, an exact depth of the mine below the water surface can be set. Limited only by the maximum length of the mooring cable.

Drifting mines were occasionally used during World War I and World War II. However, they were more feared than effective. Sometimes floating mines break from their moorings and become drifting mines; modern mines are designed to deactivate in this event. After several years at sea, the deactivation mechanism might not function as intended and the mines may remain live. Admiral Jellicoe's British fleet did not pursue and destroy the outnumbered German High Seas Fleet when it turned away at the Battle of Jutland because he thought they were leading him into a trap: he believed it possible that the Germans were either leaving floating mines in their wake, or were drawing him towards submarines, although neither of these was the case.

After World War I the drifting contact mine was banned, but was occasionally used during World War II. The drifting mines were much harder to remove than tethered mines after the war, and they caused about the same damage to both sides.

Churchill promoted "Operation Royal Marine" in 1940 and again in 1944 where floating mines were put into the Rhine in France to float down the river, becoming active after a time calculated to be long enough to reach German territory.

Frequently used in combination with coastal artillery and hydrophones, controlled mines (or command detonation mines) can be in place in peacetime, which is a huge advantage in blocking important shipping routes. The mines can usually be turned into "normal" mines with a switch (which prevents the enemy from simply capturing the controlling station and deactivating the mines), detonated on a signal or be allowed to detonate on their own. The earliest ones were developed around 1812 by Robert Fulton. The first remotely controlled mines were moored mines used in the American Civil War, detonated electrically from shore. They were considered superior to contact mines because they did not put friendly shipping at risk. The extensive American fortifications program initiated by the Board of Fortifications in 1885 included remotely controlled mines, which were emplaced or in reserve from the 1890s through the end of World War II.

Modern examples usually weigh , including of explosives (TNT or torpex).

These mines are triggered by the influence of a ship or submarine, rather than direct contact. Such mines incorporate electronic sensors designed to detect the presence of a vessel and detonate when it comes within the blast range of the warhead. The fuses on such mines may incorporate one or more of the following sensors: magnetic, passive acoustic or water pressure displacement caused by the proximity of a vessel.

First used during WWI, their use became more general in WWII. The sophistication of influence mine fuses has increased considerably over the years as first transistors and then microprocessors have been incorporated into designs. Simple magnetic sensors have been superseded by total-field magnetometers. Whereas early magnetic mine fuses would respond only to changes in a single component of a target vessel's magnetic field, a total field magnetometer responds to changes in the magnitude of the total background field (thus enabling it to better detect even degaussed ships). Similarly, the original broadband hydrophones of 1940s acoustic mines (which operate on the integrated volume of all frequencies) have been replaced by narrow-band sensors which are much more sensitive and selective. Mines can now be programmed to listen for highly specific acoustic signatures (e.g. a gas turbine powerplant or cavitation sounds from a particular design of propeller) and ignore all others. The sophistication of modern electronic mine fuzes incorporating these digital signal processing capabilities makes it much more difficult to detonate the mine with electronic countermeasures because several sensors working together (e.g. magnetic, passive acoustic and water pressure) allow it to ignore signals which are not recognised as being the unique signature of an intended target vessel.

Modern influence mines such as the BAE Stonefish are computerised, with all the programmability this implies, such as the ability to quickly load new acoustic signatures into fuses, or program them to detect a single, highly distinctive target signature. In this way, a mine with a passive acoustic fuze can be programmed to ignore all friendly vessels and small enemy vessels, only detonating when a very large enemy target passes over it. Alternatively, the mine can be programmed specifically to ignore all surface vessels regardless of size and exclusively target submarines.

Even as far back as WWII it was possible to incorporate a "ship counter" function in mine fuzes. This might set the mine to ignore the first two ships passing over it (which could be minesweepers deliberately trying to trigger mines) but detonate when the third ship passes overhead, which could be a high-value target such as an aircraft carrier or oil tanker. Even though modern mines are generally powered by a long life lithium battery, it is important to conserve power because they may need to remain active for months or even years. For this reason, most influence mines are designed to remain in a semi-dormant state until an unpowered (e.g. deflection of a mu-metal needle) or low-powered sensor detects the possible presence of a vessel, at which point the mine fuze powers up fully and the passive acoustic sensors will begin to operate for some minutes. It is possible to program computerised mines to delay activation for days or weeks after being laid. Similarly, they can be programmed to self-destruct or render themselves safe after a preset period of time. Generally, the more sophisticated the mine design, the more likely it is to have some form of anti-handling device to hinder clearance by divers or remotely piloted submersibles.

The moored mine is the backbone of modern mine systems. They are deployed where water is too deep for bottom mines. They can use several kinds of instruments to detect an enemy, usually a combination of acoustic, magnetic and pressure sensors, or more sophisticated optical shadows or electro potential sensors. These cost many times more than contact mines. Moored mines are effective against most kinds of ships. As they are cheaper than other anti-ship weapons they can be deployed in large numbers, making them useful area denial or "channelizing" weapons.
Moored mines usually have lifetimes of more than 10 years, and some almost unlimited. These mines usually weigh , including of explosives (RDX). In excess of of explosives the mine becomes inefficient, as it becomes too large to handle and the extra explosives add little to the mine's effectiveness.

Bottom mines (sometimes called ground mines) are used when the water is no more than deep or when mining for submarines down to around . They are much harder to detect and sweep, and can carry a much larger warhead than a moored mine. Bottom mines commonly utilize multiple types of sensors, which are less sensitive to sweeping.

These mines usually weigh between , including between of explosives.

Several specialized mines have been developed for other purposes than the common minefield.

The bouquet mine is a single anchor attached to several floating mines. It is designed so that when one mine is swept or detonated, another takes its place. It is a very sensitive construction and lacks reliability.

The anti-sweep mine is a very small mine (40 kg warhead) with as small a floating device as possible. When the wire of a mine sweep hits the anchor wire of the mine, it drags the anchor wire along with it, pulling the mine down into contact with the sweeping wire. That detonates the mine and cuts the sweeping wire. They are very cheap and usually used in combination with other mines in a minefield to make sweeping more difficult. One type is the Mark 23 used by the United States during World War II.

The mine is hydrostatically controlled to maintain a pre-set depth below the water's surface independently of the rise and fall of the tide.

The ascending mine is a floating distance mine that may cut its mooring or in some other way float higher when it detects a target. It lets a single floating mine cover a much larger depth range.

These are mines containing a moving weapon as a warhead, either a torpedo or a rocket.

Rocket mine: a Russian invention, the rocket mine is a bottom distance mine that fires a homing high-speed rocket (not torpedo) upwards towards the target. It is intended to allow a bottom mine to attack surface ships as well as submarines from a greater depth. One type is the Te-1 rocket propelled mine.

Torpedo mine: the torpedo mine is a self-propelled variety, able to lie in wait for a target and then pursue it e.g. the Mark 60 CAPTOR. Generally, torpedo mines incorporate computerised acoustic and magnetic fuzes. The U.S. Mark 24 "mine", code-named Fido, was actually an ASW homing torpedo. The mine designation was disinformation to conceal its function.

The mine is propelled to its intended position by propulsion equipment such as a torpedo. After reaching its destination, it sinks to the seabed and operates like a standard mine. It differs from the homing mine in that its mobile stage is before it lies in wait, rather than as part of the attacking phase.

One such design is the Mk 67 submarine launched mobile mine (which is based on a Mark 37 torpedo) are capable of travelling as far as 10 miles through or into a channel, harbor, shallow water area and other zones which would normally be inaccessible to craft laying the device. After reaching the target area they sink to the sea bed and act like conventionally laid influence mines.

During the Cold War a test was conducted with naval mine fitted with tactical nuclear warheads for the "Baker" shot of Operation Crossroads. This weapon was experimental and never went into production. There have been some reports that North Korea may be developing a nuclear mine The Seabed Arms Control Treaty prohibits the placement of nuclear weapons on the seabed beyond a 12-mile coast zone.

This comprises two moored, floating contact mines which are tethered together by a length of steel cable or chain. Typically, each mine is situated approximately away from its neighbour, and each floats a few metres below the surface of the ocean. When the target ship hits the steel cable, the mines on either side are drawn down the side of the ship's hull, exploding on contact. In this manner it is almost impossible for target ships to pass safely between two individually moored mines. Daisy-chained mines are a very simple concept which was used during World War II.

Plastic drums filled with sand or concrete are periodically rolled off the side of ships as real mines are laid in large mine-fields. These inexpensive false targets (designed to be of a similar shape and size as genuine mines) are intended to slow down the process of mine clearance: a mine-hunter is forced to investigate each suspicious sonar contact on the sea bed, whether it is real or not. Often a maker of naval mines will provide both training and dummy versions of their mines.

Historically several methods were used to lay mines. During WWI and WWII, the Germans used U-boats to lay mines around the UK. In WWII, aircraft came into favour for mine laying with one of the largest examples being the mining of the Japanese sea routes in Operation Starvation.

Laying a minefield is a relatively fast process with specialized ships, which is today the most common method. These minelayers can carry several thousand mines and manoeuvre with high precision. The mines are dropped at predefined intervals into the water behind the ship. Each mine is recorded for later clearing, but it is not unusual for these records to be lost together with the ships. Therefore, many countries demand that all mining operations be planned on land and records kept so that the mines can later be recovered more easily.

Other methods to lay minefields include:


In some cases, mines are automatically activated upon contact with the water. In others, a safety lanyard is pulled (one end attached to the rail of a ship, aircraft or torpedo tube) which starts an automatic timer countdown before the arming process is complete. Typically, the automatic safety-arming process takes some minutes to complete. This allows the people laying the mines sufficient time to move out of its activation and blast zones.

In the 1930s, Germany had experimented with the laying of mines by aircraft. It became a crucial element in their overall mining strategy. Aircraft had the advantage of speed, and they would never get caught in their own minefields. German mines held a large explosive charge. From April to June 1940, the Luftwaffe laid 1,000 mines in British waters. Soviet ports were mined, as was the Arctic convoy route to Murmansk. The Heinkel He 115 could carry two medium or one large mine while the Heinkel He 59, Dornier Do 18, Junkers Ju 88 and Heinkel He 111 could carry more.

The USSR was relatively ineffective in its use of naval mines in WWII in comparison with its record in previous wars. Small mines were developed for use in rivers and lakes, and special mines for shallow water. A very large chemical mine was designed to sink through ice with the aid of a melting compound. Special aerial mine designs finally arrived in 1943–1944, the AMD-500 and AMD-1000. Various Soviet Naval Aviation torpedo bombers were pressed into the role of aerial mining in the Baltic Sea and the Black Sea, including Ilyushin DB-3s, Il-4s and Lend Lease Douglas Boston IIIs.

In September 1939, the UK announced the placement of extensive defensive minefields in waters surrounding the Home Islands. Offensive aerial mining operations began in April 1940 when 38 mines were laid at each of these locations: the Elbe River, the port of Lübeck and the German naval base at Kiel. In the next 20 months, mines delivered by aircraft sank or damaged 164 Axis ships with the loss of 94 aircraft. By comparison, direct aerial attacks on Axis shipping had sunk or damaged 105 vessels at a cost of 373 aircraft lost. The advantage of aerial mining became clear, and the UK prepared for it. A total of 48,000 aerial mines were laid by the Royal Air Force (RAF) in the European Theatre during World War II.

As early as 1942, American mining experts such as Naval Ordnance Laboratory scientist Dr. Ellis A. Johnson, CDR USNR, suggested massive aerial mining operations against Japan's "outer zone" (Korea and northern China) as well as the "inner zone", their home islands. First, aerial mines would have to be developed further and manufactured in large numbers. Second, laying the mines would require a sizable air group. The US Army Air Forces had the carrying capacity but considered mining to be the navy's job. The US Navy lacked suitable aircraft. Johnson set about convincing General Curtis LeMay of the efficacy of heavy bombers laying aerial mines.

B-24 Liberators, PBY Catalinas and other bomber aircraft took part in localized mining operations in the Southwest Pacific and the China Burma India (CBI) theaters, beginning with a successful attack on the Yangon River in February 1943. Aerial minelaying operations involved a coalition of British, Australian and American aircrews, with the RAF and the Royal Australian Air Force (RAAF) carrying out 60% of the sorties and the USAAF and US Navy covering 40%. Both British and American mines were used. Japanese merchant shipping suffered tremendous losses, while Japanese mine sweeping forces were spread too thin attending to far-flung ports and extensive coastlines. Admiral Thomas C. Kinkaid, who directed nearly all RAAF mining operations in CBI, heartily endorsed aerial mining, writing in July 1944 that "aerial mining operations were of the order of 100 times as destructive to the enemy as an equal number of bombing missions against land targets."

A single B-24 dropped three mines into Haiphong harbor in October 1943. One of those mines sank a Japanese freighter. Another B-24 dropped three more mines into the harbor in November, and a second freighter was sunk by a mine. The threat of the remaining mines prevented a convoy of ten ships from entering Haiphong; and six of those ships were sunk by attacks before they reached a safe harbor. The Japanese closed Haiphong to all steel-hulled ships for the remainder of the war after another small ship was sunk by one of the remaining mines, although they may not have realized no more than three mines remained.

Using Grumman TBF Avenger torpedo bombers, the US Navy mounted a direct aerial mining attack on enemy shipping in Palau on 30 March 1944 in concert with simultaneous conventional bombing and strafing attacks. The dropping of 78 mines deterred 32 Japanese ships from escaping Koror harbor; and 23 of those immobilized ships were sunk in a subsequent bombing raid. The combined operation sank or damaged 36 ships. Two Avengers were lost, and their crews were recovered. The mines brought port usage to a halt for 20 days. Japanese mine sweeping was unsuccessful; and the Japanese abandoned Palau as a base when their first ship attempting to traverse the swept channel was damaged by a mine detonation.

In March 1945, Operation Starvation began in earnest, using 160 of LeMay's B-29 Superfortress bombers to attack Japan's inner zone. Almost half of the mines were the US-built Mark 25 model, carrying 1250 lbs of explosives and weighing about 2,000 lbs. Other mines used included the smaller 1,000 lb Mark 26. Fifteen B-29s were lost while 293 Japanese merchant ships were sunk or damaged. Twelve thousand aerial mines were laid, a significant barrier to Japan's access to outside resources. Prince Fumimaro Konoe said after the war that the aerial mining by B-29s had been "equally as effective as the B-29 attacks on Japanese industry at the closing stages of the war when all food supplies and critical material were prevented from reaching the Japanese home islands." The United States Strategic Bombing Survey (Pacific War) concluded that it would have been more efficient to combine the United States's effective anti-shipping submarine effort with land- and carrier-based air power to strike harder against merchant shipping and begin a more extensive aerial mining campaign earlier in the war. Survey analysts projected that this would have starved Japan, forcing an earlier end to the war. After the war, Dr. Johnson looked at the Japan inner zone shipping results, comparing the total economic cost of submarine-delivered mines versus air-dropped mines and found that, though 1 in 12 submarine mines connected with the enemy as opposed to 1 in 21 for aircraft mines, the aerial mining operation was about ten times less expensive per enemy ton sunk.

Between 600,000 and 1,000,000 naval mines of all types were laid in WWII. Advancing military forces worked to clear mines from newly-taken areas, but extensive minefields remained in place after the war. Air-dropped mines had an additional problem for mine sweeping operations: they were not meticulously charted. In Japan, much of the B-29 mine-laying work had been performed at high altitude, with the drifting on the wind of mines carried by parachute adding a randomizing factor to their placement. Generalized danger areas were identified, with only the quantity of mines given in detail. Mines used in Operation Starvation were supposed to be self-sterilizing, but the circuit did not always work. Clearing the mines from Japanese waters took so many years that the task was eventually given to the Japan Maritime Self-Defense Force.

For the purpose of clearing all types of naval mines, the Royal Navy employed German crews and minesweepers from June 1945 to January 1948, organised in the German Mine Sweeping Administration (GMSA), which consisted of 27,000 members of the former "Kriegsmarine" and 300 vessels. Mine clearing was not always successful: a number of ships were damaged or sunk by mines after the war. Two such examples were the liberty ships "Pierre Gibault" which was scrapped after hitting a mine in a previously cleared area off the Greek island of Kythira in June 1945, and "Nathaniel Bacon" which hit a minefield off Civitavecchia, Italy in December 1945, caught fire, was beached, and broke in two.

The damage that may be caused by a mine depends on the "shock factor value", a combination of the initial strength of the explosion and of the distance between the target and the detonation. When taken in reference to ship hull plating, the term "Hull Shock Factor" (HSF) is used, while keel damage is termed "Keel Shock Factor" (KSF). If the explosion is directly underneath the keel, then HSF is equal to KSF, but explosions that are not directly underneath the ship will have a lower value of KSF.

Usually only created by contact mines, direct damage is a hole blown in the ship. Among the crew, fragmentation wounds are the most common form of damage. Flooding typically occurs in one or two main watertight compartments, which can sink smaller ships or disable larger ones. Contact mine damage often occurs at or close to the waterline near the bow, but depending on circumstances a ship could be hit anywhere on its outer hull surface (the mine attack being a good example of a contact mine detonating amidships and underneath the ship).

The bubble jet effect occurs when a mine or torpedo detonates in the water a short distance away from the targeted ship. The explosion creates a bubble in the water, and due to the difference in pressure, the bubble will collapse from the bottom. The bubble is buoyant, and so it rises towards the surface. If the bubble reaches the surface as it collapses, it can create a pillar of water that can go over a hundred meters into the air (a "columnar plume"). If conditions are right and the bubble collapses onto the ship's hull, the damage to the ship can be extremely serious; the collapsing bubble forms a high-energy jet similar to shaped charge can break a metre-wide hole straight through the ship, flooding one or more compartments, and is capable of breaking smaller ships apart. The crew in the areas hit by the pillar are usually killed instantly. Other damage is usually limited.

The Baengnyeong incident, in which the ROKS "Cheonan" broke in half and sank off the coast South Korea in 2010, was caused by the bubble jet effect, according to an international investigation.

If the mine detonates at a distance from the ship, the change in water pressure causes the ship to resonate. This is frequently the most deadly type of explosion, if it is strong enough. The whole ship is dangerously shaken and everything on board is tossed around. Engines rip from their beds, cables from their holders, etc.. A badly shaken ship usually sinks quickly, with hundreds, or even thousands of small leaks all over the ship and no way to power the pumps. The crew fare no better, as the violent shaking tosses them around. This shaking is powerful enough to cause disabling injury to knees and other joints in the body, particularly if the affected person stands on surfaces connected directly to the hull (such as steel decks).

The resulting gas cavitation and shock-front-differential over the width of the human body is sufficient to stun or kill divers.

Weapons are frequently a few steps ahead of countermeasures, and mines are no exception. In this field the British, with their large seagoing navy, have had the bulk of world experience, and most anti-mine developments, such as degaussing and the double-L sweep, were British inventions. When on operational missions, such as the recent invasion of Iraq, the US still relies on British and Canadian minesweeping services. The US has worked on some innovative mine-hunting countermeasures, such as the use of military dolphins to detect and flag mines. However, they are of questionable effectiveness. Mines in nearshore environments remain a particular challenge. They are small and as technology has developed they can have anechoic coatings, be non-metallic, and oddly shaped to resist detection. Further, oceanic conditions and the sea bottoms of the area of operations can degrade sweeping and hunting efforts. Mining countermeasures are far more expensive and time-consuming than mining operations, and that gap is only growing with new technologies.

Ships can be designed to be difficult for mines to detect, to avoid detonating them. This is especially true for minesweepers and mine hunters that work in minefields, where a minimal signature outweighs the need for armour and speed. These ships have hulls of glass fibre or wood instead of steel to avoid magnetic signatures. These ships may use special propulsion systems, with low magnetic electric motors, to reduce magnetic signature, and Voith-Schneider propellers, to limit the acoustic signature. They are built with hulls that produce a minimal pressure signature. These measures create other problems. They are expensive, slow, and vulnerable to enemy fire. Many modern ships have a mine-warning sonar—a simple sonar looking forward and warning the crew if it detects possible mines ahead. It is only effective when the ship is moving slowly. 

A steel-hulled ship can be "degaussed" (more correctly, de-oerstedted or depermed) using a special degaussing station that contains many large coils and induces a magnetic field in the hull with alternating current to demagnetize the hull. This is a rather problematic solution, as magnetic compasses need recalibration and all metal objects must be kept in exactly the same place. Ships slowly regain their magnetic field as they travel through the Earth's magnetic field, so the process has to be repeated every six months.

A simpler variation of this technique, called "wiping", was developed by Charles F. Goodeve which saved time and resources.

Between 1941 and 1943 the US Naval Gun factory (a division of the Naval Ordnance Laboratory) in Washington, D.C., built physical models of all US naval ships. Three kinds of steel were used in shipbuilding: mild steel for bulkheads, a mixture of mild steel and high tensile steel for the hull, and special treatment steel for armor plate. The models were placed within coils which could simulate the Earth's magnetic field at any location. The magnetic signatures were measured with degaussing coils. The objective was to reduce the vertical component of the combination of the Earth's field and the ship's field at the usual depth of German mines. From the measurements, coils were placed and coil currents determined to minimize the chance of detonation for any ship at any heading at any latitude.

Some ships are built with magnetic inductors, large coils placed along the ship to counter the ship's magnetic field. Using magnetic probes in strategic parts of the ship, the strength of the current in the coils can be adjusted to minimize the total magnetic field. This is a heavy and clumsy solution, suited only to small-to-medium-sized ships. Boats typically lack the generators and space for the solution, while the amount of power needed to overcome the magnetic field of a large ship is impractical.

Active countermeasures are ways to clear a path through a minefield or remove it completely. This is one of the most important tasks of any mine warfare flotilla.

A sweep is either a contact sweep, a wire dragged through the water by one or two ships to cut the mooring wire of floating mines, or a distance sweep that mimics a ship to detonate the mines. The sweeps are dragged by minesweepers, either purpose-built military ships or converted trawlers. Each run covers between one and two hundred meters, and the ships must move slowly in a straight line, making them vulnerable to enemy fire. This was exploited by the Turkish army in the Battle of Gallipoli in 1915, when mobile howitzer batteries prevented the British and French from clearing a way through minefields.

If a contact sweep hits a mine, the wire of the sweep rubs against the mooring wire until it is cut. Sometimes "cutters", explosive devices to cut the mine's wire, are used to lessen the strain on the sweeping wire. Mines cut free are recorded and collected for research or shot with a deck gun.

Minesweepers protect themselves with an oropesa or paravane instead of a second minesweeper. These are torpedo-shaped towed bodies, similar in shape to a Harvey Torpedo, that are streamed from the sweeping vessel thus keeping the sweep at a determined depth and position. Some large warships were routinely equipped with paravane sweeps near the bows in case they inadvertently sailed into minefields—the mine would be deflected towards the paravane by the wire instead of towards the ship by its wake. More recently, heavy-lift helicopters have dragged minesweeping sleds, as in the 1991 Persian Gulf War.

The distance sweep mimics the sound and magnetism of a ship and is pulled behind the sweeper. It has floating coils and large underwater "drums". It is the only sweep effective against bottom mines.

During WWII, RAF Coastal Command used Vickers Wellington bombers Wellington DW.Mk I fitted with degaussing coils to trigger magnetic mines.

Modern influence mines are designed to discriminate against false inputs and are, therefore, much harder to sweep. They often contain inherent anti-sweeping mechanisms. For example, they may be programmed to respond to the unique noise of a particular ship-type, its associated magnetic signature and the typical pressure displacement of such a vessel. As a result, a mine-sweeper must accurately mimic the required target signature to trigger detonation. The task is complicated by the fact that an influence mine may have one or more of a hundred different potential target signatures programmed into it.

Another anti-sweeping mechanism is a ship-counter in the mine fuze. When enabled, this allows detonation only after the mine fuze has been triggered a pre-set number of times. To further complicate matters, influence mines may be programmed to arm themselves (or disarm automatically—known as "self-sterilization") after a pre-set time. During the pre-set arming delay (which could last days or even weeks) the mine would remain dormant and ignore any target stimulus, whether genuine or false.

When influence mines are laid in an ocean minefield, they may have various combinations of fuze settings configured. For example, some mines (with the acoustic sensor enabled) may become active within three hours of being laid, others (with the acoustic and magnetic sensors enabled) may become active after two weeks but have the ship-counter mechanism set to ignore the first two trigger events, and still others in the same minefield (with the magnetic and pressure sensors enabled) may not become armed until three weeks have passed. Groups of mines within this mine-field may have different target signatures which may or may not overlap. The fuzes on influence mines allow many different permutations, which complicates the clearance process.

Mines with ship-counters, arming delays and highly specific target signatures in mine fuzes can falsely convince a belligerent that a particular area is clear of mines or has been swept effectively because a succession of vessels have already passed through safely.
As naval mines have become more sophisticated, and able to discriminate between targets, so they have become more difficult to deal with by conventional sweeping. This has given rise to the practice of mine-hunting.
Mine hunting is very different from sweeping, although some minehunters can do both tasks. Minehunting pays little attention to the nature of the mine itself. Nor does the method change much. At the current state of the art, Minehunting remains the best way to deal with influence mines proving to be both safer and more effective than sweeping. Specialized high-frequency sonars and high fidelity sidescaning sonar are used for mine location. Mines are hunted using sonar, then inspected and destroyed either by divers or ROVs (remote controlled unmanned mini-submarines). It is slow, but also the most reliable way to remove mines. Minehunting started during the Second World War, but it was only after the war that it became truly effective.

Sea mammals (mainly the bottlenose dolphin) have been trained to hunt and mark mines, most famously by the U.S. Navy Marine Mammal Program. Mine-clearance dolphins were deployed in the Persian Gulf during the Iraq War in 2003. The US Navy claims that these dolphins were effective in helping to clear more than 100 antiship mines and underwater booby traps from Umm Qasr Port.

French naval officer Jacques Yves Cousteau's Undersea Research Group was once involved in mine-hunting operations: They removed or detonated a variety of German mines, but one particularly defusion-resistant batch—equipped with acutely sensitive pressure, magnetic, and acoustic sensors and wired together so that one explosion would trigger the rest—was simply left undisturbed for years until corrosion would (hopefully) disable the mines.
A more drastic method is simply to run a ship through the minefield, letting other ships safely follow the same path. An early example of this was Farragut's actions at Mobile Bay during the American Civil War. However, as mine warfare became more developed this method became uneconomical.
This method was revived by the German "Kriegsmarine" during WWII. Left with a surfeit of idle ships due to the Allied blockade, the "Kriegsmarine" introduced a ship known as "Sperrbrecher" ("block breaker"). Typically an old cargo ship, loaded with cargo that made her less vulnerable to sinking (wood for example), the "Sperrbrecher" was run ahead of the ship to be protected, detonating any mines that might be in their path. The use of "Sperrbrecher" obviated the need to continuous and painstaking sweeping, but the cost was high. Over half the 100 or so ships used as "Sperrbrecher" were sunk during the war. Alternatively, a shallow draught vessel can be steamed through the minefield at high speed to generate a pressure wave sufficient to trigger mines, with the minesweeper moving fast enough to be sufficiently clear of the pressure wave so that triggered mines do not destroy the ship itself. These techniques are the only publicly known to be employed way to sweep pressure mines. The technique can be simply countered by use of a ship-counter, set to allow a certain number of passes before the mine is actually triggered. Modern doctrine calls for ground mines to be hunted rather than swept. A new system is being introduced for sweeping pressure mines, however counters are going to remain a problem.

An updated form of this method is the use of small unmanned ROVs (such as the "Seehund" drone) that simulate the acoustic and magnetic signatures of larger ships and are built to survive exploding mines. Repeated sweeps would be required in case one or more of the mines had its "ship counter" facility enabled i.e. were programmed to ignore the first 2, 3, or even 6 target activations.

The United States Navy MK56 ASW mine (the oldest still in use by the United States) was developed in 1966. More advanced mines include the MK60 CAPTOR (short for "encapsulated torpedo"), the MK62 and MK63 Quickstrike and the MK67 SLMM (Submarine Launched Mobile Mine). Today, most U.S. naval mines are delivered by aircraft.

MK67 SLMM Submarine Launched Mobile Mine
The SLMM was developed by the United States as a submarine deployed mine for use in areas inaccessible for other mine deployment techniques or for covert mining of hostile environments. The SLMM is a shallow-water mine and is basically a modified Mark 37 torpedo.

General characteristics

MK65 Quickstrike
The Quickstrike is a family of shallow-water aircraft-laid mines used by the United States, primarily against surface craft. The MK65 is a 2,000-lb (900 kg) dedicated, purpose-built mine. However, other Quickstrike versions (MK62, MK63, and MK64) are converted general-purpose bombs. These latter three mines are actually a single type of electronic fuze fitted to Mk82, Mk83 and Mk84 air-dropped bombs. Because this latter type of Quickstrike fuze only takes up a small amount of storage space compared to a dedicated sea mine, the air-dropped bomb casings have dual purpose i.e. can be fitted with conventional contact fuzes and dropped on land targets, or have a Quickstrike fuze fitted which converts them into sea mines.

General characteristics


MK56
General characteristics


According to a statement made to the UK Parliament in 2002:

...the Royal Navy does not have any mine stocks and has not had since 1992. Notwithstanding this, the United Kingdom retains the capability to lay mines and continues research into mine exploitation. Practice mines, used for exercises, continue to be laid in order to retain the necessary skills.

However, a British company (BAE Systems) does manufacture the Stonefish influence mine for export to friendly countries such as Australia, which has both war stock and training versions of Stonefish, in addition to stocks of smaller Italian MN103 Manta mines. The computerised fuze on a Stonefish mine contains acoustic, magnetic and water pressure displacement target detection sensors. Stonefish can be deployed by fixed-wing aircraft, helicopters, surface vessels and submarines. An optional kit is available to allow Stonefish to be air-dropped, comprising an aerodynamic tail-fin section and parachute pack to retard the weapon's descent. The operating depth of Stonefish ranges between 30 and 200 metres. The mine weighs 990 kilograms and contains a 600 kilogram aluminised PBX explosive warhead.

Mine warfare remains the most cost-effective of asymmetrical naval warfare. Mines are relatively cheap and being small allows them to be easily deployed. Indeed, with some kinds of mines, trucks and rafts will suffice. At present there are more than 300 different mines available. Some 50 countries currently have mining ability. The number of naval mine producing countries has increased by 75% since 1988. It is also noted that these mines are of an increasing sophistication while even the older type mines present a significant problem. It has been noted that mine warfare may become an issue with terrorist organizations. Mining busy shipping straits and mining shipping harbors remain some of the most serious threats.






</doc>
<doc id="22104" url="https://en.wikipedia.org/wiki?curid=22104" title="Nawal El Moutawakel">
Nawal El Moutawakel

Nawal El Moutawakel (Amazigh: Nawal Lmutawakkil; ; born on April 15, 1962 in Casablanca) is a Moroccan former hurdler, who won the inaugural women's 400 metres hurdles event at the 1984 Summer Olympics, and was the inaugural female, Muslim, born in Africa, Moroccan to become an Olympic medalist (gold). In 2007, El Moutawakel was named the Minister of Sports in the upcoming cabinet of Morocco.

Although she had been a quite accomplished runner, the victory of El Moutawakel, who studied at Iowa State University at the time, was a surprise. King Hassan II of Morocco telephoned El Moutawakel to give his congratulations, and he declared that all girls born the day of her victory were to be named in her honor. Her medal also meant the breakthrough for sporting women in Morocco and other mostly Muslim countries.

She was a pioneer for Muslim and Arabic athletes in that she confounded long-held beliefs that women of such backgrounds could not succeed in athletics.

In 1993 she started running for fun, a 5 km run for women in Casablanca that has since become the biggest women's race held in a Muslim country, with up to 30,000 who came to run.

In 1995, El Moutawakel became a council member of the International Association of Athletics Federations (IAAF), and in 1998 she became a member of the International Olympic Committee (IOC).

El Moutawakel is a member of the International Olympic Committee, and she was the president of the evaluation commissions for the selection of the host city for the Summer Olympics of 2012 and 2016. Since 2012 she is a Vice-President of the IOC.

In 2006, El Moutawakel was one of the eight honored to bear the Olympic flag at the 2006 Winter Olympics Opening Ceremony in Turin, Italy. On 26 July 2012, she carried the London Olympics torch through Westminster.

El Moutawakel was one of the ambassadors of the Morocco bid for the 2026 FIFA World Cup.

Representing Africa


 


</doc>
<doc id="22106" url="https://en.wikipedia.org/wiki?curid=22106" title="North Melbourne Football Club">
North Melbourne Football Club

The North Melbourne Football Club, nicknamed the Kangaroos or less formally the Roos, the Kangas or North, is an Australian rules football club that competes in the Australian Football League (AFL), the sport's premier competition. Founded in the suburb of North Melbourne in 1869, it is based at its traditional home ground, Arden Street Oval, and currently plays its home matches at both the nearby Docklands Stadium and Blundstone Arena in Hobart, Tasmania.

The club's mascot is a grey kangaroo donning the club uniform, and its use dates from the mid-20th century. The club is also unofficially known as "The Shinboners", a term which dates back to its 19th-century abattoir-worker origins. The club's motto is "Victoria amat curam", Latin for "Victory Demands Dedication". Aside from their representation in the AFL, the Kangaroos also field teams in the following competitions; AFL Women's, VFL Women's and Victorian Football League.

North Melbourne Football Club was founded in North Melbourne in 1869 by local cricketers desiring to keep fit over the winter months. One thought is that the club was connected to the St Mary's Church of England Cricket Club, now the St Mary's Anglican Church North Melbourne, whose colours – blue and white – are reflected in the club's colours today. The association between the St Mary's Church of England Cricket Club and the establishment of the North Melbourne Football Club is believed to have been an informal gathering to play some competitive sport. Information on the club's first ever match is limited, but it is known that it took place in Royal Park, which also served as the club's home ground until 1882. The ball used in the match was purchased by a local resident called Tom Jacks, who sold some roofing iron to pay for it. James Henry Gardiner is considered the founder of the club. He continued an active role with North Melbourne until his death in 1921.

Regular premiership matches of Australian Football commenced in Victoria in 1870. Although North Melbourne was a part of this, it was classed as a "junior club". "The Australasian" noted them as being "one of the best of many junior clubs".

The club continued to develop, graduating to senior ranks in 1874, finishing 4th. Along with the promotion, the club adopted its first uniform of blue and white horizontal stripes.

In 1876, North Melbourne disbanded, and many of its player and members joined Albert-park, giving the club such a strong North Melbourne character that many described it as "Albert-park "cum" North Melbourne". In 1877, the club was re-established as a stand-alone club under the new name of "Hotham".

Football took a giant step forward in 1877, with the formation of Victoria's first colonial football league, the VFA. Hotham were prime movers in establishing this league and were afforded a place in light of their previous contributions to Australian Football.

The 1880s marked the emergence of the modern identity we now associate with North today. In 1882, the club amalgamated with the Hotham Cricket Club and moved into the North Melbourne Recreation Reserve (Arden St Oval), which remains the home of the club today. The joint venture was aimed at affecting improvements at the Hotham Cricket Ground, which was the name of the Reserve at the time. Four years later the club adopted the traditional uniform of blue and white vertical stripes at the insistence of the VFA, who wanted a visible contrast between Geelong's and Hotham's uniforms. The third significant development occurred in 1888 with the club returning to its original name of the North Melbourne Football Club. This followed the name of the local area reverting from Hotham to North Melbourne.

The 1880s saw the club develop a penchant for inter-colonial travel with trips to Tasmania (1881/1887) and South Australia (1889). Hotham also found itself well represented at the first ever inter-colonial representative game in 1879 with four players from the club gaining selection for Victoria.

The VFA grew to 13 senior clubs in the 1890s. Led by Geelong and Essendon, the largest clubs of the VFA formed their own break away league, the Victorian Football League (VFL), in 1896. Despite finishing 6th in 1896, North Melbourne was not invited to the breakaway competition. The main reasons for being excluded were:

North continued on in the depleted VFA, emerging as a powerhouse, finishing 2nd in 1897, 1898 and 1899. In 1903, after 34 years of competing, the club won its first premiership, defeating Richmond in the final. The club became back to back premiers in 1904 after Richmond forfeited the grand final due to the appointment of an umpire whose performance when the two teams met earlier in the year was severely criticised by Richmond players and officials.

North merged with fellow VFA football club West Melbourne in 1907, which at the time had lost its home ground. The joint venture saw a chance of promotion, and the club applied for admission to the more prestigious VFL in 1908, but Richmond and University were admitted instead. North was kicked out of the VFA during the 1907/08 offseason as a result of applying to join the VFL, before the local community reestablished the North Melbourne Football Club under a new committee, successfully enabling the club to play in the VFA in the 1908 season.

The reformation of the Club necessitated a massive clean out of the team, leaving only two players remaining from the previous season. The 1910 season was marked by one of the most sensational transfers in Victorian football history, when Andy Curran masterminded the clearance of Carlton's famed "Big Four" of 'Mallee' Johnson, Fred Jinks, Charlie Hammond and Frank 'Silver' Caine to North Melbourne. These signings secured the Northerners' third premiership in 1910.

The 1912 finals series was one of the most amazing ever, with the semi-final having to be played three times, after North and Brunswick drew twice. North was eventually victorious and moved on to the final, but lost the game by a mere four points with the last kick of the day.

The next few years were punctuated by "The Invincibles". In the Northerners' most illustrious period ever, the club went undefeated from 1914 to 1919, collecting premierships in 1914, 1915 and 1918 – the league was in recess in 1916 and 1917 due to World War I. As well as this, the club won the championship in both 1915 and 1918 for finishing on top of the ladder, and accounted for VFL side St Kilda comfortably. During this period the club won 58 consecutive matches including 49 successive premiership matches, a record that has remained unmatched in Association or League history since.

Despite being rejected from the VFL in both 1896 and 1907, North persisted in trying to gain admission into the League. On 30 June 1921, North told its players it would disband and try to gain entry to the VFL by the 'back-door'. Essendon League Football Club had lost its playing ground at East Melbourne and had decided to acquire the North Melbourne Recreation Reserve as a new playing ground. North accepted their proposal in the idea that the clubs would amalgamate. All of North's players were urged to join the Essendon League Club to help facilitate the amalgamation. The amalgamation was foiled when some members of the VFA launched a successful legal challenge. As a result, the Essendon League Club moved instead to the Essendon Oval, replacing the ground's original occupants, Essendon Association.

North was now without a playing team and the Essendon Association Club was now without a ground, so as a matter of convenience the two clubs amalgamated so they could compete in the 1922 season. As it had after the merger with West Melbourne, North once again managed to avert its destruction.

After three attempts, 29 years of waiting and numerous other applications to enter the VFL, finally North was rewarded for its persistence with admittance to the League in 1925, along with Footscray and Hawthorn. Even then, the opportunity was almost lost as the League delegates debated into the early hours of the morning on which clubs should be invited to join the intake. It was only after much deliberation that North Melbourne's name was eventually substituted for Prahran's making North "the lucky side" of the invitees that included Footscray and Hawthorn. North Melbourne was forced to change its uniform to avoid a clash when it joined the VFL.

North Melbourne were cellar dwellers for its first twenty-five years of VFL membership and struggled to win matches in the superior VFL competition, with the only bright note being Sel Murray winning the VFL Leading Goalkicker Medal in 1941 with 88 goals. By the late 1940s, North Melbourne had developed a strong list and significant supporter base. In 1949 North secured the VFL Minor Premiership, finishing top of the ladder at the end of the home-and-away season with 14 wins and 5 losses. They failed to make the Grand Final that year (eventually won by Essendon), but in 1950 they did reach the final, defeated by a more efficient Essendon. It was in this year that the club adopted the "Kangaroos" mascot.

In February 1965, North Melbourne moved its playing and training base from the Arden Street Oval to Coburg Oval, signing a seven-year lease with the City of Coburg after initially negotiating long-term leases for up to 40 years. The club came to an arrangement to merge with the VFA's Coburg Football Club, whom it was displacing from the ground; fourteen Coburg committeemen joined the North Melbourne committee, but the merger was never completed after Coburg established a rival committee which remained loyal to the VFA. The lease at Coburg lasted only eight months; the Coburg council was hesitant to build a new grandstand without the security of a long-term lease, and neither party made the returns they expected, so it was terminated by mutual agreement in September 1965 and North Melbourne returned to the Arden Street Oval.

Onfield, the 1950s and 1960s were lean years for North Melbourne, though the club did secure two consecutive Night Premierships in 1965 and 1966. Allen Aylett was a brilliant player in the late 1950s and early 1960s (and captain between 1961 and 1964), as was Noel Teasdale, who lost the Brownlow Medal on a countback in 1965 (he was later awarded a retrospective medal when the counting system was amended).

In the late 1960s, under the leadership of Allen Aylett, North Melbourne began its climb to supremacy. As part of a major recruitment drive North secured the services of several big-name stars, including Barry Davis from Essendon, Doug Wade from Geelong, John Rantall from South Melbourne, and Barry Cable from Perth. In a major coup, the great Ron Barassi was appointed coach in 1973. Barrassi reversed the club's playing fortunes, taking a struggling team that was once regarded as the traditional cellar dwellers of the competition through to a golden era of success that transformed North Melbourne into one of the powerhouses of the VFL. Barassi took North to a Grand Final (losing to Richmond by 41 points) in 1974 and brought success in his 1975 and 1977 seasons. North made five consecutive Grand Finals from 1974–1978) and defeated Norwood in the 1975 national championship and thus declared Champions of Australia.
In 1973 and 1974, North's wingman Keith Greig (recruited from Brunswick Football Club, Victoria) won consecutive Brownlow Medals; forward Malcolm Blight (recruited from Woodville Football Club, South Australia) then won the award in 1978. Doug Wade (recruited from Geelong Football Club, Geelong) won the Coleman medal in 1974 with his 103 goals for the season.

Barassi remained team coach until 1980, but only a Night Premiership in that year resulted in him leaving Arden Street. North then entered another period of decline, though Malcolm Blight kicked 103 goals to take out the Coleman medal in 1982, and another Brownlow win came through the talented Ross Glendinning in 1983. In that year, North Melbourne won a third Minor Premiership with 16 wins and 6 losses for the season, but they failed to make the Grand Final.

The capable coaching of John Kennedy aside, the 1980s and early 1990s were lean years for the Kangaroos. However, the rebuilding of the club was taking place. The Krakouer brothers (Jim and Phil) brought a spark into the side and lifted many hopes for North supporters and the excitement to the general football public. The innovative idea of night games was instigated by the club and meeting the challenges, the club survived. One major highlight was the recruitment of forward John Longmire in 1989, who topped the club goalkicking over five consecutive seasons (1990–1994) and won the Coleman medal in 1990 with 98 goals. At the beginning of the 1993 season, in a dramatic and controversial move, the board of the club sacked coach and long-time player Wayne Schimmelbusch, and appointed Denis Pagan in his place. Results were immediate, as North reached the finals for the first time in nearly a decade.

Pagan was instrumental in appointing young centre half-forward Wayne Carey as the club's youngest-ever captain. Carey had been recruited at the same time as Longmire, but had taken longer to develop as a player. Over the next nine seasons, Carey came to be regarded as the standout player in the league, and was known as 'the King'.

North Melbourne became a powerhouse through the 1990s under Pagan and Carey, and finished in the top four from 1994 until 2000. After being eliminated in the preliminary finals in 1994 and 1995, North went on to defeat the Sydney Swans in the 1996 Grand Final to take out the club's third premiership, and the gold centenary AFL cup; Glenn Archer won the Norm Smith Medal. The club was again eliminated in the preliminary final in 1997. In 1998, as the club won both the pre-season Ansett Cup and topped the ladder with 16 wins and 6 losses, but went on to lose the 1998 Grand Final to Adelaide, not helped by an inaccurate goalkicking performance of 8.22 (70) to Adelaide's 15.15 (105). In 1999, the Kangaroos finished in second position on the ladder, and went on to defeat Carlton in the Grand Final, winning the club's fourth VFL/AFL premiership; former Sydney midfielder Shannon Grant taking out the Norm Smith Medal. The club was eliminated in the preliminary finals in 2000 against Melbourne.

In 1996, the club was in advanced talks with the Fitzroy Football Club to create the North Fitzroy Kangaroos Football Club, which was in a terminal financial condition, to a merger between the two clubs; however, Fitzroy ultimately merged with the Brisbane Bears instead.

Seeking new markets and greater financial security in an increasingly corporatized AFL environment, the title "North Melbourne" was officially dropped from the logo in 1999, from which time the team played only as the "Kangaroos". During the successful 1999 season, North Melbourne played home games in Sydney with a view of becoming a second team in New South Wales; however, the experiment was not successful, with crowds averaging only 12,000.

The 21st century did not begin well for North Melbourne. Its decade-long onfield potency was in decline, questions were raised about its financial position and long-term sustainability. Furthermore, three of the people most important to the club's success in the 1990s left the club under acrimonious circumstances: CEO Greg Miller left the club, captain Wayne Carey left prior to the 2002 season following an extramarital affair with the wife of teammate and vice captain Anthony Stevens, coach Denis Pagan was lured to Carlton at the end of 2002. Pagan was replaced by 1996 premiership player Dean Laidley, who had previously been an Assistant Coach at Collingwood from 1999 until the end of season 2002.

On a post-season holiday, several players were caught in the 2002 Bali bombing terrorist attack, notably defender Jason McCartney, who suffered second-degree burns to over 50% of his body while carrying others to safety and nearly died during surgery after being flown back to Melbourne. In what is regarded as one of the most inspirational stories of Australian rules football and Australian sport in general, McCartney successfully returned to action on 6 June 2003 against Richmond at Docklands Stadium. Playing at full forward, he took a mark in the final quarter, scored a goal from the resulting set shot and set up Leigh Harding's winning goal with two minutes remaining. McCartney retired immediately after the game, citing that his recovery had left him spent, and he was chaired from the ground. McCartney wore the numbers "88" and "202" on the front of his long-sleeved for the match, signifying the Australian and total number of victims of the Bali bombings, while many in the crowd bore signs reading "Bali 88/202".

Onfield, the club reached the elimination finals in 2002 and 2005, but otherwise failed to reach the finals from 2001 until 2006.
After two seasons of finals North Melbourne dropped to 13th in 2009, and coach Dean Laidley announced his resignation with Darren Crocker acting as caretaker coach for the rest of the season, to eventually be replaced by ex-Brisbane Lions premiership player and Collingwood assistant coach Brad Scott. A$15 million redevelopment of the Arden Street, which had started in 2006, was completed in 2009, giving the club top-class training facilities.

North Melbourne struggled in its first two years under Brad Scott, finishing 9th in both 2010 and 2011. In 2012, the club returned to the finals for the first time since 2008, finishing the season in 8th place, but would go down to the West Coast Eagles by 96 points in an elimination final. In 2012, the club began a three-year deal to play two games each year at Blundstone Arena in Hobart, Tasmania. The club finished 10th in 2013 in a season full of close losses. Nick Dal Santo signed with the club at the end of the 2013 season as a restricted free agent.

In 2014, North Melbourne finished 6th at the end of the home and away season and reached 40,000 members for the first time in the club's history.
In September, North Melbourne went on to defeat Essendon by 12 points in the 2nd Elimination Final, only taking the lead in the last quarter. The following week, North Melbourne beat Geelong in the 2nd Semi-final by 6 points advancing them through to their first preliminary final since 2007. They lost to Sydney by 71 points. In 2015 the club made history by becoming the first team to qualify for a preliminary final from 8th spot, losing to the West Coast Eagles by 25 points.
In 2016, North Melbourne won its first nine matches, which is the club's best start to a season in its VFL/AFL history. On 27 July 2016, the club announced it had surpassed 45,000 members for the first time in the club's history. In 2016, the Kangaroos fielded what was the oldest team in AFL history. Unfortunately after the midpoint of the season they fell away and struggled against some of the worst teams in competition. In the mid season of 2019 Brad Scott made the decision to leave NMFC after a great 10 years at the club taking them to the finals on multiple occasions. Rhyce Shaw took over as caretaker coach in the interim and was later awarded the position as head coach for the following season.

The club was widely known as the "Shinboners" for much of its early history. The origins of the nickname are unknown but it may have had something to do with the club's reputation for targeting the shinbones of opposition players, or to do with local butchers who showed their support for North by dressing up beef leg-bones in the club colours. By 1926, the club was known as the "Blue Birds", but this nickname did not last. It was Phonse Tobin, North president from 1953 to 1956, who oversaw the club adopting the kangaroo emblem in 1954; Tobin found the image of a shinbone unsavoury and wanted the club to have a mascot it could show with pride. In selecting a new name, he wanted something characteristically Australian and was inspired by a large kangaroo he saw on display outside a city store.

The official name of the club is North Melbourne, but the club has gone under several other aliases over the years. The club was founded as the "North Melbourne Football Club", but changed to "North Melbourne cum Albert Park" after merging with Albert Park in 1876. Following the reformation of the club in 1877, it was known as the "Hotham Football Club" but later took the name "North Melbourne" again in 1888. In 1998 the club proposed changing its name to the "Northern Kangaroos", but it was rejected by the AFL. From 1999 to 2007, the club traded without much success as "The Kangaroos" in a bid to increase its appeal nationally; this decision was reversed at the end of 2007 and the club has again reverted to the name "North Melbourne".

"Join in the Chorus" is the official anthem of the North Melbourne Football Club. It is sung to the tune of a Scottish folk song from around 1911, "A Wee Deoch an Doris".

The song is generally sung, in accordance to common football tradition, after a victory. It is also played before every match.

"Join in the Chorus" is believed to be the oldest club anthem of any AFL club and has been associated with North from its early VFA days. The preamble of the song originates from a score of a theatre musical called "Australia: Heart to Heart and Hand to Hand", written by Toso Taylor in the 1890s in pre-federation Australia. The second verse is unknown in origin and was presumably added later by members of the club when the song was chosen. The chorus was appropriated from a song written and performed by Scottish musician Harry Lauder. The recording currently used by the club was performed by the Fable Singers in April 1972 and only includes the choruses.

The song has a strong Victorian heritage and has been traditionally sung by the Victorian State Football and Victorian Cricket teams respectively. The lyrics have occasionally been changed, including updating the year in the song (e.g. "North Melbourne will be premiers in 1993"), or to remove the words "North Melbourne" during the period when the club was competing only as the Kangaroos.

For the 2015 premiership season, You Am I's lead singer, Tim Rogers, a North Melbourne supporter, announced that he would assist in an updated version of the song including the two verses. This version is only played at North home games as the team runs onto the ground.

The term "Shinboner spirit" is often used to refer to camaraderie and determination of players or members of the North Melbourne Football Club. The term persists to the modern day, despite North Melbourne having switched its official nickname from the Shinboners to the Kangaroos in the 1950s.

Because it relates to the club's original nickname, Shinboner spirit is often associated with the complete history of the club. In 2005, to celebrate the club's 80th anniversary of senior competition in the VFL and the 30th anniversary of its first VFL premiership, the Kangaroos held a "Shinboner Spirit" gala event attended by almost the entire surviving players. In the awards ceremony, the key Shinboners of the past 80 years were acknowledged and Glenn Archer was named the "Shinboner of the Century".

The North Melbourne Football Club has a long history of wearing various designs in the colours of royal blue and white.

Most of the club's earliest jumpers were long-sleeved and not the sleeveless design common today. In their early years the club sported a hooped design when they took to the field. This changed at the behest of the VFA in 1884 who insisted that Hotham change their jumpers to vertical stripes to provide a visible contrast between Hotham and Geelong.

After 1884 the vertical top was worn more often, usually in the lace-up design in the gallery below.

After the merger with West Melbourne, North used a composite jumper that incorporated West Melbourne's red sash for the 1908 season. The merger was in reality, a takeover. The red sash was a token gesture and was removed the following season.

In the early 1920s North experimented with an NMFC monogram design, following League clubs like Carlton and South Melbourne.

Upon promotion to the VFL in 1925, North Melbourne was forced to abandon its royal blue and white striped jumper as it was deemed the jumper design clashed with other clubs. During this period a jumper with a V design was used for several years, before the club returned to using its striped jumper combination of royal blue and white which has been used continuously since 1932.

North Melbourne's guernsey since entering the VFL in 1925 consists of white and royal blue vertical stripes. Up until 2016, North Melbourne's home jumper was predominantly white, but that has recently become the away design and a more predominantly blue design has been made the home guernsey.

Changes in the North Melbourne uniform through the years:

VFA:

VFL/AFL:

North Melbourne has experienced 7 logo changes since its introduction, with 5 of them featuring a bounding kangaroo behind a shield of blue and white stripes. In 2016, North Melbourne introduced a new logo that featured a much fiercer looking kangaroo, with its head only, sitting on top of the words 'North Melbourne' inside a shield. The change was welcomed as the previous logo (2007-2016) didn't seem to represent what they stood for or the direction they were heading. The new kangaroo looks slightly to the right, indicating that it is looking into the future.

Arden Street Oval was home to the Kangaroos between 1882 and 1985. The oval is currently owned by the City of Melbourne and leased by the North Melbourne Football Club for social, administration and training facilities. The grandstands were removed because VFL/AFL matches are no longer played there.


`The North Melbourne Football Club is a non-profit organisation limited by guarantee. Members of the club serve as the guarantees of capital and have full voting rights at AGMs to elect directors to the club's board.

The club's board of directors has nine members, with each director serving a three-year term before their position is put up for re-election at an AGM. Only one-third of the board is contested at each AGM due to the rolling structure of the terms of the directors. This structure safeguards the entire board from being ousted at a single AGM and has made North Melbourne immune to a lot of the in-house fighting witnessed at other AFL football clubs. The board governs the club as well as selecting a chairman to head the club through a majority vote of directors.

North Melbourne is unique in its structure, because from 1986 to 2006 the club was privately owned and limited by shares. The club was floated in 1986 through a membership vote led by then chairman Bob Ansett. At the meeting, members were encouraged to buy into the club by purchasing shares. The float ended up raising over $3 million and helped to keep the club solvent through the next decade.

In 1991, the John Elliott-led Carlton Football Club attempted a hostile take over North Melbourne by purchasing a large parcel of shares formerly owned by Bob Ansett. The Blues acquired 20 per cent of the capital but that stake was eventually bought back by John Magowan, the former head of Merrill Lynch Australia, in 2001. The resulting melodrama saw the formation of B-Class shareholders who had the effective power of veto over any attempt to merge or relocate the club.

Further takeover attempts were made in the first decade of the 21st century by the Southport Sharks. Then chairman Allan Aylett knocked back a proposal from the Sharks that would have seen them gain a majority stake in the club in exchange for an injection of capital. In early 2006, another proposal from Sharks to underwrite the Kangaroos' games on the Gold Coast, in exchange for a slice of the shareholder structure at the club was knocked back after AFL intervention.

Due to an Australian Taxation Office ruling in 2006, the club proposed a shareholder restructure that would have seen the B Class shareholders power reduced significantly and some voting rights returned to members. This was done to avoid extraordinary taxes being placed on the club, but the move was blocked in December by Bob Ansett and his proxies who feared that the restructure would make the club vulnerable to further takeover bids.

On 28 February 2007, another meeting was called to resolve the shareholder issue. A motion was passed that would return see some voting rights return to members and stop any future tax increments.

In April 2007 it was revealed the AFL was attempting to buy out the shareholders of the club in a bid to gain full ownership, and force a relocation of the club to the Gold Coast.

During October 2007, a group called We Are North Melbourne emerged and launched a public campaign, calling for ordinary members to be given the final say on the relocation issue. While the group became synonymous with the push to keep the club in Melbourne, its first priority was to see the club's shareholder structure wound-up and control returned to ordinary members.

North Melbourne reverted to public company in November 2008. A moratorium was passed at an extraordinary general meeting that will allow James Brayshaw's board to serve unopposed until 2010, so as to allow his ticket the maximum time to enact their policies to make the North Melbourne Football Club financially viable.

On 20 November 2016, former Aussie Rules footballer and Football Federation Australia chairman Ben Buckley replaced James Brayshaw as the new chairman of the club.

In Round 1,1985, North Melbourne pioneered the concept of playing football on Friday nights. Since then, North Melbourne has played the most Friday night games of any AFL club.

Friday night matches later became the most lucrative timeslot for televised games, and North Melbourne's relatively low supporter base resulted in fewer Friday night matches. Between 2010 and 2014, North Melbourne had hosted an annual Friday night match against Carlton in recognition of its pioneering role in the concept.

After years of campaigning to play on Good Friday, the AFL announced on 25 October 2016 that North Melbourne will play the Western Bulldogs on Good Friday 2017. Good Friday in Australia is also considered as a day where people raise money for the Royal Childrens Hospital, and North Melbourne announced on 7 March 2017 that $5 from each ticket will go to the charity. Also, North Melbourne will play Essendon on Good Friday 19 April 2019.

North Melbourne has a strong history of supporting Aboriginal footballers and fostering Aboriginal talent in the VFL and AFL. The first indigenous footballer to play for the club was Percy Johnson in the 1950s, and was followed by other fan favorites like Bertie Johnson, Barry Cable and the Krakouer brothers in the following decades.

The following is a list of Indigenous footballers to have played senior football at the club:


The following footballers who were killed in action during the World Wars played senior football for North Melbourne.


In 2014, North Melbourne put forward a proposal in which the away team's club songs would no longer be played at their home matches, however, this was quickly rejected by the Australian Football League. Such a move would have placed the AFL in line with other leagues such as the National Rugby League and overseas competitions in creating a true home ground advantage for the home side.

Essendon – North and Essendon have a chequered history that dates back to the late 19th century; firstly in 1896, Essendon had North excluded from the VFL because both clubs drew supporters from the same area. North supporters have long been bitter with Essendon for excluding them from the VFL, and have blamed that for their small supporter base in comparison to Essendon's. North's first VFL Grand Final was against Essendon in 1950. The rivalry was reignited in the 90s as both teams were constantly in premiership contention. In 1998, following comments by Essendon coach labelling Kangaroos executives Greg Miller and Mark Dawson "marshmallows", a reference to their softness, North supporters threw marshmallows at Sheedy after the opening Qualifying Final. In 2014 North Melbourne versed Essendon in Elimination Final 2 Essendon was leading by 30 odd points then North came back to win by 12 points

Hawthorn – North and Hawthorn have a fierce rivalry that dates back to the 1970s when they played off against each other in three Grand Finals in the space of four years. From 1974 to 1978 the two clubs played against each other in ten finals, and took each other on for the Australian Championship in Adelaide in 1976. During the 1980s Hawthorn dominated North, and during the 90s the results were reversed with North dominating Hawthorn.
North Melbourne defeated Hawthorn in the 1975 Grand Final by 55 points. However, Hawthorn defeated North Melbourne in the 1976 Grand Final by 30 points and in the 1978 Grand Final by 18 points.
The rivalry re-ignited in 2014 following a choking incident involving Brian Lake having North Melbourne forward Drew Petrie in a choking hold during a clash between the two sides at Docklands Stadium and reached fever pitch in 2015 following several fights including an all in during the first term of their round 5 clash.

At a special function in August 2001, the North Melbourne Team of the Century was announced. There was no minimum number of games set for selection. Wayne Carey was named as captain and Denis Pagan as coach. The selection panel was Geoff Poulter (journalist), Father Gerard Dowling (club historian), Keith McKenzie (former coach), Lloyd Holyoak (former president), Max Ritchie (former player and chairman of selectors) and Greg Miller (chief executive).

On 18 March 2005, the North Melbourne football club held a special gala dinner entitled the "North Story" to celebrate the 80th anniversary of North's admission to the VFL, and the 30th anniversary of the club's first VFL premiership. Over 3500 people attended the historic event held at the Royal Exhibition Building, including almost all surviving North Melbourne players. Glenn Archer was voted the Shinboner of the Century by his peers as the player who most represents the 'Shinboner Spirit'. The following players were voted 'Shinboners' of their era:


To commemorate the 150th year of the founding of the North Melbourne Football Club a 150th Year Celebration was organised for the first weekend of August 2019 which commenced with a Friday Night blockbuster against arch rivals Hawthorn. Starting from 27 points down in the first quarter, the Roos fought back heroically against the Hawks to triumph as 22 point winners, and get the weekend celebrations underway. The following day the Roos VFL side took on Box Hill and similarly won in a heroic performance coming back from 31 points down at three quarter time to win by 2 points with just minutes to spare. To cap off the weekend, a 150th Year Celebration Dinner was held at the Melbourne Convention Centre where the 150 greatest ever North Melbourne players were announced with a top 10 greatest North Melbourne players announced on the night from the results of an expert panel.

Top 10 Greatest North Players

North Melbourne operated its own seconds/reserves team from 1925 until 1999, and will begin to do so again from the 2018 season. From 1919 to 1991 the VFL/AFL operated a reserves competition, and from 1992 to 1999 a "de facto" AFL reserves competition was run by the Victorian State Football League, and North Melbourne fielded its reserves team in both of these competitions while it was in the VFL/AFL, allowing players who were not selected for the senior team to play for North Melbourne in the lower grade. During that time, the North Melbourne reserves team won seven premierships (1947, 1957, 1967, 1978, 1979, 1995, 1996).

Following the demise of the AFL reserves competition, North Melbourne's reserves team was dissolved, and over the following eighteen years the club entered reserves affiliations with a range of Victorian Football League clubs. Under the affiliations, reserves players for North Melbourne play VFL football with one of the affiliated clubs. The club had five different affiliation arrangements over that time:

From 2018 until 2019, North Melbourne re-established its own reserves team which played in the VFL. It played its home games at Chirnside Park in Werribee until mid-2019, and then at the redeveloped Arden Street Oval in the second half of 2019. However, the 2020 VFL season was cancelled due to the COVID-19 pandemic, and the reserves team was again disbanded by the club part of a cost-reduction measure in the wake of the high financial impact of the pandemic. The structure of the club's reserves program from 2021 onwards is not yet announced.

In 2017, following the inaugural AFL Women's (AFLW) season, North Melbourne was among eight clubs that applied for licences to enter the competition from 2019 onwards. In September 2017, the club was announced as one of two clubs, along with , to receive a licence to join the competition in 2019. In April 2018, the club announced the signing of midfielder Emma Kearney, who had just won the AFL Women's best and fairest and a premiership and club best-and-fairest with the Bulldogs. North Melbourne began fielding a team in the second-tier VFL Women's league in 2020.

AFL Women's

VFL Women's




</doc>
<doc id="22107" url="https://en.wikipedia.org/wiki?curid=22107" title="Treaty on the Non-Proliferation of Nuclear Weapons">
Treaty on the Non-Proliferation of Nuclear Weapons

The Treaty on the Non-Proliferation of Nuclear Weapons, commonly known as the Non-Proliferation Treaty or NPT, is an international treaty whose objective is to prevent the spread of nuclear weapons and weapons technology, to promote cooperation in the peaceful uses of nuclear energy, and to further the goal of achieving nuclear disarmament and general and complete disarmament. Between 1965 and 1968, the treaty was negotiated by the Eighteen Nation Committee on Disarmament, a United Nations-sponsored organization based in Geneva, Switzerland.

Opened for signature in 1968, the treaty entered into force in 1970. As required by the text, after twenty-five years, NPT Parties met in May 1995 and agreed to extend the treaty indefinitely. More countries are parties to the NPT than any other arms limitation and disarmament agreement, a testament to the treaty's significance. As of August 2016, 191 states have become parties to the treaty, though North Korea, which acceded in 1985 but never came into compliance, announced its withdrawal from the NPT in 2003, following detonation of nuclear devices in violation of core obligations. Four UN member states have never accepted the NPT, three of which possess or are thought to possess nuclear weapons: India, Israel, and Pakistan. In addition, South Sudan, founded in 2011, has not joined.

The treaty defines nuclear-weapon states as those that have built and tested a nuclear explosive device before 1 January 1967; these are the United States, Russia, the United Kingdom, France, and China. Four other states are known or believed to possess nuclear weapons: India, Pakistan, and North Korea have openly tested and declared that they possess nuclear weapons, while Israel is deliberately ambiguous regarding its nuclear weapons status.

The NPT is often seen to be based on a central bargain:

the NPT non-nuclear-weapon states agree never to acquire nuclear weapons and the NPT nuclear-weapon states in exchange agree to share the benefits of peaceful nuclear technology and to pursue nuclear disarmament aimed at the ultimate elimination of their nuclear arsenals. 

The treaty is reviewed every five years in meetings called Review Conferences of the Parties to the Treaty of Non-Proliferation of Nuclear Weapons. Even though the treaty was originally conceived with a limited duration of 25 years, the signing parties decided, by consensus, to unconditionally extend the treaty indefinitely during the Review Conference in New York City on 11 May 1995, in the culmination of U.S. government efforts led by Ambassador Thomas Graham Jr.

At the time the NPT was proposed, there were predictions of 25–30 nuclear weapon states within 20 years. Instead, over forty years later, five states are not parties to the NPT, and they include the only four additional states believed to possess nuclear weapons. Several additional measures have been adopted to strengthen the NPT and the broader nuclear nonproliferation regime and make it difficult for states to acquire the capability to produce nuclear weapons, including the export controls of the Nuclear Suppliers Group and the enhanced verification measures of the International Atomic Energy Agency (IAEA) Additional Protocol.

Critics argue that the NPT cannot stop the proliferation of nuclear weapons or the motivation to acquire them. They express disappointment with the limited progress on nuclear disarmament, where the five authorized nuclear weapons states still have 22,000 warheads in their combined stockpile and have shown a reluctance to disarm further. Several high-ranking officials within the United Nations have said that they can do little to stop states using nuclear reactors to produce nuclear weapons.

The NPT consists of a preamble and eleven articles. Although the concept of "pillars" is not expressed anywhere in the NPT, the treaty is nevertheless sometimes interpreted as a "three-pillar" system, with an implicit balance among them:
These pillars are interrelated and mutually reinforcing. An effective nonproliferation regime whose members comply with their obligations provides an essential foundation for progress on disarmament and makes possible greater cooperation on the peaceful use of nuclear energy. With the right to access the benefits of peaceful nuclear technology comes the responsibility of nonproliferation. Progress on disarmament reinforces efforts to strengthen the nonproliferation regime and to enforce compliance with obligations, thereby also facilitating peaceful nuclear cooperation.
The "pillars" concept has been questioned by some who believe that the NPT is, as its name suggests, principally about nonproliferation, and who worry that "three pillars" language misleadingly implies that the three elements have equivalent importance.

Under Article I of the NPT, nuclear-weapon states pledge not to transfer nuclear weapons or other nuclear explosive devices to any recipient or in any way assist, encourage or induce any non-nuclear-weapon state in the manufacture or acquisition of a nuclear weapon.

Under Article II of the NPT, non-nuclear-weapon states pledge not to acquire or exercise control over nuclear weapons or other nuclear explosive devices and not to seek or receive assistance in the manufacture of such devices. 

Under Article III of the Treaty, non-nuclear-weapon states pledge to accept IAEA safeguards to verify that their nuclear activities serve only peaceful purposes.

Five states are recognized by NPT as nuclear weapon states (NWS): China (signed 1992), France (1992), the Soviet Union (1968; obligations and rights now assumed by the Russian Federation), the United Kingdom (1968), and the United States (1968), which also happen to be the five permanent members of the United Nations Security Council.

These five NWS agree not to transfer "nuclear weapons or other nuclear explosive devices" and "not in any way to assist, encourage, or induce" a non-nuclear weapon state (NNWS) to acquire nuclear weapons (Article I). NNWS parties to the NPT agree not to "receive", "manufacture", or "acquire" nuclear weapons or to "seek or receive any assistance in the manufacture of nuclear weapons" (Article II). NNWS parties also agree to accept safeguards by the International Atomic Energy Agency (IAEA) to verify that they are not diverting nuclear energy from peaceful uses to nuclear weapons or other nuclear explosive devices (Article III).

The five NWS parties have made undertakings not to use their nuclear weapons against a non-NWS party except in response to a nuclear attack, or a conventional attack in alliance with a Nuclear Weapons State. However, these undertakings have not been incorporated formally into the treaty, and the exact details have varied over time. The U.S. also had nuclear warheads targeted at North Korea, a non-NWS, from 1959 until 1991. The previous United Kingdom Secretary of State for Defence, Geoff Hoon, has also explicitly invoked the possibility of the use of the country's nuclear weapons in response to a non-conventional attack by "rogue states". In January 2006, President Jacques Chirac of France indicated that an incident of state-sponsored terrorism on France could trigger a small-scale nuclear retaliation aimed at destroying the "rogue state's" power centers.

Under Article VI of the NPT, all Parties undertake to pursue good-faith negotiations on effective measures relating to cessation of the nuclear arms race, to nuclear disarmament, and to general and complete disarmament.

Article VI of the NPT represents the only binding commitment in a multilateral treaty to the goal of disarmament by the nuclear-weapon states. The NPT's preamble contains language affirming the desire of treaty signatories to ease international tension and strengthen international trust so as to create someday the conditions for a halt to the production of nuclear weapons, and treaty on general and complete disarmament that liquidates, in particular, nuclear weapons and their delivery vehicles from national arsenals.

The wording of the NPT's Article VI arguably imposes only a vague obligation on all NPT signatories to move in the general direction of nuclear and total disarmament, saying, "Each of the Parties to the Treaty undertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a treaty on general and complete disarmament." Under this interpretation, Article VI does not strictly require all signatories to actually conclude a disarmament treaty. Rather, it only requires them "to negotiate in good faith."

On the other hand, some governments, especially non-nuclear-weapon states belonging to the Non-Aligned Movement, have interpreted Article VI's language as being anything but vague. In their view, Article VI constitutes a formal and specific obligation on the NPT-recognized nuclear-weapon states to disarm themselves of nuclear weapons, and argue that these states have failed to meet their obligation. The International Court of Justice (ICJ), in its advisory opinion on the Legality of the Threat or Use of Nuclear Weapons, issued 8 July 1996, unanimously interprets the text of Article VI as implying that

There exists an obligation to pursue in good faith and bring to a conclusion negotiations leading to nuclear disarmament in all its aspects under strict and effective international control.

The ICJ opinion notes that this obligation involves all NPT parties (not just the nuclear weapon states) and does not suggest a specific time frame for nuclear disarmament.

Critics of the NPT-recognized nuclear-weapon states (the United States, Russia, China, France, and the United Kingdom) sometimes argue that what they view as the failure of the NPT-recognized nuclear weapon states to disarm themselves of nuclear weapons, especially in the post–Cold War era, has angered some non-nuclear-weapon NPT signatories of the NPT. Such failure, these critics add, provides justification for the non-nuclear-weapon signatories to quit the NPT and develop their own nuclear arsenals.

Other observers have suggested that the linkage between proliferation and disarmament may also work the other way, i.e., that the failure to resolve proliferation threats in Iran and North Korea, for instance, will cripple the prospects for disarmament. No current nuclear weapons state, the argument goes, would seriously consider eliminating its last nuclear weapons without high confidence that other countries would not acquire them. Some observers have even suggested that the very progress of disarmament by the superpowers—which has led to the elimination of thousands of weapons and delivery systems—could eventually make the possession of nuclear weapons more attractive by increasing the perceived strategic value of a small arsenal. As one U.S. official and NPT expert warned in 2007, "logic suggests that as the number of nuclear weapons decreases, the 'marginal utility' of a nuclear weapon as an instrument of military power increases. At the extreme, which it is precisely disarmament's hope to create, the strategic utility of even one or two nuclear weapons would be huge."

NPT Article IV acknowledges the right of all Parties to develop nuclear energy for peaceful purposes and to benefit from international cooperation in this area, in conformity with their nonproliferation obligations. Article IV also encourages such cooperation. This so-called third pillar provides for the transfer of nuclear technology and materials to NPT Parties for peaceful purposes in the development of civilian nuclear energy programs in those countries, subject to IAEA safeguards to demonstrate that their nuclear programs are not being used for the development of nuclear weapons.

As the commercially popular light water reactor nuclear power station uses enriched uranium fuel, it follows that states must be able either to enrich uranium or purchase it on an international market. Mohamed ElBaradei, then Director General of the International Atomic Energy Agency, has called the spread of enrichment and reprocessing capabilities the "Achilles' heel" of the nuclear nonproliferation regime. As of 2007 13 states have an enrichment capability.

During the 1960s and 1970s many states, almost 60, were supplied with research reactors fuelled by weapon grade highly enriched uranium (HEU) through the United States Atoms for Peace program and a similar Soviet Union program. In the 1980s a program to convert HEU research reactors to use low enriched fuel was started in the United States due to proliferation concerns. However 26 states possessed more that 1 kg of civilian HEU in 2015, and as of 2016 the stocks of HEU for civilian research were 60 tonnes, with 74 research reactors still using HEU.

Because the availability of fissile material has long been considered the principal obstacle to, and "pacing element" for, a country's nuclear weapons development effort, it was declared a major emphasis of U.S. policy in 2004 to prevent the further spread of uranium enrichment and plutonium reprocessing (a.k.a. "ENR") technology. Countries possessing ENR capabilities, it is feared, have what is in effect the option of using this capability to produce fissile material for weapons use on demand, thus giving them what has been termed a "virtual" nuclear weapons program. The degree to which NPT members have a "right" to ENR technology notwithstanding its potentially grave proliferation implications, therefore, is at the cutting edge of policy and legal debates surrounding the meaning of Article IV and its relation to Articles I, II, and III of the treaty.

Countries that have become Parties to the NPT as non-nuclear-weapon States have a strong record of not building nuclear weapons, although some tried and one eventually left the NPT and acquired nuclear weapons. Iraq was found by the IAEA to have violated its safeguards obligations and subject to punitive sanctions by the UN Security Council. North Korea never came into compliance with its NPT safeguards agreement and was cited repeatedly for these violations, and later withdrew from the NPT and tested multiple nuclear devices. Iran was found in non-compliance with its NPT safeguards obligations in an unusual non-consensus decision because it "failed in a number of instances over an extended period of time" to report aspects of its enrichment program.<ref name="IAEA-GOV/2003/75"></ref><ref name="IAEA-GOV/2005/77"></ref> In 1991, Romania reported previously undeclared nuclear activities by the former regime and the IAEA reported this non-compliance to the Security Council for information only. Libya pursued a clandestine nuclear weapons program before abandoning it in December 2003. The IAEA reported Syria's safeguards non-compliance to the UN Security Council, which did not take action.

In some regions, the fact that all neighbors are verifiably free of nuclear weapons reduces any pressure individual states might feel to build those weapons themselves, even if neighbors are known to have peaceful nuclear energy programs that might otherwise be suspicious. In this, the treaty works as designed.

In 2004, Mohamed ElBaradei said that by some estimates thirty-five to forty states could have the knowledge to develop nuclear weapons.

"Article I": Each nuclear-weapons state (NWS) undertakes not to transfer, to any recipient, nuclear weapons, or other nuclear explosive devices, and not to assist any non-nuclear weapon state to manufacture or acquire such weapons or devices.

"Article II": Each non-NWS party undertakes not to receive, from any source, nuclear weapons, or other nuclear explosive devices; not to manufacture or acquire such weapons or devices; and not to receive any assistance in their manufacture.

"Article III": Each non-NWS party undertakes to conclude an agreement with the IAEA for the application of its safeguards to all nuclear material in all of the state's peaceful nuclear activities and to prevent diversion of such material to nuclear weapons or other nuclear explosive devices.

"Article IV": 1. Nothing in this Treaty shall be interpreted as affecting the inalienable right of all the Parties to the Treaty to develop research, production and use of nuclear energy for peaceful purposes without discrimination and in conformity with Articles I and II of this Treaty.

2. All the Parties to the Treaty undertake to facilitate, and have the right to participate in, the fullest possible exchange of equipment, materials and scientific and technological information for the peaceful uses of nuclear energy. Parties to the Treaty in a position to do so shall also co-operate in contributing alone or together with other States or international organizations to the further development of the applications of nuclear energy for peaceful purposes, especially in the territories of non-nuclear-weapon States Party to the Treaty, with due consideration for the needs of the developing areas of the world.

"Article VI": Each party "undertakes to pursue negotiations in good faith on effective measures relating to cessation of the nuclear arms race at an early date and to nuclear disarmament, and on a Treaty on general and complete disarmament under strict and effective international control".

"Article IX": "For the purposes of this Treaty, a nuclear-weapon State is one which has manufactured and exploded a nuclear weapon or other nuclear explosive device prior to 1 January 1967."

"Article X": Establishes the right to withdraw from the Treaty giving 3 months' notice. It also establishes the duration of the Treaty (25 years before 1995 Extension Initiative).

The impetus behind the NPT was concern for the safety of a world with many nuclear weapon states. It was recognized that the Cold War deterrent relationship between just the United States and the Soviet Union was fragile. Having more nuclear-weapon states would reduce security for all, multiplying the risks of miscalculation, accidents, unauthorized use of weapons, escalation in tensions, and nuclear conflict. Moreover, since the use of nuclear weapons in Hiroshima and Nagasaki in 1945, it has been apparent that the development of nuclear capabilities by States could enable them to divert technology and materials for weapons purposes. Thus, the problem of preventing such diversions became a central issue in discussions on peaceful uses of nuclear energy.

Initial efforts, which began in 1946, to create an international system enabling all States to have access to nuclear technology under appropriate safeguards, were terminated in 1949 without the achievement of this objective, due to serious political differences between the major Powers. By then, both the United States and the former Soviet Union had tested nuclear weapons, and were beginning to build their stockpiles.

In December 1953, US President Dwight D. Eisenhower in his "Atoms for Peace" proposal, presented to the eighth session of the United Nations General Assembly, urged that an international organization be established to disseminate peaceful nuclear technology, while guarding against development of weapons capabilities in additional countries. His proposal resulted in 1957 in the establishment of the International Atomic Energy Agency (IAEA), which was charged with the dual responsibility for promotion and control of nuclear technology. IAEA technical activities began in 1958. An interim safeguards system for small nuclear reactors, put in place in 1961, was replaced in 1964 by a system covering larger installations and, over the following years, was expanded to include additional nuclear facilities. In recent years, efforts to strengthen the effectiveness and improve the efficiency of the IAEA safeguards system culminated in the approval of the Model Additional Protocol by the IAEA Board of Governors in May 1997.

Within the framework of the United Nations, the principle of nuclear non-proliferation was addressed in negotiations as early as 1957. The NPT process was launched by Frank Aiken, Irish Minister for External Affairs, in 1958. The NPT gained significant momentum in the early 1960s. The structure of a treaty to uphold nuclear non-proliferation as a norm of international behaviour had become clear by the mid-1960s, and by 1968 final agreement had been reached on a Treaty that would prevent the proliferation of nuclear weapons, enable cooperation for the peaceful use of nuclear energy, and further the goal of achieving nuclear disarmament. It was opened for signature in 1968, with Finland the first State to sign. Accession became nearly universal after the end of the Cold War and of South African apartheid. In 1992, The People's Republic of China and France acceded to the NPT, the last of the five nuclear powers recognized by the treaty to do so.

The treaty provided, in article X, for a conference to be convened 25 years after its entry into force to decide whether the treaty should continue in force indefinitely, or be extended for an additional fixed period or periods. Accordingly, at the NPT Review and Extension Conference in May 1995, state parties to the treaty agreed-without a vote-on the treaty's indefinite extension, and decided that review conferences should continue to be held every five years. After Brazil acceded to the NPT in 1998, the only remaining non-nuclear-weapon state which had not signed was Cuba, which joined the NPT (and the Treaty of Tlatelolco NWFZ) in 2002.

Several NPT states parties have given up nuclear weapons or nuclear weapons programs. South Africa undertook a nuclear weapons program, but has since renounced it and acceded to the treaty in 1991 after destroying its small nuclear arsenal; after this, the remaining African countries signed the treaty. The former Soviet Republics where nuclear weapons had been based, namely Ukraine, Belarus and Kazakhstan, transferred those weapons to Russia and joined the NPT by 1994 following the signature of the Budapest Memorandum on Security Assurances.

Successor states from the breakups of Yugoslavia and Czechoslovakia also joined the treaty soon after their independence. Montenegro and East Timor were the last countries to accede to the treaty on their independence in 2006 and 2003; the only other country to accede in the 21st century was Cuba in 2002. The three Micronesian countries in Compact of Free Association with the USA joined the NPT in 1995, along with Vanuatu.

Major South American countries Argentina, Chile, and Brazil joined in 1995 and 1998. Arabian Peninsula countries included Saudi Arabia and Bahrain in 1988, Qatar and Kuwait in 1989, UAE in 1995, and Oman in 1997. The European states of Monaco and Andorra joined in 1995–6. Also acceding in the 1990s were Myanmar in 1992 and Guyana in 1993.

At the time the treaty was being negotiated, NATO had in place secret nuclear weapons sharing agreements whereby the United States provided nuclear weapons to be deployed by, and stored in, other NATO states. Some argue this is an act of proliferation violating Articles I and II of the treaty. A counter-argument is that the U.S. controlled the weapons in storage within the NATO states, and that no transfer of the weapons or control over them was intended "unless and until a decision were made to go to war, at which the treaty would no longer be controlling", so there is no breach of the NPT. These agreements were disclosed to a few of the states, including the Soviet Union, negotiating the treaty, but most of the states that signed the NPT in 1968 would not have known about these agreements and interpretations at that time.

As of 2005, it is estimated that the United States still provides about 180 tactical B61 nuclear bombs for use by Belgium, Germany, Italy, the Netherlands and Turkey under these NATO agreements. Many states, and the Non-Aligned Movement, now argue this violates Articles I and II of the treaty, and are applying diplomatic pressure to terminate these agreements. They point out that the pilots and other staff of the "non-nuclear" NATO states practice handling and delivering the U.S. nuclear bombs, and non-U.S. warplanes have been adapted to deliver U.S. nuclear bombs which must have involved the transfer of some technical nuclear weapons information. NATO believes its "nuclear forces continue to play an essential role in war prevention, but their role is now more fundamentally political".

U.S. nuclear sharing policies were originally designed to help prevent the proliferation of nuclear weapons—not least by persuading the then West Germany not to develop an independent nuclear capability by assuring it that West Germany would be able, in the event of war with the Warsaw Pact, to wield (U.S.) nuclear weapons in self-defense. (Until that point of all-out war, however, the weapons themselves would remain in U.S. hands.) The point was to limit the spread of countries having their own nuclear weapons programs, helping ensure that NATO allies would not choose to go down the proliferation route. (West Germany was discussed in U.S. intelligence estimates for a number of years as being a country with the potential to develop nuclear weapons capabilities of its own if officials in Bonn were not convinced that their defense against the Soviet Union and its allies could otherwise be met.)

Four states—India, Israel, Pakistan, and South Sudan—have never signed the treaty. India and Pakistan have publicly disclosed their nuclear weapon programs, and Israel has a long-standing policy of deliberate ambiguity with regards to its nuclear program (see List of states with nuclear weapons).

India has detonated nuclear devices, first in 1974 and again in 1998. India is estimated to have enough fissile material for more than 150 warheads. India was among the few countries to have a no first use policy, a pledge not to use nuclear weapons unless first attacked by an adversary using nuclear weapons, however India's former NSA Shivshankar Menon signaled "a significant shift from "no first use" to "no first use against non-nuclear weapon states"" in a speech on the occasion of Golden Jubilee celebrations of the National Defence College in New Delhi on 21 October 2010, a doctrine Menon said reflected India's "strategic culture, with its emphasis on minimal deterrence".

India argues that the NPT creates a club of "nuclear haves" and a larger group of "nuclear have-nots" by restricting the legal possession of nuclear weapons to those states that tested them before 1967, but the treaty never explains on what ethical grounds such a distinction is valid. India's then External Affairs Minister Pranab Mukherjee said during a visit to Tokyo in 2007: "If India did not sign the NPT, it is not because of its lack of commitment for non-proliferation, but because we consider NPT as a flawed treaty and it did not recognize the need for universal, non-discriminatory verification and treatment." Although there have been unofficial discussions on creating a South Asian nuclear weapons free zone, including India and Pakistan, this is considered to be highly unlikely for the foreseeable future.

In early March 2006, India and the United States finalized an agreement, in the face of criticism in both countries, to restart cooperation on civilian nuclear technology. Under the deal India has committed to classify 14 of its 22 nuclear power plants as being for civilian use and to place them under IAEA safeguards. Mohamed ElBaradei, then Director General of the IAEA, welcomed the deal by calling India "an important partner in the non-proliferation regime."

In December 2006, United States Congress approved the United States-India Peaceful Atomic Energy Cooperation Act, endorsing a deal that was forged during Prime Minister Singh's visit to the United States in July 2005 and cemented during President Bush's visit to India earlier in 2006. The legislation allows for the transfer of civilian nuclear material to India. Despite its status outside the Nuclear Non-Proliferation Treaty, nuclear cooperation with India was permitted on the basis of its clean non-proliferation record, and India's need for energy fueled by its rapid industrialization and a billion-plus population.

On 1 August 2008, the IAEA approved the India Safeguards Agreement and on 6 September 2008, India was granted the waiver at the Nuclear Suppliers Group (NSG) meeting held in Vienna, Austria. The consensus was arrived after overcoming misgivings expressed by Austria, Ireland and New Zealand and is an unprecedented step in giving exemption to a country, which has not signed the NPT and the Comprehensive Test Ban Treaty (CTBT). While India could commence nuclear trade with other willing countries. The U.S. Congress approved this agreement and President Bush signed it on 8 October 2008.

When China announced expanded nuclear cooperation with Pakistan in 2010, proponents of arms control denounced both the deals, claiming that they weakened the NPT by facilitating nuclear programmes in states which are not parties to the NPT.

, Australia, a top three uranium producer and home to world's largest known reserves, had continued its refusal to export Uranium to India despite diplomatic pressure from India.
In November 2011 the Australian Prime Minister announced a desire to allow exports to India, a policy change which was authorized by her party's national conference in December. On 4 December 2011, Prime Minister Julia Gillard overturned Australia's long-standing ban on exporting uranium to India. She further said "We should take a decision in the national interest, a decision about strengthening our strategic partnership with India in this the Asian century," and said that any agreement to sell uranium to India would include strict safeguards to ensure it would only be used for civilian purposes, and not end up in nuclear weapons. On Sep 5, 2014; Australian Prime Minister Tony Abbott sealed a civil nuclear deal to sell uranium to India. "We signed a nuclear cooperation agreement because Australia trusts India to do the right thing in this area, as it has been doing in other areas," Abbott told reporters after he and Indian Prime Minister Narendra Modi signed a pact to sell uranium for peaceful power generation.

In May 1998, following India's nuclear tests earlier that month, Pakistan conducted two sets of nuclear tests, the Chagai-I and Chagai-II. Although there is little confirmed information in public, as of 2015, Pakistan was estimated to have as many as 120 warheads. According to analyses of the Carnegie Endowment for International Peace and the Stimson Center, Pakistan has enough fissile material for 350 warheads.

Pakistani officials argue that the NPT is discriminatory. When asked at a briefing in 2015 whether Islamabad would sign the NPT if Washington requested it, Foreign Secretary Aizaz Ahmad Chaudhry was quoted as responding "It is a discriminatory treaty. Pakistan has the right to defend itself, so Pakistan will not sign the NPT. Why should we?" Until 2010, Pakistan had always maintained the position that it would sign the NPT if India did so. In 2010, Pakistan abandoned this historic position and stated that it would join the NPT only as a recognized nuclear-weapon state.

The NSG Guidelines currently rule out nuclear exports by all major suppliers to Pakistan, with very narrow exceptions, since it does not have full-scope IAEA safeguards (i.e. safeguards on all its nuclear activities). Pakistan has sought to reach an agreement similar to that with India, but these efforts have been rebuffed by the United States and other NSG members, on the grounds that Pakistan's track record as a nuclear proliferator makes it impossible for it to have any sort of nuclear deal in the near future.

By 2010, China reportedly signed a civil nuclear agreement with Pakistan, using the justification that the deal was "peaceful." The British government criticized this, on the grounds that 'the time is not yet right for a civil nuclear deal with Pakistan'. China did not seek formal approval from the nuclear suppliers group, and claimed instead that its cooperation with Pakistan was "grandfathered" when China joined the NSG, a claim that was disputed by other NSG members. Pakistan applied for membership on 19 May 2016, supported by Turkey and China However, many NSG members opposed Pakistan's membership bid due to its track record, including the illicit procurement network of Pakistani scientist A.Q. Khan, which aided the nuclear programs of Iran, Libya and North Korea. Pakistani officials reiterated the request in August 2016.

Israel has a long-standing policy of deliberate ambiguity with regards to its nuclear program (see List of countries with nuclear weapons). Israel has been developing nuclear technology at its Dimona site in the Negev since 1958, and some nonproliferation analysts estimate that Israel may have stockpiled between 100 and 200 warheads using reprocessed plutonium. The position on the NPT is explained in terms of "Israeli exceptionality", a term coined by Professor Gerald M. Steinberg, in reference to the perception that the country's small size, overall vulnerability, as well as the history of deep hostility and large-scale attacks by neighboring states, require a deterrent capability.

The Israeli government refuses to confirm or deny possession of nuclear weapons, although this is now regarded as an open secret after Israeli junior nuclear technician Mordechai Vanunu—subsequently arrested and sentenced for treason by Israel—published evidence about the program to the British "Sunday Times" in 1986.

On 18 September 2009 the General Conference of the International Atomic Energy Agency called on Israel to open its nuclear facilities to IAEA inspection and adhere to the non-proliferation treaty as part of a resolution on "Israeli nuclear capabilities," which passed by a narrow margin of 49–45 with 16 abstentions. The chief Israeli delegate stated that "Israel will not co-operate in any matter with this resolution." However, similar resolutions were defeated in 2010, 2013, 2014, and 2015. As with Pakistan, the NSG Guidelines currently rule out nuclear exports by all major suppliers to Israel.

North Korea acceded to the treaty on 12 December 1985, but gave notice of withdrawal from the treaty on 10 January 2003 following U.S. allegations that it had started an illegal enriched uranium weapons program, and the U.S. subsequently stopping fuel oil shipments under the Agreed Framework which had resolved plutonium weapons issues in 1994. The withdrawal became effective 10 April 2003 making North Korea the first state ever to withdraw from the treaty. North Korea had once before announced withdrawal, on 12 March 1993, but suspended that notice before it came into effect.

On 10 February 2005, North Korea publicly declared that it possessed nuclear weapons and pulled out of the six-party talks hosted by China to find a diplomatic solution to the issue. "We had already taken the resolute action of pulling out of the Nuclear Non-Proliferation Treaty and have manufactured nuclear arms for self-defence to cope with the Bush administration's evermore undisguised policy to isolate and stifle the DPRK [Democratic People's Republic of Korea]," a North Korean Foreign Ministry statement said regarding the issue. Six-party talks resumed in July 2005.

On 19 September 2005, North Korea announced that it would agree to a preliminary accord. Under the accord, North Korea would scrap all of its existing nuclear weapons and nuclear production facilities, rejoin the NPT, and readmit IAEA inspectors. The difficult issue of the supply of light water reactors to replace North Korea's indigenous nuclear power plant program, as per the 1994 Agreed Framework, was left to be resolved in future discussions. On the next day North Korea reiterated its known view that until it is supplied with a light water reactor it will not dismantle its nuclear arsenal or rejoin the NPT.

On 2 October 2006, the North Korean foreign minister announced that his country was planning to conduct a nuclear test "in the future", although it did not state when. On Monday, 9 October 2006 at 01:35:28 (UTC) the United States Geological Survey detected a magnitude 4.3 seismic event north of Kimchaek, North Korea indicating a nuclear test. The North Korean government announced shortly afterward that they had completed a successful underground test of a nuclear fission device.

In 2007, reports from Washington suggested that the 2002 CIA reports stating that North Korea was developing an enriched uranium weapons program, which led to North Korea leaving the NPT, had overstated or misread the intelligence. On the other hand, even apart from these press allegations, there remains some information in the public record indicating the existence of a uranium effort. Quite apart from the fact that North Korean First Vice Minister Kang Sok Ju at one point admitted the existence of a uranium enrichment program, Pakistan's then-President Musharraf revealed that the A.Q. Khan proliferation network had provided North Korea with a number of gas centrifuges designed for uranium enrichment. Additionally, press reports have cited U.S. officials to the effect that evidence obtained in dismantling Libya's WMD programs points toward North Korea as the source for Libya's uranium hexafluoride (UF) – which, if true, would mean that North Korea has a uranium conversion facility for producing feedstock for centrifuge enrichment.

Iran is a party to the NPT since 1970 but was found in non-compliance with its NPT safeguards agreement, and the status of its nuclear program remains in dispute. In November 2003 IAEA Director General Mohamed ElBaradei reported that Iran had repeatedly and over an extended period failed to meet its safeguards obligations under the NPT with respect to:
After about two years of EU3-led diplomatic efforts and Iran temporarily suspending its enrichment program, the IAEA Board of Governors, acting under Article XII.C of the IAEA Statute, found in a rare non-consensus decision with 12 abstentions that these failures constituted non-compliance with the IAEA safeguards agreement. This was reported to the UN Security Council in 2006, after which the Security Council passed a resolution demanding that Iran suspend its enrichment.
Instead, Iran resumed its enrichment program.

The IAEA has been able to verify the non-diversion of declared nuclear material in Iran, and is continuing its work on verifying the absence of undeclared activities. In February 2008, the IAEA also reported that it was working to address "alleged studies" of weaponization, based on documents provided by certain Member States, which those states claimed originated from Iran. Iran rejected the allegations as "baseless" and the documents as "fabrications." In June 2009, the IAEA reported that Iran had not "cooperated with the Agency in connection with the remaining issues ... which need to be clarified to exclude the possibility of military dimensions to Iran's nuclear program."

The United States concluded that Iran violated its Article III NPT safeguards obligations, and further argued based on circumstantial evidence that Iran's enrichment program was for weapons purposes and therefore violated Iran's Article II nonproliferation obligations. The November 2007 US National Intelligence Estimate (NIE) later concluded that Iran had halted an active nuclear weapons program in the fall of 2003 and that it had remained halted as of mid-2007. The NIE's "Key Judgments," however, also made clear that what Iran had actually stopped in 2003 was only "nuclear weapon design and weaponization work and covert uranium conversion-related and uranium enrichment-related work"-namely, those aspects of Iran's nuclear weapons effort that had not by that point already been leaked to the press and become the subject of IAEA investigations.

Since Iran's uranium enrichment program at Natanz—and its continuing work on a heavy water reactor at Arak that would be ideal for plutonium production—began secretly years before in conjunction with the very weaponization work the NIE discussed and for the purpose of developing nuclear weapons, many observers find Iran's continued development of fissile material production capabilities distinctly worrying. Particularly because fissile material availability has long been understood to be the principal obstacle to nuclear weapons development and the primary "pacing element" for a weapons program, the fact that Iran has reportedly suspended weaponization work may not mean very much. As The Bush Administration's Director of National Intelligence (DNI) Mike McConnell hds put it in 2008, the aspects of its work that Iran allegedly suspended were thus "probably the least significant part of the program."

Iran stated it has a legal right to enrich uranium for peaceful purposes under the NPT, and further says that it had "constantly complied with its obligations under the NPT and the Statute of the International Atomic Energy Agency". Iran also stated that its enrichment program has been part of its civilian nuclear energy program, which is allowed under Article IV of the NPT. The Non-Aligned Movement has welcomed the continuing cooperation of Iran with the IAEA and reaffirmed Iran's right to the peaceful uses of nuclear technology. 

Early during his tenure as United Nations Secretary General, between 2007 and 2016, Ban Ki-moon welcomed the continued dialogue between Iran and the IAEA. He urged a peaceful resolution of the issue.

In April 2010, during the signing of the U.S.-Russia New START Treaty, President Obama said that the United States, Russia, and other nations were demanding that Iran face consequences for failing to fulfill its obligations under the Nuclear Non-Proliferation Treaty, saying "We will not tolerate actions that flout the NPT, risk an arms race in a vital region, and threaten the credibility of the international community and our collective security."

In 2015, Iran negotiated a nuclear deal with the P5+1, a group of countries that consisted of the five permanent members of the UN Security Council (China, France, Russia, the United Kingdom, and the United States) plus Germany. On July 14 2015, the P5+1 and Iran concluded the Joint Comprehensive Plan of Action, lifting sanctions on Iran in exchange for constraints and on Iran's nuclear activities and increased verification by the IAEA. On May 8 2018, the United States withdrew from the JCPOA and reimposed sanctions on Iran.

South Africa is the only country that developed nuclear weapons by itself and later dismantled them – unlike the former Soviet states Ukraine, Belarus and Kazakhstan, which inherited nuclear weapons from the former USSR and also acceded to the NPT as non-nuclear weapon states.

During the days of apartheid, the South African government developed a deep fear of both a black uprising and the threat of communism. This led to the development of a secret nuclear weapons program as an ultimate deterrent. South Africa has a large supply of uranium, which is mined in the country's gold mines. The government built a nuclear research facility at Pelindaba near Pretoria where uranium was enriched to fuel grade for the Koeberg Nuclear Power Station as well as weapon grade for bomb production.

In 1991, after international pressure and when a change of government was imminent, South African Ambassador to the United States Harry Schwarz signed the Nuclear Non-Proliferation Treaty. In 1993, the then president Frederik Willem de Klerk openly admitted that the country had developed a limited nuclear weapon capability. These weapons were subsequently dismantled before South Africa acceded to the NPT and opened itself up to IAEA inspection. In 1994, the IAEA completed its work and declared that the country had fully dismantled its nuclear weapons program.

Libya had signed (in 1968) and ratified (in 1975) the Nuclear Non-Proliferation Treaty and was subject to IAEA nuclear safeguards inspections, but undertook a secret nuclear weapons development program in violation of its NPT obligations, using material and technology provided by the A.Q. Khan proliferation network—including actual nuclear weapons designs allegedly originating in China. Libya began secret negotiations with the United States and the United Kingdom in March 2003 over potentially eliminating its WMD programs. In October 2003, Libya was embarrassed by the interdiction of a shipment of Pakistani-designed centrifuge parts sent from Malaysia, also as part of A. Q. Khan's proliferation ring.

In December 2003, Libya announced that it had agreed to eliminate all its WMD programs, and permitted U.S. and British teams (as well as IAEA inspectors) into the country to assist this process and verify its completion. The nuclear weapons designs, gas centrifuges for uranium enrichment, and other equipment—including prototypes for improved SCUD ballistic missiles—were removed from Libya by the United States. (Libyan chemical weapons stocks and chemical bombs were also destroyed on site with international verification, with Libya joining the Chemical Weapons Convention.) Libya's non-compliance with its IAEA safeguards was reported to the U.N. Security Council, but with no action taken, as Libya's return to compliance with safeguards and Article II of the NPT was welcomed.

In 2011, the Libyan government of Muammar al-Gaddafi was overthrown in the Libyan Civil War with the assistance of a military intervention by NATO forces acting under the auspices of UN Security Council Resolution 1973. Gaddafi's downfall 8 years after the disarmament of Libya, in which Gaddafi agreed to eliminate Libya's nuclear weapons program, has been repeatedly cited by North Korea, which views Gaddafi's fate as a "cautionary tale" that influences North Korea's decision to maintain and intensify its nuclear weapons program and arsenal despite pressure to denuclearize.

Syria is a state party to the NPT since 1969 and has a limited civil nuclear program. Before the advent of the Syrian Civil War it was known to operate only one small Chinese-built research reactor, SRR-1. Despite being a proponent of a Weapons of Mass Destruction Free Zone in the Middle East the country was accused of pursuing a military nuclear program with a reported nuclear facility in a desert Syrian region of Deir ez-Zor. The reactor's components had likely been designed and manufactured in North Korea, with the reactor's striking similarity in shape and size to the North Korean Yongbyon Nuclear Scientific Research Center. That information alarmed Israeli military and intelligence to such a degree that the idea of a targeted airstrike was conceived. It resulted in Operation Orchard, that took place on 6 September 2007 and saw as many as eight Israeli aircraft taking part. The Israeli government is said to have bounced the idea of the operation off of the US Bush administration, although the latter declined to participate. The nuclear reactor was destroyed in the attack, which also killed about ten North Korean workers. The attack did not cause an international outcry or any serious Syrian retaliatory moves as both parties tried to keep it secret: Despite a half-century state of war declared by surrounding states, Israel did not want publicity as regards its breach of the ceasefire, while Syria was not willing to acknowledge its clandestine nuclear program.

Article X allows a state to leave the treaty if "extraordinary events, related to the subject matter of this Treaty, have jeopardized the supreme interests of its country", giving three months' (ninety days') notice. The state is required to give reasons for leaving the NPT in this notice.

NATO states argue that when there is a state of "general war" the treaty no longer applies, effectively allowing the states involved to leave the treaty with no notice. This is a necessary argument to support the NATO nuclear weapons sharing policy, but a troubling one for the logic of the treaty. NATO's argument is based on the phrase "the consequent need to make every effort to avert the danger of such a war" in the treaty preamble, inserted at the behest of U.S. diplomats, arguing that the treaty would at that point have failed to fulfill its function of prohibiting a general war and thus no longer be binding. Many states do not accept this argument. See United States–NATO nuclear weapons sharing above.

North Korea has also caused an uproar by its use of this provision of the treaty. Article X.1 only requires a state to give three months' notice in total, and does not provide for other states to question a state's interpretation of "supreme interests of its country". In 1993, North Korea gave notice to withdraw from the NPT. However, after 89 days, North Korea reached agreement with the United States to freeze its nuclear program under the Agreed Framework and "suspended" its withdrawal notice. In October 2002, the United States accused North Korea of violating the Agreed Framework by pursuing a secret uranium enrichment program, and suspended shipments of heavy fuel oil under that agreement. In response, North Korea expelled IAEA inspectors, disabled IAEA equipment, and, on 10 January 2003, announced that it was ending the suspension of its previous NPT withdrawal notification. North Korea said that only one more day's notice was sufficient for withdrawal from the NPT, as it had given 89 days before.

The IAEA Board of Governors rejected this interpretation. Most countries held that a new three-months withdrawal notice was required, and some questioned whether North Korea's notification met the "extraordinary events" and "supreme interests" requirements of the treaty. The Joint Statement of 19 September 2005 at the end of the Fourth Round of the Six-Party Talks called for North Korea to "return" to the NPT, implicitly acknowledging that it had withdrawn.

The main outcome of the 2000 Conference was the adoption by consensus of a comprehensive Final Document, which included among other things "practical steps for the systematic and progressive efforts" to implement the disarmament provisions of the NPT, commonly referred to as the Thirteen Steps.

On 18 July 2005, US President George W. Bush met Indian Prime Minister Manmohan Singh and declared that he would work to change US law and international rules to permit trade in US civilian nuclear technology with India. At the time, British columnist George Monbiot argued that the U.S.-India nuclear deal, in combination with US attempts to deny Iran (an NPT signatory) civilian nuclear fuel-making technology, might destroy the NPT regime.

In the first half of 2010, it was strongly believed that China had signed a civilian nuclear deal with Pakistan claiming that the deal was "peaceful".

Arms control advocates criticised the reported China-Pakistan deal as they did in case of U.S.-India deal claiming that both the deals violate the NPT by facilitating nuclear programmes in states which are not parties to the NPT. Some reports asserted that the deal was a strategic move by China to balance US influence in South-Asia.

According to a report published by U.S. Department of Defense in 2001, China had provided Pakistan with nuclear materials and has given critical technological assistance in the construction of Pakistan's nuclear weapons development facilities, in violation of the Nuclear Non-Proliferation Treaty, of which China even then was a signatory.

At the Seventh Review Conference in May 2005, there were stark differences between the United States, which wanted the conference to focus on non-proliferation, especially on its allegations against Iran, and most other countries, who emphasized the lack of serious nuclear disarmament by the nuclear powers. The non-aligned countries reiterated their position emphasizing the need for nuclear disarmament.

The 2010 Review Conference was held in May 2010 in New York City, and adopted a final document that included a summary by the Review Conference President, Ambassador Libran Capactulan of the Philippines, and an Action Plan that was adopted by consensus. The 2010 conference was generally considered a success because it reached consensus where the previous Review Conference in 2005 ended in disarray, a fact that many attributed to the U.S. President Barack Obama's commitment to nuclear nonproliferation and disarmament. Some have warned that this success raised unrealistically high expectations that could lead to failure at the next Review Conference in 2015.
The "Global Summit on Nuclear Security" took place 12–13 April 2010. The summit was proposed by President Obama in Prague and was intended to strengthen the Nuclear Non-Proliferation Treaty in conjunction with the Proliferation Security Initiative and the Global Initiative to Combat Nuclear Terrorism. Forty seven states and three international organizations took part in the summit, which issued a communiqué and a work plan. For further information see 2010 Nuclear Security Summit.
In a major policy speech at the Brandenburg Gate in Berlin on 19 June 2013, United States President Barack Obama outlined plans to further reduce the number of warheads in the U.S. nuclear arsenal. According to "Foreign Policy", Obama proposed a "one-third reduction in strategic nuclear warheads—on top of the cuts already required by the New START treaty—bringing the number of deployed warheads to about 1,000". Obama is seeking to "negotiate these reductions with Russia to continue to move beyond Cold War nuclear postures," according to briefing documents provided to "Foreign Policy". In the same speech, Obama emphasized his administration's efforts to isolate any nuclear weapons capabilities emanating from Iran and North Korea. He also called for a renewed bipartisan effort in the United States Congress to ratify the Comprehensive Nuclear-Test-Ban Treaty and called on countries to negotiate a new treaty to end the production of fissile material for nuclear weapons.

On 24 April 2014, it was announced that the nation of the Marshall Islands has brought suit in The Hague against the United States, the former Soviet Union, the United Kingdom, France, China, India, Pakistan, North Korea and Israel seeking to have the disarmament provisions of the NNPT enforced.

The 2015 Review Conference of the Parties to the Treaty on the Non-Proliferation of Nuclear Weapons (NPT) was held at the United Nations in New York from 27 April to 22 May 2015 and presided over by Ambassador Taous Feroukhi of Algeria. The Treaty, particularly article VIII, paragraph 3, envisages a review of the operation of the Treaty every five years, a provision which was reaffirmed by the States parties at the 1995 NPT Review and Extension Conference and the 2000 NPT Review Conference. At the 2015 NPT Review Conference, States parties examined the implementation of the Treaty's provisions since 2010. Despite intensive consultations, the Conference was not able to reach agreement on the substantive part of the draft Final Document.

Over the years the NPT has come to be seen by many Third World states as "a conspiracy of the nuclear 'haves' to keep the nuclear 'have-nots' in their place". This argument has roots in Article VI of the treaty which "obligates the nuclear weapons states to liquidate their nuclear stockpiles and pursue complete disarmament. The non-nuclear states see no signs of this happening". Some argue that the NWS have not fully complied with their disarmament obligations under Article VI of the NPT. Some countries such as India have criticized the NPT, because it "discriminated against states not possessing nuclear weapons on January 1, 1967," while Iran and numerous Arab states have criticized Israel for not signing the NPT. There has been disappointment with the limited progress on nuclear disarmament, where the five authorized nuclear weapons states still have 22,000 warheads among them and have shown a reluctance to disarm further.

As noted , the International Court of Justice, in its advisory opinion on the Legality of the Threat or Use of Nuclear Weapons, stated that "there exists an obligation to pursue in good faith and bring to a conclusion negotiations leading to nuclear disarmament in all its aspects under strict and effective international control. Some critics of the nuclear-weapons states contend that they have failed to comply with Article VI by failing to make disarmament the driving force in national planning and policy with respect to nuclear weapons, even while they ask other states to plan for their security without nuclear weapons.

The United States responds to criticism of its disarmament record by pointing out that, since the end of the Cold War, it has eliminated over 13,000 nuclear weapons, and eliminated over 80% of its deployed strategic warheads and 90% of non-strategic warheads deployed to NATO, in the process eliminating whole categories of warheads and delivery systems and reducing its reliance on nuclear weapons. U.S. officials have also pointed out the ongoing U.S. work to dismantle nuclear warheads. By the time accelerated dismantlement efforts ordered by President George W. Bush were completed, the U.S. arsenal was less than a quarter of its size at the end of the Cold War, and smaller than it had been at any point since the Eisenhower administration, well before the drafting of the NPT.

The United States has also purchased many thousands of weapons' worth of uranium formerly in Soviet nuclear weapons for conversion into reactor fuel. As a consequence of this latter effort, it has been estimated that the equivalent of one lightbulb in every ten in the United States is powered by nuclear fuel removed from warheads previously targeted at the United States and its allies during the Cold War.

The U.S. Special Representative for Nuclear Nonproliferation agreed that nonproliferation and disarmament are linked, noting that they can be mutually reinforcing but also that growing proliferation risks create an environment that makes disarmament more difficult. The United Kingdom, France and Russia likewise defend their nuclear disarmament records, and the five NPT NWS issued a joint statement in 2008 reaffirming their Article VI disarmament commitments.

According to Thomas Reed and Danny Stillman, the "NPT has one giant loophole": Article IV gives each non-nuclear weapon state the 'inalienable right' to pursue nuclear energy for the generation of power. A "number of high-ranking officials, even within the United Nations, have argued that they can do little to stop states using nuclear reactors to produce nuclear weapons". A 2009 United Nations report said that:

The revival of interest in nuclear power could result in the worldwide dissemination of uranium enrichment and spent fuel reprocessing technologies, which present obvious risks of proliferation as these technologies can produce fissile materials that are directly usable in nuclear weapons.
According to critics, those states which possess nuclear weapons, but are not authorized to do so under the NPT, have not paid a significant price for their pursuit of weapons capabilities. Also, the NPT has been explicitly weakened by a number of bilateral deals made by NPT signatories, notably the United States.

Based on concerns over the slow pace of nuclear disarmament and the continued reliance on nuclear weapons in military and security concepts, doctrines and policies, the Treaty on the Prohibition of Nuclear Weapons was adopted in July 2017 and was subsequently opened for signature on 20 September 2017. Upon entry into force, it will prohibit each state party from the development, testing, production, stockpiling, stationing, transfer, use and threat of use of nuclear weapons, as well as assistance to those activities. It reaffirms in its preamble the vital role of the full and effective implementation of the NPT.




</doc>
<doc id="22109" url="https://en.wikipedia.org/wiki?curid=22109" title="Nikolai Bukharin">
Nikolai Bukharin

Nikolai Ivanovich Bukharin ( – 15 March 1938) was a Bolshevik revolutionary, Soviet politician, Marxist philosopher and prolific author on revolutionary theory. 
As a young man, he spent six years in exile working closely with fellow exiles Vladimir Lenin and Leon Trotsky. After the revolution of February 1917, he returned to Moscow, where his Bolshevik credentials earned him a high rank in the Bolshevik party and after the October Revolution became editor of the party newspaper "Pravda."
Within the Bolshevik Party, Bukharin was initially a left communist, but gradually moved from the left to the right from 1921. His strong support for and defence of the New Economic Policy (NEP) eventually saw him lead the Right Opposition. By late 1924, this stance had positioned Bukharin favourably as Joseph Stalin's chief ally, with Bukharin soon elaborating Stalin's new theory and policy of Socialism in One Country. Together, Bukharin and Stalin ousted Trotsky, Grigory Zinoviev and Lev Kamenev from the party at the XVth Communist Party Congress in December 1927. From 1926 to 1929, Bukharin enjoyed great power as General Secretary of the Comintern's executive committee. However, Stalin's decision to proceed with collectivisation drove the two men apart, and Bukharin was expelled from the Politburo in 1929.

When the Great Purge began in 1936, Stalin looked for any pretext to liquidate his former allies and rivals for power, and some of Bukharin's letters, conversations and tapped phone-calls indicated disloyalty. Arrested in February 1937, Bukharin was charged with conspiring to overthrow the Soviet state. After a show trial that alienated many Western communist sympathisers, he was executed in March 1938.

Nikolai Bukharin was born on 27 September (9 October, new style), 1888, in Moscow. He was the second son of two schoolteachers, Ivan Gavrilovich Bukharin and Liubov Ivanovna Bukharina. His childhood is vividly recounted in his mostly autobiographic novel "How It All Began".

Bukharin's political life began at the age of sixteen, with his lifelong friend Ilya Ehrenburg, when they participated in student activities at Moscow University related to the Russian Revolution of 1905. He joined the Russian Social Democratic Labour Party in 1906, becoming a member of the Bolshevik faction. With Grigori Sokolnikov, Bukharin convened the 1907 national youth conference in Moscow, which was later considered the founding of Komsomol. 

By age twenty, he was a member of the Moscow Committee of the party. The committee was widely infiltrated by the Tsarist secret police, the Okhrana. As one of its leaders, Bukharin quickly became a person of interest to them. During this time, he became closely associated with Valerian Obolensky and Vladimir Smirnov. He also met his future first wife, Nadezhda Mikhailovna Lukina, his cousin and the sister of Nikolai Lukin, who was also a member of the party. They married in 1911, soon after returning from internal exile.

In 1911, after a brief imprisonment, Bukharin was exiled to Onega in Arkhangelsk, but he soon escaped to Hanover. He stayed in Germany for a year before visiting Kraków (now in Poland) in 1912 to meet Vladimir Lenin for the first time. During the exile, he continued his education and wrote several books that established him in his 20s as a major Bolshevik theorist. His work, "" influenced Lenin, who freely borrowed from it in his larger and better-known work, "Imperialism, the Highest Stage of Capitalism". He and Lenin also often had hot disputes on theoretical issues, as well as Bukharin's closeness with the European Left and his anti-statist tendencies. Bukharin developed an interest in the works of Austrian Marxists and non-Marxist economic theorists, such as Aleksandr Bogdanov, who deviated from Leninist positions. Also, while in Vienna in 1913, he helped the Georgian Bolshevik Joseph Stalin write an article, "Marxism and the National Question," at Lenin's request.

In October 1916, while based in New York City, Bukharin edited the newspaper "Novy Mir" ("New World") with Leon Trotsky and Alexandra Kollontai. When Trotsky arrived in New York in January 1917, Bukharin was the first of the emigrés to greet him. (Trotsky's wife recalled, "with a bear hug and immediately began to tell them about a public library which stayed open late at night and which he proposed to show us at once" dragging the tired Trotskys across town "to admire his great discovery").

At the news of the Russian Revolution of February 1917, exiled revolutionaries from around the world began to flock back to the homeland. Trotsky left New York on 27 March 1917, sailing for St. Petersburg. Bukharin left New York in early April and returned to Russia by way of Japan (where he was temporarily detained by local police), arriving in Moscow in early May 1917. Politically, the Bolsheviks in Moscow were a minority in relation to the Mensheviks and Social Democrats. As more people began to be attracted to Lenin's promise to bring peace by withdrawing from the Great War, membership in the Bolshevik faction began to increase dramatically —from 24,000 members in February 1917 to 200,000 members in October 1917. Upon his return to Moscow, Bukharin resumed his seat on the Moscow City Committee and also became a member of the Moscow Regional Bureau of the party.
To complicate matters further, the Bolsheviks themselves were divided into a right wing and a left wing. The right-wing of the Bolsheviks, including Aleksei Rykov and Viktor Nogin, controlled the Moscow Committee, while the younger left-wing Bolsheviks, including Vladimir Smirnov, Valerian Osinsky, Georgii Lomov, Nikolay Yakovlev, Ivan Kizelshtein and Ivan Stukov, were members of the Moscow Regional Bureau. On 10 October 1917, Bukharin, along with two other Moscow Bolsheviks: Andrei Bubnov and Grigori Sokolnikov were elected to the Central Committee. This strong representation on the Central Committee was a direct recognition of the fact that the Moscow Bureau had grown in importance. Whereas the Bolsheviks had previously been a minority in Moscow behind the Mensheviks and the Socialist Revolutionaries, by September 1917 the Bolsheviks were in the majority in Moscow. Furthermore, the Moscow Regional Bureau was formally responsible for the party organizations in each of the thirteen (13) central provinces around Moscow—which accounted for 37% of the whole population of Russia and 20% of the Bolshevik membership.While no one dominated revolutionary politics in Moscow during the October Revolution as Trotsky did in St. Petersburg, Bukharin certainly was the most prominent leader in Moscow. During the October Revolution, Bukharin drafted, introduced, and defended the revolutionary decrees of the Moscow Soviet. Bukharin then represented the Moscow Soviet in their report to the revolutionary government in Petrograd. Following the October Revolution, Bukharin became the editor of the party's newspaper, "Pravda".

Bukharin believed passionately in the promise of world revolution. In the Russian turmoil near the end of World War I, when a negotiated peace with the Central Powers was looming, he demanded a continuance of the war, fully expecting to incite all the foreign proletarian classes to arms. Even as he was uncompromising toward Russia's battlefield enemies, he also rejected any fraternization with the capitalist Allied powers: he reportedly wept when he learned of official negotiations for assistance.
Bukharin emerged as the leader of the Left Communists in bitter opposition to Lenin's decision to sign the Treaty of Brest-Litovsk. In this wartime power struggle, Lenin's arrest had been seriously discussed by them and Left Socialist Revolutionaries in 1918. Bukharin revealed this in a Pravda article in 1924 and stated that it had been "a period when the party stood a hair from a split, and the whole country a hair from ruin."

After the ratification of the treaty, Bukharin resumed his responsibilities within the party. In March 1919, he became a member of the Comintern's executive committee and a candidate member of the Politburo. During the Civil War period, he published several theoretical economic works, including the popular primer "The ABC of Communism" (with Yevgeni Preobrazhensky, 1919), and the more academic "Economics of the Transitional Period" (1920) and "Historical Materialism" (1921).

By 1921, he changed his position and accepted Lenin's emphasis on the survival and strengthening of the Soviet state as the bastion of the future world revolution. He became the foremost supporter of the New Economic Policy (NEP), to which he was to tie his political fortunes. Considered by the left communists as a retreat from socialist policies, the NEP reintroduced money and allowed private ownership and capitalistic practices in agriculture, retail trade, and light industry while the state retained control of heavy industry. While some have criticized Bukharin for this apparent U-turn, his change of emphasis can be partially explained by the necessity for peace and stability following seven years of war in Russia, and the failure of communist revolutions in Central and Eastern Europe, which ended the prospect of worldwide revolution.

After Lenin's death in 1924, Bukharin became a full member of the Politburo. In the subsequent power struggle among Leon Trotsky, Grigory Zinoviev, Lev Kamenev and Stalin, Bukharin allied himself with Stalin, who positioned himself as centrist of the Party and supported the NEP against the Left Opposition, which wanted more rapid industrialization, escalation of class struggle against the kulaks (wealthier peasants), and agitation for world revolution. It was Bukharin who formulated the thesis of "Socialism in One Country" put forth by Stalin in 1924, which argued that socialism (in Marxist theory, the transitional stage from capitalism to communism) could be developed in a single country, even one as underdeveloped as Russia. This new theory stated that socialist gains could be consolidated in a single country, without that country relying on simultaneous successful revolutions across the world. The thesis would become a hallmark of Stalinism.

Trotsky, the prime force behind the Left Opposition, was defeated by a triumvirate formed by Stalin, Zinoviev, and Kamenev, with the support of Bukharin. At the Fourteenth Party Congress in December 1925, Stalin openly attacked Kamenev and Zinoviev, revealing that they had asked for his aid in expelling Trotsky from the Party. By 1926, the Stalin-Bukharin alliance ousted Zinoviev and Kamenev from the Party leadership, and Bukharin enjoyed the highest degree of power during the 1926–1928 period. He emerged as the leader of the Party's right wing, which included two other Politburo members (Alexei Rykov, Lenin's successor as Chairman of the Council of People's Commissars and Mikhail Tomsky, head of trade unions) and he became General Secretary of the Comintern's executive committee in 1926. However, prompted by a grain shortage in 1928, Stalin reversed himself and proposed a program of rapid industrialization and forced collectivization because he believed that the NEP was not working fast enough. Stalin felt that in the new situation the policies of his former foes—Trotsky, Zinoviev, and Kamenev—were the right ones.

Bukharin was worried by the prospect of Stalin's plan, which he feared would lead to "military-feudal exploitation" of the peasantry. Bukharin did want the Soviet Union to achieve industrialization but he preferred the more moderate approach of offering the peasants the opportunity to become prosperous, which would lead to greater grain production for sale abroad. Bukharin pressed his views throughout 1928 in meetings of the Politburo and at the Communist Party Congress, insisting that enforced grain requisition would be counterproductive, as War Communism had been a decade earlier.

Bukharin's support for the continuation of the NEP was not popular with higher Party cadres, and his slogan to peasants, "Enrich yourselves!" and proposal to achieve socialism "at snail's pace" left him vulnerable to attacks first by Zinoviev and later by Stalin. Stalin attacked Bukharin's views, portraying them as capitalist deviations and declaring that the revolution would be at risk without a strong policy that encouraged rapid industrialization.

Having helped Stalin achieve unchecked power against the Left Opposition, Bukharin found himself easily outmaneuvered by Stalin. Yet Bukharin played to Stalin's strength by maintaining the appearance of unity within the Party leadership. Meanwhile, Stalin used his control of the Party machine to replace Bukharin's supporters in the Rightist power base in Moscow, trade unions, and the Comintern.Bukharin attempted to gain support from earlier foes including Kamenev and Zinoviev who had fallen from power and held mid-level positions within the Communist party. The details of his meeting with Kamenev, to whom he confided that Stalin was "Genghis Khan" and changed policies to get rid of rivals, were leaked by the Trotskyist press and subjected him to accusations of factionalism. Jules Humbert-Droz, a former ally and friend of Bukharin, reported in his "memóirs" that in spring 1929, Bukharin told him that he had formed an alliance with Zinoviev and Kamenev and they were planning to use individual terror (assassination) to get rid of Stalin. Eventually, Bukharin lost his position in the Comintern and the editorship of "Pravda" in April 1929 and he was expelled from the Politburo on 17 November of that year.

Bukharin was forced to renounce his views under pressure. He wrote letters to Stalin pleading for forgiveness and rehabilitation, but through wiretaps of Bukharin's private conversations with Stalin's enemies, Stalin knew Bukharin's repentance was insincere.

International supporters of Bukharin, Jay Lovestone of the Communist Party USA among them, were also expelled from the Comintern. They formed an international alliance to promote their views, calling it the "International Communist Opposition", though it became better known as the Right Opposition, after a term used by the Trotskyist Left Opposition in the Soviet Union to refer to Bukharin and his supporters there.

In the brief period of thaw in 1934–1936, Bukharin was politically rehabilitated and was made editor of "Izvestia" in 1934. There, he consistently highlighted the dangers of fascist regimes in Europe and the need for "proletarian humanism". One of his first decisions as editor was to invite Boris Pasternak to contribute to the newspaper and sit in on editorial meetings. Pasternak described Bukharin as "a wonderful, historically extraordinary man, but fate has not been kind to him." They first met during the lying-in-state of the Soviet police chief, Vyacheslav Menzhinsky in May 1934, when Pasternak was seeking help for his fellow poet, Osip Mandelstam, who had been arrested - though at that time neither Pasternak nor Bukharin knew why. 

Bukharin had acted as Mandelstam's political protector since 1922. According to Mandelstam's wife, Nadezhda, "M. owed him all the pleasant things in his life. His 1928 volume of poetry would never have come out without the active intervention of Bukharin. The journey to Armenia, our apartment and ration cards, contracts for future volumes – all this was arranged by Bukharin." Bukharin wrote to Stalin, pleading clemency for Mandelstam, and appealed personally to the head of the NKVD, Genrikh Yagoda. It was Yagoda who told him about Mandelstam's Stalin Epigram, after which he refused to have any further contact with Nadezhda Mandelstam, who had lied to him by denying that her husband had written "anything rash". – but continued to befriend Pasternak.

Soon after Mandelstam's arrest, Bukharin was delegated to prepare the official report on poetry for the First Soviet Writers' Congress, in August 1934. He could not any longer risk mentioning Mandelstam in his speech to the congress, but did devote a large section of his to Pasternak, whom he described as "remote from current affairs...a singer of the old intelligensia...delicate and subtle...a wounded and easily vulnerable soul. He is the embodiment of chaste but self-absorbed laboratory craftsmanship..." His speech was greeted with wild applause, though it greatly offended some of the listeners, such as the communist poet Semyon Kirsanov, who complained: "according to Bukharin, all the poets who have used their verses to participate in political life are out of date, but the others are not out of date, the so-called pure (and not so pure) lyric poets."

When Bukharin was arrested two years later, Boris Pasternak displayed extraordinary courage by having a letter delivered to Bukharin's wife saying that he was convinced of his innocence.

Stalin's collectivization policy proved to be as disastrous as Bukharin predicted, but Stalin had by then achieved unchallenged authority in the party leadership. However, there were signs that moderates among Stalin's supporters sought to end official terror and bring a general change in policy, after mass collectivization was largely completed and the worst was over. Although Bukharin had not challenged Stalin since 1929, his former supporters, including Martemyan Ryutin, drafted and clandestinely circulated an anti-Stalin platform, which called Stalin the "evil genius of the Russian Revolution".

However, Sergey Kirov, First Secretary of the Leningrad Regional Committee was assassinated in Leningrad in December 1934, and his death was used by Stalin as a pretext to launch the Great Purge, in which about 700,000 people were to perish as Stalin eliminated all past and potential opposition to his authority. Some historians believe that Kirov's assassination in 1934 was arranged by Stalin himself or at least that there is sufficient evidence to plausibly posit such a conclusion. After Kirov's assassination, the NKVD charged an ever-growing group of former oppositionists with Kirov's murder and other acts of treason, terrorism, sabotage, and espionage.

In February 1936, shortly before the purge started in earnest, Bukharin was sent to Paris by Stalin to negotiate the purchase of the Marx and Engels archives, held by the German Social Democratic Party (SPD) before its dissolution by Hitler. He was joined by his young wife Anna Larina, which therefore opened the possibility of exile, but he decided against it, saying that he could not live outside the Soviet Union.

Bukharin, who had been forced to follow the Party line since 1929, confided to his old friends and former opponents his real view of Stalin and his policy. His conversations with Boris Nicolaevsky, a Menshevik leader who held the manuscripts on behalf of the SPD, formed the basis of "Letter of an Old Bolshevik", which was very influential in contemporary understanding of the period (especially the Ryutin Affair and the Kirov murder), although there are doubts about its authenticity.

According to Nicolaevsky, Bukharin spoke of "the mass annihilation of completely defenseless men, with women and children" under forced collectivization and liquidation of kulaks as a class that dehumanized the Party members with "the profound psychological change in those communists who took part in the campaign. Instead of going mad, they accepted terror as a normal administrative method and regarded obedience to all orders from above as a supreme virtue. ... They are no longer human beings. They have truly become the cogs in a terrible machine."

Yet to another Menshevik leader, Fyodor Dan, he confided that Stalin became "the man to whom the Party granted its confidence" and "is a sort of a symbol of the Party" even though he "is not a man, but a devil." In Dan's account, Bukharin's acceptance of the Soviet Union's new direction was thus a result of his utter commitment to Party solidarity.

To André Malraux, he also confided, "Now he is going to kill me". To his boyhood friend, Ilya Ehrenburg, he expressed the suspicion that the whole trip was a trap set up by Stalin. Indeed, his contacts with Mensheviks during this trip were to feature prominently in his trial.

Following the trial and execution of Zinoviev, Kamenev, and other leftist Old Bolsheviks in 1936, Bukharin and Rykov were arrested on 27 February 1937 following a plenum of the Central Committee and were charged with conspiring to overthrow the Soviet state.

Bukharin was tried in the Trial of the Twenty One on 2–13 March 1938 during the Great Purge, along with ex-premier Alexei Rykov, Christian Rakovsky, Nikolai Krestinsky, Genrikh Yagoda, and 16 other defendants alleged to belong to the so-called "Bloc of Rightists and Trotskyites". In a trial meant to be the culmination of previous show trials, it was alleged that Bukharin and others sought to assassinate Lenin and Stalin from 1918, murder Maxim Gorky by poison, partition the Soviet Union and hand out her territories to Germany, Japan, and Great Britain.

Even more than earlier Moscow show trials, Bukharin's trial horrified many previously sympathetic observers as they watched allegations become more absurd than ever and the purge expand to include almost every living Old Bolshevik leader except Stalin. For some prominent communists such as Bertram Wolfe, Jay Lovestone, Arthur Koestler, and Heinrich Brandler, the Bukharin trial marked their final break with communism and even turned the first three into passionate anti-Communists eventually.

While Anastas Mikoyan and Vyacheslav Molotov later claimed that Bukharin was never tortured and his letters from prison do not give the suggestion that he was tortured, it is also known that his interrogators were instructed with the order: "beating permitted". Bukharin held out for three months, but threats to his young wife and infant son, combined with "methods of physical influence" wore him down. But when he read his confession amended and corrected personally by Stalin, he withdrew his whole confession. The examination started all over again, with a double team of interrogators.

Bukharin's confession and his motivation became subject of much debate among Western observers, inspiring Koestler's acclaimed novel "Darkness at Noon" and a philosophical essay by Maurice Merleau-Ponty in "Humanism and Terror." His confessions were somewhat different from others in that while he pleaded guilty to the "sum total of crimes," he denied knowledge when it came to specific crimes. Some astute observers noted that he would allow only what was in the written confession and refuse to go any further.

There are several interpretations of Bukharin's motivations (besides being coerced) in the trial. Koestler and others viewed it as a true believer's last service to the Party (while preserving the little amount of personal honor left) whereas Bukharin biographer Stephen Cohen and Robert Tucker saw traces of Aesopian language, with which Bukharin sought to turn the table into an anti-trial of Stalinism (while keeping his part of the bargain to save his family). While his letters to Stalin – he wrote 34 very emotional and desperate letters tearfully protesting his innocence and professing his loyalty – suggest a complete capitulation and acceptance of his role in the trial, it contrasts with his actual conduct in the trial. Bukharin himself speaks of his "peculiar duality of mind" in his last plea, which led to "semi-paralysis of the will" and Hegelian "unhappy consciousness", which likely stemmed not only from his knowledge of the ruinous reality of Stalinism (although he could not of course say so in the trial) but also of the impending threat of fascism.

The result was a curious mix of fulsome confessions (of being a "degenerate fascist" working for the "restoration of capitalism") and subtle criticisms of the trial. After disproving several charges against him (one observer noted that he "proceeded to demolish or rather showed he could very easily demolish the whole case.") and saying that "the confession of the accused is not essential. The confession of the accused is a medieval principle of jurisprudence" in a trial that was solely based on confessions, he finished his last plea with the words:

the monstrousness of my crime is immeasurable especially in the new stage of struggle of the U.S.S.R. May this trial be the last severe lesson, and may the great might of the U.S.S.R. become clear to all.
The state prosecutor Vyshinsky characterized Bukharin as an "accursed crossbreed of fox and pig" who supposedly committed a "whole nightmare of vile crimes".

While in prison, he wrote at least four book-length manuscripts including a lyrical autobiographical novel, "How It All Began", philosophical treatise "Philosophical Arabesques", a collection of poems, and "Socialism and Its Culture" – all of which were found in Stalin's archive and published in the 1990s.

Among other intercessors, the French author and Nobel laureate Romain Rolland wrote to Stalin seeking clemency, arguing that "an intellect like that of Bukharin is a treasure for his country." He compared Bukharin's situation to that of the great chemist Antoine Lavoisier who was guillotined during the French Revolution: "We in France, the most ardent revolutionaries... still profoundly grieve and regret what we did. ... I beg you to show clemency." He had earlier written to Stalin in 1937, "For the sake of Gorky I am asking you for mercy, even if he may be guilty of something," to which Stalin noted: "We must not respond." Bukharin was shot on 15 March 1938 at the Kommunarka shooting ground, but the announcement of his death was overshadowed by the Nazi Anschluss of Austria.

According to Zhores and Roy Medvedev in "The Unknown Stalin" (2006), Bukharin's last message to Stalin stated "Koba, why do you need me to die?", which was written in a note to Stalin just before his execution. "Koba" was Stalin's "nom de guerre", and Bukharin's use of it was a sign of how close the two had once been. The note was allegedly found still in Stalin's desk after his death in 1953.

Despite the promise to spare his family, Bukharin's wife, Anna Larina, was sent to a labor camp, but she survived to see her husband officially rehabilitated by the Soviet state under Mikhail Gorbachev in 1988.

Bukharin was immensely popular within the party throughout the twenties and thirties, even after his fall from power. In his testament, Lenin portrayed him as the Golden Boy of the party, writing:

Speaking of the young C.C. members, I wish to say a few words about Bukharin and Pyatakov. They are, in my opinion, the most outstanding figures (among the youngest ones), and the following must be borne in mind about them: Bukharin is not only a most valuable and major theorist of the Party; he is also rightly considered the favourite of the whole Party, but his theoretical views can be classified as fully Marxist only with great reserve, for there is something scholastic about him (he has never made a study of the dialectics, and, I think, never fully understood it) ... Both of these remarks, of course, are made only for the present, on the assumption that both these outstanding and devoted Party workers fail to find an occasion to enhance their knowledge and amend their one-sidedness.

Bukharin made several notable contributions to Marxist–Leninist thought, most notably "The Economics of the Transition Period" (1920) and his prison writings, "Philosophical Arabesques", as well as being a founding member of the Soviet Academy of Arts and Sciences, and a keen botanist. His primary contributions to economics were his critique of marginal utility theory, his analysis of imperialism, and his writings on the transition to communism in the Soviet Union.

His ideas, especially in economics and the question of market-socialism, later became highly influential in Chinese market-socialism and Deng Xiaoping's reforms.

British author Martin Amis argues that Bukharin was perhaps the only major Bolshevik to acknowledge "moral hesitation" by questioning, even in passing, the violence and sweeping reforms of the early Soviet Union. Amis writes that Bukharin said "during the Civil War he had seen 'things that I would not want even my enemies to see'."


Bukharin was a cartoonist who left many cartoons of contemporary Soviet politicians. The renowned artist Konstantin Yuon once told him: "Forget about politics. There is no future in politics for you. Painting is your real calling." His cartoons are sometimes used to illustrate the biographies of Soviet officials. Russian historian Yury Zhukov stated that Nikolai Bukharin's portraits of Joseph Stalin were the only ones drawn from the original, not from a photograph.






</doc>
<doc id="22110" url="https://en.wikipedia.org/wiki?curid=22110" title="Nasal consonant">
Nasal consonant

In phonetics, a nasal, also called a nasal occlusive or nasal stop in contrast with an oral stop or nasalized consonant, is an occlusive consonant produced with a lowered velum, allowing air to escape freely through the nose. The vast majority of consonants are oral consonants. Examples of nasals in English are , and , in words such as "nose", "bring" and "mouth". Nasal occlusives are nearly universal in human languages. There are also other kinds of nasal consonants in some languages.

Nearly all nasal consonants are nasal occlusives, in which air escapes through the nose but not through the mouth, as it is blocked (occluded) by the lips or tongue. The oral cavity still acts as a resonance chamber for the sound. Rarely, non-occlusive consonants may be nasalized.

Most nasals are voiced, and in fact, the nasal sounds and are among the most common sounds cross-linguistically. Voiceless nasals occur in a few languages such as Burmese, Welsh, Icelandic and Guaraní. (Compare oral stops, which block off the air completely, and fricatives, which obstruct the air with a narrow channel. Both stops and fricatives are more commonly voiceless than voiced, and are known as obstruents.)

In terms of acoustics, nasals are sonorants, which means that they do not significantly restrict the escape of air (as it can freely escape out the nose). However, nasals are also obstruents in their articulation because the flow of air through the mouth is blocked. This duality, a sonorant airflow through the nose along with an obstruction in the mouth, means that nasal occlusives behave both like sonorants and like obstruents. For example, nasals tend to pattern with other sonorants such as and , but in many languages, they may develop from or into stops.

Acoustically, nasals have bands of energy at around 200 and 2,000 Hz.
1. The symbol is commonly used to represent the dental nasal as well, rather than , as it is rarely distinguished from the alveolar nasal.

Examples of languages containing nasal occlusives:

The voiced retroflex nasal is is a common sound in Languages of India.

The voiced palatal nasal is a common sound in European languages, such as: Spanish , French and Italian , Catalan and Hungarian , Czech and Slovak , Polish , Occitan and Portuguese , and (before a vowel) Modern Greek .

Many Germanic languages, including German, Dutch, English and Swedish, as well as varieties of Chinese such as Mandarin and Cantonese, have , and . Tamil has a six-fold distinction between , , , , and .

Catalan, Occitan, Spanish, and Italian have , , as phonemes, and and as allophones. Nevertheless, in several American dialects of Spanish, there is no palatal nasal but only a palatalized nasal, , as in English "canyon".

In Brazilian Portuguese and Angolan Portuguese , written , is typically pronounced as , a nasal palatal approximant, a nasal glide (in Polish, this feature is also possible as an allophone). Semivowels in Portuguese often nasalize before and always after nasal vowels, resulting in and . What would be coda nasal occlusives in other West Iberian languages is only slightly pronounced before dental consonants. Outside this environment the nasality is spread over the vowel or become a nasal diphthong ("mambembe" , outside the final, only in Brazil, and "mantém" in all Portuguese dialects).

The Japanese syllabary kana ん, typically romanized as "n" and occasionally "m", can manifest as one of several different nasal consonants depending on what consonant follows it; this allophone, colloquially written in IPA as , is known as the moraic nasal, per the language's moraic structure.

Welsh has a set of voiceless nasals, [m̥], [n̥] and [ŋ̊], which occur predominantly as a result of nasal mutation of their voiced counterparts ([m], [n] and [ŋ]).

The Mapos Buang language of New Guinea has a phonemic uvular nasal, [ɴ], which contrasts with a velar nasal. It is extremely rare for a language to have [ɴ] as a phoneme.

Yanyuwa is highly unusual in that it has a seven-way distinction between [m], [n̪], [n], [ɳ], [ṉ] (palato-alveolar), [ŋ̟] (front velar), and [ŋ̠] (back velar). This may be the only language in existence that contrasts nasals at seven distinct points of articulation.

The term 'nasal occlusive' (or 'nasal stop') is generally abbreviated to "nasal". However, there are also nasalized fricatives, nasalized flaps, nasal glides, and nasal vowels, as in French, Portuguese, and Polish. In the , nasal vowels and nasalized consonants are indicated by placing a tilde (~) over the vowel or consonant in question: French "sang" , Portuguese "bom" .

A few languages have phonemic voiceless nasal occlusives. Among them are Icelandic, Faroese, Burmese, Jalapa Mazatec, Kildin Sami, Welsh, and Central Alaskan Yup'ik. Iaai of New Caledonia has an unusually large number of them, with , along with a number of voiceless approximants.

Ladefoged and Maddieson (1996) distinguish purely nasal consonants, the nasal occlusives such as "m n ng" in which the airflow is purely nasal, from partial nasal consonants such as prenasalized consonants and nasal pre-stopped consonants, which are nasal for only part of their duration, as well as from nasalized consonants, which have simultaneous oral and nasal airflow. In some languages, such as Portuguese, a nasal consonant may have occlusive and non-occlusive allophones. In general, therefore, a nasal consonant may be:


A few languages, perhaps 2%, contain no phonemically distinctive nasals. This led Ferguson (1963) to assume that all languages have at least one primary nasal occlusive. However, there are exceptions.

When a language is claimed to lack nasals altogether, as with several Niger–Congo languages or the Pirahã language of the Amazon, nasal and non-nasal or prenasalized consonants usually alternate allophonically, and it is a theoretical claim on the part of the individual linguist that the nasal is not the basic form of the consonant. In the case of some Niger–Congo languages, for example, nasals occur before only nasal vowels. Since nasal vowels are phonemic, it simplifies the picture somewhat to assume that nasalization in occlusives is allophonic. There is then a second step in claiming that nasal vowels nasalize oral occlusives, rather than oral vowels denasalizing nasal occlusives, that is, whether are phonemically without full nasals, or without prenasalized stops. Postulating underlying oral or prenasalized stops rather than true nasals helps to explain the apparent instability of nasal correspondences throughout Niger–Congo compared with, for example, Indo-European.

This analysis comes at the expense, in some languages, of postulating either a single nasal consonant that can only be syllabic, or a larger set of nasal vowels than oral vowels, both typologically odd situations. The way such a situation could develop is illustrated by a Jukunoid language, Wukari. Wukari allows oral vowels in syllables like "ba, mba" and nasal vowels in "bã, mã", suggesting that nasals become prenasalized stops before oral vowels. Historically, however, *mb became **mm before nasal vowels, and then reduced to *m, leaving the current asymmetric distribution.

In older speakers of the Tlingit language, and are allophones. Tlingit is usually described as having an unusual, perhaps unique lack of despite having five lateral obstruents; the older generation could be argued to have but at the expense of having no nasals.

Several of languages surrounding Puget Sound, such as Quileute (Chimakuan family), Lushootseed (Salishan family), and Makah (Wakashan family), are truly without any nasalization whatsoever, in consonants or vowels, except in special speech registers such as baby talk or the archaic speech of mythological figures (and perhaps not even that in the case of Quileute). This is an areal feature, only a few hundred years old, where nasals became voiced stops ( became , etc.) after colonial contact. For example, "Snohomish" is currently pronounced "sdohobish", but was transcribed with nasals in the first English-language records.

The only other places in the world where this is known to occur is in Melanesia. In the central dialect of the Rotokas language of Bougainville Island, nasals are only used when imitating foreign accents. (A second dialect has a series of nasals.) The Lakes Plain languages of West Irian are similar.

The unconditioned loss of nasals, as in Puget Sound, is unusual. However, currently in Korean, word-initial and are shifting to and . This started out in nonstandard dialects and was restricted to the beginning of prosodic units (a common position for fortition), but has expanded to many speakers of the standard language to the beginnings of common words even within prosodic units.




</doc>
<doc id="22111" url="https://en.wikipedia.org/wiki?curid=22111" title="Nuvistor">
Nuvistor

The nuvistor is a type of vacuum tube announced by RCA in 1959. Most nuvistors are basically thimble-shaped, but somewhat smaller than a thimble, and much smaller than conventional tubes of the day, almost approaching the compactness of early discrete transistor casings. Triodes and a few tetrodes were made. The tube is made entirely of metal and ceramic. Making nuvistors requires special equipment, since there is no intubation to pump gases out of the envelope. Instead, the entire structure is assembled, inserted into its metal envelope, sealed and processed in a large vacuum chamber with simple robotic devices.

Nuvistors are among the highest performing small signal receiving tubes. They feature excellent VHF and UHF performance plus low noise figures, and were widely used throughout the 1960s in television sets (beginning with RCA's "New Vista" line of color sets in 1961 with the CTC-11 chassis), radio and high-fidelity equipment primarily in RF sections, and oscilloscopes. They competed with the solid state revolution, and along with GE's Compactron, probably held it at bay for a few years. RCA discontinued their use in television tuners for its product line in late 1971. One famous application was in the Ampex MR-70, a costly studio tape recorder whose entire electronics section was based on nuvistors. Another limited application of this very small tube was in studio-grade microphones from that era, the AKG/Norelco C12a, which employed the 7586, being a good example. It was also later found that, with minor circuit modification, the nuvistor made a sufficient replacement for the obsolete Telefunken VF14 tube, used in the famed Neumann U 47 studio microphone.. Tektronix also used nuvistors in several of its high end oscilloscopes of the 1960s, before replacing them later with JFET transistors.




</doc>
<doc id="22113" url="https://en.wikipedia.org/wiki?curid=22113" title="No Logo">
No Logo

No Logo: Taking Aim at the Brand Bullies is a book by the Canadian author Naomi Klein. First published by Knopf Canada and Picador in December 1999, shortly after the 1999 WTO Ministerial Conference protests in Seattle had generated media attention around such issues, it became one of the most influential books about the alter-globalization movement and an international bestseller.

The book focuses on branding and often makes connections with the anti-globalization movement. Throughout the four parts ("No Space", "No Choice", "No Jobs", and "No Logo"), Klein writes about issues such as sweatshops in the Americas and Asia, culture jamming, corporate censorship, and Reclaim the Streets. She pays special attention to the deeds and misdeeds of Nike, The Gap, McDonald's, Shell, and Microsoft – and of their lawyers, contractors, and advertising agencies. Many of the ideas in Klein's book derive from the influence of the Situationists, an art/political group founded in the late 1950s.

However, while globalization appears frequently as a recurring theme, Klein rarely addresses the topic of globalization itself, and when she does, it is usually indirectly. She goes on to discuss globalization in much greater detail in her book, "Fences and Windows" (2002).

The book comprises four sections: "No Space", "No Choice", "No Jobs", and "No Logo". The first three deal with the negative effects of brand-oriented corporate activity, while the fourth discusses various methods people have taken in order to fight back.

The book begins by tracing the history of brands. Klein argues that there has been a shift in the usage of branding and gives examples of this shift to "anti-brand" branding. Early examples of brands were often used to put a recognizable face on factory-produced products. These slowly gave way to the idea of selling lifestyles. According to Klein, in response to an economic crash in the 1980s (due to the Latin American debt crisis, Black Monday (1987), the savings and loan crisis, and the Japanese asset price bubble), corporations began to seriously rethink their approach to marketing and to target the youth demographic, as opposed to the baby boomers, who had previously been considered a much more valuable segment.

The book discusses how brand names such as Nike or Pepsi expanded beyond the mere products which bore their names, and how these names and logos began to appear everywhere. As this happened, the brands' obsession with the youth market drove them to further associate themselves with whatever the youth considered "cool". Along the way, the brands attempted to associate their names with everything from movie stars and athletes to grassroots social movements.

Klein argues that large multinational corporations consider the marketing of a brand name to be more important than the actual manufacture of products; this theme recurs in the book, and Klein suggests that it helps explain the shift to production in Third World countries in such industries as clothing, footwear, and computer hardware.

This section also looks at ways in which brands have "muscled" their presence into the school system, and how in doing so, they have pipelined advertisements into the schools and used their position to gather information about the students. Klein argues that this is part of a trend toward targeting younger and younger consumers.

In the second section, Klein discusses how brands use their size and clout to limit the number of choices available to the public – whether through market dominance (e.g., Wal-Mart) or through aggressive invasion of a region (e.g., Starbucks). Klein argues that each company's goal is to become the dominant force in its respective field. Meanwhile, other corporations, such as Sony or Disney, simply open their own chains of stores, preventing the competition from even putting their products on the shelves.

This section also discusses the way that corporations merge with one another in order to add to their ubiquity and provide greater control over their image. ABC News, for instance, is allegedly under pressure not to air any stories that are overly critical of Disney, its parent company. Other chains, such as Wal-Mart, often threaten to pull various products off their shelves, forcing manufacturers and publishers to comply with their demands. This might mean driving down manufacturing costs or changing the artwork or content of products like magazines or albums so they better fit with Wal-Mart's image of family friendliness.

Also discussed is the way that corporations abuse copyright laws in order to silence anyone who might attempt to criticize their brand.

In this section, the book takes a darker tone and looks at the way in which manufacturing jobs move from local factories to foreign countries, and particularly to places known as export processing zones. Such zones often have no labor laws, leading to dire working conditions.

The book then shifts back to North America, where the lack of manufacturing jobs has led to an influx of work in the service sector, where most of the jobs are for minimum wage and offer no benefits. The term "McJob" is introduced, defined as a job with poor compensation that does not keep pace with inflation, inflexible or undesirable hours, little chance of advancement, and high levels of stress. Meanwhile, the public is being sold the perception that these jobs are temporary employment for students and recent graduates, and therefore need not offer living wages or benefits.

All of this is set against a backdrop of massive profits and wealth being produced within the corporate sector. The result is a new generation of employees who have come to resent the success of the companies they work for. This resentment, along with rising unemployment, labour abuses abroad, disregard for the environment, and the ever-increasing presence of advertising breeds a new disdain for corporations.

The final section of the book discusses various movements that have sprung up during the 1990s. These include "Adbusters" magazine and the culture-jamming movement, as well as Reclaim the Streets and the McLibel trial. Less radical protests are also discussed, such as the various movements aimed at putting an end to sweatshop labour.

Klein concludes by contrasting consumerism and citizenship, opting for the latter. "When I started this book," she writes, "I honestly didn't know whether I was covering marginal atomized scenes of resistance or the birth of a potentially broad-based movement. But as time went on, what I clearly saw was a movement forming before my eyes."

After the book's release, Klein was heavily criticized by the newspaper "The Economist", leading to a broadcast debate with Klein and the magazine's writers, dubbed "No Logo vs. Pro Logo".

The 2004 book "The Rebel Sell" (published as "Nation of Rebels" in the United States) specifically criticized "No Logo", stating that turning the improving quality of life in the working class into a fundamentally anti-market ideology is shallow.

In this book, Klein criticized Nike so severely that Nike published a point-by-point response.

In 2000, "No Logo" was short-listed for the "Guardian" First Book Award in 2000.

In 2001, the book won the following awards:

Several imprints of "No Logo" exist, including a hardcover first edition, a subsequent hardcover edition, and a paperback. A 10th anniversary edition was published by Fourth Estate that includes a new introduction by the author. Translations from the original English into several other languages have also been published. The subtitle, "Taking Aim at the Brand Bullies", was dropped in some later editions.

Naomi Klein explains her ideas in the 40-minute video "No Logo – Brands, Globalization & Resistance" (2003), directed by Sut Jhally.

Members of the English rock group Radiohead have stated that the book influenced them particularly during the making of their fourth and fifth albums, "Kid A" (2000) and "Amnesiac" (2001), respectively. (The albums were recorded over the same sessions.) The band recommended the book to fans on their website and considered calling the album "Kid A" "No Logo" for a time. Argentine artist Indio Solari wrote a song for his first solo album named "Nike es la cultura" ("Nike is the culture"), in which he says, "You shout No Logo! Or you doesn't shout No Logo! Or you shout No Logo No!" in reference to this book.

Dhani Harrison, son of George Harrison and front-man of English electronic/alternative rock group Thenewno2, has stated that "No Logo" had a large influence on their release, "You Are Here" (2008). Argentine-American rock singer Kevin Johansen wrote a song, "Logo", inspired by Klein's book. A copy of "No Logo" is even used in the official video for the song. Rapper MC Lars's album "This Gigantic Robot Kills" contains a track entitled "No Logo", a satirical analysis of anti-government youth, partially inspired by the book.



</doc>
<doc id="22115" url="https://en.wikipedia.org/wiki?curid=22115" title="National War College">
National War College

The National War College (NWC) of the United States is a school in the National Defense University. It is housed in Roosevelt Hall on Fort Lesley J. McNair, Washington, D.C., the third-oldest Army post still active.

The National War College (NWC) was officially established on July 1, 1946, as an upgraded replacement for the Army-Navy Staff College, which operated from June 1943 to July 1946. The college was one of James Forrestal's favorite causes.

According to Lt. Gen. Leonard T. Gerow, President of the Board which recommended its formation:

Mid-level and senior military officers who are likely to be promoted to the most senior ranks are selected to study at the War College in preparation for higher staff and command positions. About 75 percent of the student body is composed of equal representation from the land, air, and sea (including Marine and Coast Guard) services. The remaining 25 percent are drawn from the Department of State and other federal departments and agencies. In addition, international fellows from a number of countries join the student body. The curriculum is based upon critical analysis of strategic problem solving with an emphasis on strategic leadership. Starting with the 2014–2015 academic year, the curriculum will be based upon a core standard throughout National Defense University.

Because of NWC's privileged location close to the White House, the Supreme Court, and Capitol Hill, it has been able throughout its history to call upon an extraordinarily well-connected array of speakers to animate its discussions. All lectures at the National War College are conducted under a strict "no quotation nor attribution" policy which has facilitated discussion on some of the most difficult issues of the day.

Graduates of the National War College include numerous current and former flag officers, general officers, and U.S. ambassadors. Notable graduates include:

Roosevelt Hall (built 1903–1907) is a Beaux Arts–style building housing the NWC since its inception in 1946. Designed by the New York architectural firm McKim, Mead and White, it is now designated a National Historical Landmark and is listed on the National Register of Historic Places.




</doc>
<doc id="22117" url="https://en.wikipedia.org/wiki?curid=22117" title="Neelin">
Neelin

Neelin is a small community in the Canadian province of Manitoba. It is located on Manitoba Provincial Highway 5 in the Rural Municipality of Argyle, about 29 km east of Killarney, or about 200 km southwest of Winnipeg.



</doc>
<doc id="22118" url="https://en.wikipedia.org/wiki?curid=22118" title="Norn language">
Norn language

Norn is an extinct North Germanic language that was spoken in the Northern Isles (Orkney and Shetland) off the north coast of mainland Scotland and in Caithness in the far north of the Scottish mainland. After Orkney and Shetland were pledged to Scotland by Norway in 1468–69, it was gradually replaced by Scots. Norn is thought to have become extinct in 1850, after the death of Walter Sutherland, the language's last known speaker.

Norse settlement in the islands probably began in the early 9th century. These settlers are believed to have arrived in very substantial numbers and like those who migrated to Iceland and the Faroe Islands it is probable that most came from the west coast of Norway. Shetland toponymy bears some resemblance to that of northwest Norway, while Norn vocabulary implies links with more southerly Norwegian regions.

Orkney and Shetland were pledged to James III in 1468 and 1469 respectively, and it is with these pledges that the replacement of Norn with Scots is most associated. However, the decline of Norse speech in Orkney probably began in 1379 when the earldom passed into the hands of the Sinclairs, and Scots had superseded Norse as the language of prestige on the island by the early 15th century.

In Shetland, the transition began later, but by the end of the 15th century both island groups were bilingual. Despite this, the process by which Scots overtook Norn as the primary spoken language on the islands was not a swift one, and most natives of Orkney and Shetland probably spoke Norn as a first language until the late 16th and early-to-mid 17th centuries respectively. One of the last documents written in Norn was for a 1597 mortgage issued over a property belonging to Else, sister of Anna Throndsen, who had married a Shetland man Andrew Mowat of Heogoland in Eshaness.

It is not known exactly when Norn became extinct. Sources from the 17th and 18th centuries speak of Norn (sometimes identified as "Norse", "Norwegian" or "Danish") as being in a state of decline and generally indicate that the language remained stronger in Shetland than in Orkney. A source from 1670 states that there are "only three or four parishes" in Orkney where people speak "Noords or rude Danish" and that they do so "chiefly when they are at their own houses". Another from 1701 indicates that there were still a few monoglot "Norse" speakers who were capable of speaking "no other thing," and notes that there were more speakers of the language in Shetland than in Orkney. It was said in 1703 that the people of Shetland generally spoke a Lowland Scots dialect brought to Shetland from the end of the fifteenth century by settlers from Fife and Lothian, but that "many among them retain the ancient Danish Language"; while in 1750 Orkney-born James Mackenzie wrote that Norn was not yet entirely extinct, being "retained by old people," who still spoke it among each other.

The last reports of Norn speakers are claimed to be from the 19th century, with some claims of a very limited use up until the early 20th century, but it is more likely that the language was dying out in the late 18th century. The isolated islands of Foula and Unst are variously claimed as the last refuges of the language in Shetland, where there were people "who could repeat sentences in Norn", probably passages from folk songs or poems, as late as 1893. Walter Sutherland from Skaw in Unst, who died about 1850, has been cited as the last native speaker of the Norn language.
However, fragments of vocabulary survived the death of the main language and remain to this day, mainly in place-names and terms referring to plants, animals, weather, mood, and fishing vocabulary.

Norn had also been a spoken language in Caithness but had probably become extinct there by the 15th century, replaced by Scots. Hence, some scholars also speak about "Caithness Norn", but others avoid this. Even less is known about "Caithness Norn" than about Orkney and Shetland Norn. Almost no written Norn has survived, but what little remains includes a version of the Lord's Prayer and a ballad, "Hildina". Michael P Barnes, professor of Scandinavian Studies at University College London, has published a study, "The Norn Language of Orkney and Shetland".

Norn is an Indo-European language belonging to the North Germanic branch of the Germanic languages. Together with Faroese, Icelandic and Norwegian, it belongs to the West Scandinavian group, separating it from the East Scandinavian group consisting of Swedish, Danish and Gutnish.

While this classification is based on the differences between the North Germanic languages at the time they split, their present-day characteristics justify another classification, dividing them into Insular Scandinavian and Mainland Scandinavian language groups based on mutual intelligibility. Under this system, Norwegian is grouped together with Danish and Swedish because the last millennium has seen all three undergo important changes, especially in grammar and lexis, which have set them apart from Faroese and Icelandic.

Norn is generally considered to have been fairly similar to Faroese, sharing many phonological and grammatical traits, and might even have been mutually intelligible with it. Thus, it can be considered an Insular Scandinavian language.

Few written texts remain. It is distinct from the present-day Shetland dialect, which evolved from Middle English.

The phonology of Norn can never be determined with much precision because of the lack of source material, but the general aspects can be extrapolated from the few written sources that exist. Norn shared many traits with the dialects of southwest Norway. That includes a voicing of to after vowels and (in the Shetland dialect but only partially in the Orkney dialect) a conversion of and ("thing" and "that" respectively) to and respectively.

Norn grammar had features very similar to the other Scandinavian languages. There were two numbers, three genders and four cases (nominative, accusative, genitive and dative). The two main conjugations of verbs in present and past tense were also present. Like all other North Germanic languages, it used a suffix instead of a prepositioned article to indicate definiteness as in modern Scandinavian: ' ("man"); ' ("the man"). Though it is difficult to be certain of many of the aspects of Norn grammar, documents indicate that it may have featured subjectless clauses, which were common in the West Scandinavian languages.

The following are Norn and Old Norse versions of the Lord's Prayer:

A Shetland "guddick" (riddle) in Norn, which Jakob Jakobsen heard told on Unst, the northernmost island in Shetland, in the 1890s. The same riddle is also known from the Faroe Islands, Norway, Iceland, and a variation also occurs in England.
The answer is a cow: four teats hang, four legs walk, two horns and two ears stand skyward, two eyes show the way to the field and one tail comes shaking (dangling) behind.

Most of the use of Norn/Norse in modern-day Shetland and Orkney is purely ceremonial, and mostly in Old Norse, for example the Shetland motto, which is "" ("with law shall land be built") which is the same motto used by the Icelandic police force and inspired by the old Norwegian Frostathing Law.

Another example of the use of Norse/Norn in the Northern Isles can be found in the names of ferries:

Norn words are still used to describe many of the colour and pattern variations in the native sheep of Shetland and Orkney, which survive as the Shetland and North Ronaldsay breeds. Icelandic uses similar words for many of the same colour variations in Icelandic sheep.

There are some enthusiasts who are engaged in developing and disseminating a modern form called Nynorn ("New Norn"), based upon linguistic analysis of the known records and Norse linguistics in general.





</doc>
<doc id="22120" url="https://en.wikipedia.org/wiki?curid=22120" title="Nuoro">
Nuoro

Nuoro ( ; ) is a city and "comune" (municipality) in central-eastern Sardinia, Italy, situated on the slopes of the Monte Ortobene. It is the capital of the province of Nuoro. With a population of 36,347 (2011), it is the sixth-largest city in Sardinia.

Birthplace of several renowned artists, including writers, poets, painters, sculptors, Nuoro hosts some of the most important museums in Sardinia. It is considered an important cultural center of the region and it has been referred to as the "Sardinian Athens". Nuoro is the hometown of Grazia Deledda, the only Italian woman to win (1926) the Nobel Prize in Literature.

The earliest traces of human settlement in the Nuoro area (called " the Nuorese") are the so-called Domus de janas, rock-cut tombs dated at the third millennium BC. However, fragments of ceramics of the Ozieri culture have also been discovered and dated at c. 3500 BC.

The Nuorese was a centre of the Nuragic civilization (which developed in Sardinia from c. 1500 BC to c. 250 BC), as attested by more than 30 Nuragic sites, such has the village discovered in the countryside of Tanca Manna, just outside Nuoro, which was made of about 800 huts.

The Nuorese was crossed by a Roman road which connected Karalis (Cagliari) to Ulbia (Olbia). The legacy of the Roman colonization can especially be found in the variety of the Sardinian language which is still spoken today in Nuoro: Nuorese Sardinian is considered the most conservative dialect of Sardinian, which is in turn the most conservative Romance language.

After the fall of the Western Roman Empire, Sardinia was held first by the Vandals and then by the Byzantines. According to the letters of Pope Gregory I, a Romanized and Christianized culture (that of the "provinciales") co-existed with several Pagan cultures (those of the "Gens Barbaricina", i.e. "Barbarian People") mainly located in the island's interior. As the Byzantine control waned, the Judicates appeared. A small village known as Nugor appears on a medieval map from 1147. In the two following centuries it grew to more than 1000 inhabitants. Nuoro remained a town of average importance under the Aragonese and Spanish domination of Sardinia, until famine and plague struck it in the late 17th century.

After the annexation to the Kingdom of Sardinia, the town became the administrative center of the area, obtaining the title of city in 1836.

Since 1972 in Nuoro is active the Istituto superiore regionale etnografico (ISRE), which is an institution that promotes the "study and documentation of the social and cultural life of Sardinia in its traditional manifestations and its transformations". In fact, in addition to managing museums and libraries, it organizes national and international events, including:
the Sardinia International Ethnographic Film Festival (SIEFF) and the Festival Biennale Italiano dell’Etnografia (ETNU) (Italian Biennial Festival of Ethnography).



Along with Italian, the traditional language spoken in Nuoro is Sardinian, in its Logudorese-Nuorese variety.

Nuoro is home to the world's rarest pasta, "su filindeu". The name in Sardinian language means "the threads (or wool) of God" and is made exclusively by the women of a single family in the town, with the recipe being passed down through generations.

Nuoro is served by the SS 131 DCN (Olbia-Abbasanta), the SS 129 (Orosei-Macomer), and the SS 389 (Monti-Lanusei).

ARST, Azienda Regionale Sarda Trasporti provide regular connections to Cagliari, Sassari, Olbia, and to several minor centres in the province and the region.

Other private operators (including Deplano Autolinee, Turmotravel, Redentours) connects Nuoro to various cities and airports in the island.

Nuoro is connected by train to Macomer via Ferrovie della Sardegna.

ATP Nuoro's bus system provides service within the city.





</doc>
<doc id="22122" url="https://en.wikipedia.org/wiki?curid=22122" title="Nürburgring">
Nürburgring

The Nürburgring is a 150,000 person capacity motorsports complex located in the town of Nürburg, Rhineland-Palatinate, Germany. It features a Grand Prix race track built in 1984, and a much longer "Nordschleife" "North loop" track which was built in the 1920s around the village and medieval castle of Nürburg in the Eifel mountains. The north loop is long and has more than 300 metres (1,000 feet) of elevation change from its lowest to highest points. Jackie Stewart nicknamed the old track "The Green Hell".

Originally, the track featured four configurations: the -long "Gesamtstrecke" ("Whole Course"), which in turn consisted of the "Nordschleife" ("North Loop"), and the "Südschleife" ("South Loop"). There also was a warm-up loop called "Zielschleife" ("Finish Loop") or "Betonschleife" ("Concrete Loop"), around the pit area.

Between 1982 and 1983 the start/finish area was demolished to create a new "GP-Strecke", and this is used for all major and international racing events. However, the shortened "Nordschleife" is still in use for racing, testing and public access.

In 1907, the first Eifelrennen race was held on the one-off Taunus circuit, a 117 km (73 mi) made up of public roads starting between the towns of Wehrleim and Saalburg just north of Frankfurt. In the early 1920s, ADAC Eifelrennen races were held on the twisty 33.2 km (20.6 mi) Nideggen public road circuit near Cologne and Bonn. Sometime around 1925, the construction of a dedicated race track was proposed just south of the Nideggen circuit around the ancient castle of the town of Nürburg, following the examples of Italy's Monza and Targa Florio courses, and Berlin's AVUS, yet with a different character. The layout of the circuit in the mountains was similar to the Targa Florio event, one of the most important motor races at that time. The original Nürburgring was to be a showcase for German automotive engineering and racing talent. Construction of the track, designed by the "Eichler Architekturbüro" from Ravensburg (led by architect Gustav Eichler), began in September 1925.

The track was completed in spring of 1927, and the ADAC Eifelrennen races were continued there. The first races to take place on 18 June 1927 showed motorcycles and sidecars. The first motorcycle race was won by Toni Ulmen on an English 350 cc Velocette. The cars followed a day later, and Rudolf Caracciola was the winner of the over 5000 cc class in a Mercedes-Benz Compressor. In addition, the track was opened to the public in the evenings and on weekends, as a one-way toll road. The whole track consisted of 174 bends (prior to 1971 changes), and averaged in width. The fastest time ever around the full "Gesamtstrecke" was by Louis Chiron, at an average speed of 112.31 km/h (72 mph) in his Bugatti.

In 1929 the full Nürburgring was used for the last time in major racing events, as future Grands Prix would be held only on the "Nordschleife". Motorcycles and minor races primarily used the shorter and safer "Südschleife". Memorable pre-war races at the circuit featured the talents of early "Ringmeister" (Ringmasters) such as Rudolf Caracciola, Tazio Nuvolari and Bernd Rosemeyer.

After World War II, racing resumed in 1947 and in 1951, the "Nordschleife" of the Nürburgring again became the main venue for the German Grand Prix as part of the Formula One World Championship (with the exception of 1959, when it was held on the AVUS in Berlin). A new group of "Ringmeister" arose to dominate the race – Alberto Ascari, Juan Manuel Fangio, Stirling Moss, Jim Clark, John Surtees, Jackie Stewart and Jacky Ickx.

On 5 August 1961, during practice for the 1961 German Grand Prix, Phil Hill became the first person to complete a lap of the "Nordschleife" in under 9 minutes, with a lap of 8 minutes 55.2 seconds (153.4 km/h or 95.3 mph) in the Ferrari 156 "Sharknose" Formula One car. Over half a century later, even the highest performing road cars still have difficulty breaking 8 minutes without a professional race driver or one very familiar with the track. Also, several rounds of the German motorcycle Grand Prix were held, mostly on the "Südschleife", but the Hockenheimring and the Solitudering were the main sites for Grand Prix motorcycle racing.

In 1953, the ADAC 1000 km Nürburgring race was introduced, an Endurance race and Sports car racing event that counted towards the World Sportscar Championship for decades. The 24 Hours Nürburgring for touring car racing was added in 1970.

By the late 1960s, the "Nordschleife" and many other tracks were becoming increasingly dangerous for the latest generation of F1 cars. In 1967, a chicane was added before the start/finish straight, called "Hohenrain", in order to reduce speeds at the pit lane entry. This made the track longer. Even this change, however, was not enough to keep Stewart from nicknaming it "The Green Hell" following his victory in the 1968 German Grand Prix amid a driving rainstorm and thick fog. In 1970, after the fatal crash of Piers Courage at Zandvoort, the F1 drivers decided at the French Grand Prix to boycott the Nürburgring unless major changes were made, as they did at Spa the year before. The changes were not possible on short notice, and the German GP was moved to the Hockenheimring, which had already been modified.

In accordance with the demands of the F1 drivers, the "Nordschleife" was reconstructed by taking out some bumps, smoothing out some sudden jumps (particularly at Brünnchen), and installing Armco safety barriers. The track was made straighter, following the race line, which reduced the number of corners. The German GP could be hosted at the Nürburgring again, and was for another six years from 1971 to 1976.

In 1973 the entrance into the dangerous and bumpy Kallenhard corner was made slower by adding another left-hand corner after the fast Metzgesfeld sweeping corner. Safety was improved again later on, e.g. by removing the jumps on the long main straight and widening it, and taking away the bushes right next to the track at the main straight, which had made that section of the Nürburgring dangerously narrow. A second series of three more F1 races was held until 1976. However, primarily due to its length of over , and the lack of space due to its situation on the sides of the mountains, increasing demands by the F1 drivers and the FIA's CSI commission were too expensive or impossible to meet. For instance, by the 1970s the German Grand Prix required five times the marshals and medical staff as a typical F1 race, something the German organizers were unwilling to provide. Additionally, even with the 1971 modifications it was still possible for cars to become airborne off the track. The Nürburgring was also unsuitable for the burgeoning television market; its vast expanse made it almost impossible to effectively cover a race there. As a result, early in the season it was decided that the 1976 race would be the last to be held on the old circuit.

Niki Lauda, the reigning world champion and only person ever to lap the full "Nordschleife" in under seven minutes (6:58.6, 1975), proposed to the other drivers that they boycott the circuit in 1976. Lauda was not only concerned about the safety arrangements and the lack of marshals around the circuit, he also did not like the prospect of running the race in another rainstorm. Usually when that happened, some parts of the circuit were wet and other parts were dry, which is what the conditions of the circuit were for that race. The other drivers voted against the idea and the race went ahead. Lauda crashed in his Ferrari coming out of the left-hand kink before Bergwerk after a new magnesium component on his Ferrari's rear suspension failed. He was badly burned as his car was still loaded with fuel in lap 2. Lauda was saved by the combined actions of fellow drivers Arturo Merzario, Guy Edwards, Brett Lunger, and Harald Ertl, rather than by the ill-equipped track marshals.

The crash also showed that the track's distances were too long for regular fire engines and ambulances, even though the "ONS-Staffel" was equipped with a Porsche 911 rescue car, marked (R). The old Nürburgring never hosted another F1 race again, as the German Grand Prix was moved to the Hockenheimring for 1977. The German motorcycle Grand Prix was held for the last time on the old Nürburgring in 1980, also permanently moving to Hockenheim.

By its very nature, the "Nordschleife" was impossible to make safe in its old configuration. It soon became apparent that it would have to be completely overhauled if there was any prospect of Formula One returning there- the Nurburgring's administration and race organizers were not willing to provide the enormous expense of providing the amount of marshals needed for a Grand Prix- up to 6 times the amount that most other circuits needed. With this in mind, in 1981 work began on a -long new circuit, which was built on and around the old pit area.

At the same time, a bypass shortened the "Nordschleife" to , and with an additional small pit lane, this version was used for races in 1983, e.g. the 1000km Nürburgring endurance race, while construction work was going on nearby. During qualifying for that race, the late Stefan Bellof set a lap of 6:11.13 for the "Nordschleife" in his Porsche 956, or on average. This lap held the all-time record for 35 years (partially because no major racing has taken place there since 1984) until it was surpassed by Timo Bernhard in the Porsche 919 Hybrid Evo, which ran the slightly longer version of the circuit in 5:19.546- averaging on June 29, 2018.

Meanwhile, more run-off areas were added at corners like Aremberg and Brünnchen, where originally there were just embankments protected by Armco barriers. The track surface was made safer in some spots where there had been nasty bumps and jumps. Racing line markers were added to the corners all around the track as well. Also, bushes and hedges at the edges of corners were taken out and replaced with Armco and grass. 

The former "Südschleife" had not been modified in 1970/71 and was abandoned a few years later in favour of the improved "Nordschleife". It is now mostly gone (in part due to the construction of the new circuit) or converted to a normal public road, but since 2005 a vintage car event has been hosted on the old track layout, including part of the parking area.

The new track was completed in 1984 and named "GP-Strecke" (: literally, ""Grand Prix Course""). It was built to meet the highest safety standards. 
However, it was considered in character a mere shadow of its older sibling. Some fans, who had to sit much farther away from the track, called it "Eifelring", "Ersatzring", "Grünering" or similar nicknames, believing it did not deserve to be called Nürburgring. Like many circuits of the time, it offered few overtaking opportunities.

Prior to the 2013 German Grand Prix both Mark Webber and Lewis Hamilton said they like the track. Webber described the layout as "an old school track" before adding, "It’s a beautiful little circuit for us to still drive on so I think all the guys enjoy driving here." While Hamilton said "It’s a fantastic circuit, one of the classics and it hasn’t lost that feel of an old classic circuit."

To celebrate its opening, an exhibition race was held, on 12 May, featuring an array of notable drivers. Driving identical Mercedes 190E 2.3–16's, the line-up was Elio de Angelis, Jack Brabham (Formula 1 World Champion 1959, 1960, 1966), Phil Hill (1961), Denis Hulme (1967), James Hunt (1976), Alan Jones (1980), Jacques Laffite, Niki Lauda (1975, 1977)*, Stirling Moss, Alain Prost*, Carlos Reutemann, Keke Rosberg (1982), Jody Scheckter (1979), Ayrton Senna*, John Surtees (1964) and John Watson. Senna won ahead of Lauda, Reutemann, Rosberg, Watson, Hulme and Jody Scheckter, being the only one to resist Lauda's performance who – having missed the qualifying – had to start from the last row and overtook all the others except Senna. There were nine former and two future Formula 1 World Champions competing, in a field of 20 cars with 16 Formula 1 drivers; the other four were local drivers: Klaus Ludwig, Manfred Schurti, Udo Schütz and Hans Herrmann.

Besides other major international events, the Nürburgring has seen the brief return of Formula One racing, as the 1984 European Grand Prix was held at the track, followed by the 1985 German Grand Prix. As F1 did not stay, other events were the highlights at the new Nürburgring, including the 1000km Nürburgring, DTM, motorcycles, and newer types of events, like truck racing, vintage car racing at the AvD "Oldtimer Grand Prix", and even the "Rock am Ring" concerts.

Following the success and first world championship of Michael Schumacher, a second German F1 race was held at the Nürburgring between 1995 and 2006, called the European Grand Prix, or in 1997 and 1998, the Luxembourg Grand Prix.

For 2002, the track was changed, by replacing the former "Castrol-chicane" at the end of the start/finish straight with a sharp right-hander (nicknamed "Haug-Hook"), in order to create an overtaking opportunity. Also, a slow Omega-shaped section was inserted, on the site of the former kart track. This extended the GP track from , while at the same time, the Hockenheimring was shortened from .

Both the Nürburgring and the Hockenheimring events have been losing money due to high and rising Formula One license fees charged by Bernie Ecclestone and low attendance due to high ticket prices; starting with the 2007 Formula One season, Hockenheim and Nürburgring will alternate for hosting of the German GP.

In Formula One, Ralf Schumacher collided with his teammate Giancarlo Fisichella and his brother at the start of the 1997 race which was won by Jacques Villeneuve. In 1999, in changing conditions, Johnny Herbert managed to score the only win for the team of former "Ringmeister" Jackie Stewart. One of the highlights of the 2005 season was Kimi Räikkönen's spectacular exit while in the last lap of the race, when his suspension gave way after being rattled lap after lap by a flat-spotted tyre that was not changed due to the short-lived rule.

Prior to the 2007 European Grand Prix, the "Audi S" (turns 8 and 9) was renamed "Michael Schumacher S" after Michael Schumacher. Schumacher had retired from Formula One the year before, but returned in 2010, and in 2011 became the second Formula One driver to drive through a turn named after them (after Ayrton Senna driving his "S for Senna" at Autódromo José Carlos Pace).

In 2007, the FIA announced that Hockenheimring and Nürburgring would alternate with the German Grand Prix with Nürburgring hosting in 2007. Due to name-licensing problems, it was held as the European Grand Prix that year. In 2014, the new owners of the Nürburgring were unable to secure a deal to continue hosting the German Grand Prix in the odd numbered years, so the 2015 and 2017 German Grands Prix were cancelled.

In July 2020, it was announced that after seven years, the race track would be an official Formula One Grand Prix with the event taking place from 9 to 11 October 2020. This race will be called the Eifel Grand Prix in honour of the nearby mountain range meaning the venue will hold a Grand Prix under a fourth different name having hosted races under the German, European and Luxembourg Grands Prix titles previously.

While it is unusual for deaths to occur during sanctioned races, there are many accidents and several deaths each year during public sessions. It is common for the track to be closed several times a day for cleanup, repair, and medical intervention. While track management does not publish any official figures, several regular visitors to the track have used police reports to estimate the number of fatalities at somewhere between 3 and 12 in a full year. Jeremy Clarkson noted in "Top Gear" in 2004 that "over the years this track has claimed over 200 lives".

Several touring car series still compete on the "Nordschleife", using either only the simple version with its separate small pit lane, or a combined -long track that uses a part of the original modern F1 track (without the Mercedes Arena section, which is often used for support pits) plus its huge pit facilities. Entry-level competition requires a regularity test (GLP) for street-legal cars. Two racing series (RCN/CHC and VLN) compete on 15 Saturdays each year, for several hours.

The annual highlight is the 24 Hours Nürburgring weekend, held usually in mid-May, featuring 220 cars – from small cars to Turbo Porsches or factory race cars built by BMW, Opel, Audi, and Mercedes-Benz, over 700 drivers (amateurs and professionals), and up to 290,000 spectators.

As of 2015 the World Touring Car Championship holds the FIA WTCC Race of Germany at the Nordschleife as a support category to the 24 Hours.

Automotive media outlets and manufacturers use the "Nordschleife" as a standard to publish their lap times achieved with their production vehicles.

BMW Sauber’s Nick Heidfeld made history on 28 April 2007 as the first driver in over thirty years to tackle the Nürburgring "Nordschleife" track in a contemporary Formula One car. Heidfeld’s three laps in an F1.06 were part of festivities celebrating BMW’s contribution to motorsport. About 45,000 spectators showed up for the main event, the third four-hour VLN race of the season. Conceived largely as a photo opportunity, the lap times were not as fast as the car was capable of, BMW instead choosing to run the chassis at a particularly high ride height to allow for the "Nordschleife"'s abrupt gradient changes and to limit maximum speeds accordingly. Former F1 driver Hans-Joachim Stuck was injured during the race when he crashed his BMW Z4.

As part of the festivities before the 2013 24 Hours Nürburgring race, Michael Schumacher and other Mercedes-Benz drivers took part in a promotional event which saw Schumacher complete a demonstration lap of the Nordschleife at the wheel of a 2011 Mercedes W02. As with Heidfeld's lap, and also partly due to Formula One's strict in-season testing bans, the lap left many motorsport fans underwhelmed.

Since its opening in 1927, the track has been used by the public for the so-called "Touristenfahrten", i.e. anyone with a road-legal car or motorcycle, as well as tour buses, motor homes, or cars with trailers. It is opened every day of the week, except when races take place. The track may be closed for weeks during the winter months, depending on weather conditions and maintenance work. Passing on the right is prohibited, and some sections have speed limits; the normal traffic rules (StVO in German) apply also here.

The Nürburgring is a popular attraction for many driving enthusiasts and riders from all over the world, partly because of its history and the challenge it provides. The lack of oncoming traffic and intersections sets it apart from regular roads, and the absence of a blanket speed limit is a further attraction.

Normal ticket buyers on tourist days cannot quite complete a full lap of the "Nordschleife", which bypasses the modern "GP-Strecke", as they are required to slow down and pass through a "pit lane" section where toll gates are installed. On busier days, a mobile ticket barrier is installed on the main straight in order to reduce the length of queues at the fixed barriers. This is open to all ticket holders. On rare occasions, it is possible to drive both the "Nordschleife" and the Grand Prix circuit combined.

Drivers interested in lap times often time themselves from the first bridge after the barriers to the last gantry (aka Bridge-to-Gantry or BTG time) before the exit. However, the track's general conditions state that any form of racing, including speed record attempts, is forbidden. The driver's insurance coverage may consequently be voided, leaving the driver fully liable for damage. Normal, non-racing, non-timed driving accidents might be covered by driver's insurance, but it is increasingly common for UK insurers especially to insert exclusion clauses that mean drivers and riders on the Nürburgring only have third-party coverage or are not covered at all.

Drivers who have crashed into the barriers, suffered mechanical failure or been otherwise required to be towed off track during "Touristenfahrten" sessions are referred to as having joined the "Bongard Club". This nickname is derived from the name of the company which operates the large yellow recovery flatbed trucks which ferry those unfortunate drivers and their vehicles to the nearest exit. Due to the high volume of traffic, there is an emphasis on quickly clearing and repairing any compromised safety measures so the track can be immediately re-opened for use.

Additionally, those found responsible for damage to the track or safety barriers are required to pay for repairs, along with the time and cost associated with personnel and equipment to address those damages, making any accident or breakdown a potentially expensive incident. Because it is technically operated as a public toll road, failing to report an accident or instance where track surfaces are affected is considered unlawfully leaving the scene of an accident. This is all part of the rules and regulations which aim to ensure a safe experience for all visitors to the track.

One of the original purposes of the "Nordschleife" was as a test track for auto manufacturers, and its demanding layout had been traditionally used as a proving ground. Weekdays are often booked for so-called "Industriefahrten" for auto makers and the media. With the advent of the Internet, awareness of the "Nordschleife" has risen in Germany and abroad, in addition to publicity in print media. In 1999, Porsche reported that their new 996 GT3 had lapped the Nürburgring in under eight minutes, and in subsequent years, manufacturers from overseas also showed up to test cars. Some high-performance models are promoted with videotaped laps published on the web, and the claimed lap times are generating discussion. Few of these supercars are actually entered in racing where the claims could be backed up.

For sixteen weeks per year, the industry pool () rents exclusive daytime use of the track for automotive development, and endurance testing. the industry pool consisted of approximately 30 car manufacturers, associations, and component suppliers. By 2019, the track was being rented by the industry pool for 18 weeks per year.

The TV Series "Top Gear" has also used the "Nordschleife" for its challenges, often involving Sabine Schmitz. In addition, during series 17 (summer 2011) of Top Gear, James May was very critical of the ride quality of cars whose development processes included testing on the "Nordschleife", saying that cars which were tested at Nordschleife got ruined.

Multiple layouts of the Nürburgring have been featured in video games, such as the "Gran Turismo" series, the "Forza Motorsport" series, "iRacing" and "Assetto Corsa". "Grand Prix Legends", a historic racing simulator also included the Nürburgring on its roster of default Grand Prix tracks.

Other pastimes are hosted at the Nürburgring, such as the Rock am Ring, Germany's biggest rock music festival, attracting close to 100,000 rock fans each year since 1985. Since 1978, the "Nordschleife" is also the venue of a major running event ("Nürburgring-Lauf/Run am Ring"). In 2003, a major bicycling event ("Rad am Ring") was added and it became the multi-sports event "Rad & Run am Ring".

In 2009, new commercial areas opened, including a hotel and shopping mall. In the summer of 2009, ETF Ride Systems opened a new interactive dark ride application called "Motor Mania" at the racetrack, in collaboration with Lagotronics B.V. The roller coaster "ring°racer" was scheduled to open in 2011 but never started its operations due to technical failures.

In 2012, the track was preparing to file for bankruptcy as a result of nearly $500 million in debts and the inability to secure financing. On 1 August 2012, the government of Rheinland-Pfalz guaranteed $312 million to allow the track to meet its debt obligations.

In 2013, the Nürburgring was for sale for US$165 million (€127.3 million). The sale process was by sealed-bid auction with an expected completion date of "Late Summer". This meant there was to be a new owner in 2013, unencumbered by the debts of the previous operation, with the circuit expected to return to profitability.

On March 11, 2014 it was reported that the Nürburgring was sold for 77 million euros ($106.8 million). Düsseldorf-based Capricorn Development was the buyer. The company was to take full ownership of the Nürburgring on January 1, 2015. But in October 2014, Russian billionaire, the chairman of Moscow-based Pharmstandard, Viktor Kharitonin, bought a majority stake in the Nürburgring.

In May 2015, the Nürburgring was set to hold the first Grüne Hölle Rock festival as a replacement for the Rock am Ring festival, but the project did not take place. Grüne Hölle Rock has changed their name to Rock im Revier and will be held in the Schalke area.

The "Nordschleife" operates in a clockwise direction, and was formerly known for its abundance of sharp crests, causing fast-moving, firmly-sprung racing cars to jump clear off the track surface at many locations.

Although by no means the most fearsome, "Flugplatz" is perhaps the most aptly (although coincidentally) named and widely remembered. The name of this part of the track comes from a small airfield, which in the early years was located close to the track in this area. The track features a very short straight that climbs sharply uphill for a short time, then suddenly drops slightly downhill, and this is immediately followed by two very fast right-hand kinks. Chris Irwin's career was ended following a massive accident at "Flugplatz", in a Ford 3L GT sports car in 1968. Manfred Winkelhock flipped his March Formula Two car at the same corner in 1980. This section of the track was renovated in 2016 after an accident in which a Nissan GTR flew over the fence and killed a spectator. The "Flugplatz" is one of the most important parts of the Nürburgring because after the two very fast right handers comes what is possibly the fastest part of the track: a downhill straight called "Kottenborn", into a very fast curve called "Schwedenkreuz" (Swedish Cross). Drivers are flat out for some time here.

Right before "Flugplatz" is "Quiddelbacher-Höhe" (peak, as in "mountain summit"), where the track crosses a bridge over the Bundesstraße 257.

The "Fuchsröhre" is soon after the very fast downhill section succeeding the "Flugplatz". After negotiating a long right hand corner called "Aremberg" (which is after "Schwedenkreuz") the road goes slightly uphill, under a bridge and then it plunges downhill, and the road switches back left and right and finding a point of reference for the racing line is difficult. This whole sequence is flat out and then, the road climbs sharply uphill. The road then turns left and levels out at the same time; this is one of the many jumps of the Nürburgring where the car goes airborne. This leads to the "Adenauer Forst" (forest) turns. The "Fuchsröhre" is one of the fastest and most dangerous parts of the Nürburgring because of the extremely high speeds in such a tight and confined place; this part of the Nürburgring goes right through a forest and there is only about 7–8 feet of grass separating the track from Armco barrier, and beyond the barriers is a wall of trees.

Perhaps the most notorious corner on the long circuit, "Bergwerk" has been responsible for some serious and sometimes fatal accidents. A tight right-hand corner, coming just after a long, fast section and a left-hand kink on a small crest, was where Carel Godin de Beaufort fatally crashed. The fast kink was also the scene of Niki Lauda's infamous fiery accident during the 1976 German Grand Prix. This left kink is often referred to as the "Lauda Links" (Lauda left). The "Bergwerk", along with the "Breidscheid"/"Adenauer" Bridge corners before it, are one of the series of corners that make or break one's lap time around the Nürburgring because of the fast, lengthy uphill section called "Kesselchen" (Little Valley) that comes after the "Bergwerk".

Although being one of the slower corners on the "Nordschleife", the "Karussell" is perhaps its most famous and one of its most iconic- it is one of two berm-style, banked corners on the track. Soon after the driver has negotiated the long uphill section after "Bergwerk" and gone through a section called "Klostertal" (Monastery Valley), the driver turns right through a long hairpin, past an abandoned section called "Steilstrecke" (Steep Route) and then goes up another hill towards the "Karrusell". The entrance to the corner is blind, although Juan Manuel Fangio is reputed to have advised a young driver to "aim for the tallest tree," a feature that was also built into the rendering of the circuit in the "Gran Turismo 4" and "Grand Prix Legends" video games. Once the driver has reached the top of the hill, the road then becomes sharply banked on one side and level on the other- this banking drops off, rather than climbing up like most bankings on circuits. The sharply banked side has a concrete surface, and there is a foot-wide tarmac surface on the bottom of the banking for cars to get extra grip through the very rough concrete banking. Cars drop into the concrete banking, and keep the car in the corner (which is 210 degrees, much like a hairpin bend) until the road levels out and the concrete surface becomes tarmac again. This corner is very hard on the driver's wrists and hands because of the prolonged bumpy cornering the driver must do while in the "Karrusell". Usually cars come out of the top of the end of the banking to hit the apex that comes right after the end of the "Karrusell".

The combination of a recognisable corner, slow-moving cars, and the variation in viewing angle as cars rotate around the banking, means that this is one of the circuit's most popular locations for photographers. It is named after German pre-WWII racing driver Rudolf Caracciola, who reportedly made the corner his own by hooking the inside tires into a drainage ditch to help his car "hug" the curve. As more concrete was uncovered and more competitors copied him, the trend took hold. At a later reconstruction, the corner was remade with real concrete banking, as it remains to this day.

Shortly after the "Karussell" is a steep section, with gradients in excess of 16%, leading to a right-hander called "Hohe Acht", which is some 300 m higher in altitude than "Breidscheid".

A favourite spectator vantage point, the "Brünnchen" section is composed of two right-hand corners and a very short straight. The first corner goes sharply downhill and the next, after the very short downhill straight, goes uphill slightly. This is a section of the track where on public days, accidents happen particularly at the blind uphill right-hand corner. Like almost every corner at the Nürburgring, both right-handers are blind. The short straight used to have a steep and sudden drop-off that caused cars to take off and a bridge that went over a pathway; these were taken out and smoothed over when the circuit was rebuilt in 1970 and 1971.

The "Pflanzgarten", which is soon after the "Brünnchen", is one of the fastest, trickiest and most difficult sections of the Nürburgring. It is full of jumps, including two huge ones, one of which is called "Sprunghügel" (Hill Jump). This very complex section is unique in that it is made up of two different sections; getting the entire "Pflanzgarten" right is crucial to a good lap time around the Nürburgring. This section was the scene of Briton Peter Collins's fatal accident during the 1958 German Grand Prix, and the scene of a number of career-ending accidents in Formula One in the 1970s —Britons Mike Hailwood and Ian Ashley were two victims of the Pflanzgarten.

"Pflanzgarten 1" is made up of a slightly banked, downhill left hander which then suddenly switches back left, then right. Then immediately, giving the driver nearly no time to react (knowledge of this section is key) the road drops away twice: the first jump is only slight, then right after (somewhat like a staircase) the road drops away very sharply which usually causes almost all cars to go airborne at this jump; the drop is so sudden. Then, immediately after the road levels out very shortly after the jump and the car touches the ground again, the road immediately and suddenly goes right very quickly and then right again; this is what makes up the end of the first "Pflanzgarten"- a very fast multiple apex sequence of right hand corners.

The road then goes slightly uphill and then through another jump; the road suddenly drops away and levels out and at the same time, the road turns through a flat-out left hander. Then, the road drops away again very suddenly, which is the second huge jump of the "Pflanzgarten" known as the "Sprunghügel". The road then goes downhill then quickly levels out, then it goes through a flat-out right hander and this starts the "Stefan Bellof S" (named as such because Bellof crashed a Porsche 956 there during the 1983 Nurburgring 1000 km), which was known as "Pflanzgarten 2" prior to 2013. The "Stefan Bellof S" is very tricky because the road quickly switches back left and right—a car is going so fast through here that it is like walking on a tightrope. It is very difficult to find the racing line here because the curves come up so quickly, so it is hard to find any point of reference. Then, after a jump at the end of the switchback section, it goes through a flat-out, top gear right hander and into a short straight that leads into two very fast curves called the "Schwalbenschwanz" (Swallow's Tail).

The room for error on every part of the consistently high-speed "Pflanzgarten" and the "Stefan Bellof S" is virtually non-existent (much like the entire track itself). The road and the surface of the "Pflanzgarten" and the "Stefan Bellof S" moves around unpredictably; knowledge of this section is key to getting through cleanly.

The "Schwalbenschwanz" is a sequence of very fast sweepers located after the "Stefan Bellof S". After a short straight, there is a very fast right hand sweeper that progressively goes uphill, and this leads into a blind left-hander that is a bit slower. The apex is completely blind, and the corner then changes gradient a bit; it goes up then down, which leads into a short straight that ends at the "Kleines Karussell". Originally, this part had a bridge that went over a stream and was very bumpy; this bridge was taken out and replaced with a culvert (large industrial pipe) so that the road could be smoothed over.

The "Kleines Karussell" is similar to its bigger brother, except that it is a 90 degree corner instead of 210 degrees, and is faster and slightly less banked. Once this part of the track is dealt with, the drivers are near the end of the lap; with two more corners to negotiate before the 2.135 km long "Döttinger Höhe" straight.

Lap times recorded on the Nürburgring "Nordschleife" are published by several manufacturers. They are published and discussed in print media, and online.


The Nürburgring is known for its changeable weather. The near-fatal accident of Niki Lauda in 1976 was accompanied by poor weather conditions and also the 2007 Grand Prix race saw an early deluge take several cars out through aquaplaning, with Vitantonio Liuzzi making a lucky escape, hitting a retrieving truck with the rear wing first, rather than the fatal accident that befell Jules Bianchi seven years later at Suzuka. In spite of this reputation, the Nürburg weather station only recorded an average of between 1981–2010. Contrasting this, the relatively nearby Ardennes racetrack of Spa-Francorchamps in Wallonia, Belgium has a much rainier climate, seen by data from the village hosting the track called Stavelot and the village of Malmedy that circuit passes by.

Nürburg has a semi-continental climate with both oceanic and continental tendencies. It does however land in the former category (Köppen "Cfb"). Due to the Nordschleife's varied terrain and elevation, weather may be completely different on either end of the track. The elevation shift also makes thermal differences a strong possibility. The modern Grand Prix circuit also has sizeable elevation changes between the start-finish straight and the lowest point on the opposite end of the track, but the geographical distance and actual elevation gain between the two are lower. Annual sunshine is in the 1500s, which is low by European standards, but only slightly gloomier than the nearest large city of Cologne located on a plain. Contrasting that, Nürburg has cooler weather year round due to the higher elevation of the Eifel Mountains than the Rhine Valley.














</doc>
<doc id="22126" url="https://en.wikipedia.org/wiki?curid=22126" title="Northern Hemisphere">
Northern Hemisphere

The Northern Hemisphere is the half of Earth that is north of the Equator. For other planets in the Solar System, north is defined as being in the same celestial hemisphere relative to the invariable plane of the solar system as Earth's North Pole.

Owing to the Earth's axial tilt, winter in the Northern Hemisphere lasts from the December solstice (typically December 21 UTC) to the March equinox (typically March 20 UTC), while summer lasts from the June solstice through to the September equinox (typically on 23 September UTC). The dates vary each year due to the difference between the calendar year and the astronomical year.

Its surface is 60.7% water, compared with 80.9% water in the case of the Southern Hemisphere, and it contains 67.3% of Earth's land.

The Arctic is a region around the North Pole (90° latitude). Its climate is characterized by cold winters and cool summers. Precipitation mostly comes in the form of snow. Areas inside the Arctic Circle (66°34′ latitude) experience some days in summer when the Sun never sets, and some days during the winter when it never rises. The duration of these phases varies from one day for locations right on the Arctic Circle to several months near the Pole, which is the middle of the Northern Hemisphere.

Between the Arctic Circle and the Tropic of Cancer (23°26′ latitude) lies the Northern temperate zone. The changes in these regions between summer and winter are generally mild, rather than extreme hot or cold. However, a temperate climate can have very unpredictable weather.

Tropical regions (between the Tropic of Cancer and the Equator, 0° latitude) are generally hot all year round and tend to experience a rainy season during the summer months, and a dry season during the winter months.

In the Northern Hemisphere, objects moving across or above the surface of the Earth tend to turn to the right because of the Coriolis effect. As a result, large-scale horizontal flows of air or water tend to form clockwise-turning gyres. These are best seen in ocean circulation patterns in the North Atlantic and North Pacific oceans.

For the same reason, flows of air down toward the northern surface of the Earth tend to spread across the surface in a clockwise pattern. Thus, clockwise air circulation is characteristic of high pressure weather cells in the Northern Hemisphere. Conversely, air rising from the northern surface of the Earth (creating a region of low pressure) tends to draw air toward it in a counter-clockwise pattern. Hurricanes and tropical storms (massive low-pressure systems) spin counter-clockwise in the Northern Hemisphere.

The shadow of a sundial moves clockwise on latitudes north of the subsolar point. During the day on these latitudes, the Sun tends to rise to its maximum at a southerly position. Between the Tropic of Cancer and the Equator, the sun can be seen to the north, directly overhead, or to the south at noon dependent on the time of year. In the Southern Hemisphere the midday Sun is predominantly at north.

When viewed from the Northern Hemisphere, the Moon appears inverted compared to a view from the Southern Hemisphere. The North Pole faces away from the galactic center of the Milky Way. This results in the Milky Way being sparser and dimmer in the Northern Hemisphere compared to the Southern Hemisphere, making the Northern Hemisphere more suitable for deep-space observation, as it is not "blinded" by the Milky Way.

The Northern Hemisphere is home to approximately 6.57 billion people which is around 90% of the earth's total human population of 7.3 billion people.

Earth's Northern Hemisphere comprises the following regions of continents:




</doc>
<doc id="22130" url="https://en.wikipedia.org/wiki?curid=22130" title="Noun class">
Noun class

In linguistics, a noun class is a particular category of nouns. A noun may belong to a given class because of the characteristic features of its referent, such as gender, animacy, shape, but such designations are often clearly conventional. Some authors use the term "grammatical gender" as a synonym of "noun class", but others consider these different concepts. Noun classes should not be confused with noun classifiers.

There are three main ways by which natural languages categorize nouns into noun classes:
Usually, a combination of the three types of criteria is used, though one is more prevalent.

Noun classes form a system of grammatical agreement. A noun in a given class may require:

In Modern English, countable and uncountable nouns are distinguished by the choice of "many"/"much". The choice between the relative pronoun "who" (persons) and "which" (non-persons) may also be considered a form of agreement with a semantic noun class. A few nouns also exhibit vestigial noun classes, such as "stewardess", where the suffix "-ess" added to "steward" denotes a female person. This type of noun affixation is not very frequent in English, but quite common in languages which have the true grammatical gender, including most of the Indo-European family, to which English belongs. 

When noun class is expressed on other parts of speech in addition to nouns and pronouns, the language is said to have grammatical gender.

In languages without inflectional noun classes, nouns may still be extensively categorized by independent particles called noun classifiers.

Common criteria that define noun classes include:


See Swahili for the semantic motivations for an elaborate noun-class system.

The Ojibwe language and other members of the Algonquian languages distinguish between animate and inanimate classes. Some sources argue that the distinction is between things which are powerful and things which are not. All living things, as well as sacred things and things connected to the Earth are considered powerful and belong to the animate class. Still, the assignment is somewhat arbitrary, as "raspberry" is animate, but "strawberry" is inanimate.

In Navajo (Southern Athabaskan) nouns are classified according to their animacy, shape, and consistency. Morphologically, however, the distinctions are not expressed on the nouns themselves, but on the verbs of which the nouns are the subject or direct object. For example, in the sentence ' "My shirt is lying on the bed", the verb "lies" is used because the subject ' "my shirt" is a flat, flexible object. In the sentence "My belt is lying on the bed", the verb ' "lies" is used because the subject ' "my belt" is a slender, flexible object.

Koyukon (Northern Athabaskan) has a more intricate system of classification. Like Navajo, it has classificatory verb stems that classify nouns according to animacy, shape, and consistency. However, in addition to these verb stems, Koyukon verbs have what are called "gender prefixes" that further classify nouns. That is, Koyukon has two different systems that classify nouns: (a) a classificatory verb system and (b) a gender system. To illustrate, the verb stem "-tonh" is used for enclosed objects. When "-tonh" is combined with different gender prefixes, it can result in "daaltonh" which refers to objects enclosed in boxes or "etltonh" which refers to objects enclosed in bags.

The Dyirbal language is well known for its system of four noun classes, which tend to be divided along the following semantic lines:

The class usually labeled "feminine", for instance, includes the word for fire and nouns relating to fire, as well as all dangerous creatures and phenomena. (This inspired the title of the George Lakoff book "Women, Fire, and Dangerous Things".)

The Ngangikurrunggurr language has noun classes reserved for canines and hunting weapons. The Anindilyakwa language has a noun class for things that reflect light. The Diyari language distinguishes only between female and other objects. Perhaps the most noun classes in any Australian language are found in Yanyuwa, which has 16 noun classes, including nouns associated with food, trees and abstractions, in addition to separate classes for men and masculine things, women and feminine things. In the men's dialect, the classes for men and for masculine things have simplified to a single class, marked the same way as the women's dialect marker reserved exclusively for men.

In Basque there are two classes, animate and inanimate; however, the only difference is in the declension of locative cases (inessive, locative genitive, allative, terminal allative, ablative and directional ablative). There are a few words with both masculine and feminine forms, generally words for relatives (cousin: lehengusu (m)/lehengusina (f)) or words borrowed from Latin ("king": "errege", from the Latin word "rex"; "queen": "erregina", from "regina"). In names for familiar relatives, where both genders are taken into account, either the words for each gender are put together ("son": "seme"; "daughter": "alaba"; "children"(meaning son(s) and daughter(s)): "seme-alaba(k)") or there is a noun that includes both: "father": "aita"; "mother": "ama"; "parent": "guraso".

Some members of the Northwest Caucasian family, and almost all of the Northeast Caucasian languages, manifest noun class. In the Northeast Caucasian family, only Lezgian, Udi, and Aghul do not have noun classes. Some languages have only two classes, whereas Bats has eight. The most widespread system, however, has four classes: male, female, animate beings and certain objects, and finally a class for the remaining nouns. The Andi language has a noun class reserved for insects.

Among Northwest Caucasian languages, only Abkhaz and Abaza have noun class, making use of a human male/human female/non-human distinction.

In all Caucasian languages that manifest class, it is not marked on the noun itself but on the dependent verbs, adjectives, pronouns and prepositions.

Atlantic–Congo languages can have ten or more noun classes, defined according to non-sexual criteria. Certain nominal classes are reserved for humans. The Fula language has about 26 noun classes (exact number varies slightly by dialect). According to Steven Pinker, the Kivunjo language has 16 noun classes including classes for precise locations and for general locales, classes for clusters or pairs of objects and classes for the objects that come in pairs or clusters, and classes for abstract qualities.

According to Carl Meinhof, the Bantu languages have a total of 22 noun classes called nominal classes (this notion was introduced by W. H. J. Bleek). While no single language is known to express all of them, most of them have at least 10 noun classes. For example, by Meinhof's numbering, Shona has 20 classes, Swahili has 15, Sotho has 18 and Ganda has 17.

Additionally, there are polyplural noun classes. A polyplural noun class is a plural class for more than one singular class. For example, Proto-Bantu class 10 contains plurals of class 9 nouns and class 11 nouns, while class 6 contains plurals of class 5 nouns and class 15 nouns. Classes 6 and 10 are inherited as polyplural classes by most surviving Bantu languages, but many languages have developed new polyplural classes that are not widely shared by other languages.

Specialists in Bantu emphasize that there is a clear difference between genders (such as known from Afro-Asiatic and Indo-European) and nominal classes (such as known from Niger–Congo). Languages with nominal classes divide nouns formally on the base of hyperonymic meanings. The category of nominal class replaces not only the category of gender, but also the categories of number and case.

Critics of the Meinhof's approach notice that his numbering system of nominal classes counts singular and plural numbers of the same noun as belonging to separate classes. This seems to them to be inconsistent with the way other languages are traditionally considered, where number is orthogonal to gender (according to the critics, a Meinhof-style analysis would give Ancient Greek 9 genders). If one follows broader linguistic tradition and counts singular and plural as belonging to the same class, then Swahili has 8 or 9 noun classes, Sotho has 11 and Ganda has 10.

The Meinhof numbering tends to be used in scientific works dealing with comparisons of different Bantu languages. For instance, in Swahili the word "rafiki" ‘friend’ belongs to the class 9 and its "plural form" is "marafiki" of the class 6, even if most nouns of the 9 class have the plural of the class 10. For this reason, noun classes are often referred to by combining their singular and plural forms, e.g., "rafiki" would be classified as "9/6", indicating that it takes class 9 in the singular, and class 6 in the plural.

However not all Bantu languages have these exceptions. In Ganda each singular class has a corresponding plural class (apart from one class which has no singular–plural distinction; also some plural classes correspond to more than one singular class) and there are no exceptions as there are in Swahili. For this reason Ganda linguists use the orthogonal numbering system when discussing Ganda grammar (other than in the context of Bantu comparative linguistics), giving the 10 traditional noun classes of that language.

The distinction between genders and nominal classes is blurred still further by Indo-European languages that have nouns that behave like Swahili's "rafiki". Italian, for example, has a group of nouns deriving from Latin neuter nouns that acts as masculine in the singular but feminine in the plural: "il braccio"/"le braccia"; "l'uovo"/"le uova". (These nouns are still placed in a neuter gender of their own by some grammarians.)

Here is a complete list of nominal classes in Swahili:

"Ø-" means no prefix. Some classes are homonymous (esp. 9 and 10). The Proto-Bantu class 12 disappeared in Swahili, class 13 merged with 7, and 14 with 11.

Class prefixes appear also on adjectives and verbs, e.g.:

The class markers which appear on the adjectives and verbs may differ from the noun prefixes: 

In this example, the verbal prefix a- and the pronominal prefix wa- are in concordance with the noun prefix m-: they all express class 1 despite of their different forms.

The Zande language distinguishes four noun classes:

There are about 80 inanimate nouns which are in the animate class, including nouns denoting heavenly objects (moon, rainbow), metal objects (hammer, ring), edible plants (sweet potato, pea), and non-metallic objects (whistle, ball). Many of the exceptions have a round shape, and some can be explained by the role they play in Zande mythology.

The term gender, as used by some linguists, refers to a noun-class system composed with 2, 3, or 4 classes, particularly if the classification is semantically based on a distinction between masculine and feminine. Genders are then considered a sub-class of noun classes. Not all linguists recognize a distinction between noun-classes and genders, however, and instead use either the term "gender" or "noun class" for both.

Some languages, such as Japanese, Chinese and the Tai languages, have elaborate systems of particles that go with nouns based on shape and function, but are free morphemes rather than affixes. Because the classes defined by these classifying words are not generally distinguished in other contexts, there are many linguists who take the view that they do not create noun classes.






</doc>
<doc id="22131" url="https://en.wikipedia.org/wiki?curid=22131" title="Natural gas">
Natural gas

Natural gas (also called fossil gas; sometimes just gas), is a naturally occurring hydrocarbon gas mixture consisting primarily of methane, but commonly including varying amounts of other higher alkanes, and sometimes a small percentage of carbon dioxide, nitrogen, hydrogen sulfide, or helium. It is formed when layers of decomposing plant and animal matter are exposed to intense heat and pressure under the surface of the Earth over millions of years. The energy that the plants originally obtained from the sun is stored in the form of chemical bonds in the gas.

Natural gas is a non-renewable hydrocarbon used as a source of energy for heating, cooking, and electricity generation. It is also used as a fuel for vehicles and as a chemical feedstock in the manufacture of plastics and other commercially important organic chemicals.

Although not as damaging as coal natural gas is a major cause of climate change; it is a greenhouse gas itself, and creates carbon dioxide during oxidation. Natural gas can be used in place of coal, for example, to generate electricity, which may lower net carbon dioxide emissions in absence of carbon capture.

Natural gas is found in deep underground rock formations or associated with other hydrocarbon reservoirs in coal beds and as methane clathrates. Petroleum is another resource and fossil fuel found close to and with natural gas. Most natural gas was created over time by two mechanisms: biogenic and thermogenic. Biogenic gas is created by methanogenic organisms in marshes, bogs, landfills, and shallow sediments. Deeper in the earth, at greater temperature and pressure, thermogenic gas is created from buried organic material.

In petroleum production, gas is sometimes burned as flare gas. Before natural gas can be used as a fuel, most, but not all, must be processed to remove impurities, including water, to meet the specifications of marketable natural gas. The by-products of this processing include ethane, propane, butanes, pentanes, and higher molecular weight hydrocarbons, hydrogen sulfide (which may be converted into pure sulfur), carbon dioxide, water vapor, and sometimes helium and nitrogen.

Natural gas is sometimes informally referred to simply as "gas", especially when it is being compared to other energy sources, such as oil or coal. However, it is not to be confused with gasoline, which is often shortened in colloquial usage to "gas", especially in North America.

Natural gas was discovered accidentally in ancient China, as it resulted from the drilling for brines. Natural gas was first used by the Chinese in about 500 BC (possibly even 1000 BC). They discovered a way to transport gas seeping from the ground in crude pipelines of bamboo to where it was used to boil salt water to extract the salt, in the Ziliujing District of Sichuan.

The discovery and identification of natural gas in the Americas happened in 1626. In 1821, William Hart successfully dug the first natural gas well at Fredonia, New York, United States, which led to the formation of the Fredonia Gas Light Company. The city of Philadelphia created the first municipally owned natural gas distribution venture in 1836. By 2009, 66 000 km³ (or 8%) had been used out of the total 850 000 km³ of estimated remaining recoverable reserves of natural gas. Based on an estimated 2015 world consumption rate of about 3400 km³ of gas per year, the total estimated remaining economically recoverable reserves of natural gas would last 250 years at current consumption rates. An annual increase in usage of 2–3% could result in currently recoverable reserves lasting significantly less, perhaps as few as 80 to 100 years.

In the 19th century, natural gas was primarily obtained as a by-product of producing oil. The small, light gas carbon chains came out of solution as the extracted fluids underwent pressure reduction from the reservoir to the surface, similar to uncapping a soft drink bottle where the carbon dioxide effervesces. The gas was often viewed as a by-product, a hazard, and a disposal problem in active oil fields. The large volumes produced could not be utilized until relatively expensive pipeline and storage facilities were constructed to deliver the gas to consumer markets.

Until the early part of the 20th century, most natural gas associated with oil was either simply released or burned off at oil fields. Gas venting and production flaring are still practised in modern times, but efforts are ongoing around the world to retire them, and to replace them with other commercially viable and useful alternatives. Unwanted gas (or stranded gas without a market) is often returned to the reservoir with 'injection' wells while awaiting a possible future market or to re-pressurize the formation, which can enhance oil extraction rates from other wells. In regions with a high natural gas demand (such as the US), pipelines are constructed when it is economically feasible to transport gas from a wellsite to an end consumer.

In addition to transporting gas via pipelines for use in power generation, other end uses for natural gas include export as liquefied natural gas (LNG) or conversion of natural gas into other liquid products via gas to liquids (GTL) technologies. GTL technologies can convert natural gas into liquids products such as gasoline, diesel or jet fuel. A variety of GTL technologies have been developed, including Fischer–Tropsch (F–T), methanol to gasoline (MTG) and syngas to gasoline plus (STG+). F–T produces a synthetic crude that can be further refined into finished products, while MTG can produce synthetic gasoline from natural gas. STG+ can produce drop-in gasoline, diesel, jet fuel and aromatic chemicals directly from natural gas via a single-loop process. In 2011, Royal Dutch Shell's per day F–T plant went into operation in Qatar.

Natural gas can be "associated" (found in oil fields), or "non-associated" (isolated in natural gas fields), and is also found in coal beds (as coalbed methane). It sometimes contains a significant amount of ethane, propane, butane, and pentane—heavier hydrocarbons removed for commercial use prior to the methane being sold as a consumer fuel or chemical plant feedstock. Non-hydrocarbons such as carbon dioxide, nitrogen, helium (rarely), and hydrogen sulfide must also be removed before the natural gas can be transported.

Natural gas extracted from oil wells is called casinghead gas (whether or not truly produced up the annulus and through a casinghead outlet) or associated gas. The natural gas industry is extracting an increasing quantity of gas from challenging resource types: sour gas, tight gas, shale gas, and coalbed methane.

There is some disagreement on which country has the largest proven gas reserves. Sources that consider that Russia has by far the largest proven reserves include the US CIA (47 600 km³), the US Energy Information Administration (47 800 km³), and OPEC (48 700 km³). However, BP credits Russia with only 32 900 km³, which would place it in second place, slightly behind Iran (33 100 to 33 800 km³, depending on the source). With Gazprom, Russia is frequently the world's largest natural gas extractor. Major proven resources (in cubic kilometers) are world 187 300 (2013), Iran 33 600 (2013), Russia 32 900 (2013), Qatar 25 100 (2013), Turkmenistan 17 500 (2013) and the United States 8500 (2013).
It is estimated that there are about 900 000 km³ of "unconventional" gas such as shale gas, of which 180 000 km³ may be recoverable. In turn, many studies from MIT, Black & Veatch and the DOE predict that natural gas will account for a larger portion of electricity generation and heat in the future.

The world's largest gas field is the offshore South Pars / North Dome Gas-Condensate field, shared between Iran and Qatar. It is estimated to have of natural gas and of natural gas condensates.

Because natural gas is not a pure product, as the reservoir pressure drops when non-associated gas is extracted from a field under supercritical (pressure/temperature) conditions, the higher molecular weight components may partially condense upon isothermic depressurizing—an effect called retrograde condensation. The liquid thus formed may get trapped as the pores of the gas reservoir get depleted. One method to deal with this problem is to re-inject dried gas free of condensate to maintain the underground pressure and to allow re-evaporation and extraction of condensates. More frequently, the liquid condenses at the surface, and one of the tasks of the gas plant is to collect this condensate. The resulting liquid is called natural gas liquid (NGL) and has commercial value.

Shale gas is natural gas produced from shale. Because shale has matrix permeability too low to allow gas to flow in economical quantities, shale gas wells depend on fractures to allow the gas to flow. Early shale gas wells depended on natural fractures through which gas flowed; almost all shale gas wells today require fractures artificially created by hydraulic fracturing. Since 2000, shale gas has become a major source of natural gas in the United States and Canada. Because of increased shale gas production the United States was in 2014 the number one natural gas producer in the world. Following the increased production in the United States, shale gas exploration is beginning in countries such as Poland, China, and South Africa.

Town gas is a flammable gaseous fuel made by the destructive distillation of coal. It contains a variety of calorific gases including hydrogen, carbon monoxide, methane, and other volatile hydrocarbons, together with small quantities of non-calorific gases such as carbon dioxide and nitrogen, and is used in a similar way to natural gas. This is a historical technology and is not usually economically competitive with other sources of fuel gas today.

Most town "gashouses" located in the eastern US in the late 19th and early 20th centuries were simple by-product coke ovens that heated bituminous coal in air-tight chambers. The gas driven off from the coal was collected and distributed through networks of pipes to residences and other buildings where it was used for cooking and lighting. (Gas heating did not come into widespread use until the last half of the 20th century.) The coal tar (or asphalt) that collected in the bottoms of the gashouse ovens was often used for roofing and other waterproofing purposes, and when mixed with sand and gravel was used for paving streets.

Methanogenic "Archaea" are responsible for almost all biological sources of methane, though methylphosphonate-degrading "Bacteria" produce an as-yet not fully quantified fraction of biogenic methane, particularly in the oceans. Some live in symbiotic relationships with other life forms, including termites, ruminants, and cultivated crops. Other sources of methane, the principal component of natural gas, include landfill gas, biogas, and methane hydrate. When methane-rich gases are produced by the anaerobic decay of organic matter (biomass), these are referred to as biogas (or natural biogas). Sources of biogas include swamps, marshes, and landfills, as well as agricultural waste materials such as sewage sludge and manure by way of anaerobic digesters, in addition to enteric fermentation, particularly in cattle. Landfill gas is created by decomposition of waste in landfill sites. Excluding water vapor, about half of landfill gas is methane and most of the rest is carbon dioxide, with small amounts of nitrogen, oxygen, and hydrogen, and variable trace amounts of hydrogen sulfide and siloxanes. If the gas is not removed, the pressure may get so high that it works its way to the surface, causing damage to the landfill structure, unpleasant odor, vegetation die-off, and an explosion hazard. The gas can be vented to the atmosphere, flared or burned to produce electricity or heat. Biogas can also be produced by separating organic materials from waste that otherwise goes to landfills. This method is more efficient than just capturing the landfill gas it produces. Anaerobic lagoons produce biogas from manure, while biogas reactors can be used for manure or plant parts. Like landfill gas, biogas is mostly methane and carbon dioxide, with small amounts of nitrogen, oxygen and hydrogen. However, with the exception of pesticides, there are usually lower levels of contaminants.

Landfill gas cannot be distributed through utility natural gas pipelines unless it is cleaned up to less than 3% , and a few parts per million , because and corrode the pipelines. The presence of will lower the energy level of the gas below requirements for the pipeline. Siloxanes in the gas will form deposits in gas burners and need to be removed prior to entry into any gas distribution or transmission system. Consequently, it may be more economical to burn the gas on site or within a short distance of the landfill using a dedicated pipeline. Water vapor is often removed, even if the gas is burned on site. If low temperatures condense water out of the gas, siloxanes can be lowered as well because they tend to condense out with the water vapor. Other non-methane components may also be removed to meet emission standards, to prevent fouling of the equipment or for environmental considerations. Co-firing landfill gas with natural gas improves combustion, which lowers emissions.

Biogas, and especially landfill gas, are already used in some areas, but their use could be greatly expanded. Systems have been established for use in parts of Hertfordshire, UK and Lyon in France. Using materials that would otherwise generate no income, or even cost money to get rid of, improves the profitability and energy balance of biogas production. Gas generated in sewage treatment plants is commonly used to generate electricity. For example, the Hyperion sewage plant in Los Angeles burns of gas per day to generate power New York City utilizes gas to run equipment in the sewage plants, to generate electricity, and in boilers. Using sewage gas to make electricity is not limited to large cities. The city of Bakersfield, California, uses cogeneration at its sewer plants. California has 242 sewage wastewater treatment plants, 74 of which have installed anaerobic digesters. The total biopower generation from the 74 plants is about 66 MW.

Huge quantities of natural gas (primarily methane) exist in the form of hydrates under sediment on offshore continental shelves and on land in arctic regions that experience permafrost, such as those in Siberia. Hydrates require a combination of high pressure and low temperature to form.

In 2010, the cost of extracting natural gas from crystallized natural gas was estimated to be as much as twice the cost of extracting natural gas from conventional sources, and even higher from offshore deposits.

In 2013, Japan Oil, Gas and Metals National Corporation (JOGMEC) announced that they had recovered commercially relevant quantities of natural gas from methane hydrate.

The image below is a schematic block flow diagram of a typical natural gas processing plant. It shows the various unit processes used to convert raw natural gas into sales gas pipelined to the end user markets.

The block flow diagram also shows how processing of the raw natural gas yields byproduct sulfur, byproduct ethane, and natural gas liquids (NGL) propane, butanes and natural gasoline (denoted as pentanes +).

As of 2018, natural gas production in the US has peaked twice, with current levels exceeding both previous peaks. It reached 24.1 Trillion cubic feet per year in 1973, followed by a decline, and reached 24.5 trillion cubic feet in 2001. After a brief drop, withdrawals have been increasing nearly every year since 2006, with 2017 production at 33.4 Trillion cubic feet.

Because of its low density, it is not easy to store natural gas or to transport it by vehicle. Natural gas pipelines are impractical across oceans, since the gas needs to be cooled down and compressed, as the friction in the pipeline causes the gas to heat up. Many existing pipelines in America are close to reaching their capacity, prompting some politicians representing northern states to speak of potential shortages. The large trade cost implies that natural gas markets are globally much less integrated, causing significant price differences across countries. In Western Europe, the gas pipeline network is already dense. New pipelines are planned or under construction in Eastern Europe and between gas fields in Russia, Near East and Northern Africa and Western Europe.

Whenever gas is bought or sold at custody transfer points, rules and agreements are made regarding the gas quality. These may include the maximum allowable concentration of , and . Usually sales quality gas that has been treated to remove contamination is traded on a "dry gas" basis and is required to be commercially free from objectionable odours, materials, and dust or other solid or liquid matter, waxes, gums and gum forming constituents, which might damage or adversely affect operation of equipment downstream of the custody transfer point.

LNG carriers transport liquefied natural gas (LNG) across oceans, while tank trucks can carry liquefied or compressed natural gas (CNG) over shorter distances. Sea transport using CNG carrier ships that are now under development may be competitive with LNG transport in specific conditions.

Gas is turned into liquid at a liquefaction plant, and is returned to gas form at regasification plant at the terminal. Shipborne regasification equipment is also used. LNG is the preferred form for long distance, high volume transportation of natural gas, whereas pipeline is preferred for transport for distances up to over land and approximately half that distance offshore.

CNG is transported at high pressure, typically above . Compressors and decompression equipment are less capital intensive and may be economical in smaller unit sizes than liquefaction/regasification plants. Natural gas trucks and carriers may transport natural gas directly to end-users, or to distribution points such as pipelines.

In the past, the natural gas which was recovered in the course of recovering petroleum could not be profitably sold, and was simply burned at the oil field in a process known as flaring. Flaring is now illegal in many countries. Additionally, higher demand in the last 20–30 years has made production of gas associated with oil economically viable. As a further option, the gas is now sometimes re-injected into the formation for enhanced oil recovery by pressure maintenance as well as miscible or immiscible flooding. Conservation, re-injection, or flaring of natural gas associated with oil is primarily dependent on proximity to markets (pipelines), and regulatory restrictions.

Natural gas can be indirectly exported through the absorption in other physical output. A recent study suggests that the expansion of shale gas production in the US has caused prices to drop relative to other countries. This has caused a boom in energy intensive manufacturing sector exports, whereby the average dollar unit of US manufacturing exports has almost tripled its energy content between 1996 and 2012.

A "master gas system" was invented in Saudi Arabia in the late 1970s, ending any necessity for flaring. Satellite observation, however, shows that flaring and venting are still practiced in some gas-extracting countries.

Natural gas is used to generate electricity and heat for desalination. Similarly, some landfills that also discharge methane gases have been set up to capture the methane and generate electricity.

Natural gas is often stored underground inside depleted gas reservoirs from previous gas wells, salt domes, or in tanks as liquefied natural gas. The gas is injected in a time of low demand and extracted when demand picks up. Storage nearby end users helps to meet volatile demands, but such storage may not always be practicable.

With 15 countries accounting for 84% of the worldwide extraction, access to natural gas has become an important issue in international politics, and countries vie for control of pipelines. In the first decade of the 21st century, Gazprom, the state-owned energy company in Russia, engaged in disputes with Ukraine and Belarus over the price of natural gas, which have created concerns that gas deliveries to parts of Europe could be cut off for political reasons. The United States is preparing to export natural gas.

Floating liquefied natural gas (FLNG) is an innovative technology designed to enable the development of offshore gas resources that would otherwise remain untapped due to environmental or economic factors which currently make them impractical to develop via a land-based LNG operation. FLNG technology also provides a number of environmental and economic advantages:

Many gas and oil companies are considering the economic and environmental benefits of floating liquefied natural gas (FLNG). There are currently projects underway to construct five FLNG facilities. Petronas is close to completion on their FLNG-1 at Daewoo Shipbuilding and Marine Engineering and are underway on their FLNG-2 project at Samsung Heavy Industries. Shell Prelude is due to start production 2017. The Browse LNG project will commence FEED in 2019.

Natural gas is primarily used in the northern hemisphere. North America and Europe are major consumers.

Often well head gases require removal of various hydrocarbon molecules contained within the gas. Some of these gases include heptane, pentane, propane and other hydrocarbons with molecular weights above methane (). The natural gas transmission lines extend to the natural gas processing plant or unit which removes the higher molecular weighted hydrocarbons to produce natural gas with energy content between . The processed natural gas may then be used for residential, commercial and industrial uses.

Natural gas flowing in the distribution lines is called mid-stream natural gas and is often used to power engines which rotate compressors. These compressors are required in the transmission line to pressurize and repressurize the mid-stream natural gas as the gas travels. Typically, natural gas powered engines require natural gas to operate at the rotational name plate specifications. Several methods are used to remove these higher molecular weighted gases for use by the natural gas engine. A few technologies are as follows:

Natural gas is a major source of electricity generation through the use of cogeneration, gas turbines and steam turbines. Natural gas is also well suited for a combined use in association with renewable energy sources such as wind or solar and for alimenting peak-load power stations functioning in tandem with hydroelectric plants. Most grid peaking power plants and some off-grid engine-generators use natural gas. Particularly high efficiencies can be achieved through combining gas turbines with a steam turbine in combined cycle mode. Natural gas burns more cleanly than other fuels, such as oil and coal. Because burning natural gas produces both water and carbon dioxide, it produces less carbon dioxide per unit of energy released than coal, which produces mostly carbon dioxide. Burning natural gas produces only about half the carbon dioxide per kilowatt-hour (kWh) that coal does. For transportation, burning natural gas produces about 30% less carbon dioxide than burning petroleum. The US Energy Information Administration reports the following emissions in million metric tons of carbon dioxide in the world for 2012:

Coal-fired electric power generation emits around of carbon dioxide for every megawatt-hour (MWh) generated, which is almost double the carbon dioxide released by natural gas-fired generation. Because of this higher carbon efficiency of natural gas generation, as the fuel mix in the United States has changed to reduce coal and increase natural gas generation, carbon dioxide emissions have unexpectedly fallen. Those measured in the first quarter of 2012 were the lowest of any recorded for the first quarter of any year since 1992.

Combined cycle power generation using natural gas is currently the cleanest available source of power using hydrocarbon fuels, and this technology is widely and increasingly used as natural gas can be obtained at increasingly reasonable costs. Fuel cell technology may eventually provide cleaner options for converting natural gas into electricity, but as yet it is not price-competitive. Locally produced electricity and heat using natural gas powered Combined Heat and Power plant (CHP or Cogeneration plant) is considered energy efficient and a rapid way to cut carbon emissions.

Natural gas generated power has increased from 740 TWh in 1973 to 5140 TWh in 2014, generating 22% of the worlds total electricity. Approximately half as much as generated with coal. Efforts around the world to reduce the use of coal has led some regions to switch to natural gas.

Natural gas dispensed in a residential setting can generate temperatures in excess of making it a powerful domestic cooking and heating fuel. In much of the developed world it is supplied through pipes to homes, where it is used for many purposes including ranges and ovens, gas-heated clothes dryers, heating/cooling, and central heating. Heaters in homes and other buildings may include boilers, furnaces, and water heaters. Both North America and Europe are major consumers of natural gas.

Domestic appliances, furnaces, and boilers use low pressure, usually 6 to 7 inches of water (6" to 7" WC), which is about 0.25 psig. The pressures in the supply lines vary, either utilization pressure (UP, the aforementioned 6" to 7" WC) or elevated pressure (EP), which may be anywhere from 1 psig to 120 psig. Systems using EP have a regulator at the service entrance to step down the pressure to UP.

In the US compressed natural gas (CNG) is available in some rural areas as an alternative to less expensive and more abundant LPG (liquefied petroleum gas), the dominant source of rural gas. It is used in homes lacking direct connections to public utility provided gas, or to fuel portable grills. Natural gas is also supplied by independent natural gas suppliers through Natural Gas Choice programs throughout the United States.

CNG is a cleaner and also cheaper alternative to other automobile fuels such as gasoline (petrol). By the end of 2014 there were over 20 million natural gas vehicles worldwide, led by Iran (3.5 million), China (3.3 million), Pakistan (2.8 million), Argentina (2.5 million), India (1.8 million), and Brazil (1.8 million). The energy efficiency is generally equal to that of gasoline engines, but lower compared with modern diesel engines. Gasoline/petrol vehicles converted to run on natural gas suffer because of the low compression ratio of their engines, resulting in a cropping of delivered power while running on natural gas (10–15%). CNG-specific engines, however, use a higher compression ratio due to this fuel's higher octane number of 120–130.

Besides use in road vehicles, CNG can also be used in aircraft. Compressed natural gas has been used in some aircraft like the Aviat Aircraft Husky 200 CNG and the Chromarat VX-1 KittyHawk

LNG is also being used in aircraft. Russian aircraft manufacturer Tupolev for instance is running a development program to produce LNG- and hydrogen-powered aircraft. The program has been running since the mid-1970s, and seeks to develop LNG and hydrogen variants of the Tu-204 and Tu-334 passenger aircraft, and also the Tu-330 cargo aircraft. Depending on the current market price for jet fuel and LNG, fuel for an LNG-powered aircraft could cost 5,000 rubles (US$100) less per tonne, roughly 60%, with considerable reductions to carbon monoxide, hydrocarbon and nitrogen oxide emissions.

The advantages of liquid methane as a jet engine fuel are that it has more specific energy than the standard kerosene mixes do and that its low temperature can help cool the air which the engine compresses for greater volumetric efficiency, in effect replacing an intercooler. Alternatively, it can be used to lower the temperature of the exhaust.

Natural gas is a major feedstock for the production of ammonia, via the Haber process, for use in fertilizer production.

Natural gas can be used to produce hydrogen, with one common method being the hydrogen reformer. Hydrogen has many applications: it is a primary feedstock for the chemical industry, a hydrogenating agent, an important commodity for oil refineries, and the fuel source in hydrogen vehicles.

Protein rich animal and fish feed is produced by feeding natural gas to Methylococcus capsulatus bacteria on commercial scale.

Natural gas is also used in the manufacture of fabrics, glass, steel, plastics, paint, synthetic oil, and other products. The first step in the valorization of natural gas components is usually the of the alkane into olefin. The oxidative dehydrogenation of ethane leads to ethylene which can be converted forther to ethylene epoxide, ethylene glycol, acetaldehyde or other olefins. Propane can be converted to propylene or can be oxidized to acrylic acid and acrylnitrile.

Human activity is responsible for about 60% of all methane emissions and for most of the resulting increase in atmospheric methane. Natural gas is intentionally released or is otherwise known to leak during the extraction, storage, transportation, and distribution of fossil fuels. Globally, this accounts for an estimated 33% of anthropogenic emissions in year 2020. The decomposition of municipal solid waste (a source of landfill gas) and wastewater account for an additional 18% of such emissions. These estimates include substantial uncertainties which should be reduced in the near future with improved satellite measurements, such as those planned for MethaneSAT.

After release to the atmosphere, methane is removed by gradual oxidation to carbon dioxide and water by hydroxyl radicals () formed in the troposphere or stratosphere, giving the overall chemical reaction + 2 → + 2. While the lifetime of atmospheric methane is relatively short when compared to carbon dioxide, with a half-life of about 7 years, it is more efficient at trapping heat in the atmosphere, so that a given quantity of methane has 84 times the global-warming potential of carbon dioxide over a 20-year period and 28 times over a 100-year period. Natural gas is thus a potent greenhouse gas due to the strong radiative forcing of methane in the short term, and the continuing effects of carbon dioxide in the longer term.

Targeted efforts to reduce warming quickly by reducing anthropogenic methane emissions is a climate change mitigation strategy supported by the Global Methane Initiative.

When refined and burned, natural gas can produce 25–30% less carbon dioxide per joule delivered than oil, and 40–45% less than coal. It can also produce potentially fewer toxic pollutants than other hydrocarbon fuels.

In absolute terms, natural gas use comprises nearly one quarter of human carbon emissions, and this contribution is growing rapidly. Globally, natural gas use emitted about 6.7 billion tons of during year 2017, while coal and oil use emitted 11.4 and 14.5 billion tons, respectively. According to an updated version of the Special Report on Emissions Scenario by 2030, natural gas would be the source of 11 billion tons a year because demand is increasing 1.9% per year.

The continued financing and construction of new gas pipelines indicates that huge emissions of fossil greenhouse gases could be locked-in for 40 to 50 years into the future. In the U.S. state of Texas alone, five new long-distance gas pipelines have been under construction, with the first entering service in Q3 2019, and the others scheduled to come online during 2020-2022.

To reduce its greenhouse emissions, the government of the Netherlands is subsidizing a transition away from natural gas for all homes in the country by 2050. In Amsterdam, no new residential gas accounts are allowed as of July 1, 2018, and all homes in the city are expected to be converted by 2040 to use the excess heat from adjacent industrial buildings and operations.

Natural gas produces far lower amounts of sulfur dioxide and nitrogen oxides than other fossil fuels. The pollutants due to natural gas combustion are listed below:
Natural gas extraction also produces radioactive isotopes of polonium (Po-210), lead (Pb-210) and radon (Rn-220). Radon is a gas with initial activity from 5 to 200,000 becquerels per cubic meter of gas. It decays rapidly to Pb-210 which can build up as a thin film in gas extraction equipment.

The natural gas extraction workforce face unique health and safety challenges and is recognized by the National Institute for Occupational Safety and Health (NIOSH) as a priority industry sector in the National Occupational Research Agenda (NORA) to identify and provide intervention strategies regarding occupational health and safety issues.

Some gas fields yield sour gas containing hydrogen sulfide (), a toxic compound when inhaled. Amine gas treating, an industrial scale process which removes acidic gaseous components, is often used to remove hydrogen sulfide from natural gas.

Extraction of natural gas (or oil) leads to decrease in pressure in the reservoir. Such decrease in pressure in turn may result in subsidence, sinking of the ground above. Subsidence may affect ecosystems, waterways, sewer and water supply systems, foundations, and so on.

Releasing natural gas from subsurface porous rock formations may be accomplished by a process called hydraulic fracturing or "fracking". It is estimated that hydraulic fracturing will eventually account for nearly 70% of natural gas development in North America. Since the first commercial hydraulic fracturing operation in 1949, approximately one million wells have been hydraulically fractured in the United States. The production of natural gas from hydraulically fractured wells has utilized the technological developments of directional and horizontal drilling, which improved access to natural gas in tight rock formations. Strong growth in the production of unconventional gas from hydraulically fractured wells occurred between 2000–2012.

In hydraulic fracturing, well operators force water mixed with a variety of chemicals through the wellbore casing into the rock. The high pressure water breaks up or "fracks" the rock, which releases gas from the rock formation. Sand and other particles are added to the water as a proppant to keep the fractures in the rock open, thus enabling the gas to flow into the casing and then to the surface. Chemicals are added to the fluid to perform such functions as reducing friction and inhibiting corrosion. After the "frack," oil or gas is extracted and 30–70% of the frack fluid, i.e. the mixture of water, chemicals, sand, etc., flows back to the surface. Many gas-bearing formations also contain water, which will flow up the wellbore to the surface along with the gas, in both hydraulically fractured and non-hydraulically fractured wells. This produced water often has a high content of salt and other dissolved minerals that occur in the formation.

The volume of water used to hydraulically fracture wells varies according to the hydraulic fracturing technique. In the United States, the average volume of water used per hydraulic fracture has been reported as nearly 7,375 gallons for vertical oil and gas wells prior to 1953, nearly 197,000 gallons for vertical oil and gas wells between 2000–2010, and nearly 3 million gallons for horizontal gas wells between 2000–2010.

Determining which fracking technique is appropriate for well productivity depends largely on the properties of the reservoir rock from which to extract oil or gas. If the rock is characterized by low-permeability — which refers to its ability to let substances, i.e. gas, pass through it, then the rock may be considered a source of tight gas. Fracking for shale gas, which is currently also known as a source of unconventional gas, involves drilling a borehole vertically until it reaches a lateral shale rock formation, at which point the drill turns to follow the rock for hundreds or thousands of feet horizontally. In contrast, conventional oil and gas sources are characterized by higher rock permeability, which naturally enables the flow of oil or gas into the wellbore with less intensive hydraulic fracturing techniques than the production of tight gas has required. The decades in development of drilling technology for conventional and unconventional oil and gas production has not only improved access to natural gas in low-permeability reservoir rocks, but also posed significant adverse impacts on environmental and public health.

The US EPA has acknowledged that toxic, carcinogenic chemicals, i.e. benzene and ethylbenzene, have been used as gelling agents in water and chemical mixtures for high volume horizontal fracturing (HVHF). Following the hydraulic fracture in HVHF, the water, chemicals, and frack fluid that return to the well's surface, called flowback or produced water, may contain radioactive materials, heavy metals, natural salts, and hydrocarbons which exist naturally in shale rock formations. Fracking chemicals, radioactive materials, heavy metals, and salts that are removed from the HVHF well by well operators are so difficult to remove from the water they're mixed with, and would so heavily pollute the water cycle, that most of the flowback is either recycled into other fracking operations or injected into deep underground wells, eliminating the water that HVHF required from the hydrologic cycle.

Natural gas in its native state is colorless and almost odorless. In order to assist consumers in detecting leaks, an odorizer with a scent similar to rotten eggs, tert-Butylthiol (t-butyl mercaptan), is added. Sometimes a related compound, thiophane, may be used in the mixture. Situations in which an odorant that is added to natural gas can be detected by analytical instrumentation, but cannot be properly detected by an observer with a normal sense of smell, have occurred in the natural gas industry. This is caused by odor masking, when one odorant overpowers the sensation of another. As of 2011, the industry is conducting research on the causes of odor masking.

Explosions caused by natural gas leaks occur a few times each year. Individual homes, small businesses and other structures are most frequently affected when an internal leak builds up gas inside the structure. Frequently, the blast is powerful enough to significantly damage a building but leave it standing. In these cases, the people inside tend to have minor to moderate injuries. Occasionally, the gas can collect in high enough quantities to cause a deadly explosion, disintegrating one or more buildings in the process. Many building codes now forbid the installation of gas pipes inside cavity walls and/or below floor boards to mitigate against this risk.
The gas usually dissipates readily outdoors, but can sometimes collect in dangerous quantities if flow rates are high enough. From 1994 through 2013, the United States had 745 serious incidents with gas distribution, causing 278 fatalities and 1059 injuries, with $110,658,083 in property damage. However, considering the tens of millions of structures that use the fuel, the individual risk of using natural gas is very low.

Natural gas heating systems may cause carbon monoxide poisoning if unvented or poorly vented. In 2011, natural gas furnaces, space heaters, water heaters and stoves were blamed for 11 carbon monoxide deaths in the US. Another 22 deaths were attributed to appliances running on liquified petroleum gas, and 17 deaths on gas of unspecified type. Improvements in natural gas furnace designs have greatly reduced CO poisoning concerns. Detectors are also available that warn of carbon monoxide and/or explosive gas (methane, propane, etc.).

Quantities of natural gas are measured in normal cubic meters (cubic meter of gas at "normal" temperature and pressure ) or standard cubic feet (cubic foot of gas at "standard" temperature and pressure ), . The gross heat of combustion of commercial quality natural gas is around , but this can vary by several percent. This is about (assuming a density of , an approximate value).

Gas prices for end users vary greatly across the EU. A single European energy market, one of the key objectives of the EU, should level the prices of gas in all EU member states. Moreover, it would help to resolve supply and global warming issues, as well as strengthen relations with other Mediterranean countries and foster investments in the region.

In US units, of natural gas produces around . The actual heating value when the water formed does not condense is the net heat of combustion and can be as much as 10% less.

In the United States, retail sales are often in units of therms (th); 1 therm = 100,000 BTU. Gas sales to domestic consumers are often in units of 100 standard cubic feet (scf). Gas meters measure the volume of gas used, and this is converted to therms by multiplying the volume by the energy content of the gas used during that period, which varies slightly over time. The typical annual consumption of a single family residence is 1,000 therms or one Residential Customer Equivalent (RCE). Wholesale transactions are generally done in decatherms (Dth), thousand decatherms (MDth), or million decatherms (MMDth). A million decatherms is a trillion BTU, roughly a billion cubic feet of natural gas.

The price of natural gas varies greatly depending on location and type of consumer. In 2007, a price of $7 per 1000 cubic feet () was typical in the United States. The typical caloric value of natural gas is roughly 1,000 BTU per cubic foot, depending on gas composition. This corresponds to around $7 per million BTU or around $7 per gigajoule (GJ). In April 2008, the wholesale price was $10 per 1000 cubic feet ($10/million BTU). The residential price varies from 50% to 300% more than the wholesale price. At the end of 2007, this was $12–$16 per 1000 cubic feet (). Natural gas in the United States is traded as a futures contract on the New York Mercantile Exchange. Each contract is for 10,000 million BTU or . Thus, if the price of gas is $10/million BTU on the NYMEX, the contract is worth $100,000.

Canada uses metric measure for internal trade of petrochemical products. Consequently, natural gas is sold by the gigajoule (GJ), cubic meter (m) or thousand cubic meters (E3m3). Distribution infrastructure and meters almost always meter volume (cubic foot or cubic meter). Some jurisdictions, such as Saskatchewan, sell gas by volume only. Other jurisdictions, such as Alberta, gas is sold by the energy content (GJ). In these areas, almost all meters for residential and small commercial customers measure volume (m or ft), and billing statements include a multiplier to convert the volume to energy content of the local gas supply.

A gigajoule (GJ) is a measure approximately equal to half a barrel (250 lbs) of oil, or 1 million BTUs, or of gas. The energy content of gas supply in Canada can vary from depending on gas supply and processing between the wellhead and the customer.

Outside of the European Union, the U.S., and Canada, natural gas is sold in gigajoule retail units. LNG (liquefied natural gas) and LPG (liquefied petroleum gas) are traded in metric tonnes (1,000 kg) or million BTU as spot deliveries. Long term natural gas distribution contracts are signed in cubic meters, and LNG contracts are in metric tonnes. The LNG and LPG is transported by specialized transport ships, as the gas is liquified at cryogenic temperatures. The specification of each LNG/LPG cargo will usually contain the energy content, but this information is in general not available to the public.

In the Russian Federation, Gazprom sold approximately of natural gas in 2008. In 2013 they produced of natural and associated gas. Gazprom supplied Europe with of gas in 2013.

In August 2015, possibly the largest natural gas discovery in history was made and notified by an Italian gas company ENI. The energy company indicated that it has unearthed a "supergiant" gas field in the Mediterranean Sea covering about . This was named the Zohr gas field and could hold a potential of natural gas. ENI said that the energy is about. The Zohr field was found in the deep waters off the northern coast of Egypt and ENI claims that it will be the largest ever in the Mediterranean and even the world.

Research conducted by the World Pensions Council (WPC) suggests that large US and Canadian pension funds and Asian and MENA area SWF investors have become particularly active in the fields of natural gas and natural gas infrastructure, a trend started in 2005 by the formation of Scotia Gas Networks in the UK by OMERS and Ontario Teachers' Pension Plan.

Natural gas may be stored by adsorbing it to the porous solids called sorbents. The optimal condition for methane storage is at room temperature and atmospheric pressure. Pressures up to 4 MPa (about 40 times atmospheric pressure) will yield greater storage capacity. The most common sorbent used for ANG is activated carbon (AC), primarily in three forms: Activated Carbon Fiber (ACF), Powdered Activated Carbon (PAC), activated carbon monolith.


General:



</doc>
